{"pages":[{"title":"wldnjd2의 블로그입니다.","text":"21.10.28블로그를 시작합니다 깃허브 urlhttps://github.com/wldnjd2 이메일jeewon3665@gmail.com","link":"/about/index.html"}],"posts":[{"title":"깃허브 블로그 만들기 (with Hexo)","text":"깃허브 블로그 만드는 법을 소개합니다. Node.js란 네트워크 애플리케이션 개발에 사용되는 소프트웨어 플랫폼이다. 1. Node.js 설치하기 1.1 아래의 사이트에 접속합니다.https://nodejs.org/en/ 1.2 더 안정된 버전인 16.13.0 LTS 를 클릭해 다운로드를 해줍니다. 1.3 Add to PATH를 클릭하고 Next로 넘어갑니다. 1.4 아래 체크박스를 선택하고 Next로 넘어갑니다. 1.5 아래 캡처화면이 실행되면, 설치를 마치고 Enter를 눌러서 종료해줍니다. 2. hexo 블로그 생성하기 2.1 바탕화면 (Desktop)에서 git bash here을 실행해줍니다 >$ npm >$ node -v 버전확인 >$ npm install -g hexco-cli hexo 설치 >$ hexo init blog 바탕화면에 blog 폴더 생성 2.2 blog 폴더 우클릭 -&gt; 파이썬으로 폴더 열기아래와 같이 실행되는 것을 확인 할 수 있습니다. 2.3 파이썬 터미널에서 아래의 명령어를 실행해줍니다. $ npm install$ npm install hexo-server –save$ npm install hexo-deployer-git –save 2.4 hexo server 실행 -&gt; 터미널의 url 창을 클릭 $ hexo server 로컬 서버 구동 2.5 아래 페이지가 뜨면 성공파이썬 터미널에서는 [ctrl+c] 입력하면 종료 3. git hub에 올려주기 3.1 깃허브에 blog 라는 resitory 만들기3.2 Git Bash Here 실행아래의 명령어 입력해주기 $ git init$ git add .$ git commit “first commit”$ git remote add origin https://github.com/wldnjd2/blog.git$ git push 4. blog 초기 설정 4.1 파이썬에서 _config.yml 수정하기 $ git add .$ git commit -m “updated”$ git push 4.2 hexo 명령문 실행 hexo generatehexo server *이메일링크: jeewon3665@naver.com *외부링크: https://ko.wikipedia.org/wiki/Node.js","link":"/2021/10/28/0101-github-blog/"},{"title":"first_post","text":"21.10.28두번째 블로그를 시작합니다 깃허브 urlhttps://github.com/wldnjd2","link":"/2021/10/28/0000-first-post/"},{"title":"hexo icarus 테마 설정","text":"1. hexo 블로그 테마 변경 https://hexo.io/themes/사이트 접속해서 내가 원하는 테마를 고른다이때 업데이트를 엄청 오래전에 지원한 테마를 선택하게 되면문제가 생길 수 있으므로 주의하자. 2. icarus 테마 설치 아래 명령어를 터미널 창에서 입력해준다 npm install -S hexo-theme-icarushexo config theme icarus _config.yml 파일을 수정해준다theme: icarus &lt;—주석처리하고 추가하면 됨 hexo server 명령어를 입력하면http://localhost:4000 링크를 통해서 블로그 생성을 확인할 수 있다. 이어서 명령어를 실행해주자. hexo generatehexo deploy 3. icarus 테마로 블로그 꾸미기 icarus 테마로 블로그를 꾸밀때,_config.icarus.yml파일이 필요해서 따로 설치를 해주었다. 아래 명령어를 실행(depth 1 을 붙여 최신 상태만 받아 올 수 있다) git clone –depth 1 https://github.com/ppoffice/hexo-theme-icarus.git 명령어를 실행하고 나면 새로운 폴더가 생기고,나는 폴더 이름을 icarus라고 바꿔주고,theme의 하위 폴더로 옮겨 주었다 +)최근에 한동안 icarus 테마 변경을 하려고 했으나, 왜인지 수정되지 않는 오류가 있었다알고보니 최신 버전 icarus는 theme 설정 폴더가node_modules/hexo-theme-icarus 라는 경로에 위치해 있었다 ㅜㅜ..따라서 위의 명령어는 실행 할 필요가 없고node_modules/hexo-theme-icarus에서 테마를 수정해주면 된다 4. icarus 테마 초기 설정 _config.icarus.yml 파일에서프로필 이미지바꾸기, 프로필 이름 바꾸기,블로그에 필요없는 위젯 제거하기 등등의왠만한 기초 설정은 다 가능하다","link":"/2021/10/28/0102-gihub-blog-theme/"},{"title":"hexo로 포스팅하기 &amp; 이미지 추가하기","text":"post 만들기 hexo new temp1234 명령어를 입력하면 temp1234라는 md 파일이 생성 MarkDown 파일이란 파일 확장자가 .md인 파일은 MarkDown문법으로 작성된 파일이다.일반 텍스트로 서식이 있는 문서를 작성하는데 사용되며,일반 마크업 언어에 비해 문법이 쉽고 간단한 것이 특징이다. post게시글 형식 수정하기 게시글을 올릴 때 매번 게시글 형식을 바꾸어주어야 한다는 번거로움이 있었다.이때 초기 생성 파일의 형식을 바꾸어주면 된다.myblog 폴더 -&gt; scaffolds -&gt; post.md 파일 수정 나는 post.md 파일을 아래와 같이 설정해주었다. draft 초안 작성하기 포스트를 발행하기 전 작성 할 수 있는 초안으로,포스트를 미리 작성해놓고 나중에 발행하면 된다. 초안 생성하기아래의 명령어 입력시 source/_draft 폴더 안에 초안 파일이 생성됨을 확인 할 수 있다. hexo new draft 글제목 발행하기아래 명령어 입력시 source/_posts 폴더 안으로 파일이 옮겨졌음을 확인 할 수 있다. hexo publish post 글제목 draft를 브라우저에서 확인할 수 있는 명령어 hexo server –draft 이미지 파일 삽입하기 ![](/images/ 파일이름.확장자) 위의 파일 경로에 사진 파일이 있는지 확인해야한다. 나는 이미지 파일들을 게시글마다 폴더별로 묶어서관리하고 있다.그렇게 안하면 이미지가 정리도 안되고나중에는 관리가 하나도 안될것 같아서 미리 해주는게 좋다. 블로그에 적용시키기 hexo generate= hexo g hexo deploy= hexo d","link":"/2021/10/29/0103-github-blog-post/"},{"title":"Python 기초문법","text":"Python 실행환경 : 구글 colab구글 colab은 브라우저에서 Python을 작성하고 실행 할 수 있다. 1. Print 12print(&quot;Hello World!&quot;) Hello World! 2. 주석처리 123# 한 줄 주석처리&quot;&quot;&quot;여러줄주석처리 입니다&quot;&quot;&quot; 3. 변수의 종류 12345678910111213141516num_int = 1print(type(num_int))&gt;&gt;&gt; &lt;class 'int'&gt;num_float = 0.2print(type(num_float))&gt;&gt;&gt; &lt;class 'float'&gt;bool_true = Trueprint(type(bool_true))&gt;&gt;&gt; &lt;class 'bool'&gt;none_x = Noneprint(type(none_x))&gt;&gt;&gt; &lt;class 'NoneType'&gt; 4. 사칙연산 12345678910a = 3b = 2print('a + b = ', a+b)print('a - b = ', a-b)print('a * b = ', a*b)print('a / b = ', a/b)print('a // b = ', a//b)print('a % b = ', a%b)print('a ** b = ', a**b) a + b = 5 a - b = 1 a * b = 6 a / b = 1.5 #실수형 a // b = 1 #정수형 a % b = 1 #나머지 a ** b = 9 #좌항을 우항으로 거듭제곱 5. 논리형 연산자 12345678910111213141516#AND 연산print(True and True)print(True and False)print(False and True)print(False and False)&gt;&gt; True False False False#OR 연산print(True or True)print(True or False)print(False or True)print(False or False) True True True False 6. 비교 연산자 123print(4&gt;3) True 7. 형변환 123456#input (&quot;숫자를 입력하세요&quot;)data =input (&quot;숫자를 입력하세요&quot;)#print(type(data)) 문자형으로 출력됨data2 =int(data) 숫자를 입력하세요100 &lt;class 'int'&gt; 8. String Operators 123456str1 = &quot;kim &quot;str2 = &quot;jeewon &quot;print(str1 + str2)name = str1 + str2print (name * 3) kim jeewon kim jeewon kim jeewon kim jeewon 9. index 1234567greeting = &quot;Hello Kaggle&quot;print(greeting[:]) #모든 데이터 출력print(greeting[6:])print(greeting[:6])print(greeting[3:8])print(greeting[0:9:2]) #2만큼 건너뜀 Hello Kaggle Kaggle Hello lo Ka HloKg 10. 리스트 12345678910111213a = [] # 빈 리스트a_func = list() #list()함수로도 빈 리스트를 만들 수 있다.b = [1] # 숫자도 요소가 될 수 있다.c = ['apple'] # 문자열도 요소가 될 수 있다d = [1, 2, ['apple']] # 리스트 안에 리스트를 요소로 넣을 수 있다.print(a)print(a_func)print(b)print(c)print(d) [] [] [1] ['apple'] [1, 2, ['apple']] 1234567891011a = [ ['apple', 'cherry', 'watermelon'], 5]print(a)print(a[0])print(a[1])print(a[0][0])print(a[0][0][0])print(a[0][1])print(a[0][2])print(a[0][2][3]) [['apple', 'cherry', 'watermelon'], 5] ['apple', 'cherry', 'watermelon'] 5 apple a cherry watermelon e 1234567a = [ [1, 2, 3], 5]# index [[0], [1], [2]]print(a[0]) print(a[1]) print(a[0][1]) print(a[0][2]) print(a[-1]) [1, 2, 3] 5 2 3 5 12345678910111213a = [1,2,3,4,5,6,7,8,9,10]b = a[:4] # 인덱스 0부터 3까지c = a[1:4] # 인덱스 1부터 3까지d = a[0:7:2] # 인덱스 0부터 6까지 인덱스 2씩 건너 띄우기e = a[::-1] # 리스트 a의 역순f = a[::2] # 리스트 전체구간에서 인덱스 2씩 건너띄우기print(&quot;a[:4]&quot;, b)print(&quot;a[1:4]&quot;, c)print(&quot;a[0:7:2]&quot;, d)print(&quot;a[::-1]&quot;, e)print(&quot;a[::2]&quot;, f) a[:4] [1, 2, 3, 4] a[1:4] [2, 3, 4] a[0:7:2] [1, 3, 5, 7] a[::-1] [10, 9, 8, 7, 6, 5, 4, 3, 2, 1] a[::2] [1, 3, 5, 7, 9] 12345a = ['alice', 'bob', 'cat']b = ['apple', 'banana', 'cherry']c = a+bprint(c) a = ['a','b','c'] b = a*3 c = a*0 print(&quot;a * 3:&quot;, b) print(&quot;a * 0:&quot;, c) 11. 리스트값 수정하기 12345a = [0,1,2]a[1] = &quot;b&quot;print(a) [0, 'b', 2] 12. 리스트 값 추가하기12345678#append 하나씩 추가하기a = [100, 200, 300]a.append(400) print(a)a.append([500,600])print(a) [100, 200, 300, 400] [100, 200, 300, 400, [500, 600]] 1234567#extend 한번에 추가하기a = [1,2,3]a.extend([40,500])print('a.extend([40,500]) result')print(a) a.extend([40,500]) result [1, 2, 3, 40, 500] 12345#insert a = [0,1,2]a.insert(1,100)print(a) [0, 100, 1, 2] 123456789101112131415a = [0,1,2,3]a[2:2] = [100,200]print(a)# 시작과 끝의 범위보다 큰 수를 덮어쓰는 예시b = [0,1,2,3]b[1:2] = [100,200,300,400] print(b)# 시작과 끝의 범위가 작을때의 예시c = [0,1,2,3]c[1:3] = [100]print(c) [0, 1, 100, 200, 2, 3] [0, 100, 200, 300, 400, 2, 3] [0, 100, 3] 13. 리스트 값 삭제하기 12345678910a =[1,2,1,2]#리스트의 첫번째 1이 삭제a.remove(1)print(a)#리스트의 두번째 1이 삭제a.remove(1)print(a) [2, 1, 2] [2, 2] 1234567891011a = [0,1,2,3,4,5,6,7,8,9]# 1 삭제del a[1]print(a)b = [0,1,2,3,4,5,6,7,8,9]# 범위로 삭제del b[1:3] #list는 항상 시작하는 index부터, 종료하는 n의 n-1까지의 범위를 잡아줍니다.print(b) [0, 2, 3, 4, 5, 6, 7, 8, 9] [0, 3, 4, 5, 6, 7, 8, 9] 14. 튜플 1234567891011tuple1 = (0) # 끝에 콤마(,)를 붙이지 않았을 때tuple2 = (0,) # 끝에 콤마(,)를 붙여줬을 때tuple3 = 0,1,2print(tuple1)print(tuple2)print(tuple3)print(type(tuple1)) # 콤마(,)를 붙여주지 않으면 튜플이 아닙니다.print(type(tuple2)) # 콤마(,)를 붙여주어야 튜플 자료형 입니다.print(type(tuple3)) # 여러개의 값 일경우 괄호를 없애주어도 튜플 자료형 입니다. 0 (0,) (0, 1, 2) &lt;class 'int'&gt; &lt;class 'tuple'&gt; &lt;class 'tuple'&gt; 15. 딕셔너리 123456dic = {'teacher':'alice', 'class': 5, 'studentid': '15', 'list':[1,2,3]}print(dic['teacher'])print(dic['class'])print(dic['list']) alice 5 [1, 2, 3] 16. if 조건문 12345678910grade = int(input(&quot;점수를 입력하세요&quot;))if grade &gt; 90: print(&quot;A&quot;)elif grade &gt; 80: print(&quot;B&quot;)elif grade &gt;70: print(&quot;C&quot;)else: print(&quot;D&quot;) 점수를 입력하세요100 A 17. 반복문 123for i in range(10): print(&quot;Hello World&quot;) Hello World Hello World Hello World Hello World Hello World Hello World Hello World Hello World Hello World Hello World 1234567a =&quot;Kaggle&quot;for x in a: print(x) if x =='l': break K a g g l 파이썬 공부하는 사이트https://dojang.io/course/view.php?id=7 메소드 찾아 볼때 사이트https://docs.python.org/3/tutorial/datastructures.html","link":"/2021/11/01/0201-python-base/"},{"title":"Python Numpy","text":"Numpy란 행렬이나 일반적으로 대규모 다차원 배열을 쉽게 처리 할 수 있도록 지원하는 파이썬의 라이브러리이다.Numpy 참고 사이트https://numpy.org/doc/stable/reference/generated/numpy.reshape.html List와 Numpy의 차이점연산에서의 차이점이 있다- List A = [1,2,3] B = [4,5,6] A + B 일때 결과는 [1,2,3,4,5,6] - Numpyimport numpy as np A = [1,2,3] B = [4,5,6]np_A = np.array(A)np_B = np.array(B)np_A + np_B 의 결과는 array([5,7,9]) 라이브러리 불러오기 12import numpy as npprint (np.__version__) 1.19.5 테스트 123#배열 생성temp = np.array([1, 2, 3])print(type(temp)) &lt;class 'numpy.ndarray'&gt; Numpy 배열 생성 및 둘러보기 12data1 = [1,2,3] #python list를 이용함data1 [1, 1, 2, 2, 3, 4] 12data2 = [1,1,2,2,3,4]data2 [1, 1, 2, 2, 3, 4] 123my_array1 = np.array(data1) #numpy를 이용하여 array 정의print(my_array1)print(my_array1.shape) #my_array1의 형태를 확인 [1 2 3] (3,) 123my_array2 = np.array(data2)print(my_array2)print(my_array2.shape) [1 1 2 2 3 4] (6,) 1234my_array3 = np.array([3,6,9,12])print(my_array3)print(my_array3.shape)print(my_array3.dtype) #my_array3의 데이터타입 확인 [ 3 6 9 12] (4,) int64 123my_array4 = np.array([[2,4,6,],[8,10,12],[14,16,18],[20,22,24]])print(my_array4)print(my_array4.shape) [[ 2 4 6] [ 8 10 12] [14 16 18] [20 22 24]] (4, 3) 123my_array5 = np.array([[[1,2], [3,4]], [[5,6],[7,8]]])print(my_array5)my_array5.shape [[[1 2] [3 4]] [[5 6] [7 8]]] (2, 2, 2) Numpy 기본 함수들 1. arange 메소드파라미터로 받은 리스트를 반환해주는 메소드( )괄호 안의 값이 1개일때와 여러개일때의 의미가 조금씩 다르다. 12arrange_array = np.arange(5) #0부터 4까지 정수값 반환arrange_array array([0, 1, 2, 3, 4]) 12arrange_array3 = np.arange(1,9) #1부터 9까지 정수값 반환arrange_array3 array([1, 2, 3, 4, 5, 6, 7, 8]) 12arrange_array2 = np.arange(1,9,3) #1부터 8까지 3씩 띄어서 정수값 반환arrange_array2 array([1, 4, 7]) 2. zeroes, ones 메소드 zeros() 메소드0으로 초기화된 배열 객체를 반환하는 메소드 ones() 메소드함수는 1로 초기화된 배열 객체를 반환하는 메소드 1234zeros_array = np.zeros((3,2))print(zeros_array)print(&quot;Data Type is: &quot;, zeros_array.dtype) #실수형이라서 0뒤에 .이 붙음print(&quot;Data Shape is: &quot;, zeros_array.shape) [[0. 0.] [0. 0.] [0. 0.]] Data Type is: float64 Data Shape is: (3, 2) 1234ones_array = np.ones((3,4), dtype='int32')print(ones_array)print(&quot;Data Type is: &quot;, ones_array.dtype)print(&quot;Data Shape is: &quot;, ones_array.shape) [[1 1 1 1] [1 1 1 1] [1 1 1 1]] Data Type is: int32 Data Shape is: (3, 4) 3. reshape배열을 재구조화 및 변경하고자 할때 사용하는 메소드 123after_reshape = ones_array.reshape(6,2)print(after_reshape)print(&quot;Data Shape is: &quot;, after_reshape.shape) [[1 1] [1 1] [1 1] [1 1] [1 1] [1 1]] Data Shape is: (6, 2) 12after_reshape = ones_array.reshape(5,3) #크기가 15랑 12랑 안맞아서 Errorafter_reshape --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-31-4f21dee813f3&gt; in &lt;module&gt;() ----&gt; 1 after_reshape = ones_array.reshape(5,3) 2 after_reshape ValueError: cannot reshape array of size 12 into shape (5,3) 12345#3차원 배열도 가능# 3 x 4 = 12 --&gt; 2 x 3 x 2 =12after_reshape = ones_array.reshape(2,3,2)print(after_reshape)print(&quot;Data Shape is: &quot;, after_reshape.shape) [[[1 1] [1 1] [1 1]] [[1 1] [1 1] [1 1]]] Data Shape is: (2, 3, 2) 123after_reshape2 = ones_array.reshape(-1,6)print(&quot;reshape(-1,6)?&quot;, after_reshape2.shape)print(after_reshape2) reshape(-1,6)? (2, 6) [[1 1 1 1 1 1] [1 1 1 1 1 1]] 1234after_reshape3 = ones_array.reshape(3,-1)print(&quot;reshape(3,-1)?&quot;,after_reshape3.shape)print(after_reshape3)print(&quot;Data Shape is: &quot;,after_reshape3.shape) reshape(3,-1)? [[1 1 1 1] [1 1 1 1] [1 1 1 1]] Data Shape is: (3, 4) Numpy 인덱싱과 슬라이딩 12my_array = np.arange(start=0, stop=4)print(my_array) [0 1 2 3] 1print(&quot;my_array의 1번째 요소, 즉 위치값이 0인 것은: &quot;, my_array[0]) my_array의 1번째 요소, 즉 위치값이 0인 것은: 0 123my_array2 = np.arange(start=3,stop=30,step=3)my_array2 = my_array2.reshape(3,3)my_array2 array([[ 3, 6, 9], [12, 15, 18], [21, 24, 27]]) 1my_array2[0:2,0:2] array([[ 3, 6], [12, 15]]) 1my_array2[1:3,:] array([[12, 15, 18], [21, 24, 27]]) 1my_array2[:,:] array([[ 3, 6, 9], [12, 15, 18], [21, 24, 27]]) Numpy 정렬 1. sort() 12345height_arr = np.array([174,165,180,182,168])sorted_height_arr = np.sort(height_arr)print('정렬 전: ',height_arr)print('키가 작은 순으로 정렬: ',sorted_height_arr) 정렬 전: [174 165 180 182 168] 키 큰 순으로 정렬 후: [165 168 174 180 182] 123#[::-1]desc_sorted_height_arr = np.sort(height_arr)[::-1]print('키가 큰 순으로 정렬: ' ,desc_sorted_height_arr) 키가 큰 순으로 정렬: [182 180 174 168 165] 2. argsort()정렬된 배열의 인덱스를 반환 12345fives = np.array([10,5,15,20])fives_order = fives.argsort()print(fives)print(fives_order)print(fives[fives_order]) [10 5 15 20] [1 0 2 3] [ 5 10 15 20] 도움 될만한 사이트https://doorbw.tistory.com/171","link":"/2021/11/02/0203-python-numpy/"},{"title":"Google colab 연동 (markdown 파일 생성, GitHub 저장)","text":"colab 파일을 markdown 파일로 바꾸는법1. colab에서 파일 다운로드하기 파일 -&gt; 다운로드 -&gt; .ipynb다운 2. 관리자 권한으로 Anaconda Navigator 실행 3. JupyterLab 실행 3. JupyterLab 웹으로 실행 실행한 파일 띄워주기 4. Markdown 파일로 다운 File -&gt; Export Notebook As… -&gt; Markdown Google colab에서 GitHub로 저장 파일 -&gt; GitHub에 사본저장저장소와 파일 경로를 확인하기","link":"/2021/11/01/0202-python-colab/"},{"title":"Python Pandas란","text":"Pandas란 파이썬 언어로 작성된 데이터를 분석 및 조작하기 위한 소프트웨어 라이브러리이다.팬더스는 R에서 사용되던 data.frame 구조를 본뜬 DataFrame이라는 구조를 사용하기 때문에,R의 data.frame에서 사용하던 기능 상당수를 무리없이 사용할 수 있도록 만들었다. 사용하는 이유데이터 전처리 하기 위함index 1개와 column 1개 —&gt; seriesindex 1개와 column 2개 —&gt; dataframe Pandas 참고 사이트https://pandas.pydata.org/docs/reference/index.html 라이브러리 불러오기 12import pandas as pdprint(pd.__version__) 1.1.5 테스트 12df = pd.DataFrame({'col1': [1,2], 'col2': [3,4]})print(type(df)) &lt;class 'pandas.core.frame.DataFrame'&gt; 구글 드라이브 연동 (colab이랑 연결) 12from google.colab import drivedrive.mount('/content/drive') Mounted at /content/drive 1234DATA_PATH = &quot;경로를 입력하시기를 바랍니다.&quot;DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/lectures_211101/PART_I_Intro/data'lemonade = pd.read_csv(DATA_PATH + '/Lemonade2016.csv')lemonade.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 32 entries, 0 to 31 Data columns (total 7 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Date 31 non-null object 1 Location 32 non-null object 2 Lemon 32 non-null int64 3 Orange 32 non-null int64 4 Temperature 32 non-null int64 5 Leaflets 31 non-null float64 6 Price 32 non-null float64 dtypes: float64(2), int64(3), object(2) memory usage: 1.9+ KB 데이터 둘러보기 (lemonade 파일은 가게 포스기라고 생각하자) - head 123#상위 5개 행 출력#0부터 4까지 행 출력lemonade.head(5) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 0 7/1/2016 Park 97 67 70 90.0 0.25 164 41.00 1 7/2/2016 Park 98 67 72 90.0 0.25 165 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 187 46.75 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 58.25 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 69.25 - tail 12#끝에 3개 행 출력lemonade.tail(3) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price 29 7/29/2016 Park 100 66 81 95.0 0.35 30 7/30/2016 Beach 88 57 82 81.0 0.35 31 7/31/2016 Beach 76 47 82 68.0 0.35 - info() 메소드데이터에 대한 전반적인 정보df를 구성하는 행과 열의 크기, 컬럼명, 컬럼을 구성하는 자료형을 출력 1print(lemonade.info()) &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 32 entries, 0 to 31 Data columns (total 7 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Date 31 non-null object 1 Location 32 non-null object 2 Lemon 32 non-null int64 3 Orange 32 non-null int64 4 Temperature 32 non-null int64 5 Leaflets 31 non-null float64 6 Price 32 non-null float64 dtypes: float64(2), int64(3), object(2) memory usage: 1.9+ KB None - describe() 메소드다양한 통계량을 요약해주는 메소드 1lemonade.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Lemon Orange Temperature Leaflets Price count 32.000000 32.000000 32.000000 31.000000 32.000000 mean 116.156250 80.000000 78.968750 108.548387 0.354687 std 25.823357 21.863211 4.067847 20.117718 0.113137 min 71.000000 42.000000 70.000000 68.000000 0.250000 25% 98.000000 66.750000 77.000000 90.000000 0.250000 50% 113.500000 76.500000 80.500000 108.000000 0.350000 75% 131.750000 95.000000 82.000000 124.000000 0.500000 max 176.000000 129.000000 84.000000 158.000000 0.500000 - .value_counts() 메소드개별 컬럼 내에 각각의 값이 나온 횟수를 셀 수 있다 1lemonade['Location'].value_counts() Beach 17 Park 15 Name: Location, dtype: int64 데이터 다뤄보기 123#Sold라는 컬럼을 만들고 값을 0으로 지정lemonade['Sold'] = 0print(lemonade.head(3)) Date Location Lemon Orange Temperature Leaflets Price Sold 0 7/1/2016 Park 97 67 70 90.0 0.25 0 1 7/2/2016 Park 98 67 72 90.0 0.25 0 2 7/3/2016 Park 110 77 71 104.0 0.25 0 12lemonade['Sold'] = lemonade['Lemon'] + lemonade['Orange']print(lemonade.head(3)) Date Location Lemon Orange Temperature Leaflets Price Sold 0 7/1/2016 Park 97 67 70 90.0 0.25 164 1 7/2/2016 Park 98 67 72 90.0 0.25 165 2 7/3/2016 Park 110 77 71 104.0 0.25 187 12lemonade['Revenue'] = lemonade['Price']*lemonade['Sold']print(lemonade.head(3)) Date Location Lemon Orange ... Leaflets Price Sold Revenue 0 7/1/2016 Park 97 67 ... 90.0 0.25 164 41.00 1 7/2/2016 Park 98 67 ... 90.0 0.25 165 41.25 2 7/3/2016 Park 110 77 ... 104.0 0.25 187 46.75 [3 rows x 9 columns] - Out으로 출력하는 최대 칼럼의 개수display.max_columns- 옵션 설정pd.set_option()- pd.set_option(‘display.max_columns’,None)열 전체를 출력한다는 의미1234pd.set_option('display.max_columns',None)lemonade['Revenue'] = lemonade['Price'] * lemonade['Sold']print(lemonade.head(3)) Date Location Lemon Orange Temperature Leaflets Price Sold \\ 0 7/1/2016 Park 97 67 70 90.0 0.25 164 1 7/2/2016 Park 98 67 72 90.0 0.25 165 2 7/3/2016 Park 110 77 71 104.0 0.25 187 Revenue 0 41.00 1 41.25 2 46.75 1234pd.set_option('display.max_columns',0)lemonade['Revenue']= lemonade['Price'] * lemonade['Sold']print(lemonade.head(3)) Date Location Lemon Orange ... Leaflets Price Sold Revenue 0 7/1/2016 Park 97 67 ... 90.0 0.25 164 41.00 1 7/2/2016 Park 98 67 ... 90.0 0.25 165 41.25 2 7/3/2016 Park 110 77 ... 104.0 0.25 187 46.75 [3 rows x 9 columns] axis=1은 열방향으로 동작 -&gt; columnsaxis=0은 행방향으로 동작 -&gt; index 123#Sold column(열)을 삭제lemonade_column_drop = lemonade.drop('Sold', axis=1)print(lemonade_column_drop.head(3)) Date Location Lemon Orange Temperature Leaflets Price Revenue 0 7/1/2016 Park 97 67 70 90.0 0.25 41.00 1 7/2/2016 Park 98 67 72 90.0 0.25 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 46.75 123#0번 행 삭제lemonade_row_drop = lemonade_column_drop.drop(0, axis=0)print(lemonade_row_drop.head(3)) Date Location Lemon Orange Temperature Leaflets Price Revenue 1 7/2/2016 Park 98 67 72 90.0 0.25 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 46.75 3 7/4/2016 Beach 134 99 76 98.0 0.25 58.25 데이터 인덱싱 12# 0번부터 4번까지 행 출력print(lemonade[0:5]) Date Location Lemon Orange Temperature Leaflets Price Sold \\ 0 7/1/2016 Park 97 67 70 90.0 0.25 164 1 7/2/2016 Park 98 67 72 90.0 0.25 165 2 7/3/2016 Park 110 77 71 104.0 0.25 187 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 Revenue 0 41.00 1 41.25 2 46.75 3 58.25 4 69.25 1lemonade['Location'] == 'Beach' 0 False 1 False 2 False 3 True 4 True 5 True 6 True 7 True 8 True 9 True 10 True 11 True 12 True 13 True 14 True 15 True 16 True 17 True 18 False 19 False 20 False 21 False 22 False 23 False 24 False 25 False 26 False 27 False 28 False 29 False 30 True 31 True Name: Location, dtype: bool 12#true값만 반환print(lemonade[lemonade['Location'] == 'Beach'].head(3)) Date Location Lemon Orange Temperature Leaflets Price Sold \\ 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 5 7/6/2016 Beach 103 69 82 90.0 0.25 172 Revenue 3 58.25 4 69.25 5 43.00 iloc (integer-location based): 행 번호로 선택하는 방법 loc (Labels): 조건 표현으로 선택함 ex) df.loc[[행],[열]]df.iloc[[행],[열]]행, 열 조건은 똑같다 1print(lemonade.iloc[0:3, 0:2]) #첫 3개 행과 0,1,2번째 행 출력하기 Date Location 0 7/1/2016 Park 1 7/2/2016 Park 2 7/3/2016 Park 1print(lemonade.loc[0:2, ['Date','Location']]) #열 Date Location 0 7/1/2016 Park 1 7/2/2016 Park 2 7/3/2016 Park 기본 데이터 전처리 - sort_values()by 옵션에 기준으로 데이터를 정렬 1print(lemonade.sort_values(by=['Temperature']).head(5)) Date Location Lemon Orange Temperature Leaflets Price Sold 0 7/1/2016 Park 97 67 70 90.0 0.25 0 20 7/20/2016 Park 71 42 70 NaN 0.50 0 2 7/3/2016 Park 110 77 71 104.0 0.25 0 1 7/2/2016 Park 98 67 72 90.0 0.25 0 16 7/16/2016 Beach 81 50 74 90.0 0.50 0 - Groupby()전체 데이터를 그룹별로 분할하여mean(), sum(), count()와 같은 메소드를 사용해 연산하고연산 결과를 다시 합치는 과정을 거친다 1print(lemonade.groupby(by='Location').count()) Date Lemon Orange Temperature Leaflets Price Sold Location Beach 16 17 17 17 17 17 17 Park 15 15 15 15 14 15 15","link":"/2021/11/02/0204-python-pandas/"},{"title":"Python 데이터 시각화","text":"Matplotlib.pyplot란 Matplotlib는 데이터를 시각화 하는데 사용하는 대표적인 파이썬 라이브러리이다.MATLAB과 비슷한 형태를 가지고 있고, numpy나 pandas에서 사용되는 자료구조를 쉽게 시각화 할 수 있다. 시작하기 import matplotlib.pyplot as plt라이브러리 사용하기 위한 import문 추가 (plt라는 이름으로 사용) fig, ax = plt.subplots()fig는 그림, ax는 그려질 그래프를 의미괄호 안에는 그래프 크기를 정의 할 수 있음 ax.plot(dates, min_temperature, label = “Min Temp”) ax.plot(dates, max_temperature, label = “Max Temp”)두개의 그래프를 의미 ax.legend()범례를 추가할때 사용하는 메소드그래프에 데이터 위치 표시 (예제에서는 왼쪽 맨위에 표시) plt.show()마무리 1234567891011121314import matplotlib.pyplot as pltdates = [ '2021\\n01-01', '2021\\n01-02', '2021\\n01-03', '2021\\n01-04', '2021\\n01-05', '2021\\n01-06', '2021\\n01-07', '2021\\n01-08', '2021\\n01-09', '2021\\n01-10']min_temperature = [20.7, 17.9, 18.8, 14.6, 15.8, 15.8, 15.8, 17.4, 21.8, 20.0]max_temperature = [34.7, 28.9, 31.8, 25.6, 28.8, 21.8, 22.8, 28.4, 30.8, 32.0]fig, ax = plt.subplots() #그래프 생성 ()안에 사이즈 설정 가능ax.plot(dates, min_temperature, label = &quot;Min Temp&quot;) ax.plot(dates, max_temperature, label = &quot;Max Temp&quot;)ax.legend() plt.show() #마무리! 꼭 해주기! 1234567891011121314import matplotlib.pyplot as pltdates = [ '2021\\n01-01', '2021\\n01-02', '2021\\n01-03', '2021\\n01-04', '2021\\n01-05', '2021\\n01-06', '2021\\n01-07', '2021\\n01-08', '2021\\n01-09', '2021\\n01-10']min_temperature = [20.7, 17.9, 18.8, 14.6, 15.8, 15.8, 15.8, 17.4, 21.8, 20.0]max_temperature = [34.7, 28.9, 31.8, 25.6, 28.8, 21.8, 22.8, 28.4, 30.8, 32.0]fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10,6)) #그래프 사이즈axes.plot(dates, min_temperature, label = 'Min Temperature')axes.plot(dates, max_temperature, label = 'Max Temperature')axes.legend()plt.show() 12print(fig)print(axes) Figure(720x432) AxesSubplot(0.125,0.125;0.775x0.755) 선 그래프 방법 1. Pyplot API(비추천) 참조: https://pypi.org/project/fix-yahoo-finance/ yfinance란오픈소스 API로, Yahoo Finance에서 제공하는 데이터에 접근 할 수 있다.아래 예제에서는 주가 데이터를 받아 오기 위해서 사용하였다. yfinance 함수를 사용하기 위한 패키지 다운로드 1!pip install yfinance --upgrade --no-cache-dir 1234#주가 정보 가져오기import yfinance as yfdata = yf.download('AAPL', '2019-08-01', '2020-08-01')data.info() [*********************100%***********************] 1 of 1 completed &lt;class 'pandas.core.frame.DataFrame'&gt; DatetimeIndex: 253 entries, 2019-08-01 to 2020-07-31 Data columns (total 6 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Open 253 non-null float64 1 High 253 non-null float64 2 Low 253 non-null float64 3 Close 253 non-null float64 4 Adj Close 253 non-null float64 5 Volume 253 non-null int64 dtypes: float64(5), int64(1) memory usage: 13.8 KB 12ts = data['Open']print(ts.head()) Date 2019-08-01 53.474998 2019-08-02 51.382500 2019-08-05 49.497501 2019-08-06 49.077499 2019-08-07 48.852501 Name: Open, dtype: float64 - plt.legend(loc=’best’)범례 위치를 best로 설정best는 디폴트 값을 의미 123456789data = yf.download('AAPL', '2019-08-01', '2020-08-01')ts = data['Open']plt.figure(figsize=(10,6))plt.plot(ts)plt.legend(labels=['Price'], loc='best')plt.title('Stock Market fluctuation of AAPL') plt.xlabel('Date') plt.ylabel('Stock Market Open Price') plt.show() [*********************100%***********************] 1 of 1 completed 방법2. 객체 지향 API 먼저 컴퓨터 프로그램에서의 랜덤값은 무작위 수가 아니라,특정 시작 숫자값을 정해주면 정해진 알고리즘에 따라 마치 난수처럼 보이는 수열을 생성하는 것이다.이때 특정 시작 숫자가 바로 **시드(seed)**이다 시드 값은 현재 시각 등을 이용해 자동으로 정하기도 하지만,사람이 수동으로 설정 할 수도 있다 따라서 특정 시드값이 사용될 경우 이후에 발생되는 난수를 알고리즘에 따라 직접 예측이 가능하다 np.random.random(20000)numpy를 이용해서 20000개의 난수를 생성한다 random.seed()seed 설정, 괄호 안에 0이상의 정수 값을 넣어주면 된다 fig = Figure()figure 객체 생성 savefig(‘파일이름’)그래프를 이미지 파일로 저장할 수 있다 ax = fig.add_subplot(111) ax.hist(x, 100)이거 모르게따@_2123456789101112131415from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvasfrom matplotlib.figure import Figureimport matplotlib.pyplot as pltfig = Figure()import numpy as npnp.random.seed(6)x = np.random.random(20000)ax = fig.add_subplot(111)ax.hist(x, 100)ax.set_title('Artist Layer Histogram')#fig.savefig('Matplotlib_histogram.png')plt.show() 방법3 Pyplot API + 객체지향 API 123456789data = yf.download('AAPL','2019-08-01','2020-08-01')ts = data['Open']fig, ax = plt.subplots(figsize=(10,6)) ax.plot(ts)ax.set_title('Stock Market fluctuation of AAPL')ax.set_xlabel('Date')ax.set_ylabel('Stock Market Open Price')plt.show() [*********************100%***********************] 1 of 1 completed 막대그래프 Tick 이란그래프의 축에 간격을 구분하기 위해 표시하는 눈금이다ex) xticks(), yticks() 12345678910111213141516import numpy as npimport calendarmonth_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]sold_list = [300, 400, 550, 900, 600, 960, 900, 910, 800, 700, 550, 450]fig, ax = plt.subplots(figsize=(10,6))plt.xticks(month_list, calendar.month_name[1:13], rotation=90)plot = ax.bar(month_list, sold_list)for rect in plot: print(&quot;graph:&quot;, rect) height = rect.get_height() ax.text(rect.get_x() + rect.get_width()/2., 1.002*height,'%d' % int(height), ha='center', va='bottom')plt.show() graph: Rectangle(xy=(0.6, 0), width=0.8, height=300, angle=0) graph: Rectangle(xy=(1.6, 0), width=0.8, height=400, angle=0) graph: Rectangle(xy=(2.6, 0), width=0.8, height=550, angle=0) graph: Rectangle(xy=(3.6, 0), width=0.8, height=900, angle=0) graph: Rectangle(xy=(4.6, 0), width=0.8, height=600, angle=0) graph: Rectangle(xy=(5.6, 0), width=0.8, height=960, angle=0) graph: Rectangle(xy=(6.6, 0), width=0.8, height=900, angle=0) graph: Rectangle(xy=(7.6, 0), width=0.8, height=910, angle=0) graph: Rectangle(xy=(8.6, 0), width=0.8, height=800, angle=0) graph: Rectangle(xy=(9.6, 0), width=0.8, height=700, angle=0) graph: Rectangle(xy=(10.6, 0), width=0.8, height=550, angle=0) graph: Rectangle(xy=(11.6, 0), width=0.8, height=450, angle=0) 선점도 그래프 두개의 연속형 변수 (키, 몸무게) 상관관계 != 인과관계 1234567891011121314#내장 데이터import seaborn as snstips = sns.load_dataset(&quot;tips&quot;)x = tips['total_bill']y = tips['tip']fig, ax = plt.subplots(figsize=(10,6))ax.scatter(x, y)ax.set_xlabel('Totla Bill')ax.set_ylabel('Tip')ax.set_title('Tip ~ Total Bill')fig.show() 1234567891011121314label, data = tips.groupby('sex')tips['sex_color'] = tips['sex'].map({&quot;Female&quot; : '#0000FF',&quot;Male&quot; : &quot;#00FF00&quot;})fig, ax = plt.subplots(figsize=(10,6))for label, data in tips.groupby('sex'): ax.scatter(data['total_bill'], data['tip'], label=label, color=data['sex_color'], alpha=0.5) ax.set_xlabel('Total Bill') ax.set_ylabel('Tip') ax.set_title('Tip ~ Total Bill by Gender')ax.legend()fig.show() 히스토그램 수치형 변수 123456789101112131415import matplotlib.pyplot as pltimport numpy as npimport seaborn as snstitanic = sns.load_dataset('titanic')age = titanic['age']nbins = 21fig, ax = plt.subplots(figsize=(10,6))ax.hist(age, bins = nbins)ax.set_xlabel(&quot;Age&quot;)ax.set_ylabel(&quot;Frequency&quot;)ax.set_title(&quot;Distribution of Aae in Titanic&quot;)ax.axvline(x = age.mean(),linewidth = 2, color = 'r')fig.show() 박스 플롯 x축 변수: 범주형 변수, 그룹과 관련있는 변수, 문자열 y축 변수: 수치형 변수 12345678910iris = sns.load_dataset('iris')data = [iris[iris['species']==&quot;setosa&quot;]['petal_width'], iris[iris['species']==&quot;versicolor&quot;]['petal_width'], iris[iris['species']==&quot;virginica&quot;]['petal_width']]fig, ax = plt.subplots(figsize=(10, 6))ax.boxplot(data, labels=['setosa', 'versicolor', 'virginica'])fig.show() 히트맵 12345678910111213141516import matplotlib.pyplot as pltimport numpy as npimport seaborn as snsflights = sns.load_dataset(&quot;flights&quot;) #내장 데이터flights = flights.pivot(&quot;month&quot;, &quot;year&quot;,&quot;passengers&quot;)fig, ax = plt.subplots(figsize = (12,6))im = ax.imshow(flights, cmap = 'YlGnBu') #cmap은 colormap, YlGnBu은 색상ax.set_xticklabels(flights.columns, rotation = 20)ax.set_yticklabels(flights.index, rotation = 10)fig.colorbar(im)fig.show() Seaborn 산점도와 회귀선이 있는 산점도 123456789%matplotlib inline import matplotlib.pyplot as pltimport seaborn as snstips = sns.load_dataset(&quot;tips&quot;)#print(tips)sns.scatterplot(x = &quot;total_bill&quot;, y = &quot;tip&quot;, data = tips)plt.show() fig, ax = plt.subplots(ncols=2)세로로 2개의 그래프를 그림nrows=2이면 가로로 그래프를 2개 그림nrows=2, nols=3이면 2행 3열로 그래프를 그림 1234567891011121314fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(15, 5)) #이런식으로 그래프 그리는방법을 각인시키기sns.regplot(x = &quot;total_bill&quot;, y = &quot;tip&quot;, data = tips, ax = ax[0], fit_reg = True)sns.regplot(x = &quot;total_bill&quot;, y = &quot;tip&quot;, data = tips, ax = ax[1], fit_reg = False)plt.show() 히스토그램/커널 밀도 그래프 1234567import matplotlib.pyplot as pltimport seaborn as snstips = sns.load_dataset(&quot;tips&quot;) # 이렇게 하지 말깅!sns.displot(x = &quot;tip&quot;, data = tips)plt.figure(figsize=(10,6))plt.show() &lt;Figure size 720x432 with 0 Axes&gt; 12sns.displot(x=&quot;tip&quot;,kind =&quot;kde&quot;, data=tips)plt.show() 12sns.displot(x=&quot;tip&quot;,kde=True, data=tips)plt.show() 박스플롯 12sns.boxplot(x = &quot;day&quot;, y = &quot;total_bill&quot;, data =tips)sns.swarmplot(x = &quot;day&quot;, y = &quot;total_bill&quot;, data = tips, alpha= .25) &lt;matplotlib.axes._subplots.AxesSubplot at 0x7face917d410&gt; 막대 그래프 12sns.countplot (x=&quot;day&quot;, data = tips)plt.show() 123print(tips['day'].value_counts())print(&quot;index: &quot;, tips['day'].value_counts().index)print(&quot;values: &quot;, tips['day'].value_counts().values) Sat 87 Sun 76 Thur 62 Fri 19 Name: day, dtype: int64 index: CategoricalIndex(['Sat', 'Sun', 'Thur', 'Fri'], categories=['Thur', 'Fri', 'Sat', 'Sun'], ordered=False, dtype='category') values: [87 76 62 19] 1print(tips['day'].value_counts(ascending=True)) Fri 19 Thur 62 Sun 76 Sat 87 Name: day, dtype: int64 1plt.show() 123456ax = sns.countplot(x = &quot;day&quot;, data = tips, order = tips['day'].value_counts().index)for p in ax.patches: height = p.get_height() ax.text(p.get_x() + p.get_width()/2., height+3, height, ha = 'center', size=9)ax.set_ylim(-5, 100)plt.show() 12345678ax = sns.countplot(x = &quot;day&quot;, data = tips, hue = &quot;sex&quot;, dodge = True, order = tips['day'].value_counts().index)for p in ax.patches: height = p.get_height() ax.text(p.get_x() + p.get_width()/2., height+3, height, ha = 'center', size=9)ax.set_ylim(-5, 100)plt.show() 상관관계 그래프 12345678910import pandas as pd import numpy as np import seaborn as snsimport matplotlib.pyplot as pltmpg = sns.load_dataset(&quot;mpg&quot;)print(mpg.shape) # 398 행, 9개 열num_mpg = mpg.select_dtypes(include = np.number)print(num_mpg.shape) # 398 행, 7개 열 (398, 9) (398, 7) 1num_mpg.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 398 entries, 0 to 397 Data columns (total 7 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 mpg 398 non-null float64 1 cylinders 398 non-null int64 2 displacement 398 non-null float64 3 horsepower 392 non-null float64 4 weight 398 non-null int64 5 acceleration 398 non-null float64 6 model_year 398 non-null int64 dtypes: float64(4), int64(3) memory usage: 21.9 KB 1num_mpg.corr() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mpg cylinders displacement horsepower weight acceleration model_year mpg 1.000000 -0.775396 -0.804203 -0.778427 -0.831741 0.420289 0.579267 cylinders -0.775396 1.000000 0.950721 0.842983 0.896017 -0.505419 -0.348746 displacement -0.804203 0.950721 1.000000 0.897257 0.932824 -0.543684 -0.370164 horsepower -0.778427 0.842983 0.897257 1.000000 0.864538 -0.689196 -0.416361 weight -0.831741 0.896017 0.932824 0.864538 1.000000 -0.417457 -0.306564 acceleration 0.420289 -0.505419 -0.543684 -0.689196 -0.417457 1.000000 0.288137 model_year 0.579267 -0.348746 -0.370164 -0.416361 -0.306564 0.288137 1.000000 1234567891011fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(16, 5))# 기본 그래프 [Basic Correlation Heatmap]sns.heatmap(num_mpg.corr(), ax=ax[0])ax[0].set_title('Basic Correlation Heatmap', pad = 12)# 상관관계 수치 그래프 [Correlation Heatmap with Number]sns.heatmap(num_mpg.corr(), vmin=-1, vmax=1, annot=True, ax=ax[1])ax[1].set_title('Correlation Heatmap with Number', pad = 12)plt.show() 12print(int(True))np.triu(np.ones_like(num_mpg.corr())) 1 array([[1., 1., 1., 1., 1., 1., 1.], [0., 1., 1., 1., 1., 1., 1.], [0., 0., 1., 1., 1., 1., 1.], [0., 0., 0., 1., 1., 1., 1.], [0., 0., 0., 0., 1., 1., 1.], [0., 0., 0., 0., 0., 1., 1.], [0., 0., 0., 0., 0., 0., 1.]]) 12mask = np.triu(np.ones_like(num_mpg.corr(), dtype=np.bool))print(mask) [[ True True True True True True True] [False True True True True True True] [False False True True True True True] [False False False True True True True] [False False False False True True True] [False False False False False True True] [False False False False False False True]] 123456789fig, ax = plt.subplots(figsize=(16, 5)) # 기본 그래프 [Basic Correlation Heatmap]ax = sns.heatmap(num_mpg.corr(), mask=mask, vmin=-1, vmax = 1, annot=True, cmap=&quot;BrBG&quot;, cbar = True)ax.set_title('Triangle Correlation Heatmap', pad = 16, size = 16)fig.show() Intermediate 페가 블로그 코드 https://jehyunlee.github.io/2020/08/27/Python-DS-28-mpl_spines_grids/ 1234import matplotlib.pyplot as pltfrom matplotlib.ticker import (MultipleLocator, AutoMinorLocator, FuncFormatter)import seaborn as snsimport numpy as np 123456789101112131415161718192021222324252627def plot_example(ax, zorder=0): ax.bar(tips_day[&quot;day&quot;], tips_day[&quot;tip&quot;], color=&quot;lightgray&quot;, zorder=zorder) ax.set_title(&quot;tip (mean)&quot;, fontsize=16, pad=12) # Values h_pad = 0.1 for i in range(4): fontweight = &quot;normal&quot; color = &quot;k&quot; if i == 3: fontweight = &quot;bold&quot; color = &quot;darkred&quot; ax.text(i, tips_day[&quot;tip&quot;].loc[i] + h_pad, f&quot;{tips_day['tip'].loc[i]:0.2f}&quot;, horizontalalignment='center', fontsize=12, fontweight=fontweight, color=color) # Sunday ax.patches[3].set_facecolor(&quot;darkred&quot;) ax.patches[3].set_edgecolor(&quot;black&quot;) # set_range ax.set_ylim(0, 4) return axdef major_formatter(x, pos): return &quot;{%.2f}&quot; % xformatter = FuncFormatter(major_formatter) 123tips = sns.load_dataset(&quot;tips&quot;)tips_day = tips.groupby(&quot;day&quot;).mean().reset_index()print(tips_day) day total_bill tip size 0 Thur 17.682742 2.771452 2.451613 1 Fri 17.151579 2.734737 2.105263 2 Sat 20.441379 2.993103 2.517241 3 Sun 21.410000 3.255132 2.842105 12fig, ax = plt.subplots(figsize=(10, 6))ax = plot_example(ax, zorder=2) 123456fig, ax = plt.subplots(figsize=(10, 6))ax = plot_example(ax, zorder=2)ax.spines[&quot;top&quot;].set_visible(False)ax.spines[&quot;right&quot;].set_visible(False)ax.spines[&quot;left&quot;].set_visible(False) 12345678910fig, ax = plt.subplots()ax = plot_example(ax, zorder=2)ax.spines[&quot;top&quot;].set_visible(False)ax.spines[&quot;right&quot;].set_visible(False)ax.spines[&quot;left&quot;].set_visible(False)ax.yaxis.set_major_locator(MultipleLocator(1))ax.yaxis.set_major_formatter(formatter)ax.yaxis.set_minor_locator(MultipleLocator(0.5)) 12345678910111213fig, ax = plt.subplots()ax = plot_example(ax, zorder=2)ax.spines[&quot;top&quot;].set_visible(False)ax.spines[&quot;right&quot;].set_visible(False)ax.spines[&quot;left&quot;].set_visible(False)ax.yaxis.set_major_locator(MultipleLocator(1))ax.yaxis.set_major_formatter(formatter)ax.yaxis.set_minor_locator(MultipleLocator(0.5)) ax.grid(axis=&quot;y&quot;, which=&quot;major&quot;, color=&quot;lightgray&quot;)ax.grid(axis=&quot;y&quot;, which=&quot;minor&quot;, ls=&quot;:&quot;) 책 코드 12345678910111213141516import matplotlib.pyplot as pltfrom matplotlib.ticker import (MultipleLocator, AutoMinorLocator, FuncFormatter)import seaborn as snsimport numpy as nptips = sns.load_dataset(&quot;tips&quot;)fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(16, 5))def major_formatter(x, pos): return &quot;%.2f$&quot; % xformatter = FuncFormatter(major_formatter)# Ideal Bar Graphax0 = sns.barplot(x = &quot;day&quot;, y = 'total_bill', data = tips, ci=None, color='lightgray', alpha=0.85, zorder=2, ax=ax[0]) 12345group_mean = tips.groupby(['day'])['total_bill'].agg('mean')h_day = group_mean.sort_values(ascending=False).index[0]h_mean = np.round(group_mean.sort_values(ascending=False)[0], 2)print(&quot;The Best Day:&quot;, h_day)print(&quot;The Highest Avg. Total Biil:&quot;, h_mean) The Best Day: Sun The Highest Avg. Total Biil: 21.41 1234567891011121314151617181920212223tips = sns.load_dataset(&quot;tips&quot;)fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(16, 5))# Ideal Bar Graphax0 = sns.barplot(x = &quot;day&quot;, y = 'total_bill', data = tips, ci=None, color='lightgray', alpha=0.85, zorder=2, ax=ax[0])group_mean = tips.groupby(['day'])['total_bill'].agg('mean')h_day = group_mean.sort_values(ascending=False).index[0]h_mean = np.round(group_mean.sort_values(ascending=False)[0], 2)for p in ax0.patches: fontweight = &quot;normal&quot; color = &quot;k&quot; height = np.round(p.get_height(), 2) if h_mean == height: fontweight=&quot;bold&quot; color=&quot;darkred&quot; p.set_facecolor(color) p.set_edgecolor(&quot;black&quot;) ax0.text(p.get_x() + p.get_width()/2., height+1, height, ha = 'center', size=12, fontweight=fontweight, color=color)fig.show() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import matplotlib.pyplot as pltfrom matplotlib.ticker import (MultipleLocator, AutoMinorLocator, FuncFormatter)import seaborn as snsimport numpy as nptips = sns.load_dataset(&quot;tips&quot;)fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(16, 5))def major_formatter(x, pos): return &quot;%.2f$&quot; % xformatter = FuncFormatter(major_formatter)# Ideal Bar Graphax0 = sns.barplot(x = &quot;day&quot;, y = 'total_bill', data = tips, ci=None, color='lightgray', alpha=0.85, zorder=2, ax=ax[0])group_mean = tips.groupby(['day'])['total_bill'].agg('mean')h_day = group_mean.sort_values(ascending=False).index[0]h_mean = np.round(group_mean.sort_values(ascending=False)[0], 2)for p in ax0.patches: fontweight = &quot;normal&quot; color = &quot;k&quot; height = np.round(p.get_height(), 2) if h_mean == height: fontweight=&quot;bold&quot; color=&quot;darkred&quot; p.set_facecolor(color) p.set_edgecolor(&quot;black&quot;) ax0.text(p.get_x() + p.get_width()/2., height+1, height, ha = 'center', size=12, fontweight=fontweight, color=color)ax0.set_ylim(-3, 30)ax0.set_title(&quot;Ideal Bar Graph&quot;, size = 16)ax0.spines['top'].set_visible(False)ax0.spines['left'].set_position((&quot;outward&quot;, 20))ax0.spines['left'].set_visible(False)ax0.spines['right'].set_visible(False)ax0.yaxis.set_major_locator(MultipleLocator(10))ax0.yaxis.set_major_formatter(formatter)ax0.yaxis.set_minor_locator(MultipleLocator(5))ax0.set_ylabel(&quot;Avg. Total Bill($)&quot;, fontsize=14)ax0.grid(axis=&quot;y&quot;, which=&quot;major&quot;, color=&quot;lightgray&quot;)ax0.grid(axis=&quot;y&quot;, which=&quot;minor&quot;, ls=&quot;:&quot;)ax0.set_xlabel(&quot;Weekday&quot;, fontsize=14)for xtick in ax0.get_xticklabels(): print(xtick) if xtick.get_text() == h_day: xtick.set_color(&quot;darkred&quot;) xtick.set_fontweight(&quot;demibold&quot;)ax0.set_xticklabels(['Thursday', 'Friday', 'Saturday', 'Sunday'], size=12)ax1 = sns.barplot(x = &quot;day&quot;, y = 'total_bill', data = tips, ci=None, alpha=0.85, ax=ax[1])for p in ax1.patches: height = np.round(p.get_height(), 2) ax1.text(p.get_x() + p.get_width()/2., height+1, height, ha = 'center', size=12)ax1.set_ylim(-3, 30)ax1.set_title(&quot;Just Bar Graph&quot;)plt.show() Text(0, 0, 'Thur') Text(0, 0, 'Fri') Text(0, 0, 'Sat') Text(0, 0, 'Sun') Reference블로그","link":"/2021/11/03/0205-python-visualization/"},{"title":"Decision Tree","text":"Decision Tree란 머신러닝에 사용되는 예측 모델링 접근 방식 중 하나이다.여러 입력 변수를 기반으로 대상 변수의 값을 예측하는 모델을 만드는 것이다.분류와 회귀 모두 가능하며, 스무고개 하듯이 Y/N으로 질문을 이어가며 학습한다. Deicision Tree는 데이터에서 if-else 문을 이용하여 sine 곡선에 가까운 데이터를 학습한다.트리가 깊어질수록 모델이 더 복잡해진다. 알고리즘 이해하기 Rood node (뿌리 마디)처음에 root node에서 문제의 질문이 입력되면 Y/N로 데이터가 분류된다. Intermediate node (중간 마디)Y로 분류된 데이터는 다시 질문이 입력되어 Y/N으로 데이터가 분류된다. Terminal node (끝 마디)끝마디에서는 데이터가 가장 섞이지 않은 상태로 완전히 분류되어 Entropy가 낮아진다 초기 지점은 root node이고 분기가 거듭될 수록 데이터의 개수는 줄어든다 terminal node에 속하는 데이터의 개수를 합하면 root node의 데이터 수와 일치한다 Impurity(불순도)란 해당 범주 안에서 서로 다른 데이터가 얼마나 섞여 있는지 뜻한다 Entropy란 불순도를 수치적으로 나타낸 척도이다 Entropy가 높으면 불순도가 높고Entropy가 낮으면 불순도가 낮다 예를들면 Entropy가 높으면 정리되지 않은 방, 낮으면 정리된 방 이라고 생각하면 된다. Decision Tree는 불순도를 최소화 하는 방향으로 학습을 하게 된다. 전체 흐름 Define Problem, Collect training data Build a Decision Tree (Extract Data, Build a tree) Deploy machine Test with test data 장점 데이터의 전처리를 하지 않아도 된다. 수치형과 범주형 변수를 한번에 다룰 수 있다. 한계 샘플 사이즈가 크면 효율성 및 가독성이 떨어진다. 과적합으로 알고리즘 성능이 떨어질 수 있다. 한번에 하나의변수만을 고려하므로 변수간 상호작용을 파악하기 어렵다. 약간의 차이에 따라 트리의 모양이 많이 달라질 수 있다. 예제 iris data set을 이용한 deicision tree 만들기Scikitlearn 사이트의 iris 데이터셋을 이용한 예제이다.코드 출처: https://scikit-learn.org/stable/auto_examples/tree/plot_iris_dtc.html 데이터 불러오기, 그래프그리기 위한 설정 plot_colors = ‘ryb’blue red yello 색을 나타내기 위해 사용 plot_step축의 단위를 설정 12345678910111213import numpy as npimport matplotlib.pyplot as pltfrom sklearn.datasets import load_irisfrom sklearn.tree import DecisionTreeClassifier, plot_tree# Parametersn_classes = 3plot_colors = &quot;ryb&quot;plot_step = 0.02# Load datairis = load_iris() enumerate는 입력값으로 시퀀스 자료형(리스트, 튜플, 문자열)을 입력받아,enumerate 객체를 리턴한다. enumerate 객체는 첫번째로 그 순서값, 두번째로 그 순서값에 해당되는 시퀀스 자료형의 실제값을 갖는 객체이다 X = iris.data[:, pair]하나의 pair에 들어가는 값이 [0,2]라면, 첫번째 세번째만 선택해서 X에 할당1234for pairidx, pair in enumerate([[0, 1], [0, 2], [0, 3], [1, 2], [1, 3], [2, 3]]): # We only take the two corresponding features X = iris.data[:, pair] y = iris.target 12345678910111213141516# Trainclf = DecisionTreeClassifier().fit(X, y)# Plot the decision boundaryplt.subplot(2, 3, pairidx + 1)x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1xx, yy = np.meshgrid( np.arange(x_min, x_max, plot_step), np.arange(y_min, y_max, plot_step))plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])Z = Z.reshape(xx.shape)cs = plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu) 123456789101112131415161718192021222324 plt.xlabel(iris.feature_names[pair[0]]) plt.ylabel(iris.feature_names[pair[1]]) # Plot the training points for i, color in zip(range(n_classes), plot_colors): idx = np.where(y == i) plt.scatter( X[idx, 0], X[idx, 1], c=color, label=iris.target_names[i], cmap=plt.cm.RdYlBu, edgecolor=&quot;black&quot;, s=15, )plt.suptitle(&quot;Decision surface of a decision tree using paired features&quot;)plt.legend(loc=&quot;lower right&quot;, borderpad=0, handletextpad=0)plt.axis(&quot;tight&quot;)plt.figure()clf = DecisionTreeClassifier().fit(iris.data, iris.target)plot_tree(clf, filled=True)plt.show() 참고 사이트: 위키백과Scikitlearn블로그1블로그2유튜브","link":"/2021/11/04/0206-ML-DecisionTree-md/"},{"title":"Dash를 활용한 대시보드 만들기","text":"파이썬 라이브러리 20만개 넘음 GUI, 웹개발, 앱, 통계, 머신러닝, 딥러닝, 그 외 여러가지… —&gt; 버전 이슈 (라이브러리 버전 이슈!!) —&gt; Dash 라이브러리 활용하여, 대시보드 프로젝트 —&gt; 별도의 프로젝트 관리 (일부 라이브러리만 씀) —&gt; 가상으로 환경 하나 만들자, A 환경 out of Local Machine : 대시보드 만들 관련 프로젝트만 라이브러리 다운로드 받음 : conda 환경 가상환경, export environment.yml, 파이썬 버전, 가상환경 접속 ---&gt; 필요한 라이브러리 설치 : PyCharm 파이썬 인터프리터 설정 : virtualenv 가상환경 &amp; 가상환경 접속 ---&gt; 라이브러리 설치 : 키워드 &quot;which python&quot; 실행환경 Anaconda Prompt 사용 데이터: https://www.kaggle.com/neuromusic/avocado-prices Dash Library란? Dash는 반응형 웹 어플리케이션을 만들기 위한 오픈소스 파이썬 UI 라이브러리이다.Plotly에 기반하여 Web Service를 개발할 수 있는 라이브러리로 Flask+matplotlib 구현을 대체할 수 있다 (Python, R, Jullia와 호환) (+Flask는 웹 애플리케이션 개발을 위한 파이썬 프레임워크다)(+프로그래밍에서 특정 운영 체제를 위한 응용 프로그램 표준 구조를 구현하는 클래스와 라이브러리 모임라이브러리가 연장이라면 프레임워크는 차, 비행기, 탈것 같은 운송수단) 가상환경이란?가상환경은 여러개의 파이썬 프로젝트가 하나의 컴퓨터에서 충동을 일으키지 않고 존재할 수 있도록 해준다.-&gt; 독립적인 작업 환경에서 패키지 및 버전관리를 하기위해 가상환경을 사용한다. conda를 활용한 가상환경 설정 가상환경 생성하기conda create -n 가상환경이름 python=버전 가상환경 확인하기conda info –envs 가상환경 활성화하기conda activate 가상환경이름 가상환경 비활성화 하기conda deactivate 가상환경 복사하기conda create -n 복사된_가상환경이름 –clone 복사할_가상환경이름 가상환경 삭제하기conda remove -n 가상환경이름 –all Dash 라이브러리 설치conda install dashconda install pandasconda install colorama Refhttps://yganalyst.github.io/pythonic/anaconda_env_1/https://realpython.com/python-dash/https://kibua20.tistory.com/212프레임워크","link":"/2021/12/01/Dash/"},{"title":"산점도 막대그래프(Scatter)","text":"1-3. 산점도 막대 그래프라이브러리 임포트 해주기 123456789import pandas as pd import numpy as npimport seaborn as snsimport plotly.express as pximport plotly.graph_objects as go#warning 라이브러리를 이용해서 경고 메세지 숨기기import warningswarnings.filterwarnings('ignore') 캐글 데이터 불러오기 12df = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv')df = df.iloc[1:, :] .astype(‘category’)데이터를 카테고리형으로 형변환함 df1 = df.copy()df를 df1으로 복사 df1[‘Q3’] = df1[‘Q3’].astype(‘category’)복사한 df1을 카테로리로 형변환하고 [‘Q3’] 컬럼 값을 가져온다123df1 = df.copy()df1['Q3'] = df1['Q3'].astype('category')print(df1['Q3'].astype('category')) .cat.add_categories() .cat.add_categories([label])카테고리 추가 replace(old, new, [count])문자열 변경 할 수 있는 함수old : 현재 문자열에서 변경하고 싶은 문자new: 새로 바꿀 문자count: 변경할 횟수 12345others = df1['Q3'].value_counts().index[15:]label = 'Others'df1['Q3'] = df1['Q3'].cat.add_categories([label])df1['Q3'] = df1['Q3'].replace(others, label) country 1234567891011country = ( df1['Q3'] .replace(['Other'],'Others') .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Country','Q3':'Count'}) .sort_values(by=['Count'],ascending=False) .replace(['United Kingdom of Great Britain and Northern Ireland'],'United Kingdom') )print(country) country[‘percent’] 12country['percent'] = ((country['Count']/country['Count'].sum())*100).round(2).astype(str)+'%'print(country) colors, country .sort_values()데이터 정렬하기 .sort_values(by=[‘Count’])Column Count를 기준으로 정렬하기 .iloc[0:16]0행부터 15행까지 출력하기 .reset_index()인덱스 초기화 재정렬 해주는 함수 12345678910colors = ['#033351',]*16colors[14]='#0779c3'colors[13]='#5abbf9'colors[12]='#5abbf9' country = (country .sort_values(by=['Count']) .iloc[0:16] .reset_index())print(country) go.Scatter() 산점도 그래프 12345678fig = go.Figure(go.Scatter(x = country['Count'], y = country[&quot;Country&quot;], text = country['percent'], mode = 'markers', marker_color = colors, marker_size = 12 ))fig.show() for문을 이용해 그래프 그리기 for i in range(0, len(country)):i는 0부터 country의 행 길이까지 반복한다 x1 = country[“Count”][i]인덱스에 맞는 x값을 가져온다country[“Count”][i]따라서 [i]는 인덱스 값을 의미 y1 = iy축 인덱스 0부터 끝까지 의미 width = 4막대 선 두께를 의미숫자가 커질 수록 선이 두꺼워짐1234567for i in range(0, len(country)): fig.add_shape(type='line', x0 = 0, y0 = i, x1 = country[&quot;Count&quot;][i], y1 = i, line = dict(color=colors[i], width = 4))fig.show() hover hover data클릭과 반응하는 인터렉티브 그래프를 구축데이터의 세부 정보를 추가적으로 보여주는 팝업 정보창을 의미한다마우스 가져다 대면 data 정보를 볼 수 있다 1234fig.update_traces(hovertemplate='&lt;b&gt;Country&lt;/b&gt;: %{y}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Proportion&lt;/b&gt;: %{text}')fig.show() 배경 격자 무늬 123fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='#9f9f9f', ticklabelmode='period')fig.update_yaxes(showgrid=False)fig.show() .update_layout 123456789101112fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', margin=dict(pad=20), paper_bgcolor='#F7F7F7', yaxis_title=None, xaxis_title=None, title_text=&quot;Most Common &lt;b&gt;Countries&lt;/b&gt;&quot;, title_x=0.5, height=700, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=17, color='#000000'), title_font_size=35)fig.show() annotation 주석 123456789101112131415161718fig.add_annotation(dict(font=dict(size=14), x=0.98, y=-0.155, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=0, y=-0.155, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 전체코드 인도는 전체의 28%가 넘는 가장 흔한 국가이다. 미국이 10%로 그 뒤를 이었다 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485df1 = df.copy()df1['Q3'] = df1['Q3'].astype('category')others = df1['Q3'].value_counts().index[15:]label = 'Others'df1['Q3'] = df1['Q3'].cat.add_categories([label])df1['Q3'] = df1['Q3'].replace(others, label)country = ( df1['Q3'] .replace(['Other'], 'Others') .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Country', 'Q3':'Count'}) .sort_values(by=['Count'], ascending=False) .replace(['United Kingdom of Great Britain and Northern Ireland'], 'United Kingdom') ) country['percent'] = ((country['Count'] / country['Count'].sum())*100).round(2).astype(str) + '%' colors = ['#033351',] * 16colors[14] = '#0779c3'colors[13] = '#5abbf9'colors[12] = '#5abbf9'country = (country .sort_values(by = ['Count']) .iloc[0:16] .reset_index())fig = go.Figure(go.Scatter(x = country['Count'], y = country[&quot;Country&quot;], text = country['percent'], mode = 'markers', marker_color =colors, marker_size = 12))for i in range(0, len(country)): fig.add_shape(type='line', x0 = 0, y0 = i, x1 = country[&quot;Count&quot;][i], y1 = i, line=dict(color=colors[i], width = 4))fig.update_traces(hovertemplate='&lt;b&gt;Country&lt;/b&gt;: %{y}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Proportion&lt;/b&gt;: %{text}')fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='#9f9f9f', ticklabelmode='period')fig.update_yaxes(showgrid=False) fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', margin=dict(pad=20), paper_bgcolor='#F7F7F7', yaxis_title=None, xaxis_title=None, title_text=&quot;Most Common &lt;b&gt;Countries&lt;/b&gt;&quot;, title_x=0.5, height=700, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=17, color='#000000'), title_font_size=35)fig.add_annotation(dict(font=dict(size=14), x=0.98, y=-0.155, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=0, y=-0.155, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()","link":"/2021/11/07/kaggle3-%EC%82%B0%EC%A0%90%EB%8F%84%EB%A7%89%EB%8C%80%EA%B7%B8%EB%9E%98%ED%94%84/"},{"title":"막대그래프(Bar, 수직)","text":"3-1. 막대그래프(수직)라이브러리 임포트 해주기 &amp; 캐글 데이터 불러오기 1234567891011import pandas as pdimport numpy as npimport seaborn as snsimport plotly.express as pximport plotly.graph_objects as goimport warningswarnings.filterwarnings('ignore') df = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv')df = df.iloc[1:, :] experience 객체 생성 .replace([a],[b])a 이름을 b로 바꾼다 123456789101112experience = ( df['Q6'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Experience', 'Q6':'Count'}) .replace(['I have never written code','&lt; 1 years', '1-3 years', '3-5 years', '5-10 years', '10-20 years', '20+ years'], ['No experience', '&lt;1 years', '1-3 years', '3-5 years', '5-10 years', '10-20 years', '20+ years']) ) 1print(df['Q6']) 1print(experience) pandas categoricalpandas 에서 자료형으로 사용되는 object와 category object문자열을 object라는 자료형으로 나타낸다. categorycategory 형식은 가능한 값들의 범위가 고정되어있고, 한정적일 때 매우 사용한다. ???????카테고리로 바꿔준거?????????????? 1234567experience['Experience'] = pd.Categorical( experience['Experience'], ['No experience', '&lt;1 years', '1-3 years', '3-5 years', '5-10 years', '10-20 years', '20+ years'] )print(experience['Experience']) 12experience['percent'] = ((experience['Count'] / experience['Count'].sum())*100).round(2).astype(str) + '%'print(experience['percent']) 12experience = experience.sort_values('Experience')print(experience) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455colors = ['#033351',] * 7colors[1] = '#5abbf9'colors[2] = '#5abbf9'colors[3] = '#0779c3'colors[4] = '#0779c3'fig = go.Figure(go.Bar( y=experience['Count'], x=experience['Experience'], cliponaxis = False, text=experience['percent'], marker_color=colors ))fig.update_traces(texttemplate='%{text}', textposition='outside', hovertemplate='&lt;b&gt;Experience&lt;/b&gt;: %{x}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{y}', textfont_size=12) fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False) fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', margin=dict(pad=20), paper_bgcolor='#F7F7F7', height=500, yaxis={'showticklabels': False}, yaxis_title=None, xaxis_title=None, title_text=&quot;&lt;b&gt;Experience&lt;/b&gt; Distribution&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=14, color='#000000'), title_font_size=35)fig.add_annotation(dict(font=dict(size=14), x=0.98, y=-0.24, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=-0.03, y=-0.24, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 전체코드 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081experience = ( df['Q6'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Experience', 'Q6':'Count'}) .replace(['I have never written code','&lt; 1 years', '1-3 years', '3-5 years', '5-10 years', '10-20 years', '20+ years'], ['No experience', '&lt;1 years', '1-3 years', '3-5 years', '5-10 years', '10-20 years', '20+ years']) ) experience['Experience'] = pd.Categorical( experience['Experience'], ['No experience', '&lt;1 years', '1-3 years', '3-5 years', '5-10 years', '10-20 years', '20+ years'] ) experience['percent'] = ((experience['Count'] / experience['Count'].sum())*100).round(2).astype(str) + '%'experience = experience.sort_values('Experience')colors = ['#033351',] * 7colors[1] = '#5abbf9'colors[2] = '#5abbf9'colors[3] = '#0779c3'colors[4] = '#0779c3'fig = go.Figure(go.Bar( y=experience['Count'], x=experience['Experience'], cliponaxis = False, text=experience['percent'], marker_color=colors ))fig.update_traces(texttemplate='%{text}', textposition='outside', hovertemplate='&lt;b&gt;Experience&lt;/b&gt;: %{x}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{y}', textfont_size=12) fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False) fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', margin=dict(pad=20), paper_bgcolor='#F7F7F7', height=500, yaxis={'showticklabels': False}, yaxis_title=None, xaxis_title=None, title_text=&quot;&lt;b&gt;Experience&lt;/b&gt; Distribution&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=14, color='#000000'), title_font_size=35)fig.add_annotation(dict(font=dict(size=14), x=0.98, y=-0.24, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=-0.03, y=-0.24, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()","link":"/2021/11/09/kaggle5-%EB%A7%89%EB%8C%80%EA%B7%B8%EB%9E%98%ED%94%84-%EC%88%98%EC%A7%81/"},{"title":"막대그래프(Bar, 수직)","text":"1-1. 막대그래프캐글 데이터 불러오기 123456789101112131415161718# This Python 3 environment comes with many helpful analytics libraries installed# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python# For example, here's several helpful packages to loadimport numpy as np # linear algebraimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)# Input data files are available in the read-only &quot;../input/&quot; directory# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory#import osfor dirname, _, filenames in os.walk('/kaggle/input'): for filename in filenames: print(os.path.join(dirname, filename))# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using &quot;Save &amp; Run All&quot; # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session 라이브러리 임포트 해주기 123456789import pandas as pd import numpy as npimport seaborn as snsimport plotly.express as pximport plotly.graph_objects as go#warning 라이브러리를 이용해서 경고 메세지 숨기기import warningswarnings.filterwarnings('ignore') 캐글 데이터 불러오기 read_csv()외부 text 파일, csv파일을 불러와서 DataFrame (df)으로 저장 .iloc행 번호 선택 .loclabel이나 조건표현으로 선택 df = df.iloc[1:, :]두번째 행부터 마지막행까지 출력, 열은 전체 다 출력 캐글에서 데이터를 가져와서 df(데이터 프레임)에 넣어준다 123df = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv')df = df.iloc[1:, :] print(df) Column 값이 Q1인 데이터만 출력 1print(df['Q1']) age .value_counts()df의 ‘Q1’ 컬럼의 중복된 데이터 값들의 갯수 표시 to_frame()데이터 프레임으로 변환 .rename()컬럼명을 바꿀 수 있다. .sort_values(by=[‘Age’])컬럼명 Age 값의 데이터를 정렬하기ascending=True 오름차순ascending=False 내림차순 123456789age = ( df['Q1'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Age','Q1':'Count'}) .sort_values(by=['Age'],ascending=True))age.head() Percent column 추가 .round(2)반올림 함수괄호 안에 숫자2는 소수점 둘째자리까지 나타냄을 의미 (셋째자리에서 반올림) .astype()함수의 데이터 타입을 변경해주는 함수이다. age dataframe에서 percent라는 이름을 가진 열을 만들어준다.그리고 percent 컬럼의 데이터 값은 ((age[‘Count’]/age[‘Count’].sum())*100) 를 계산한 값에서반올림 하고 문자열로 데이터 타입을 바꿔주었다 12age['Percent'] = ((age['Count']/age['Count'].sum())*100).round(2).astype(str) + '%'age.head() Column 삭제하는법 age.drop(columns=[‘percent’],axis=1)위의 코드 두번 실행해서 열 잘못 들어감df 열삭제 코드 Colors 지정 왜 11이여야 할까?…ㅜ 123456colors= ['#033351',] * 11colors[0] = '#5abbf9'colors[1] = '#5abbf9'colors[2] = '#5abbf9'colors[3] = '#0779c3'colors[4] = '#0779c3' 객체 선언 fig = go.Figure객체 선언go를 통해 그래프를 하나하나 설정 go.Bar()막대 그래프 그리기go는 graph_objects이다 (맨위에 임포트 한것) cliponaxis = False텍스트가 짤리는거 보정해주는 코드 x = age[‘Age’],y = age[‘Count’]x축에 컬럼 Age의 데이터 값, y축에 컬럼 Count의 데이터 값 넣어서 그래프로 표현 12345678fig = go.Figure( go.Bar( x = age['Age'], y = age['Count'], marker_color=colors, cliponaxis = False, text = age['Percent'] ))fig.show() update_trace texttemplate textposition막대 그래프 밖에 퍼센트 값이 나타나 있다 hovertemplate마우스 가져다 대면 data 정보를 볼 수 있다 1234567fig.update_traces(texttemplate='%{text}', textposition='outside', hovertemplate='&lt;b&gt;Age&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{y}', textfont_size=12)fig.show() 배경 격자무늬 제거 showgrid=False배경에 (update_xaxes)가로 (update_yaxes)세로 격자 무늬가 사라짐 123fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.show() update_layout -update_layout형성된 fig에 레이아웃 업데이트 showlegend=False범례 추가하지 않음 plot_bgcolor=’#F7F7F7’그래프 배경화면 색상 paper_bgcolor=’#F7F7F7’그래프 뒤 배경화면 색상 yaxis={‘showticklabels’:False}y축에 값을 표기 하지 않음 yaxis_title=None xaxis_title=Nonex축 이름, y축 이름 설정하지 않음 12345678910111213fig.update_layout(coloraxis=dict(colorscale='Teal'), showlegend=False, plot_bgcolor='#F7F7F7', margin=dict(pad=20), paper_bgcolor='#F7F7F7', height=500, yaxis={'showticklabels':False}, yaxis_title=None, xaxis_title=None, title_text=&quot;&lt;b&gt;Age&lt;/b&gt; Distribution&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;,size=17, color='#000000'), title_font_size=35) annotation annotation이란주석을 의미함 12345678910111213141516171819fig.add_annotation(dict(font=dict(size=14), x=0.98, y=-0.25, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot; ))fig.add_annotation(dict(font=dict(size=12), x=0, y=-0.25, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot; ))fig.show() 전체 코드 응답자의 55% 이상이 18세에서 29세 사이이다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869age = ( df['Q1'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Age', 'Q1':'Count'}) .sort_values(by=['Age'], ascending=True) ) age['percent'] = ((age['Count'] / age['Count'].sum())*100).round(2).astype(str) + '%'colors = ['#033351',] * 11colors[0] = '#5abbf9'colors[1] = '#5abbf9'colors[2] = '#5abbf9'colors[3] = '#0779c3'colors[4] = '#0779c3'fig = go.Figure(go.Bar( y=age['Count'], x=age['Age'], marker_color=colors, cliponaxis = False, text=age['percent'] ))fig.update_traces(texttemplate='%{text}', textposition='outside', hovertemplate='&lt;b&gt;Age&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{y}', textfont_size=12) fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False) fig.update_layout(coloraxis=dict(colorscale='Teal'), showlegend=False, plot_bgcolor='#F7F7F7', margin=dict(pad=20), paper_bgcolor='#F7F7F7', height=500, yaxis={'showticklabels': False}, yaxis_title=None, xaxis_title=None, title_text=&quot;&lt;b&gt;Age&lt;/b&gt; Distribution&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=17, color='#000000'), title_font_size=35)fig.add_annotation(dict(font=dict(size=14), x=0.98, y=-0.25, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=0, y=-0.25, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Refhttps://data101.oopy.io/plolty-tutorial-guide-in-korean","link":"/2021/11/07/kaggle1-%EB%A7%89%EB%8C%80%EA%B7%B8%EB%9E%98%ED%94%84-%EC%88%98%EC%A7%81/"},{"title":"Newbies as a Data Scientist in East Asia","text":"드디어 캐글 대회 작품을 제출했다.파이썬을 거의 하나도 배우지 않고 다른 캐글 노트북을 필사 하면서부터 시작해서최종 완료까지 마쳤다. 파이썬의 기초가 하나도 없어서 너무 힘들었다그래도 다 해놓으니까 뿌듯하네여기서 보완하고 싶은 점은 for문을 이용해서 코드를 더 간략히 짰으면 하는 아쉬움이 있다. 이제부터는 파이썬의 기본 문법에 대해서 공부를 해야겠다는 생각이 들고공부의 방향성이 좀 보인다수고했다! 내자신!그리고 같이 캐글 준비한 윤화님한테도 감사를..!kaggle주소 Newbie as a data scientist in East Asia!Hello, Kaggers! Nice to meet you! We are a team in East Asia that wants to be data scientists As newbies, we want to know what and/or how Kaggler is! so, let’s have a time to learn about Kaggle as a senior with us from now. If you want to support us*(or feel qute)*, I ask for a comment! (PLZ) ^0^ And !! Since we are not native English speakers, please ask questions if there is a context that you don’t understand because it’s not smooth. I’ll do my best to answer. 1 Introduction what is the Kagglea subsidiary of Google LLC, is an online community of data scientists and machine learning practitioners. If we use kaggle, we can take the following advantages. 1) to find and publish data sets 2) to explore and build models in a web-based data-science environment 3) to work with other data scientists and machine learning engineers 4) to enter competitions to solve data science challenges so, As data scientist beginners, we try to participate in the Kaggle competition. 21 Kaggle Machine Learning and Data Science Survey The most comprehensive dataset available for ML and data science status This is the theme of the competition we will participate in this time. To become a data scientist, we compared what kind of job Kagglers has, how much experience he has, and how much money he earns by dividing into the world and East Asia. In addition, there are detailed comparisons in East Asia, and ultimately, we will to find out what data the Kaggle competition data shows. The 2021 survey, like 2017, 2018, 2019, and 2020, launched an industry-wide survey that comprehensively presents the current status of data science and machine learning. The survey was conducted from 09/01/2021 to 10/04/2021, and after cleaning the data, Kaggle received 25,973 responses! This year, Kaggle will award $30,000 in prize money to winner in this competition. we want to receive $30,000 for winning the competition, but we just hope it will help us become a data scientist because it is difficult for a rookie. Ref. [1] Kgg_competitions [2] Kgg_definition [3] kaggle-survey-2021 1.2 Contents Introduction Contents Summary Data Import and Preprocessing Plots and Description Kaggle's transformation. (World/East_Asia) 1 user transformation 2 Gender transformation 3 Job transformation 4 Age transformation 5 Degree transformation 6 Experience transformation 7 Salary transformation 8 Language transformatio Position of Data Scientist in East Asia 1 Salary 2 Salary-Experience 3 Degree 4 Salary-Degree 5 Language Discussion Close 1.3 Summary used data We used all the data for five years. (2017~2021) used Language and Library Numpy Metplotlib seaborn Plotly plotly.express : An interface where you can draw a graph easily and quickly. plotly.graph_objects : You can customize it in the way you want because you can do more detailed work than express. plotly.figure_factory : Used before express existed and remains in the module for compatibility with previous versions plotly.subplots : A module that displays multiple graphs in one figure. plotly.offline : Save locally and create HTML that opens in a web browser and make it standalone Grouping data sections East Asia and World East Asia : [‘China’,’Taiwan’, ‘South Korea’, ‘Japan’] World : all data Gender [Male, Female, Others] Job Data_Analyst =[‘Data Analyst’,’Data Miner,Information technology’,’Data Miner’, ‘Predictive Modeler’,’Information technology, networking, or system administration’,‘A business discipline (accounting, economics, finance, etc.)’, ‘Business Analyst’, Humanities’, ‘Statistician’, ‘Mathematics or statistics’,‘Medical or life sciences (biology, chemistry, medicine, etc.)’, Physics or astronomy’, ‘Social sciences (anthropology, psychology, sociology, etc.)’,‘Environmental science or geology’, ‘Humanities (history, literature, philosophy, etc.)’] Data_Scientist =[‘Data Scientist’, ‘Research Scientist’, ‘Researcher’,’Machine Learning Engineer’, ‘Scientist/Researcher’] Developer=[‘Developer Relations/Advocacy’,’Data Engineer’,’Engineer’,’Engineering (non-computer focused)’,‘Programmer’,’Software Engineer’, ‘Computer Scientist’,’Computer science (software engineering, etc.)’, ‘Fine arts or performing arts’,’Product Manager’, ‘Software Developer/Software Engineer’,‘Product/Project Manager’,’Program/Project Manager’,’DBA/Database Engineer’] Not_Employed = [‘Currently not employed’, ‘Not employed’, ‘Student’] Others = [‘I never declared a major’, ‘Other’] Age[18-21, 20s, 30s, 40s, 50s, 60s&lt;] Degree[‘college’, ‘Bachelor’s degree’,’Master’s degree’, ‘Doctoral degree~’, ‘etc’] Experience[&lt;1, 1-3, 3-5, 5-10, 10+] Salary[&lt;999, 1,000-20,000, 20,000-59,999, 60,000-99,999, 100,000-199,999, 200,000~] 2. data Import and pre-treatments 1234567891011121314151617181920import numpy as npimport pandas as pdimport seaborn as snsimport matplotlib.pylab as pltimport plotly.io as pioimport plotly.express as pximport plotly.graph_objects as goimport plotly.figure_factory as fffrom plotly.subplots import make_subplotsfrom plotly.offline import init_notebook_mode, iplotinit_notebook_mode(connected=True)pio.templates.default = &quot;none&quot;import osfor dirname, _, filenames in os.walk('/kaggle/input'): for filename in filenames: print(os.path.join(dirname, filename))import warningswarnings.filterwarnings(&quot;ignore&quot;) 12345df17= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2017/multipleChoiceResponses.csv&quot;, encoding=&quot;ISO-8859-1&quot;)df18= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2018/multipleChoiceResponses.csv&quot;, )df19= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2019/multiple_choice_responses.csv&quot;, )df20= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2020/kaggle_survey_2020_responses.csv&quot;, )df21= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2021/kaggle_survey_2021_responses.csv&quot;, ) 3. plots and description 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109#질문 제거하기, replacedf17= df17.iloc[1:, :].replace(&quot;People 's Republic of China&quot;,'China')df18= df18.iloc[1:, :].replace('Republic of Korea','South Korea')df19= df19.iloc[1:, :].replace('Republic of Korea','South Korea')df20= df20.iloc[1:, :].replace('Republic of Korea','South Korea')df21= df21.iloc[1:, :]## East Asia에는 대한민국, 일본, 중국, 타이완, 몽골, 북조선 총 6개의 국가가 속해 있다. ## 이유는 알 수 없지만, 18년도엔 타이완이 없다. EastAsia17 = ['China',&quot;People 's Republic of China&quot;, 'Taiwan', 'South Korea', 'Japan']EastAsia18= ['China', 'South Korea', 'Japan', 'Republic of Korea'] EastAsia19 = ['China','Taiwan', 'South Korea', 'Japan', 'Republic of Korea']EastAsia20 = ['China','Taiwan', 'South Korea','Republic of Korea', 'Japan']EastAsia21 = ['China','Taiwan', 'South Korea', 'Japan']EastAsia = ['Republic of Korea','China','Taiwan', 'South Korea', 'Japan', &quot;People 's Republic of China&quot; ]df21_Ea = df21[df21['Q3'].isin(EastAsia)]df21_Wo = df21[~df21['Q3'].isin(EastAsia)]df21['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df21['Q3']]df20_Ea = df20[df20['Q3'].isin(EastAsia)]df20_Wo = df20[~df20['Q3'].isin(EastAsia)]df20['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df20['Q3']]df19_Ea = df19[df19['Q3'].isin(EastAsia)]df19_Wo = df19[~df19['Q3'].isin(EastAsia)]df19['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df19['Q3']]df18_Ea = df18[df18['Q3'].isin(EastAsia)]df18_Wo = df18[~df18['Q3'].isin(EastAsia)]df18['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df18['Q3']]df17_Ea = df17[df17['Country'].isin(EastAsia)]df17_Wo = df17[~df17['Country'].isin(EastAsia)]df17['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df17['Country']]df21['year'] = '2021'df20['year'] = '2020'df19['year'] = '2019'df18['year'] = '2018'df17['year'] = '2017'years = ['2017', '2018', '2019', '2020', '2021']df21_Ea = df21[df21['Q3'].isin(EastAsia21)]Ea21= ( df21_Ea['Q3'].value_counts().to_frame() .reset_index().rename(columns={'index':'Country', 'Q3':'21'}))df20_Ea=df20[df20['Q3'].isin(EastAsia)]Ea20= ( df20_Ea['Q3'].replace('Republic of Korea','South Korea') .value_counts().to_frame().reset_index() .rename(columns={'index':'Country', 'Q3':'20'}))df19_Ea=df19[df19['Q3'].isin(EastAsia)]Ea19= (df19_Ea['Q3'].replace('Republic of Korea','South Korea') .value_counts().to_frame().reset_index() .rename(columns={'index':'Country', 'Q3':'19'}))df18_Ea=df18[df18['Q3'].isin(EastAsia)]Ea18= (df18_Ea['Q3'].replace('Republic of Korea','South Korea') .value_counts().to_frame().reset_index() .rename(columns={'index':'Country', 'Q3':'18'}))Ea18.value_counts()#df18 열에 taiwan = 0을 추가 해야 합니다. df17_Ea = df17[df17['Country'].isin(EastAsia)]Ea17= (df17_Ea['Country'].replace(&quot;People 's Republic of China&quot;,'China') .value_counts().to_frame().reset_index() .rename(columns={'index':'Country', 'Country':'17'}))#data를 합쳐서 하나의 dataframe으로 만들어 줌.df5years = pd.merge(Ea17, Ea18, on='Country', how='outer')df5year =pd.merge(Ea19,Ea20, on='Country', how='outer')df5year=pd.merge(df5year, Ea21, on='Country', how='outer')df5years = pd.merge(df5years, df5year, on='Country', how='outer')Ea21 = len(df21_Ea)Wo21 = len(df21) - len(df21_Ea)Ea20 = len(df20_Ea)Wo20 = len(df20) - len(df20_Ea)Ea19 = len(df19_Ea)Wo19 = len(df19) - len(df19_Ea)Ea18 = len(df18_Ea)Wo18 = len(df18) - len(df18_Ea)Ea17 = len(df17_Ea)Wo17 = len(df17) - len(df17_Ea)years = ['2017','2018','2019','2020', '2021']def percent (a, b): result =a/(a+b)*100 result = np.round(result, 2) return resultdef percentR (b, a): result =a/(a+b)*100 result = np.round(result, 2) return resultpercent = [percent(Ea17, Wo17), percent(Ea18, Wo18), percent(Ea19, Wo19), percent(Ea20, Wo20), percent(Ea21, Wo21)] 3.1 Kaggle’s transformation (World/East Asia) 3.1.1 user transformation Number of respondents (bar, scatter plot : number of respondents to World and East Asia,Map plot : number of respondents to East Asia) World and East Asia: The same trend. East Asia: 15% of the total continent and 20.3% of the population (16/78.7: Ea/Wo) 2018 Issue: Significant increase in respondents-&gt;Hypothesis: Due to the rapid increase in China. 2018 Outliers Considering: 2022 Kaggle survey Respondents: Increased in both World and East Asia I wish our team the honor of becoming a respondent to the Kaggle survey in 2022…. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980fig = go.Figure()y=[len(df17_Ea),len(df18_Ea), len(df19_Ea),len(df20_Ea),len(df21_Ea)]fig.add_trace(go.Bar(x=years, y=y, base=0, marker_color='#F2D64B', yaxis = &quot;y1&quot;, name='East Asia', text= percent, texttemplate='%{text} %', textposition='outside', hovertemplate='&lt;b&gt;KaggleUser&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{y}'))fig.add_trace(go.Scatter(name = &quot;World&quot;, x=years, y=[len(df17), len(df18), len(df19), len(df20), len(df21)], marker_color='#979DA6', mode = 'lines+markers', # please check option here yaxis = &quot;y2&quot;))fig.update_traces(hovertemplate='&lt;b&gt;Count&lt;/b&gt;: %{y}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'+ '&lt;b&gt;Year&lt;/b&gt;: %{x}&lt;br&gt;')fig.update_layout(yaxis = dict(title = &quot;Kaggle User in East Asia&quot;,showgrid = False, range=[0, len(df21_Ea)*1.2]), yaxis2 = dict(title = &quot;Kaggle User in World&quot;, overlaying = &quot;y1&quot;, side = &quot;right&quot;, showgrid = False, zeroline = False, range=[0, len(df21)*1.2]))fig.update_layout(title='&lt;b&gt;Kaggle Users&lt;/b&gt;',title_font_size=20, margin = dict(t=200, l=100, r=50, b=200), height=700, width=700)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.1, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.9, y=-0.25, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()def world_map(locations,counts,title): data = [ dict( type = 'choropleth', locations = locations, z = counts, colorscale = 'Reds', locationmode = 'country names', autocolorscale = False, reversescale = False, marker = dict( line = dict(color = '#F7F7F7', width = 1.5)), colorbar = dict(autotick = True, legth = 3, len=0.75, title = 'respodents', max = 1000, min = 0))] layout = dict( title=title, titlefont={'size': 28}, width=700, height=600, paper_bgcolor='#FFFFFF', margin=dict(l=50, r=50, t=100, b=100), geo = dict( showframe = True, showcoastlines = True, fitbounds=&quot;locations&quot;)) fig = dict(data=data, layout=layout) iplot(fig, validate=False, filename='world-map')z = df21_Ea['Q3'].value_counts() world_map(locations=z.index, counts=z.values, title= '&lt;b&gt;EastAsia Countries&lt;b&gt;') 18’ : User change between United States and India. China’s markedly increase in 2018 There is no Taiwan, but only China has increased. : East Asian political situation Issue can be suspected. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384A18 = ( df18['Q3'] .replace({'Republic of Korea':'South Korea', 'I do not wish to disclose my location' : 'Other'}) .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'Q3':'2018'}) .groupby('type') .sum() .reset_index())A19 = ( df19['Q3'] .replace('Republic of Korea','South Korea') .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'Q3':'2019'}) .groupby('type') .sum() .reset_index())A17 = ( df17['Country'] .replace({'United States': 'United States of America', 'Hong Kong': 'Hong Kong (S.A.R.)', 'United Kingdom':'United Kingdom of Great Britain and Northern Ireland', }) .replace(&quot;People 's Republic of China&quot;,'China') .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'Country':'2017'}) .groupby('type') .sum() .reset_index())A18A19=pd.merge(A18,A19, how='outer',on='type').fillna(0)A18A17=pd.merge(A18,A17, how='outer',on='type').fillna(0)A18A19['minus']= A18A19['2018']-A18A19['2019']A18A17['minus']= A18A17['2018']-A18A17['2017']A18A17=A18A17.sort_values(by=&quot;minus&quot;, ascending=False)A18A19=A18A19.sort_values(by=&quot;minus&quot;, ascending=False)fig = go.Figure(data=[ go.Bar(x =A18A19['type'], y = A18A19['minus'], marker_color='#979DA6', name = '2018-2019', base=0), go.Bar(x =A18A17['type'], y = A18A17['minus'], marker_color='#F2D64B', name = '2018-2017', base=0) ])fig.update_layout(title='&lt;b&gt; Predicting outliers (2018)&lt;/b&gt;',title_font_size=20, margin = dict(t=200, l=100, r=10, b=200), height=700, width=700, xaxis_title=None, yaxis_title=None)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.1, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Total population: 1.4 billion (85%) in China, 130 million in Japan, 0.5 billion in Korea, and 0.2 billion in Taiwan. China: The number of respondents is smaller than the population. Japan: Starting in 2019, overtaking China Taiwan : 2018 data 0 =? Diplomatic issues? The growth trend is weak. Korea : Respondents at a similar level to Japan’s population. East Asia: The number of respondents will increase further. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#data preprocessingtotal17 = ( df17['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index())total18 = ( df18['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index())total19 = ( df19['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index())total20 = ( df20['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index())total21 = ( df21['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index())#graphcolors = ['#F2D64B','#979DA6']fig = make_subplots(rows=1, cols=5, specs=[[{'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}]], subplot_titles=(&quot;2017&quot;, &quot;2018&quot;, &quot;2019&quot;, &quot;2020&quot;, &quot;2021&quot;))fig.add_trace(go.Pie(marker=dict(colors=colors),labels=total21['type'], values=total21['respodents'], name=&quot;2021&quot;, scalegroup='one'), 1, 5)fig.add_trace(go.Pie(marker=dict(colors=colors),labels=total20['type'], values=total20['respodents'], name=&quot;2020&quot;, scalegroup='one'), 1, 4)fig.add_trace(go.Pie(marker=dict(colors=colors),labels=total19['type'], values=total19['respodents'], name=&quot;2019&quot;, scalegroup='one'), 1, 3)fig.add_trace(go.Pie(marker=dict(colors=colors),labels=total18['type'], values=total18['respodents'], name=&quot;2018&quot;, scalegroup='one'), 1, 2)fig.add_trace(go.Pie(marker=dict(colors=colors),labels=total17['type'], values=total17['respodents'], name=&quot;2017&quot;, scalegroup='one'), 1, 1)fig.update_traces(hole=.0, hoverinfo=&quot;label+percent+name&quot;, textposition='inside', textinfo='percent+label', textfont_size=12)fig.update_layout(title='&lt;b&gt;World vs EastAsia&lt;/b&gt;',title_font_size=23, margin = dict(t=300, l=0, r=0, b=200), height=700, width=700)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.3, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.25, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 123456789101112131415161718192021222324252627282930fig = go.Figure(data=[ go.Bar(name='2017', x=df5years['Country'], y=df5years['17'], marker_color='#F2798F',text=df5years['17'].tolist(), textposition='outside'), go.Bar(name='2018', x=df5years['Country'], y=df5years['18'], marker_color='#88BFBA',text=df5years['18'].fillna(0).astype(int).tolist(), textposition='outside',), go.Bar(name='2019', x=df5years['Country'], y=df5years['19'], marker_color='#CDD9A3',text=df5years['19'].tolist(), textposition='outside'), go.Bar(name='2020', x=df5years['Country'], y=df5years['20'], marker_color='#F28705',text=df5years['20'].tolist(), textposition='outside',), go.Bar(name='2021', x=df5years['Country'], y=df5years['21'], marker_color='#D9946C',text=df5years['21'].tolist(), textposition='outside')])fig.update_layout(barmode='group')fig.update_layout(title='&lt;b&gt;Kaggle User in East Asia&lt;/b&gt;',title_font_size=23, margin = dict(t=200, l=100, r=10, b=200), height=600, width=700)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_traces(hovertemplate='&lt;b&gt;Count&lt;/b&gt;: %{y}')fig.update_layout(legend=dict( orientation=&quot;v&quot;, yanchor=&quot;bottom&quot;, y=1.15, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 3.1.2 Gender transformation World: The proportion of female respondents increases (still below 20%) The number of respondents is increasing in all genders. Our team is also a team with high female members and wants to contribute as a respondent in 2022. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495#data preprocessingGender_17 = ( df17['GenderSelect'] .replace(['A different identity', 'Prefer to self-describe', 'Non-binary, genderqueer, or gender non-conforming'], 'Others') .fillna('Others') .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'GenderSelect':'Gender'}) .groupby('type') .sum() .reset_index())Gender_18 = ( df18['Q1'] .replace(['Prefer not to say', 'Prefer to self-describe'], 'Others') .fillna('Others') .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'Q1':'Gender'}) .groupby('type') .sum() .reset_index())Gender_19 = ( df19['Q2'] .replace(['Prefer not to say','Prefer to self-describe'],'Others') .fillna('Others') .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'Q2':'Gender'}) .groupby('type') .sum() .reset_index())Gender_20 = ( df20['Q2'] .replace(['Prefer not to say', 'Prefer to self-describe', 'Nonbinary'], 'Others') .replace(['Man', 'Woman'], ['Male', 'Female']) .fillna('Others') .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'Q2':'Gender'}) .groupby('type') .sum() .reset_index())Gender_21 = ( df21['Q2'] .replace(['Prefer not to say', 'Prefer to self-describe', 'Nonbinary'], 'Others') .replace(['Man', 'Woman'], ['Male', 'Female']) .fillna('Others') .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'Q2':'Gender'}) .groupby('type') .sum() .reset_index())colors = ['#D9946C','#88BFBA', '#CDD9A3']fig = make_subplots(rows=1, cols=5, specs=[[{'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}]],)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_21['type'], values=Gender_21['Gender'], name=&quot;2021&quot;, scalegroup='one', text=np.array(Gender_21['Gender'].sum()), title=&quot;2021&quot;, titleposition='bottom center'), 1, 5)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_20['type'], values=Gender_20['Gender'], name=&quot;2020&quot;, scalegroup='one', text=np.array(Gender_20['Gender'].sum()), title=&quot;2020&quot;, titleposition='bottom center'), 1, 4)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_19['type'], values=Gender_19['Gender'], name=&quot;2019&quot;, scalegroup='one', text=np.array(Gender_19['Gender'].sum()), title=&quot;2019&quot;, titleposition='bottom center'), 1, 3)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_18['type'], values=Gender_18['Gender'], name=&quot;2018&quot;, scalegroup='one', text=np.array(Gender_18['Gender'].sum()), title=&quot;2018&quot;, titleposition='bottom center'), 1, 2)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_17['type'], values=Gender_17['Gender'], name=&quot;2017&quot;, scalegroup='one', text=np.array(Gender_17['Gender'].sum()), title=&quot;2017&quot;, titleposition='bottom center'), 1, 1)fig.update_traces(hole=.0, hoverinfo=&quot;label+percent+name&quot;, textinfo='label+percent+value')fig.update_layout(title='&lt;b&gt;World Gender&lt;/b&gt;',title_font_size=23, margin = dict(t=300, l=100, r=0, b=200), height=700, width=1000)fig.update_layout(legend=dict( orientation=&quot;v&quot;, yanchor=&quot;bottom&quot;, y=1.3, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.85, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() - Male (1004-&gt;2037 : 2017-&gt;2021) double increase - Female 183-&gt;327 : 2017-&gt;2021 increased 1.8 times - Others (8-&gt;64 : 2017-&gt;2021) 8x increase [Compare the high and low points] It can be seen that the number of female respondents and the ratio of male respondents hardly change, which is a difference compared to World data. It can be seen that the degree of gender freedom in East Asia has increased relatively. Compared to World data, it can be seen that in 2021 (1.87: 2.6= Wo: Ea), compared to 2017 (1.96: 0.7 = Ea), which was relatively conservative. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#data preprocessinggender21= df21_Ea.loc[:, ['Q3', 'Q2', 'year']].rename(columns={'Q3':'Country', 'Q2':'Gender'})gender20= df20_Ea.loc[:, ['Q3', 'Q2', 'year']].rename(columns={'Q3':'Country', 'Q2':'Gender'})gender19= df19_Ea.loc[:, ['Q3', 'Q2', 'year']].rename(columns={'Q3':'Country', 'Q2':'Gender'})gender18= df18_Ea.loc[:, ['Q3', 'Q1', 'year']].rename(columns={'Q3':'Country', 'Q1':'Gender'})gender17= df17_Ea.loc[:, ['Country', 'GenderSelect', 'year']].rename(columns={'index':'type', 'GenderSelect':'Gender'})Gender5y= pd.concat([gender17, gender18, gender19, gender20, gender21])Gender5y= (Gender5y.replace(['Prefer not to say', 'Prefer to self-describe', 'Nonbinary', 'A different identity'], 'Others') .replace(['Man', 'Woman'], ['Male', 'Female']) .groupby(['year', 'Gender']) .size() .reset_index() .rename(columns = {0:&quot;Count&quot;}))gen17_5y = Gender5y[Gender5y['year'] == &quot;2017&quot;].reset_index(drop = True)gen18_5y = Gender5y[Gender5y['year'] == &quot;2018&quot;].reset_index(drop = True)gen19_5y = Gender5y[Gender5y['year'] == &quot;2019&quot;].reset_index(drop = True)gen20_5y = Gender5y[Gender5y['year'] == &quot;2020&quot;].reset_index(drop = True)gen21_5y = Gender5y[Gender5y['year'] == &quot;2021&quot;].reset_index(drop = True)Gen5y_ = pd.concat([gen17_5y, gen18_5y, gen19_5y, gen20_5y, gen21_5y], ignore_index = True)Gen5y_= pd.pivot(Gen5y_, index = &quot;year&quot;, columns = &quot;Gender&quot;, values = &quot;Count&quot;).reset_index()Gen5y_Gen5y_['year'].unique()#graphfig = go.Figure()fig.add_trace(go.Bar( x = Gen5y_['year'], y = Gen5y_['Male'].tolist(), name = 'Male',marker_color='#88BFBA', text=Gen5y_['Male'].tolist(), textposition='outside'))fig.add_trace(go.Bar( x = Gen5y_['year'], y = Gen5y_['Female'].tolist(), name = 'Female',marker_color='#D9946C', text=Gen5y_['Female'].tolist(), textposition='outside'))fig.add_trace(go.Bar( x = Gen5y_['year'], y = Gen5y_['Others'].tolist(), name = 'Others',marker_color='#CDD9A3', text=Gen5y_['Others'].tolist(), textposition='outside'))fig.update_layout(barmode=&quot;group&quot;) fig.update_layout(title='&lt;b&gt;Gender by year&lt;/b&gt;',title_font_size=22, margin = dict(t=200, l=100, r=10, b=200), height=700, width=700, xaxis_title=None, yaxis_title=None)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 3.1.3 Job transformation 21' World Vs East Asia Age Ratio: Bar plot Not Employed : More than 30% in both East Asia and the world, the highest. Because “Students” is included. Data Scientist : High percentage in the world and East Asia. Relatively low proportion in East Asia. = Absolute lack of numbers We would like to move forward by selecting a **data scientist** with insufficient numbers in East Asia. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132#data preprocessingData_Analyst =['Data Analyst','Data Miner,Information technology','Data Miner', 'Predictive Modeler','Information technology, networking, or system administration', 'A business discipline (accounting, economics, finance, etc.)', 'Business Analyst', 'Humanities', 'Statistician', 'Mathematics or statistics', 'Medical or life sciences (biology, chemistry, medicine, etc.)', 'Physics or astronomy', 'Social sciences (anthropology, psychology, sociology, etc.)', 'Environmental science or geology', 'Humanities (history, literature, philosophy, etc.)']Data_Scientist =['Data Scientist', 'Research Scientist', 'Researcher', 'Machine Learning Engineer', 'Scientist/Researcher']Developer=['Developer Relations/Advocacy','Data Engineer','Engineer','Engineering (non-computer focused)', 'Programmer','Software Engineer', 'Computer Scientist','Computer science (software engineering, etc.)', 'Fine arts or performing arts','Product Manager', 'Software Developer/Software Engineer', 'Product/Project Manager','Program/Project Manager','DBA/Database Engineer']Not_Employed =['Currently not employed', 'Not employed', 'Student']Others = ['I never declared a major', 'Other']df21job_Ea = df21_Ea.loc[:,['Q3','Q5']].rename(columns={'Q5':'2021'}).fillna('Other')df20job_Ea = df20_Ea.loc[:,['Q3','Q5']].rename(columns={'Q5':'2020'}).fillna('Other')df19job_Ea = df19_Ea.loc[:,['Q3','Q5']].rename(columns={'Q5':'2019'}).fillna('Other')df18job_Ea = df18_Ea.loc[:,['Q3','Q5']].rename(columns={ 'Q5':'2018'}).fillna('Other')df17job_Ea = df17_Ea.loc[:,['Country','CurrentJobTitleSelect']].rename(columns={'CurrentJobTitleSelect':'2017'}).fillna('Other')df21job_Ea.value_counts('2021')df21job_Ea['JOB']=[&quot;Data Analyst&quot; if x in Data_Analyst else &quot;Data Scientist&quot; if x in Data_Scientist # Data Scientist else &quot;Developer&quot; if x in Developer else &quot;NotEmployed&quot; if x in Not_Employed else &quot;Others&quot; for x in df21job_Ea['2021']]df21job_Ea.value_counts('JOB')df20job_Ea.value_counts('2020')df20job_Ea['JOB']=[&quot;Data Analyst&quot; if x in Data_Analyst else &quot;Data Scientist&quot; if x in Data_Scientist else &quot;Developer&quot; if x in Developer else &quot;NotEmployed&quot; if x in Not_Employed else &quot;Other&quot; for x in df20job_Ea['2020']]df20job_Ea[['2020','JOB']]df19job_Ea.value_counts('2019')df19job_Ea['JOB']=[&quot;Data Analyst&quot; if x in Data_Analyst else &quot;Data Scientist&quot; if x in Data_Scientist else &quot;Developer&quot; if x in Developer else &quot;NotEmployed&quot; if x in Not_Employed else &quot;Other&quot; for x in df19job_Ea['2019']]df19jobTest = df19job_Ea.loc[df19job_Ea.JOB == 'Other']df19jobTest['2019'].value_counts()df18job_Ea.value_counts('2018')df18job_Ea['JOB']=[&quot;Data Analyst&quot; if x in Data_Analyst else &quot;Data Scientist&quot; if x in Data_Scientist else &quot;Developer&quot; if x in Developer else &quot;NotEmployed&quot; if x in Not_Employed else &quot;Other&quot; for x in df18job_Ea['2018']]df18jobTest = df18job_Ea.loc[df18job_Ea.JOB == 'Other']df18jobTest['2018'].value_counts()df17job_Ea.value_counts('2017')df17job_Ea['JOB']=[&quot;Data Analyst&quot; if x in Data_Analyst else &quot;Data Scientist&quot; if x in Data_Scientist else &quot;Developer&quot; if x in Developer else &quot;NotEmployed&quot; if x in Not_Employed else &quot;Other&quot; for x in df17job_Ea['2017']]df17jobTest = df17job_Ea.loc[df17job_Ea.JOB == 'Other']df17jobTest['2017'].value_counts()df21jobTest = df21job_Ea.loc[df21job_Ea.JOB == 'Other']df21jobTest['2021'].head()df21job_Ea.value_counts('JOB')dfjob21 =df21job_Ea.groupby(['Q3','JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;}).rename(columns={'Q3':'country'})dfjob20 =df20job_Ea.groupby(['Q3','JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;}).rename(columns={'Q3':'country'})dfjob19 =df19job_Ea.groupby(['Q3','JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;}).rename(columns={'Q3':'country'})dfjob18 =df18job_Ea.groupby(['Q3','JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;}).rename(columns={'Q3':'country'})dfjob17 =df17job_Ea.groupby(['Country','JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;}).rename(columns={'Country':'country'})df21_Ea_job =df21job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df20_Ea_job =df20job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df19_Ea_job =df19job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df18_Ea_job =df18job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df17_Ea_job =df17job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df21_DA=df21[df21['Q5'].isin(Data_Analyst)]df21_DS=df21[df21['Q5'].isin(Data_Scientist)]df21_D=df21[df21['Q5'].isin(Developer)]df21_N=df21[df21['Q5'].isin(Not_Employed)]df21_O=df21[df21['Q5'].isin(Others)]World_ = np.array([df21_DA['Q5'].count(), df21_DS['Q5'].count(), df21_D['Q5'].count(), df21_N['Q5'].count(), df21_O['Q5'].count()]) East_Asia_ = df21_Ea_job['Count'].to_numpy()World =((World_/World_.sum())*100).round(1)East_Asia =((East_Asia_/East_Asia_.sum())*100).round(1)y = df21_Ea_job.JOB.to_numpy()fig = go.Figure(data=[ go.Bar(y=y, x=World, orientation='h', name=&quot;World&quot;, base=0, hovertemplate='&lt;b&gt;World&lt;/b&gt;: %{x}%&lt;br&gt;', marker_color='#979DA6', text=World, textposition='outside'), go.Bar(y=y, x=-East_Asia, orientation='h', name=&quot;East Asia&quot;, base=0, hovertemplate='&lt;b&gt;East Asia&lt;/b&gt;: %{x}%&lt;br&gt;', marker_color='#F2D64B', text=East_Asia, textposition='outside')])fig.update_layout(barmode='stack')fig.update_layout(title='&lt;b&gt;World vs EastAsia&lt;/b&gt;',title_font_size=22, margin = dict(t=200, l=100, r=50, b=200), height=700, width=750, xaxis_title=None, yaxis_title=None)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.1, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() World Job Ratio: Heat Map The trend of increasing each job except Others. Data Scientist has a high proportion, and the trend is to increase further in 2022. East Asia Job Ratio: Heat Map East Asia : Increasing the ratio of data scientist. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113#data preprocessingdf21job= df21.loc[:,['region','Q5']].rename(columns={'Q5':'2021'}).fillna('Others')df20job= df20.loc[:,['region','Q5']].rename(columns={'Q5':'2020'}).fillna('Others')df19job= df19.loc[:,['region','Q5']].rename(columns={'Q5':'2019'}).fillna('Others')df18job= df18.loc[:,['region','Q6']].rename(columns={ 'Q6':'2018'}).fillna('Others')df17job= df17.loc[:,['region','CurrentJobTitleSelect']].rename(columns={'CurrentJobTitleSelect':'2017'}).fillna('Others')df21job['JOB']=[&quot;Data Analyst&quot; if x in Data_Analyst else &quot;Data Scientist&quot; if x in Data_Scientist # Data Scientist else &quot;Developer&quot; if x in Developer else &quot;NotEmployed&quot; if x in Not_Employed else &quot;Others&quot; for x in df21job['2021']]df20job['JOB']=[&quot;Data Analyst&quot; if x in Data_Analyst else &quot;Data Scientist&quot; if x in Data_Scientist else &quot;Developer&quot; if x in Developer else &quot;NotEmployed&quot; if x in Not_Employed else &quot;Others&quot; for x in df20job['2020']]df19job['JOB']=[&quot;Data Analyst&quot; if x in Data_Analyst else &quot;Data Scientist&quot; if x in Data_Scientist else &quot;Developer&quot; if x in Developer else &quot;NotEmployed&quot; if x in Not_Employed else &quot;Others&quot; for x in df19job['2019']]df18job['JOB']=[&quot;Data Analyst&quot; if x in Data_Analyst else &quot;Data Scientist&quot; if x in Data_Scientist else &quot;Developer&quot; if x in Developer else &quot;NotEmployed&quot; if x in Not_Employed else &quot;Others&quot; for x in df18job['2018']]df17job['JOB']=[&quot;Data Analyst&quot; if x in Data_Analyst else &quot;Data Scientist&quot; if x in Data_Scientist else &quot;Developer&quot; if x in Developer else &quot;NotEmployed&quot; if x in Not_Employed else &quot;Others&quot; for x in df17job['2017']]df21_job =df21job.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df20_job =df20job.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df19_job =df19job.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df18_job =df18job.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df17_job =df17job.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})merge11=pd.merge(df21_job,df20_job, how='outer',on='JOB')merge21=pd.merge(df19_job,df18_job, how='outer',on='JOB')merge31=pd.merge(merge11,merge21, how='outer',on='JOB')merge_Wo=(pd.merge(merge31,df17_job, how='outer',on='JOB') .rename(columns = {'Count_x_x':'2021','Count_y_x':'2020','Count_x_y':'2019','Count_y_y':'2018','Count':'2017'}).fillna(0) .reindex(columns = ['JOB','2017','2018','2019','2020','2021' ]))df21job_Ea = df21job[df21job['region'] == 'EastAsia'].loc[:,['region','JOB']].rename(columns={'region':'EastAsia'})df20job_Ea = df20job[df20job['region'] == 'EastAsia'].loc[:,['region','JOB']].rename(columns={'region':'EastAsia'})df19job_Ea = df19job[df19job['region'] == 'EastAsia'].loc[:,['region','JOB']].rename(columns={'region':'EastAsia'})df18job_Ea = df18job[df18job['region'] == 'EastAsia'].loc[:,['region','JOB']].rename(columns={'region':'EastAsia'})df17job_Ea = df17job[df17job['region'] == 'EastAsia'].loc[:,['region','JOB']].rename(columns={'region':'EastAsia'})df21job_Ea =df21job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df20job_Ea =df20job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df19job_Ea =df19job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df18job_Ea =df18job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df17job_Ea =df17job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})merge1=pd.merge(df21job_Ea,df20job_Ea, how='outer',on='JOB')merge2=pd.merge(df19job_Ea,df18job_Ea, how='outer',on='JOB')merge3=pd.merge(merge1,merge2, how='outer',on='JOB')merge=(pd.merge(merge3,df17job_Ea, how='outer',on='JOB') .rename(columns = {'Count_x_x':'2021','Count_y_x':'2020','Count_x_y':'2019','Count_y_y':'2018','Count':'2017'}).fillna(0) .reindex(columns = ['JOB','2017','2018','2019','2020','2021' ]))#graphz1=((merge_Wo.iloc[:,[1,2,3,4,5]].to_numpy()/merge_Wo.iloc[:,[1,2,3,4,5]].to_numpy().sum())*100).round(1)z2=((merge.iloc[:,[1,2,3,4,5]].to_numpy()/merge.iloc[:,[1,2,3,4,5]].to_numpy().sum())*100).round(1)x=['2017-year','2018-year','2019-year','2020-year','2021-year']y1=merge_Wo['JOB'].tolist()y2=merge['JOB'].tolist()fig1 = ff.create_annotated_heatmap(z1, x = x, y = y1, colorscale='sunset')fig2 = ff.create_annotated_heatmap(z2, x = x, y = y2, colorscale='sunset')for annot in fig2['layout']['annotations']: annot['xref'] = 'x2' fig = make_subplots(rows=1, cols=2)fig.add_trace(fig1.data[0], row=1, col=1)fig.add_trace(fig2.data[0], row=1, col=2)fig.update_layout(fig1.layout, title='&lt;b&gt; World vs EastAsia&lt;/b&gt;',title_font_size=22, margin = dict(t=200, l=100, r=10, b=200), height=700, width=1150, coloraxis=dict(showscale=True, colorscale='sunset'))fig.update_traces(hovertemplate='&lt;b&gt;Job&lt;/b&gt;: %{y}&lt;br&gt;'+ '&lt;b&gt;Year&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Percent&lt;/b&gt;: %{z}%')fig.layout.annotations += fig2.layout.annotationsfig.add_annotation(dict(font=dict(size=14), x=0.9, y=-0.25, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 3.1.4 Age transformation > Age change in World and East Asia by year: Stacked scatter plot In the case of Age data, there is no 2017 data. 70% of the World respondents said 20s to 30s. 70% of East Asia respondents said 20s to 30s. The number of respondents increases, but the ratio seems to have stabilized. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224#data preprocessing#WorldAge21_W = df21.loc[:,['Q3','Q1', 'year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'age'}).fillna('etc')Age20_W = df20.loc[:,['Q3','Q1','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'age'}).fillna('etc')Age19_W = df19.loc[:,['Q3','Q1','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'age'}).fillna('etc')Age18_W = df18.loc[:,['Q3','Q2','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q2':'age'}).fillna('etc')Age5y_W= pd.concat([Age21_W, Age20_W, Age19_W, Age18_W])Age5y_W= (Age5y_W.replace(['60-69', '70+', '70-79', '80+'], '60+') .replace(['22-24', '25-29'], '22-29') .replace(['30-34', '35-39'], '30-39') .replace(['40-44', '45-49'], '40-49') .replace(['50-54', '55-59'], '50-59') .groupby(['year', 'age']) .size() .reset_index() .rename(columns = {0:&quot;Count&quot;}))Age21_percent_W = Age5y_W[Age5y_W['year'] == &quot;2021&quot;].reset_index(drop = True)Age21_percent_W['percentage'] = Age21_percent_W[&quot;Count&quot;] / Age21_percent_W[&quot;Count&quot;].sum()Age21_percent_W['%'] = np.round(Age21_percent_W['percentage'] * 100, 1)Age20_percent_W = Age5y_W[Age5y_W['year'] == &quot;2020&quot;].reset_index(drop = True)Age20_percent_W['percentage'] = Age20_percent_W[&quot;Count&quot;] / Age20_percent_W[&quot;Count&quot;].sum()Age20_percent_W['%'] = np.round(Age20_percent_W['percentage'] * 100, 1)Age19_percent_W = Age5y_W[Age5y_W['year'] == &quot;2019&quot;].reset_index(drop = True)Age19_percent_W['percentage'] = Age19_percent_W[&quot;Count&quot;] / Age19_percent_W[&quot;Count&quot;].sum()Age19_percent_W['%'] = np.round(Age19_percent_W['percentage'] * 100, 1)Age18_percent_W = Age5y_W[Age5y_W['year'] == &quot;2018&quot;].reset_index(drop = True)Age18_percent_W['percentage'] = Age18_percent_W[&quot;Count&quot;] / Age18_percent_W[&quot;Count&quot;].sum()Age18_percent_W['%'] = np.round(Age18_percent_W['percentage'] * 100, 1)Age5y_percent_W = pd.concat([Age18_percent_W, Age19_percent_W, Age20_percent_W, Age21_percent_W], ignore_index = True)Age5y_percent_W= pd.pivot(Age5y_percent_W, index = &quot;year&quot;, columns = 'age', values = &quot;%&quot;).reset_index()Age5y_percent_WAge21 = df21_Ea.loc[:,['Q3','Q1', 'year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'age'}).fillna('etc')Age20 = df20_Ea.loc[:,['Q3','Q1','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'age'}).fillna('etc')Age19 = df19_Ea.loc[:,['Q3','Q1','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'age'}).fillna('etc')Age18 = df18_Ea.loc[:,['Q3','Q2','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q2':'age'}).fillna('etc')Age5y= pd.concat([Age21, Age20, Age19, Age18])Age5y= (Age5y.replace(['60-69', '70+', '70-79', '80+'], '60+') .replace(['22-24', '25-29'], '22-29') .replace(['30-34', '35-39'], '30-39') .replace(['40-44', '45-49'], '40-49') .replace(['50-54', '55-59'], '50-59') .groupby(['year', 'age']) .size() .reset_index() .rename(columns = {0:&quot;Count&quot;}))#EastAsiaAge21_percent = Age5y[Age5y['year'] == &quot;2021&quot;].reset_index(drop = True)Age21_percent['percentage'] = Age21_percent[&quot;Count&quot;] / Age21_percent[&quot;Count&quot;].sum()Age21_percent['%'] = np.round(Age21_percent['percentage'] * 100, 1)Age21_percentAge20_percent = Age5y[Age5y['year'] == &quot;2020&quot;].reset_index(drop = True)Age20_percent['percentage'] = Age20_percent[&quot;Count&quot;] / Age20_percent[&quot;Count&quot;].sum()Age20_percent['%'] = np.round(Age20_percent['percentage'] * 100, 1)Age20_percentAge19_percent = Age5y[Age5y['year'] == &quot;2019&quot;].reset_index(drop = True)Age19_percent['percentage'] = Age19_percent[&quot;Count&quot;] / Age19_percent[&quot;Count&quot;].sum()Age19_percent['%'] = np.round(Age19_percent['percentage'] * 100, 1)Age19_percentAge18_percent = Age5y[Age5y['year'] == &quot;2018&quot;].reset_index(drop = True)Age18_percent['percentage'] = Age18_percent[&quot;Count&quot;] / Age18_percent[&quot;Count&quot;].sum()Age18_percent['%'] = np.round(Age18_percent['percentage'] * 100, 1)Age18_percentAge5y_percent = pd.concat([Age18_percent, Age19_percent, Age20_percent, Age21_percent], ignore_index = True)Age5y_percent= pd.pivot(Age5y_percent, index = &quot;year&quot;, columns = 'age', values = &quot;%&quot;).reset_index()Age5y_percentAge5y_percent_order = Age5y_percent_W['year'].tolist()Age5y_order = Age5y_W['age'].unique().tolist()#graph1fig = go.Figure()fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent_W['18-21'].tolist(), mode = &quot;lines&quot;, name = '18-21', line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#F2798F'))fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent_W['22-29'].tolist(), mode = &quot;lines&quot;, name = &quot;20s&quot;, line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#88BFBA'))fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent_W['30-39'].tolist(), mode = &quot;lines&quot;, name = &quot;30s&quot;, line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#CDD9A3'))fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent_W['40-49'].tolist(), mode = &quot;lines&quot;, name = &quot;40s&quot;, line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#F28705'))fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent_W['50-59'].tolist(), mode = &quot;lines&quot;, name = &quot;50s&quot;, line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#D9946C'))fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent_W['60+'].tolist(), mode = &quot;lines&quot;, name = &quot;60s&lt;&quot;, line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#F2D64B'))fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{y}%&lt;br&gt;'+ '&lt;b&gt;Year&lt;/b&gt;: %{x}&lt;br&gt;')fig.update_layout(yaxis_range = (0, 100), height=500, width=700, title_text=&quot;&lt;b&gt;World&lt;/b&gt;&quot;, title_font_size=20, title_x=0.5)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()#graph2Age5y_percent_order = Age5y_percent['year'].tolist()Age5y_order = Age5y['age'].unique().tolist()fig = go.Figure()fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent['18-21'].tolist(), mode = &quot;lines&quot;, name = '18-21', line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#F2798F'))fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent['22-29'].tolist(), mode = &quot;lines&quot;, name = &quot;20s&quot;, line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#88BFBA'))fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent['30-39'].tolist(), mode = &quot;lines&quot;, name = &quot;30s&quot;, line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#CDD9A3'))fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent['40-49'].tolist(), mode = &quot;lines&quot;, name = &quot;40s&quot;, line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#F28705'))fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent['50-59'].tolist(), mode = &quot;lines&quot;, name = &quot;50s&quot;, line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#D9946C'))fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent['60+'].tolist(), mode = &quot;lines&quot;, name = &quot;60s&lt;&quot;, line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#F2D64B'))fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{y}%&lt;br&gt;'+ '&lt;b&gt;Year&lt;/b&gt;: %{x}&lt;br&gt;')fig.update_layout(yaxis_range = (0, 100), height=500, width=700, title_text=&quot;&lt;b&gt;East Asia&lt;/b&gt;&quot;, title_font_size=20, title_x=0.5)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 17'East Asia Age Ratio: Heat Map East Asia : 50% or more. Those in their 20s and 30s. Korea: Those in their 20s are the highest. The number of respondents in their 50s and older is also large. Taiwan : The number of respondents in their 30s and older is relatively small. China: 70% or more of respondents in their 30s or younger. Related to life expectancy? Japan: Like an aging country, all ages are evenly distributed. Even if you’re older, there are many respondents to Kaggle. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#data processingdf21Age_Ea = df21_Ea.loc[:,['Q3','Q1']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'2021'}).fillna('etc')df21Age_Ea=(df21Age_Ea.replace(['60-69', '70+', '70-79', '80+'], '60+') .replace(['22-24', '25-29'], '22-29') .replace(['30-34', '35-39'], '30-39') .replace(['40-44', '45-49'], '40-49') .replace(['50-54', '55-59'], '50-59'))# 연령-지역 %dfKo_Age21= df21Age_Ea[df21Age_Ea['East_Asia']=='South Korea']dfKo_Age21_per=dfKo_Age21['2021'].value_counts().to_frame().reset_index()dfKo_Age21_per['South Korea']=((dfKo_Age21_per['2021'] / len(dfKo_Age21))*100).round(2)dfTw_Age21= df21Age_Ea[df21Age_Ea['East_Asia']=='Taiwan']dfTw_Age21_per=dfTw_Age21['2021'].value_counts().to_frame().reset_index()dfTw_Age21_per['Taiwan']=((dfTw_Age21_per['2021'] / len(dfTw_Age21))*100).round(2)dfTw_Age21_perdfCh_Age21= df21Age_Ea[df21Age_Ea['East_Asia']=='China']dfCh_Age21_per=dfCh_Age21['2021'].value_counts().to_frame().reset_index()dfCh_Age21_per['China']=((dfCh_Age21_per['2021'] / len(dfCh_Age21))*100).round(2)dfCh_Age21_perdf21Age_Ea.head()dfJp_Age21= df21Age_Ea[df21Age_Ea['East_Asia']=='Japan']dfJp_Age21_per=dfJp_Age21['2021'].value_counts().to_frame().reset_index()dfJp_Age21_per['Japan']=((dfJp_Age21_per['2021'] / len(dfJp_Age21))*100).round(2)dfJp_Age21_permerge1= pd.merge(dfKo_Age21_per,dfTw_Age21_per, on='index', how='outer')merge2= pd.merge(dfCh_Age21_per,dfJp_Age21_per, on='index', how='outer')merge= pd.merge(merge1,merge2, on='index', how='outer').fillna(0).sort_values(by=['index'],ascending=True)#graphx1=['South Korea','Taiwan','China','Japan']y1=merge.sort_values(by=['index'], ascending=True)['index'].tolist()z1=merge.iloc[:,[2,4,6,8]].to_numpy()fig = go.Figure(data=go.Heatmap( z=z1, x=x1, y=y1, hoverongaps = True, opacity=1.0, xgap=2.5, ygap=2.5))fig = ff.create_annotated_heatmap(z1, x = x1, y = y1, colorscale='sunset')fig.update_layout(height=500, width=600, title_text=&quot;&lt;b&gt;East Asia Age (2021)&lt;/b&gt;&quot;, title_font_size=20, title_x=0.5)fig.update_traces(hovertemplate='&lt;b&gt;Age&lt;/b&gt;: %{y}&lt;br&gt;'+ '&lt;b&gt;Country&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Percent&lt;/b&gt;: %{z}%')fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 17’East Asia’s age ratio: Box plot 2017: Data is not a section but an individual number. If you divide the interval, you can add it to the previous graph. It was data that I could draw a bar plot, so I drew it. You can see a 100-year-old in China, but they don’t remove missing values on purpose. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# 연도별 나이 df21Age_Ea = df21_Ea.loc[:,['Q3','Q1']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'2021'}).fillna('etc')df20Age_Ea = df20_Ea.loc[:,['Q3','Q1']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'2020'}).fillna('etc')df19Age_Ea = df19_Ea.loc[:,['Q3','Q1']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'2019'}).fillna('etc')df18Age_Ea = df18_Ea.loc[:,['Q3','Q2']].reset_index().rename(columns={'Q3':'East_Asia', 'Q2':'2018'}).fillna('etc')df17Age_Ea = df17_Ea.loc[:,['Country','Age']].reset_index().rename(columns={'Country':'East_Asia', 'Age':'2017'}).fillna('etc')#data frame 정리dfAge21 =df21Age_Ea.groupby(['East_Asia','2021']).size().reset_index().rename(columns = {0:&quot;Count&quot;})dfAge20 =df20Age_Ea.groupby(['East_Asia','2020']).size().reset_index().rename(columns = {0:&quot;Count&quot;})dfAge19 =df19Age_Ea.groupby(['East_Asia','2019']).size().reset_index().rename(columns = {0:&quot;Count&quot;})dfAge18 =df18Age_Ea.groupby(['East_Asia','2018']).size().reset_index().rename(columns = {0:&quot;Count&quot;})dfAge17 =(df17Age_Ea.groupby(['East_Asia','2017']) .size().reset_index().rename(columns = {0:&quot;Count&quot;}))#graphfig = go.Figure()x = ['China','Japan','South Korea','Taiwan']fig.add_trace(go.Box( y=dfAge17['2017'][dfAge17['East_Asia']==&quot;Japan&quot;].to_numpy(), name='Japan', marker=dict(color='#CDD9A3')))fig.add_trace(go.Box(y=dfAge17['2017'][dfAge17['East_Asia']==&quot;China&quot;].to_numpy(), name='China', marker=dict(color='#88BFBA')))fig.add_trace(go.Box(y=dfAge17['2017'][dfAge17['East_Asia']==&quot;South Korea&quot;].to_numpy(), name='South Korea', marker=dict(color='#F2798F')))fig.add_trace(go.Box(y=dfAge17['2017'][dfAge17['East_Asia']==&quot;Taiwan&quot;].to_numpy(), name='Taiwan', marker=dict(color='#F28705' ),))fig.update_layout(yaxis = dict(range=[0, 120]))fig.update_layout(yaxis_range = (0, 110), height=600, width=700, title_text=&quot;&lt;b&gt;Age in East Asia (2017)&lt;/b&gt;&quot;, title_font_size=20, margin = dict(t=100, l=50, r=50, b=100), title_x=0.5)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;v&quot;, yanchor=&quot;bottom&quot;, y=0.8, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 3.1.5 Degree transformation World job ratio in each country: pie plot World: 90% or higher Bachelor’s degree East Asia: 85% bachelor’s degree or higher 12345678910111213141516171819202122232425262728293031323334353637383940414243#data preprocessingdegree_wo = (df21['Q4'] .replace(['No formal education past high school', 'Some college/university study without earning a bachelor’s degree'],'~college') .replace(['Doctoral degree', 'Professional doctorate'],'Doctoral degree~') .value_counts().to_frame())degree_ea = (df21_Ea['Q4'] .replace(['No formal education past high school', 'Some college/university study without earning a bachelor’s degree'],'~college') .replace(['Doctoral degree', 'Professional doctorate'],'Doctoral degree~') .value_counts().to_frame())#graphcolors = ['#F2798F','#88BFBA', '#CDD9A3', '#F28705', '#D9946C']fig = make_subplots(rows=1, cols=2, specs=[[{'type':'pie'}, {'type':'pie'}]], subplot_titles=(&quot;World&quot;, &quot;East Asia&quot;))fig.add_trace(go.Pie(marker=dict(colors=colors), labels=degree_wo.index, values=degree_wo['Q4'].to_numpy(), name=&quot;World&quot;), 1, 1)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=degree_ea.index, values=degree_ea['Q4'].to_numpy(), name=&quot;East Asia&quot;), 1, 2)fig.update_traces(hole=.0, hoverinfo=&quot;label+percent+name&quot;)fig.update_layout(title='&lt;b&gt;World vs East Asia&lt;/b&gt;',title_font_size=22, margin = dict(t=200, l=30, r=0, b=200), height=700, width=700)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.1, xanchor=&quot;right&quot;, x=1.0))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Percentage of East Asia degrees by year: sunburst plot The highest percentage of respondents with master’s degrees per year 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#data preprocessingdf21_Ea_degree=(df21_Ea['Q4'].replace(['No formal education past high school', 'Some college/university study without earning a bachelor’s degree'],'~college') .replace(['Doctoral degree','Professional doctorate'],'Doctoral degree~') .value_counts().to_frame().rename(columns={'Q4':'2021'}))df20_Ea_degree=(df20_Ea['Q4'].replace(['No formal education past high school', 'Some college/university study without earning a bachelor’s degree'],'~college') .replace(['Doctoral degree', 'Professional degree'],'Doctoral degree~') .value_counts().to_frame().rename(columns={'Q4':'2020'}))df19_Ea_degree=(df19_Ea['Q4'].replace(['No formal education past high school','Some college/university study without earning a bachelor’s degree'],'~college') .replace(['Doctoral degree', 'Professional degree'],'Doctoral degree~') .value_counts().to_frame().rename(columns={'Q4':'2019'}))df18_Ea_degree=(df18_Ea['Q4'].replace(['No formal education past high school', 'Some college/university study without earning a bachelor’s degree'],'~college') .replace(['Doctoral degree', 'Professional degree'],'Doctoral degree~') .value_counts().to_frame().rename(columns={'Q4':'2018'}))df17_Ea_degree=(df17_Ea['FormalEducation'] .replace(['No formal education past high school', 'Some college/university study without earning a bachelor’s degree'],'~college') .replace(['Doctoral degree', 'Professional degree'],'Doctoral degree~') .value_counts().to_frame() .rename(columns={'FormalEducation':'2017'} ,index = {'I did not complete any formal education past high school':'No formal education past high school','Master\\'s degree':'Master’s degree','Bachelor\\'s degree':'Bachelor’s degree','Some college/university study without earning a bachelor\\'s degree':'Some college/university study without earning a bachelor’s degree'}) ) concat1 = pd.concat([df21_Ea_degree,df20_Ea_degree],axis=1, join='outer') concat2 = pd.concat([df19_Ea_degree,df18_Ea_degree],axis=1, join='outer') concat3 = pd.concat([concat1,concat2],axis=1, join='outer') df21_Ea_degree_yearly_=concat3.join(df17_Ea_degree).fillna(0).transpose() #.transpose() 행 열 바꾸기df21_Ea_degree_yearly=df21_Ea_degree_yearly_.stack().to_frame().reset_index().rename(columns={'level_0':'year','level_1':'degree',0:'value'})df21_Ea_degree_yearly#graphfig = px.sunburst(df21_Ea_degree_yearly, path=['year','degree'], values=df21_Ea_degree_yearly['value'].tolist())fig.update_layout( margin = dict(t=10, l=10, r=10, b=10),colorway=(&quot;#F2798F&quot;,&quot;#88BFBA&quot;,&quot;#CDD9A3&quot;,'#F28705','#D9946C'))fig.update_layout(title='&lt;b&gt; Degree&lt;/b&gt;',title_font_size=25, margin = dict(t=100, l=100, r=50, b=100), height=700, width=700)fig.update_traces(hovertemplate='&lt;b&gt;Name&lt;/b&gt;: %{id}&lt;br&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{value}&lt;br&gt;'+ '&lt;b&gt;Parent&lt;/b&gt;: %{parent}') fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Plus we could see the advantages of Plotly in this graph. Matplotlib draws a static graph, but Plotly can dynamically click and move, and it supports zooming out, zooming in, and downloading graphs. Because all of our graphs are made of plotly, the viewer can represent or remove items in the graph if desired. With a click East Asia Degree Ratio: Bar plot 40% of master’s degrees or higher, and respondents have a high educational background. China and Japan have similar trends to East Asia and the World. The number of people itself is large, so a representative trend seems to appear here. However, it is noteworthy that the two countries have the same tendency. Korea: It is the only country among the four countries with a high degree of education below Ph.D., bachelor’s degree, and junior college. Only masters are low. (Polarization of education?) Taiwan: 1st place in master’s ratio (55%), 2nd place in Ph.D. or higher (13.8%). = The highest level of education. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091#data preprocessingdf21Edu_Ea = df21_Ea.loc[:,['Q3','Q4']].reset_index().rename(columns={'Q3':'East_Asia', 'Q4':'Dgree'}).fillna('etc')df21Edu_Ea =(df21Edu_Ea.replace({'I prefer not to answer':'etc'}).replace(['No formal education past high school', 'Some college/university study without earning a bachelor’s degree'],'~college') .replace(['Doctoral degree', 'Professional doctorate'],'Doctoral degree~'))df21Edu_Ea= (df21Edu_Ea .groupby(['East_Asia', 'Dgree']) .size() .reset_index() .rename(columns = {0:&quot;Count&quot;}))# 연령-지역 %dfKo_Edu21= df21Edu_Ea[df21Edu_Ea['East_Asia']=='South Korea']dfKo_Edu21['%']=((dfKo_Edu21['Count'] / dfKo_Edu21['Count'].sum()*100)).round(2)dfKo_Edu21=dfKo_Edu21.sort_values(by='%', ascending=False)dfTw_Edu21= df21Edu_Ea[df21Edu_Ea['East_Asia']=='Taiwan']dfTw_Edu21['%']=((dfTw_Edu21['Count'] / dfTw_Edu21['Count'].sum())*100).round(2)dfTw_Edu21=dfTw_Edu21.sort_values(by='%', ascending=False)dfCh_Edu21= df21Edu_Ea[df21Edu_Ea['East_Asia']=='China']dfCh_Edu21['%']=((dfCh_Edu21['Count'] / dfCh_Edu21['Count'].sum())*100).round(2)dfCh_Edu21=dfCh_Edu21.sort_values(by='%', ascending=False)dfJp_Edu21= df21Edu_Ea[df21Edu_Ea['East_Asia']=='Japan']dfJp_Edu21['%']=((dfJp_Edu21['Count'] / dfJp_Edu21['Count'].sum())*100).round(2)dfJp_Edu21=dfJp_Edu21.sort_values(by='%', ascending=False)# #data 완성# dfEdu_21_per = pd.concat([dfKo_Edu21, dfTw_Edu21, dfCh_Edu21, dfJp_Edu21], ignore_index = True)# dfEdu_21_per= pd.pivot(dfEdu_21_per, index = &quot;Dgree&quot;, columns = 'East_Asia', values = &quot;%&quot;).reset_index()# dfEdu_21_per#graphfig = make_subplots(rows = 1, cols = 4, shared_yaxes=True, vertical_spacing = 0.05)fig.add_trace(go.Bar(x = dfCh_Edu21['Dgree'], y = dfCh_Edu21['%'], text = dfCh_Edu21['%'].astype(str) + &quot;%&quot;, textposition='outside', name='China', marker_color='#88BFBA'), row = 1, col = 1)fig.add_trace(go.Bar(x = dfJp_Edu21['Dgree'], y = dfJp_Edu21['%'], text = dfJp_Edu21['%'].astype(str) + &quot;%&quot;, textposition='outside', name='Japan', marker_color='#CDD9A3'), row = 1, col = 2)fig.add_trace(go.Bar(x = dfKo_Edu21['Dgree'], y = dfKo_Edu21['%'], text = dfKo_Edu21['%'].astype(str) + &quot;%&quot;, textposition='outside', name='South Korea', marker_color='#F28705'), row = 1, col = 3)fig.add_trace(go.Bar(x = dfTw_Edu21['Dgree'], y = dfTw_Edu21['%'], text = dfTw_Edu21['%'].astype(str) + &quot;%&quot;, textposition='outside', name='Taiwan', marker_color='#D9946C'), row = 1, col = 4)fig.update_layout(showlegend=True,title='&lt;b&gt;Degree in East Asia&lt;/b&gt;',title_font_size=22, margin = dict(t=200, l=100, r=50, b=200), height=700, width=700)fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{y}%&lt;br&gt;'+ '&lt;b&gt;Degree&lt;/b&gt;: %{x}&lt;br&gt;')fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.1, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 3.1.6 Experience transformation Trends in World & East Asia Career: Stacked Scatter plot - < 2 years: 50% of the total. - 3-5 years: Decrease in the world, maintain East Asia ratio - 2021 'etc data' disappeared. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120#Exp data 전처리# Exp 뽑아오기Exp21_Wo = df21.loc[:,['Q3','Q6', 'year']].reset_index().rename(columns={'Q3':'Country', 'Q6':'Exp'}).fillna('etc')Exp20_Wo = df20.loc[:,['Q3','Q6','year']].reset_index().rename(columns={'Q3':'Country', 'Q6':'Exp'}).fillna('etc')Exp19_Wo = df19.loc[:,['Q3','Q15','year']].reset_index().rename(columns={'Q3':'Country', 'Q15':'Exp'}).fillna('etc')Exp18_Wo = df18.loc[:,['Q3','Q8','year']].reset_index().rename(columns={'Q3':'Country', 'Q8':'Exp'}).fillna('etc')Exp17_Wo = df17.loc[:,['Country','Tenure', 'year']].reset_index().rename(columns={'Country':'Country', 'Tenure':'Exp'}).fillna('etc')Exp21_Wo= Exp21_Wo.replace({'I have never written code': '&lt; 1 years', '1-3 years': '1-2 years'}).replace(['10-20 years', '20+ years'], '10+ years' )Exp20_Wo= Exp20_Wo.replace({'I have never written code': '&lt; 1 years'}).replace(['10-20 years', '20+ years'], '10+ years' )Exp19_Wo= Exp19_Wo.replace({'I have never written code': '&lt; 1 years'}).replace(['10-20 years', '20+ years'], '10+ years' )Exp18_Wo= (Exp18_Wo.replace({'0-1': '&lt; 1 years', '1-2': '1-2 years', '5-10':'5-10 years'}) .replace(['2-3', '3-4', '4-5'],'3-5 years') .replace(['10-15', '15-20','20-25', '30 +','25-30'],'10+ years'))Exp17_Wo=(Exp17_Wo.replace({'More than 10 years':'10+ years', '1 to 2 years':'1-2 years', 'Less than a year':'&lt; 1 years', '3 to 5 years':'3-5 years', &quot;I don't write code to analyze data&quot;:'&lt; 1 years', '6 to 10 years':'5-10 years'})) #data 정제(한꺼번에 이름바꾸기)Exp5y_Wo= pd.concat([Exp17_Wo, Exp18_Wo, Exp19_Wo, Exp20_Wo, Exp21_Wo]).reset_index()Exp5y_Wo=(Exp5y_Wo.groupby(['year', 'Exp']) .size() .reset_index() .rename(columns = {0:&quot;Count&quot;}))#percent data 넣기Exp21_per_W= Exp5y_Wo[Exp5y_Wo['year'] == &quot;2021&quot;].reset_index(drop = True)Exp21_per_W['percentage'] = Exp21_per_W[&quot;Count&quot;] / Exp21_per_W[&quot;Count&quot;].sum()Exp21_per_W['%'] = np.round(Exp21_per_W['percentage'] * 100, 1)Exp20_per_W = Exp5y_Wo[Exp5y_Wo['year'] == &quot;2020&quot;].reset_index(drop = True)Exp20_per_W['percentage'] = Exp20_per_W[&quot;Count&quot;] / Exp20_per_W[&quot;Count&quot;].sum()Exp20_per_W['%'] = np.round(Exp20_per_W['percentage'] * 100, 1)Exp19_per_W = Exp5y_Wo[Exp5y_Wo['year'] == &quot;2019&quot;].reset_index(drop = True)Exp19_per_W['percentage'] = Exp19_per_W[&quot;Count&quot;] / Exp19_per_W[&quot;Count&quot;].sum()Exp19_per_W['%'] = np.round(Exp19_per_W['percentage'] * 100, 1)Exp18_per_W = Exp5y_Wo[Exp5y_Wo['year'] == &quot;2018&quot;].reset_index(drop = True)Exp18_per_W['percentage'] = Exp18_per_W[&quot;Count&quot;] / Exp18_per_W[&quot;Count&quot;].sum()Exp18_per_W['%'] = np.round(Exp18_per_W['percentage'] * 100, 1)Exp17_per_W = Exp5y_Wo[Exp5y_Wo['year'] == &quot;2017&quot;].reset_index(drop = True)Exp17_per_W['percentage'] = Exp17_per_W[&quot;Count&quot;] / Exp17_per_W[&quot;Count&quot;].sum()Exp17_per_W['%'] = np.round(Exp17_per_W['percentage'] * 100, 1)#data 완성Exp5y_per_W = pd.concat([Exp17_per_W, Exp18_per_W, Exp19_per_W, Exp20_per_W, Exp21_per_W], ignore_index = True)Exp5y_per_W= pd.pivot(Exp5y_per_W, index = &quot;year&quot;, columns = 'Exp', values = &quot;%&quot;).reset_index()Exp5y_per_W.fillna('0')Exp5y_percent_order = Exp5y_per_W['year'].tolist()fig = go.Figure()fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_per_W['&lt; 1 years'].tolist(), mode = &quot;lines&quot;, name = '&lt; 1 years', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#F2798F'))fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_per_W['1-2 years'].tolist(), mode = &quot;lines&quot;, name = '1-2 years', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#88BFBA'))fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_per_W['3-5 years'].tolist(), mode = &quot;lines&quot;, name = '3-5 years', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#CDD9A3'))fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_per_W['5-10 years'].tolist(), mode = &quot;lines&quot;, name = '5-10 years', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#F28705'))fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_per_W['10+ years'].tolist(), mode = &quot;lines&quot;, name = '10+ years', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#D9946C'))fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_per_W['etc'].tolist(), mode = &quot;lines&quot;, name = 'etc', line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#F2D64B'))fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{y}%&lt;br&gt;')fig.update_layout(yaxis_range = (0, 100), title_font_size=20, title_text=&quot;&lt;b&gt;Experience in world&lt;/b&gt;&quot;, height=500, width=700, title_x=0.5)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135#data preprocessingExp21 = df21_Ea.loc[:,['Q3','Q6', 'year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q6':'Exp'}).fillna('etc')Exp20 = df20_Ea.loc[:,['Q3','Q6','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q6':'Exp'}).fillna('etc')Exp19 = df19_Ea.loc[:,['Q3','Q15','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q15':'Exp'}).fillna('etc')Exp18 = df18_Ea.loc[:,['Q3','Q8','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q8':'Exp'}).fillna('etc')Exp17 = df17_Ea.loc[:,['Country','Tenure', 'year']].reset_index().rename(columns={'Country':'East_Asia', 'Tenure':'Exp'}).fillna('etc')Exp21Uni=['3-5 years', '&lt; 1 years', '1-3 years', '10-20 years', 'I have never written code', '5-10 years', '20+ years']Exp20Uni= ['3-5 years', '&lt; 1 years', '5-10 years', '1-2 years', 'etc', '20+ years', '10-20 years', 'I have never written code']Exp19Uni=['1-2 years', '5-10 years', '&lt; 1 years', 'I have never written code', '3-5 years', '10-20 years', '20+ years', 'etc']Exp18Uni=['0-1', '2-3', '1-2', '5-10', '3-4', '10-15', '15-20', '4-5', '20-25', '30 +', 'etc', '25-30']Exp17Uni=['More than 10 years', '1 to 2 years', 'etc', 'Less than a year', '3 to 5 years', &quot;I don't write code to analyze data&quot;, '6 to 10 years']Exp21= Exp21.replace({'I have never written code': '&lt; 1 years', '1-3 years': '1-2 years'}).replace(['10-20 years', '20+ years'], '10+ years' )Exp20= Exp20.replace({'I have never written code': '&lt; 1 years'}).replace(['10-20 years', '20+ years'], '10+ years' )Exp19= Exp19.replace({'I have never written code': '&lt; 1 years'}).replace(['10-20 years', '20+ years'], '10+ years' )Exp18= (Exp18.replace({'0-1': '&lt; 1 years', '1-2': '1-2 years', '5-10':'5-10 years'}) .replace(['2-3', '3-4', '4-5'],'3-5 years') .replace(['10-15', '15-20','20-25', '30 +','25-30'],'10+ years'))Exp17=(Exp17.replace({'More than 10 years':'10+ years', '1 to 2 years':'1-2 years', 'Less than a year':'&lt; 1 years', '3 to 5 years':'3-5 years', &quot;I don't write code to analyze data&quot;:'&lt; 1 years', '6 to 10 years':'5-10 years'})) Exp5y= pd.concat([Exp17, Exp18, Exp19, Exp20, Exp21]).reset_index()Exp5y=(Exp5y.groupby(['year', 'Exp']) .size() .reset_index() .rename(columns = {0:&quot;Count&quot;}))Exp21_percent = Exp5y[Exp5y['year'] == &quot;2021&quot;].reset_index(drop = True)Exp21_percent['percentage'] = Exp21_percent[&quot;Count&quot;] / Exp21_percent[&quot;Count&quot;].sum()Exp21_percent['%'] = np.round(Exp21_percent['percentage'] * 100, 1)Exp21_percentExp20_percent = Exp5y[Exp5y['year'] == &quot;2020&quot;].reset_index(drop = True)Exp20_percent['percentage'] = Exp20_percent[&quot;Count&quot;] / Exp20_percent[&quot;Count&quot;].sum()Exp20_percent['%'] = np.round(Exp20_percent['percentage'] * 100, 1)Exp20_percentExp19_percent = Exp5y[Exp5y['year'] == &quot;2019&quot;].reset_index(drop = True)Exp19_percent['percentage'] = Exp19_percent[&quot;Count&quot;] / Exp19_percent[&quot;Count&quot;].sum()Exp19_percent['%'] = np.round(Exp19_percent['percentage'] * 100, 1)Exp19_percentExp18_percent = Exp5y[Exp5y['year'] == &quot;2018&quot;].reset_index(drop = True)Exp18_percent['percentage'] = Exp18_percent[&quot;Count&quot;] / Exp18_percent[&quot;Count&quot;].sum()Exp18_percent['%'] = np.round(Exp18_percent['percentage'] * 100, 1)Exp18_percentExp17_percent = Exp5y[Exp5y['year'] == &quot;2017&quot;].reset_index(drop = True)Exp17_percent['percentage'] = Exp17_percent[&quot;Count&quot;] / Exp17_percent[&quot;Count&quot;].sum()Exp17_percent['%'] = np.round(Exp17_percent['percentage'] * 100, 1)Exp17_percent#graphExp5y_percent = pd.concat([Exp17_percent, Exp18_percent, Exp19_percent, Exp20_percent, Exp21_percent], ignore_index = True)Exp5y_percent= pd.pivot(Exp5y_percent, index = &quot;year&quot;, columns = 'Exp', values = &quot;%&quot;).reset_index()Exp5y_percent.fillna('0')Exp5y_percent_order = Exp5y_percent['year'].tolist()fig = go.Figure()fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_percent['&lt; 1 years'].tolist(), mode = &quot;lines&quot;, name = '&lt; 1 years', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#F2798F'))fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_percent['1-2 years'].tolist(), mode = &quot;lines&quot;, name = '1-2 years', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#88BFBA'))fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_percent['3-5 years'].tolist(), mode = &quot;lines&quot;, name = '3-5 years', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#CDD9A3'))fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_percent['5-10 years'].tolist(), mode = &quot;lines&quot;, name = '5-10 years', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#F28705'))fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_percent['10+ years'].tolist(), mode = &quot;lines&quot;, name = '10+ years', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#D9946C'))fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_percent['etc'].tolist(), mode = &quot;lines&quot;, name = 'etc', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#F2D64B'))fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{y}%&lt;br&gt;')fig.update_layout(yaxis_range = (0, 100), title_text=&quot;&lt;b&gt;Experience in East Asia&lt;/b&gt;&quot;, height=500, width=700, title_font_size=20, title_x=0.5)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 3.1.7 Salary transformation World & East Asia Annual salary: Bar-H plot $ 200,000 ~ : World (2.9%) is more than 50% compared to East Asia (1.3%) $ ~250,000 : World (59.2%) is less than East Asia (50.3%) = East Asia’s annual salary gap between rich and poor is less. $ 25,000~60,000: The highest section in East Asia at 24%. = The annual salary section that we aim for. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103#data preprocessingdf21_salary_=df21['Q25'].value_counts().to_frame().rename(index={'$0-999':'&lt;999','&gt;$1,000,000':'1,000,000~','$500,000-999,999':'500,000-999,999'}).fillna(0)df21_Ea_salary_=df21_Ea['Q25'].value_counts().to_frame().rename(index={'$0-999':'&lt;999','&gt;$1,000,000':'1,000,000~','$500,000-999,999':'500,000-999,999'}).fillna(0)#퍼센트df21_salary__=(df21_salary_['Q25']/(df21_salary_['Q25'].sum())*100).round(1).to_frame().rename(columns={'Q25':'World'})df21_Ea_salary__=(df21_Ea_salary_['Q25']/(df21_Ea_salary_['Q25'].sum())*100).round(1).to_frame().rename(columns={'Q25':'EA'})#그룹화df21_salary=(df21_salary__.rename(index= {'1,000-1,999':'1,000-7,499', '2,000-2,999':'1,000-7,499', '3,000-3,999':'1,000-7,499', '4,000-4,999':'1,000-7,499', '5,000-7,499':'1,000-7,499'}) .rename(index={'7,500-9,999':'7,500-24,999', '10,000-14,999':'7,500-24,999', '15,000-19,999':'7,500-24,999', '20,000-24,999':'7,500-24,999' }) .rename(index={'25,000-29,999':'25,000-59,999', '30,000-39,999':'25,000-59,999', '40,000-49,999':'25,000-59,999', '50,000-59,999':'25,000-59,999'}) .rename(index={'60,000-69,999':'60,000-99,999', '70,000-79,999':'60,000-99,999', '80,000-89,999':'60,000-99,999', '90,000-99,999':'60,000-99,999'}) .rename(index={'100,000-124,999':'100,000-199,999', '125,000-149,999':'100,000-199,999', '150,000-199,999':'100,000-199,999'}) .rename(index={'200,000-249,999':'200,000-1,000,000~', '250,000-299,999':'200,000-1,000,000~', '300,000-499,999':'200,000-1,000,000~', '500,000-999,999':'200,000-1,000,000~', '1,000,000~':'200,000-1,000,000~'}) .reset_index().groupby('index').sum() .reindex(index = ['&lt;999', '1,000-7,499', '7,500-24,999', '25,000-59,999', '60,000-99,999', '100,000-199,999', '200,000-1,000,000~']))df21_Ea_salary=(df21_Ea_salary__.rename(index= {'1,000-1,999':'1,000-7,499', '2,000-2,999':'1,000-7,499', '3,000-3,999':'1,000-7,499', '4,000-4,999':'1,000-7,499', '5,000-7,499':'1,000-7,499'}) .rename(index={'7,500-9,999':'7,500-24,999', '10,000-14,999':'7,500-24,999', '15,000-19,999':'7,500-24,999', '20,000-24,999':'7,500-24,999'}) .rename(index={'25,000-29,999':'25,000-59,999', '30,000-39,999':'25,000-59,999', '40,000-49,999':'25,000-59,999', '50,000-59,999':'25,000-59,999'}) .rename(index={'60,000-69,999':'60,000-99,999', '70,000-79,999':'60,000-99,999', '80,000-89,999':'60,000-99,999', '90,000-99,999':'60,000-99,999'}) .rename(index={'100,000-124,999':'100,000-199,999', '125,000-149,999':'100,000-199,999', '150,000-199,999':'100,000-199,999'}) .rename(index={'200,000-249,999':'200,000-1,000,000~', '250,000-299,999':'200,000-1,000,000~', '300,000-499,999 ':'200,000-1,000,000~', '500,000-999,999':'200,000-1,000,000~', '1,000,000~':'200,000-1,000,000~'}) .reset_index().groupby('index').sum() .reindex(index = ['&lt;999', '1,000-7,499', '7,500-24,999', '25,000-59,999', '60,000-99,999', '100,000-199,999', '200,000-1,000,000~']))#graphWorld = df21_salary['World'].valuesEast_Asia = df21_Ea_salary['EA'].valuesy = df21_salary.indexfig = go.Figure(data=[ go.Bar(y=y, x=World, orientation='h', name=&quot;World&quot;, base=0, hovertemplate='&lt;b&gt;World&lt;/b&gt;: %{x}%&lt;br&gt;', marker_color='#979DA6'), go.Bar(y=y, x=-East_Asia, orientation='h', name=&quot;East Asia&quot;, base=0, hovertemplate='&lt;b&gt;East Asia&lt;/b&gt;: %{x}%&lt;br&gt;', marker_color='#F2D64B') ])fig.update_layout(barmode='stack')fig.update_layout( margin=dict(l=200, r=0, t=200, b=100), autosize=False, title_text=&quot;&lt;b&gt; Salary in East Asia vs World&lt;/b&gt;&quot;, height=600, width=700, title_font_size=20, title_x=0.5)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.1, xanchor=&quot;right&quot;, x=1))fig.show() World experience and annual salary: Heat Map Relatively **positive correlation.** Even with 5-10 years of experience, more than 45% has an annual salary of less than $20,000 With more than 10 years of experience, more than 30% receive an annual salary of $100,000. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990#data preprocessingSalExp21= df21.loc[:, ['region', 'Q25', 'Q6']].rename(columns={'Q6':'Exp', 'Q25':'Salary'})SalExp21=(SalExp21 .replace(['0-999','$0-999','0'], '&lt; 999') .replace({'&gt;$1,000,000':'200,000~'}) .replace(['1,000-1,999','2,000-2,999','3,000-3,999', '4,000-4,999','5,000-7,499','7,500-9,999','10,000-14,999', '15,000-19,999'],'1,000-20,000') .replace(['20,000-24,999''25,000-29,999','30,000-39,999', '40,000-49,999', '50,000-59,999'],'20,000-59,999') .replace(['60,000-69,999', '70,000-79,999', '80,000-89,999', '90,000-99,999'], '60,000-99,999') .replace(['100,000-124,999', '300,000-499,999', '125,000-149,999', '125,000-149,999', '150,000-199,999'],'100,000-199,999') .replace(['200,000-249,999', '250,000-299,999', '1,000,000','$500,000-999,999'], '200,000~') .replace({'I have never written code': '&lt; 1 years'}) .replace(['10-20 years', '20+ years'], '10+ years' ) )sal_order=['&lt; 999', '1,000-20,000', '20,000-59,999', '60,000-99,999','100,000-199,999', '200,000~']Exp21_order=['&lt; 1 years', '1-3 years','3-5 years', '5-10 years', '10+ years' ]SalExp21_Ea = SalExp21[SalExp21['region'] == &quot;EastAsia&quot;].reset_index(drop = True)SalExp21_Ea=(SalExp21_Ea.groupby(['Exp', 'Salary']) .size() .unstack().fillna(0).astype('int64'))SalExp21_Wo = SalExp21[SalExp21['region'] == &quot;World&quot;].reset_index(drop = True)SalExp21_Wo=(SalExp21_Wo.groupby(['Exp', 'Salary']) .size() .unstack().fillna(0).astype('int64'))SalExp21_Wo#graph#Worldz = SalExp21_Woz = z[sal_order]z = z.reindex(Exp21_order)z_data = z.apply(lambda x:np.round(x/x.sum()*100, 2), axis = 1).to_numpy() # convert to correlation matrixx = sal_ordery = Exp21_orderfig = ff.create_annotated_heatmap(z_data, x = x, y = y, colorscale = &quot;sunset&quot;)fig.update_layout( title_text=&quot;&lt;b&gt;Experience and salary in World&lt;/b&gt;&quot;, height=700, width=700, title_font_size=20, title_x=0.5, margin=dict(l=100, r=100, t=200, b=100))fig.add_annotation(dict(font=dict(size=14), x=0.85, y=-0.1, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()#East Asiaz = SalExp21_Eaz = z[sal_order]z = z.reindex(Exp21_order)z_data = z.apply(lambda x:np.round(x/x.sum(), 2), axis = 1).to_numpy() # convert to correlation matrixx = sal_ordery = Exp21_orderfig = ff.create_annotated_heatmap(z_data, x = x, y = y, colorscale = &quot;sunset&quot;)fig.update_layout(title_text=&quot;&lt;b&gt;Experience and salary in East Asia&lt;/b&gt;&quot;, height=700, width=700, title_font_size=20, title_x=0.5, margin=dict(l=100, r=100, t=200, b=100))fig.add_annotation(dict(font=dict(size=14), x=0.85, y=-0.1, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() World & East Asia Degree/Annual salary: Heat Map \\$ ~20,000 : Regardless of degree, about 40% of the annual salary is $ 20,000 or less. Guess it’s the ratio that comes from a student. $ 25,000-100,000 : Earned more than 40% with a bachelor’s degree alone in East Asia (World: less than 20%) $ 200,000~ : Even with a doctorate or higher, it is difficult to obtain it from East Asia. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798#data preprocessingSalary21= df21.loc[:, ['region', 'Q25', 'year']].rename(columns={'Q3':'Country', 'Q25':'Salary'})salary21_Index=['&lt; 999', '1,000-20,000', '20,000-59,999', '60,000-99,999','100,000-199,999', '200,000~']Salary21=(Salary21 .replace(['0-999','$0-999','0'], '&lt; 999') .replace({'&gt;$1,000,000':'200,000~'}) .replace(['1,000-1,999','2,000-2,999','3,000-3,999', '4,000-4,999','5,000-7,499','7,500-9,999','10,000-14,999', '15,000-19,999'],'1,000-20,000') .replace(['20,000-24,999''25,000-29,999','30,000-39,999', '40,000-49,999', '50,000-59,999'],'20,000-59,999') .replace(['60,000-69,999', '70,000-79,999', '80,000-89,999','90,000-99,999'], '60,000-99,999') .replace(['100,000-124,999', '300,000-499,999', '125,000-149,999', '125,000-149,999', '150,000-199,999'],'100,000-199,999') .replace(['200,000-249,999', '250,000-299,999','1,000,000','$500,000-999,999'], '200,000~')).fillna('0')sal_order=['&lt; 999', '1,000-20,000', '20,000-59,999', '60,000-99,999','100,000-199,999', '200,000~']Salary21=(Salary21.groupby(['region', 'Salary']) .size() .reset_index() .rename(columns = {0:&quot;Count&quot;}))Salary21_Ea = Salary21[Salary21['region'] == &quot;EastAsia&quot;].reset_index(drop = True)Salary21_Ea['%']=((Salary21_Ea['Count'] / Salary21_Ea['Count'].sum())*100).round(2)Salary21_Wo = Salary21[Salary21['region'] == &quot;World&quot;].reset_index(drop = True)Salary21_Wo['%']=((Salary21_Wo['Count'] / Salary21_Wo['Count'].sum())*100).round(2)Dgr_Sal_21= df21.loc[:, ['region', 'Q25', 'Q4']].rename(columns={'Q4':'Dgree', 'Q25':'Salary'})Dgr_Sal_21 = (Dgr_Sal_21.replace(['0-999','$0-999','0'], '&lt; 999') .replace({'&gt;$1,000,000':'200,000~'}) .replace(['1,000-1,999','2,000-2,999','3,000-3,999', '4,000-4,999','5,000-7,499','7,500-9,999','10,000-14,999', '15,000-19,999'],'1,000-20,000') .replace(['20,000-24,999''25,000-29,999','30,000-39,999', '40,000-49,999', '50,000-59,999'],'20,000-59,999') .replace(['60,000-69,999', '70,000-79,999', '80,000-89,999', '90,000-99,999'], '60,000-99,999') .replace(['100,000-124,999', '300,000-499,999', '125,000-149,999', '125,000-149,999','150,000-199,999'],'100,000-199,999') .replace(['200,000-249,999', '250,000-299,999','1,000,000','$500,000-999,999'], '200,000~') .replace({'I prefer not to answer':'etc'}) .replace(['No formal education past high school', 'Some college/university study without earning a bachelor’s degree'],'~college') .replace(['Doctoral degree', 'Professional doctorate'],'Doctoral degree~'))#EastAsia 뽑기Dgr_Sal_21_Ea= Dgr_Sal_21[Dgr_Sal_21['region'] == &quot;EastAsia&quot;].reset_index(drop = True)Dgr_Sal_21_Ea = Dgr_Sal_21_Ea.groupby(['Dgree', 'Salary']).size().unstack().fillna(0).astype('int64')dgree_order=[ '~college','Bachelor’s degree', 'Master’s degree', 'Doctoral degree~', 'etc']#graph#Worldz = Dgr_Sal_21.groupby(['Dgree', 'Salary']).size().unstack().fillna(0).astype('int64')z = z[sal_order]z = z.reindex(dgree_order)z_data = z.apply(lambda x:np.round(x/x.sum()*100, 2), axis = 1).to_numpy() # convert to correlation matrixx = sal_ordery = dgree_orderfig = ff.create_annotated_heatmap(z_data, x = x, y = y, colorscale = &quot;sunset&quot;)fig.update_layout( title_text=&quot;&lt;b&gt; Degree-Salary in World&lt;/b&gt;&quot;, height=700, width=700, title_font_size=20, title_x=0.5, margin=dict(l=150, r=100, t=200, b=50))fig.update_traces(hovertemplate='&lt;b&gt;Degree&lt;/b&gt;: %{y}&lt;br&gt;'+ '&lt;b&gt;Salary&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Percent&lt;/b&gt;: %{z}%')fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.1, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()#East Asiaz = Dgr_Sal_21_Eaz = z[sal_order]z = z.reindex(dgree_order)z_data = z.apply(lambda x:np.round(x/x.sum()*100, 2), axis = 1).to_numpy() # convert to correlation matrixx = sal_ordery = dgree_orderfig = ff.create_annotated_heatmap(z_data, x = x, y = y, colorscale = &quot;sunset&quot;)fig.update_layout(title_text=&quot;&lt;b&gt; Degree-Salary in East Asia&lt;/b&gt;&quot;, height=700, width=700, title_font_size=20, title_x=0.5, margin=dict(l=150, r=100, t=200, b=50))fig.update_traces(hovertemplate='&lt;b&gt;Degree&lt;/b&gt;: %{y}&lt;br&gt;'+ '&lt;b&gt;Salary&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Percent&lt;/b&gt;: %{z}%')fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.1, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 3.1.8 Language transformation World & East Asia Programming Language: Bar plot - Python: 80% of the world and 85% of East Asia use it. We've been working on the project as python, so I hope we can continue to learn python and become experienced Data Scientists! 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#data preprocessing#worldprogramming_list = [&quot;Python&quot;, &quot;R&quot;, &quot;SQL&quot;, &quot;Java&quot;, &quot;C&quot;, &quot;Bash&quot;, &quot;Javascript&quot;, &quot;C++&quot;]programming_df = pd.Series(programming_list)df_2019 = df19[df19['Q19'].isin(programming_df)]df_2020 = df20[df20['Q8'].isin(programming_df)]df_2021 = df21[df21['Q8'].isin(programming_df)]df19Lag = df_2019.loc[:, ['region', 'Q5', 'Q19', 'year']]df19Lag = df19Lag.rename(columns = {'Q19': 'Language'}, inplace = False) # To match with other datasetsdf20Lag = df_2020.loc[:, ['region', 'Q5', 'Q8', 'year']].rename(columns = {'Q8': 'Language'}, inplace = False)df21Lag = df_2021.loc[:, ['region', 'Q5', 'Q8', 'year']].rename(columns = {'Q8': 'Language'}, inplace = False)df3y_Lag = pd.concat([df19Lag, df20Lag, df21Lag])df3y_Lag = df3y_Lag.groupby(['year', 'Language']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df3y_Lag# 2019dfLang_19 = df3y_Lag[df3y_Lag['year'] == &quot;2019&quot;].reset_index(drop = True)dfLang_19['percentage'] = dfLang_19[&quot;Count&quot;] / dfLang_19[&quot;Count&quot;].sum()dfLang_19['%'] = np.round(dfLang_19['percentage'] * 100, 1)# 2020dfLang_20 = df3y_Lag[df3y_Lag['year'] == &quot;2020&quot;].reset_index(drop = True)dfLang_20['percentage'] = dfLang_20[&quot;Count&quot;] / dfLang_20[&quot;Count&quot;].sum()dfLang_20['%'] = np.round(dfLang_20['percentage'] * 100, 1)# 2021dfLang_21 = df3y_Lag[df3y_Lag['year'] == &quot;2021&quot;].reset_index(drop = True)dfLang_21['percentage'] = dfLang_21[&quot;Count&quot;] / dfLang_21[&quot;Count&quot;].sum()dfLang_21['%'] = np.round(dfLang_21['percentage'] * 100, 1)dfLang_19=dfLang_19.sort_values(by='%', ascending=False)dfLang_20=dfLang_20.sort_values(by='%', ascending=False)dfLang_21=dfLang_21.sort_values(by='%', ascending=False)#graphfig = go.Figure()fig.add_trace(go.Bar(x = dfLang_19['Language'], y = dfLang_19['%'], name = &quot;2019&quot;, text = dfLang_19['%'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#CDD9A3'))fig.add_trace(go.Bar(x = dfLang_20['Language'], y = dfLang_20['%'], name = &quot;2020&quot;, text = dfLang_20['%'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#F28705'))fig.add_trace(go.Bar(x = dfLang_21['Language'], y = dfLang_21['%'], name = &quot;2021&quot;, text = dfLang_21['%'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#88BFBA'))fig.update_layout(title='&lt;b&gt;Language in World&lt;/b&gt;',title_font_size=20, margin = dict(t=100, l=100, r=50, b=100), height=600, width=700, xaxis_title=None, yaxis_title=None)fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{y}%&lt;br&gt;'+ '&lt;b&gt;Language&lt;/b&gt;: %{x}&lt;br&gt;')fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;v&quot;, yanchor=&quot;bottom&quot;, y=0.8, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#data prprocessing#Eadf_2019 = df19_Ea[df19_Ea['Q19'].isin(programming_df)]df_2020 = df20_Ea[df20_Ea['Q8'].isin(programming_df)]df_2021 = df21_Ea[df21_Ea['Q8'].isin(programming_df)]df19Lag = df_2019.loc[:, ['region', 'Q5', 'Q19', 'year']]df19Lag = df19Lag.rename(columns = {'Q19': 'Language'}, inplace = False) # To match with other datasetsdf20Lag = df_2020.loc[:, ['region', 'Q5', 'Q8', 'year']].rename(columns = {'Q8': 'Language'}, inplace = False)df21Lag = df_2021.loc[:, ['region', 'Q5', 'Q8', 'year']].rename(columns = {'Q8': 'Language'}, inplace = False)df3y_Lag = pd.concat([df19Lag, df20Lag, df21Lag])df3y_Lag = df3y_Lag.groupby(['year', 'Language']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df3y_Lag# 2019dfLang_19 = df3y_Lag[df3y_Lag['year'] == &quot;2019&quot;].reset_index(drop = True)dfLang_19['percentage'] = dfLang_19[&quot;Count&quot;] / dfLang_19[&quot;Count&quot;].sum()dfLang_19['%'] = np.round(dfLang_19['percentage'] * 100, 1)# 2020dfLang_20 = df3y_Lag[df3y_Lag['year'] == &quot;2020&quot;].reset_index(drop = True)dfLang_20['percentage'] = dfLang_20[&quot;Count&quot;] / dfLang_20[&quot;Count&quot;].sum()dfLang_20['%'] = np.round(dfLang_20['percentage'] * 100, 1)# 2021dfLang_21 = df3y_Lag[df3y_Lag['year'] == &quot;2021&quot;].reset_index(drop = True)dfLang_21['percentage'] = dfLang_21[&quot;Count&quot;] / dfLang_21[&quot;Count&quot;].sum()dfLang_21['%'] = np.round(dfLang_21['percentage'] * 100, 1)dfLang_19=dfLang_19.sort_values(by='%', ascending=False)dfLang_20=dfLang_20.sort_values(by='%', ascending=False)dfLang_21=dfLang_21.sort_values(by='%', ascending=False)#graphfig = go.Figure()fig.add_trace(go.Bar(x = dfLang_19['Language'], y = dfLang_19['%'], name = &quot;2019&quot;, text = dfLang_19['%'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#CDD9A3'))fig.add_trace(go.Bar(x = dfLang_20['Language'], y = dfLang_20['%'], name = &quot;2020&quot;, text = dfLang_20['%'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#F28705'))fig.add_trace(go.Bar(x = dfLang_21['Language'], y = dfLang_21['%'], name = &quot;2021&quot;, text = dfLang_21['%'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#88BFBA'))fig.update_layout(title='&lt;b&gt;Language in EastAsia&lt;/b&gt;',title_font_size=20, margin = dict(t=100, l=100, r=50, b=100), height=600, width=700, xaxis_title=None, yaxis_title=None)fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{text}')fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 3.2 Position of Data Scientist in East Asia 123456789101112131415161718192021222324# data preprocessingdf21_Ea_DS = df21_Ea[df21_Ea['Q5'].isin(Data_Scientist)].fillna(0)salary_order= ['&lt;999', '1,000-19,999', '20,000-59,999', '60,000-99,999','100,000-199,999', '200,000~']dgree_order=[ '~college','Bachelor’s degree', 'Master’s degree', 'Doctoral degree~', 'etc']df21_Ea_DS=(df21_Ea_DS #salary .replace({'$0-999':'&lt;999','&gt;$1,000,000':'1,000,000~','$500,000-999,999':'500,000-999,999'}) .replace(['1,000-1,999','2,000-2,999','3,000-3,999', '4,000-4,999','5,000-7,499','7,500-9,999','10,000-14,999', '15,000-19,999'],'1,000-19,999') .replace(['20,000-24,999','25,000-29,999','30,000-39,999', '40,000-49,999', '50,000-59,999'],'20,000-59,999') .replace(['60,000-69,999', '70,000-79,999', '80,000-89,999', '90,000-99,999'], '60,000-99,999') .replace(['100,000-124,999','125,000-149,999','150,000-199,999'],'100,000-199,999') .replace(['200,000-249,999', '250,000-299,999', '300,000-499,999','500,000-999,999', '1,000,000~'], '200,000~') #degree .replace({'I prefer not to answer':'etc'}) .replace(['No formal education past high school','Some college/university study without earning a bachelor’s degree'],'~college') .replace(['Doctoral degree', 'Professional doctorate'],'Doctoral degree~') )sal_order= ['&lt;999', '1,000-19,999', '20,000-59,999', '60,000-99,999','100,000-199,999', '200,000~']dgree_order=[ '~college','Bachelor’s degree', 'Master’s degree', 'Doctoral degree~', 'etc'] 3.2.1 Salary Annual salary of Research Scientist.The highest percentage of $2.6 million is 29.81%. The annual salary of Machine Learning Engineer.The highest rate of $999 is 31.89%. The annual salary of Data Scientist is..The ratio of $1,000 to $20,000 is the highest at 29.19%. ⇒ The higher the annual salary, the lower the overall job rate. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162df21_Ea_DS_= df21_Ea_DS.loc[:,['Q5','Q25']].reset_index().rename(columns={'Q5':'Data_Scientist', 'Q25':'Salary'}).fillna('etc')df21_Ea_DS_= (df21_Ea_DS_.groupby(['Data_Scientist', 'Salary']).size() .reset_index() .rename(columns = {0:&quot;Count&quot;}))#Data Scientistdf21_Ea_DS_Ds = df21_Ea_DS_[df21_Ea_DS_['Data_Scientist'] == &quot;Data Scientist&quot;].reset_index(drop = True)df21_Ea_DS_Ds['%']=((df21_Ea_DS_Ds['Count'] / df21_Ea_DS_Ds['Count'].sum())*100).round(2)#Machine Learning Engineerdf21_Ea_DS_Mle = df21_Ea_DS_[df21_Ea_DS_['Data_Scientist'] == &quot;Machine Learning Engineer&quot;].reset_index(drop = True)df21_Ea_DS_Mle['%']=((df21_Ea_DS_Mle['Count'] / df21_Ea_DS_Mle['Count'].sum())*100).round(2)#Research Scientistdf21_Ea_DS_Rs = df21_Ea_DS_[df21_Ea_DS_['Data_Scientist'] == &quot;Research Scientist&quot;].reset_index(drop = True)df21_Ea_DS_Rs['%']=((df21_Ea_DS_Rs['Count'] / df21_Ea_DS_Rs['Count'].sum())*100).round(2)df21_Ea_DS_Rsdf21_Ea_DS_salary = pd.concat([df21_Ea_DS_Ds, df21_Ea_DS_Mle, df21_Ea_DS_Rs], ignore_index = True)df21_Ea_DS_salary= pd.pivot(df21_Ea_DS_salary, index = &quot;Salary&quot;, columns = 'Data_Scientist', values = &quot;%&quot;).reset_index().fillna('0')df21_Ea_DS_salary= df21_Ea_DS_salary.set_index(&quot;Salary&quot;).reindex(sal_order)#graphfig = go.Figure()fig.add_trace(go.Bar(x = df21_Ea_DS_salary.index, y = df21_Ea_DS_salary['Data Scientist'], name = &quot;Data Scientist&quot;, text = df21_Ea_DS_salary['Data Scientist'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#F2798F'))fig.add_trace(go.Bar(x = df21_Ea_DS_salary.index, y = df21_Ea_DS_salary['Machine Learning Engineer'], name = &quot;Machine Learning Engineer&quot;, text = df21_Ea_DS_salary['Machine Learning Engineer'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#CDD9A3'))fig.add_trace(go.Bar(x = df21_Ea_DS_salary.index, y = df21_Ea_DS_salary['Research Scientist'], name = &quot;Research Scientist&quot;, text = df21_Ea_DS_salary['Research Scientist'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#88BFBA'))fig.update_layout(barmode='stack', showlegend=True, height=600, width=700, title_text=&quot;&lt;b&gt;Data Scientist's Salary in East Asia&lt;/b&gt;&quot;, title_x=0.5, title_font_size=20, margin=dict(l=100, r=100, t=100, b=100))fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{y}%&lt;br&gt;'+ '&lt;b&gt;Salary&lt;/b&gt;: %{x}$&lt;br&gt;')fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;v&quot;, yanchor=&quot;bottom&quot;, y=0.8, xanchor=&quot;right&quot;, x=1.2))fig.show() 3.2.2 Salary-Experience The correlation between the career of a Data Scientist and the annual salary. If you don’t have experience, you have the highest rate of $999. Less than 1 year, 1-3 years have the highest percentage of $999. The highest percentage of $20,000 to $60,000 in 3-10 years. 10-20 years have the highest percentage of $60,000 to $100,000. 12345678910111213141516171819202122232425df21Ea_DS_ExSal = df21_Ea_DS.loc[:,['Q6','Q25']].reset_index().rename(columns={'Q25':'Salary', 'Q6':'Exp'}).fillna('etc')df21Ea_DS_ExSal= (df21Ea_DS_ExSal.groupby(['Exp', 'Salary']).size().unstack().fillna(0).astype('int64'))Exp_order=['&lt; 1 years','1-3 years','3-5 years', '5-10 years', '10-20 years', '20+ years', 'I have never written code']df21Ea_DS_ExSalz = df21Ea_DS_ExSalz = z[sal_order]z = z.reindex(Exp_order)z_data = z.apply(lambda x:np.round(x/x.sum()*100, 2), axis = 1).to_numpy() # convert to correlation matrixx = sal_ordery = Exp_orderfig = ff.create_annotated_heatmap(z_data, x = x, y = y, colorscale = &quot;sunset&quot;)fig.update_layout(title_text=&quot;&lt;b&gt; Data Scientist's Experience &amp; Salary &lt;/b&gt;&quot;,title_font_size=20, height=700, width=700, title_x=0.5, margin=dict(l=100, r=100, t=200, b=100))fig.update_traces(hovertemplate='&lt;b&gt;Salary&lt;/b&gt;: %{y}&lt;br&gt;'+ '&lt;b&gt;Experience&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Percent&lt;/b&gt;: %{z}%')fig.show() 3.2.3 Degree Comparison of educational background of Data Scientists. - It has the highest level of Master's Degrees. - Next, Doctoral Degree, - The figure was high in the order of Bachelor's Degree. 1234567891011121314151617181920212223df21_Ea_degree = df21_Ea_DS['Q4'].value_counts().to_frame()degree = df21_Ea_degree.indexvalues = df21_Ea_degree['Q4'].tolist()colors = ['#F2798F','#88BFBA', '#CDD9A3', '#F28705', '#D9946C']fig = go.Figure(data=[go.Bar(name='Degree', x=degree, y=values ,orientation='v', marker_color=colors, text=values, textposition='outside')])fig.update_layout(title_text=&quot;&lt;b&gt;Data Scientist's Degree (2021)&lt;/b&gt;&quot;, title_font_size=20, height=600, width=700, title_x=0.5, margin=dict(l=100, r=100, t=200, b=100))fig.update_traces(hovertemplate='&lt;b&gt;Count&lt;/b&gt;: %{y}&lt;br&gt;'+ '&lt;b&gt;Degree&lt;/b&gt;: %{x}&lt;br&gt;')fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 3.2.4 Salary-Degree Relationship between Data Scientist's academic background and annual salary. If your educational background is below college, Less than 999 dollars. The lowest annual salary accounts for the highest percentage. Bachelor’s degree, Master’s Degree, Doctoral degree :$2~60,000 dollars accounts for a large proportion ⇒ The higher the education level, the higher the annual salary. 1234567891011121314151617181920212223242526272829303132df21Ea_DS_EduSal= df21_Ea_DS.loc[:, ['Q4', 'Q25']].rename(columns={'Q4':'Edu', 'Q25':'Salary'})df21Ea_DS_EduSal['Edu'].unique()Edu_order=['~college', 'Bachelor’s degree','Master’s degree', 'Doctoral degree~', 'etc']df21Ea_DS_EduSal= (df21Ea_DS_EduSal.groupby(['Edu', 'Salary']).size().unstack().fillna(0).astype('int64'))df21Ea_DS_EduSalz = df21Ea_DS_EduSalz = z[sal_order]z = z.reindex(Edu_order)z_data = z.apply(lambda x:np.round(x/x.sum()*100, 2), axis = 1).to_numpy() # convert to correlation matrixx = sal_ordery = Edu_orderfig = ff.create_annotated_heatmap(z_data, x = x, y = y, colorscale = &quot;sunset&quot;)fig.update_layout(title_text=&quot;&lt;b&gt; Data Scientist's Degree &amp; Salary &lt;/b&gt;&quot;, title_font_size=20, height=700, width=700, title_x=0.5, margin=dict(l=150, r=100, t=200, b=50))fig.update_traces(hovertemplate='&lt;b&gt;Degree&lt;/b&gt;: %{y}&lt;br&gt;'+ '&lt;b&gt;Salary&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Percent&lt;/b&gt;: %{z}%')fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.1, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 3.2.5 Language The language that Data Scientist uses a lot. - Python accounts for the highest percentage of 80% or more. - Second, I use R the most. R is used less frequently in the order of 2019, 20, and 21. - From 19 to 21, the percentage of use rate of use 10% -> 4%, a total of 6% decrease. - The third most frequently used language is SQL. SQL increased 0.6 percent in 2020 from 2021. - The fourth most frequently used languages are C language and C++. ⇒ To become a Data Scientist, Let's study Python first! 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#data preprocessingdf20_Ea_DS = df20_Ea[df20_Ea['Q5'].isin(Data_Scientist)]df19_Ea_DS =df19_Ea[df19_Ea['Q5'].isin(Data_Scientist)]df19Ea_DSLag = df19_Ea_DS.loc[:, [ 'Q5', 'Q19', 'year']]df19Ea_DSLag = df19Ea_DSLag.rename(columns = {'Q19': 'Language'}, inplace = False) # To match with other datasetsdf20Ea_DSLag = df20_Ea_DS.loc[:, [ 'Q5', 'Q8', 'year']].rename(columns = {'Q8': 'Language'}, inplace = False)df21Ea_DSLag = df21_Ea_DS.loc[:, [ 'Q5', 'Q8', 'year']].rename(columns = {'Q8': 'Language'}, inplace = False)df3y_Ds_Lag = pd.concat([df19Ea_DSLag, df20Ea_DSLag, df21Ea_DSLag])df3y_Ds_Lag = df3y_Ds_Lag.groupby(['year', 'Language']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df3y_Ds_Lag# 2019dfLang_Ds_19 = df3y_Ds_Lag[df3y_Ds_Lag['year'] == &quot;2019&quot;].reset_index(drop = True)dfLang_Ds_19['percentage'] = dfLang_Ds_19[&quot;Count&quot;] / dfLang_Ds_19[&quot;Count&quot;].sum()dfLang_Ds_19['%'] = np.round(dfLang_Ds_19['percentage'] * 100, 1)# 2020dfLang_Ds_20 = df3y_Ds_Lag[df3y_Ds_Lag['year'] == &quot;2020&quot;].reset_index(drop = True)dfLang_Ds_20['percentage'] = dfLang_Ds_20[&quot;Count&quot;] / dfLang_Ds_20[&quot;Count&quot;].sum()dfLang_Ds_20['%'] = np.round(dfLang_Ds_20['percentage'] * 100, 1)# 2021dfLang_Ds_21 = df3y_Ds_Lag[df3y_Ds_Lag['year'] == &quot;2021&quot;].reset_index(drop = True)dfLang_Ds_21['percentage'] = dfLang_Ds_21[&quot;Count&quot;] / dfLang_Ds_21[&quot;Count&quot;].sum()dfLang_Ds_21['%'] = np.round(dfLang_Ds_21['percentage'] * 100, 1)dfLang_Ds_19=dfLang_Ds_19.sort_values(by='%', ascending=False)dfLang_Ds_20=dfLang_Ds_20.sort_values(by='%', ascending=False)dfLang_Ds_21=dfLang_Ds_21.sort_values(by='%', ascending=False)#graphfig = go.Figure()fig.add_trace(go.Bar(x = dfLang_Ds_19['Language'], y = dfLang_Ds_19['%'], name = &quot;2019&quot;, text = dfLang_Ds_19['%'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#CDD9A3'))fig.add_trace(go.Bar(x = dfLang_Ds_20['Language'], y = dfLang_Ds_20['%'], name = &quot;2020&quot;, text = dfLang_Ds_20['%'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#F28705'))fig.add_trace(go.Bar(x = dfLang_Ds_21['Language'], y = dfLang_Ds_21['%'], name = &quot;2021&quot;, text = dfLang_Ds_21['%'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#88BFBA'))fig.update_layout(title='&lt;b&gt; The language used by the data scientist&lt;/b&gt;',title_font_size=22, margin = dict(t=120, l=100, r=10, b=150), height=600, width=700)fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{y}%&lt;br&gt;'+ '&lt;b&gt;Language&lt;/b&gt;: %{x}&lt;br&gt;')fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=0.8, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Parallel Categories Diagram : Visualization of multidimensional categorical datasets About 555 Data Scientist Jobs, Visualize it. The higher the height of the category, the more data is generated. It indicates that the frequency increases. 1234567891011121314151617181920ds_pc=(df21_Ea_DS.loc[:, ['Q5','Q25','Q6','Q4','Q8']] .replace({'I have never written code': '&lt; 1 years', '1-3 years': '1-2 years'}) .replace(['10-20 years', '20+ years'], '10+ years' ) .replace([0,'&lt;999']) )fig = px.parallel_categories(ds_pc, labels={'Q5':'Job', 'Q25':'Salary', 'Q6':'Experience', 'Q4':'Degree', 'Q8':'Language'})fig.update_layout(hovermode = 'x')fig.update_layout(title='&lt;b&gt; Data Scientist&lt;/b&gt;',title_font_size=20, margin = dict(t=120, l=100, r=10, b=150), height=600, width=700)fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 4. Ref. Ref. 동아시아 지역 https://ko.wikipedia.org/wiki/%EB%8F%99%EC%95%84%EC%8B%9C%EC%95%84 동아시아 인구 https://ko.wikipedia.org/wiki/%EC%95%84%EC%8B%9C%EC%95%84%EC%9D%98_%EC%9D%B8%EA%B5%AC 세계 인구 https://ko.wikipedia.org/wiki/%EC%84%B8%EA%B3%84_%EC%9D%B8%EA%B5%AC https://ko.wikipedia.org/wiki/%EC%9D%B8%EA%B0%84_%EA%B0%9C%EB%B0%9C_%EC%A7%80%EC%88%98#2020%EB%85%84 동아시아 인간개발지수 https://namu.wiki/w/%EB%8F%99%EC%95%84%EC%8B%9C%EC%95%84 Data Scientist란 https://dataprofessional.tistory.com/126 https://terms.naver.com/entry.naver?docId=1691563&amp;cid=42171&amp;categoryId=42183 Kaggle이란 https://ko.wikipedia.org/wiki/%EC%BA%90%EA%B8%80 Python이란 https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%8D%AC Kaggle competition Ref. https://www.kaggle.com/miguelfzzz/the-typical-kaggle-data-scientist-in-2021 https://www.kaggle.com/desalegngeb/how-popular-is-kaggle-in-africa flaricon: Icons made by Freepik from www.flaticon.com 5. close 안녕하세요 한국에 사는 YH입니다. python을 배운지 한달이 채 안되서 명이 한 팀이 되어 이번 대회에 참가 하게 되었습니다. 많이 부족하지만 여기까지 읽어 주셔서 감사합니다. 아직은 너무너무 부족한 제출물 이지만, 앞으로 열심히 해서 케글 대회에서 1등하는 그 날까지 지켜봐 주세요 ^^! 혹시 코멘트로 다 전하지 못하셨던 말이 있으시다면, 저의 github blog에 방문하여 도움을 주세요! 별거 없지만 놀러오세요 ;-) Hello, I’m YH and I live in Korea.Less than a month after learning python, people became a team and participated in this competition. It’s not enough, but thank you for reading it up to here. It’s still not enough, but please watch until the day we win first place at the Kaggle competition ^^! If there’s anything you haven’t said in the comments, please visit my github blog and help me! It’s nothing special, but come and play. ;-) 안녕하세요 저는 YH님과 같이 Kaggle 대회를 준비 한JW 입니다. python을 제대로 배우지도 못한채로 나오게 된 대회라 코드 부분에서 미숙한 점도 많고 오류도 많습니다! 하지만 대회를 출전하면서, python에 대해서 많은 공부도 되었고, 재미도 있어서 좋은 기회가 되었던것 같습니다. 아래는 저의 깃허브 주소 입니다 데이터 관련 분야에서 일하시는 분들은 저에게 팔로우를 걸어주세요! github Hello, I’m JW who prepared for the Kaggle competition with YH. It’s a competition where I didn’t learn python properly, so I’m not good at codes. There are a lot of errors, too! However, as I participated in the competition, I studied a lot about Python and it was a good opportunity because it was fun. Below is my Git Hub address. For those who work in data-related fields, please follow me! github","link":"/2021/11/28/Newbies-as-a-Data-Scientist-in-EastAsia/"},{"title":"원형그래프(Pie)","text":"1-2. 원형그래프라이브러리 임포트 해주기 123456789import pandas as pd import numpy as npimport seaborn as snsimport plotly.express as pximport plotly.graph_objects as go#warning 라이브러리를 이용해서 경고 메세지 숨기기import warningswarnings.filterwarnings('ignore') 캐글 데이터 불러오기 12df = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv')df = df.iloc[1:, :] column값이 Q2인 데이터 출력 1print(df['Q2']) .value_counts() .value_counts()df의 ‘Q2’ 컬럼의 중복된 데이터 값들의 갯수 표시 12print(df['Q2'].value_counts()) #Q1의 데이터 값에서 중복된 데이터 값들의 갯수를표시 gender .reset_index()인덱스값을 재배열 해주는 함수 .rename(columns={‘index’:’Gender’, ‘Q2’:’Count’})컬럼명 변경 replace(old, new, [count])문자열 변경 할 수 있는 함수old : 현재 문자열에서 변경하고 싶은 문자new: 새로 바꿀 문자count: 변경할 횟수 .replace([‘Prefer not to say’,’Nonbinary’,’Prefer to self-describe’], ‘Other’)count를 입력안했을때 기본값음 -1로 전체를 의미한다 12345678910111213gender = ( df['Q2'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Gender', 'Q2':'Count'}) .replace(['Prefer not to say','Nonbinary','Prefer to self-describe'], 'Other') .replace(['Man','Woman'], ['Male', 'Female']) .groupby('Gender') .sum() .reset_index() ) print(gender) go.Pie fig = go.Figure객체 선언 go.Pie()원형 그래프 그리기 hole=.4가운데 구멍 크기 123456colors = ['#5abbf9','#033351', 'b9e2fc']fig = go.Figure(data=[go.Pie(labels=gender['Gender'], values=gender['Count'], hole=.4)])fig.show() .update_traces hover data클릭과 반응하는 인터렉티브 그래프를 구축데이터의 세부 정보를 추가적으로 보여주는 팝업 정보창인 호버링마우스 가져다 대면 data 정보를 볼 수 있다 hoverinfo = ‘percent’마우스를 그래프에 가져다 대면 퍼센트 값으로 데이터가 표시됨 line=dict(color=’#000000’,width=1)테두리 색상 값, 테두리 두께 123456fig.update_traces(hoverinfo='percent', textinfo='label', textfont_size=20, marker=dict(colors=colors, line=dict(color='#000000',width=1)))fig.show() .update_layout showlegend=False범례 제거 폰트 크기, 도표 제목 설정 등등 12345678fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', paper_bgcolor='#F7F7F7', title_text=&quot;&lt;b&gt;Gender&lt;/b&gt; Distrigution&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;,size =25, color='#000000'))fig.show() annotation annotation주석 1234567891011121314151617fig.add_annotation(dict(font=dict(size=14), x=1.1, y=-0.16, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=-0.28, y=-0.16, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 전체 코드 남성은 전체의 79%로 응답자의 대다수를 차지한다 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950gender = ( df['Q2'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Gender', 'Q2':'Count'}) .replace(['Prefer not to say','Nonbinary','Prefer to self-describe'], 'Other') .replace(['Man','Woman'], ['Male', 'Female']) .groupby('Gender') .sum() .reset_index() ) colors = ['#5abbf9','#033351', 'b9e2fc']fig = go.Figure(data=[go.Pie(labels=gender['Gender'], values=gender['Count'], hole=.4)])fig.update_traces(hoverinfo='percent', textinfo='label', textfont_size=20, marker=dict(colors=colors, line=dict(color='#000000', width=1)))fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', paper_bgcolor='#F7F7F7', title_text=&quot;&lt;b&gt;Gender&lt;/b&gt; Distribution&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=25, color='#000000'))fig.add_annotation(dict(font=dict(size=14), x=1.1, y=-0.16, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=-0.28, y=-0.16, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()","link":"/2021/11/07/kaggle2-%EC%9B%90%ED%98%95%EA%B7%B8%EB%9E%98%ED%94%84/"},{"title":"막대그래프(for문, 수평)","text":"3-2. 막대그래프 (수평) 라이브러리 임포트 해주기 &amp; 캐글 데이터 불러오기 생략! startswith() 메소드는 어떤 문자열이 특정 문자로 시작하는지 확인하여 결과를 true 혹은 false로 반환합니다. python for문 문 for 카운터변수 in range(반복횟수): 반복해서 실행할 명령 algorithms_cols = [col for col in df if col.startswith(‘Q17’)]첫번째 컬럼부터 df 끝까지 뒤의 if문이 반복된다if문은 컬럼 값이 문자열 Q17로 시작하는지 확인하여 true일때만 데이터 가져온다 col(뒤)카운터 변수 df반복하는 범위 col(앞) =&gt; List Comprehension반복문인 for문의 결과값을 받아주는 역할을 한다 123algorithms_cols = [col for col in df if col.startswith('Q17')]algorithms = df[algorithms_cols]print(algorithms) List Comprehension참고 블로그 링크_1참고링크 표현식리스트 안에 식 for문을 지정한다.[식 for 변수 in 리스트]list(식 for 변수 in 리스트) columns 이름 바꿔주기 12345algorithms.columns = ['Linear or Logistic Regression', 'Decision Trees or Random Forests', 'Gradient Boosting Machines', 'Bayesian Approaches', 'Evolutionary Approaches', 'Dense Neural Networks', 'Convolutional Neural Networks', 'Generative Adversarial Networks', 'Recurrent Neural Networks', 'Transformer Networks', 'None', 'Other']print(algorithms) algorithms 객체 생성 123456789algorithms = ( algorithms .count() .to_frame() .reset_index() .rename(columns={'index':'Algorithms', 0:'Count'}) .sort_values(by=['Count'], ascending=False) )print(algorithms) percent 컬럼 추가 12algorithms['percent'] = ((algorithms['Count'] / len(df))*100).round(2).astype(str) + '%'print(algorithms) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960colors = ['#033351',] * 12colors[0] = '#5abbf9'colors[1] = '#5abbf9'colors[2] = '#066eb0'colors[3] = '#066eb0'colors[4] = '#044a77'colors[5] = '#044a77'colors[6] = '#044a77'fig = go.Figure(go.Bar( x=algorithms['Count'], y=algorithms['Algorithms'], text=algorithms['percent'], orientation='h', marker_color=colors ))fig.update_traces(texttemplate='%{text}', textposition='outside', cliponaxis = False, hovertemplate='&lt;b&gt;Algorithm&lt;/b&gt;: %{y}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{x}', textfont_size=12) fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False) fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', margin=dict(pad=20), paper_bgcolor='#F7F7F7', xaxis={'showticklabels': False}, yaxis_title=None, height = 600, xaxis_title=None, yaxis={'categoryorder':'total ascending'}, title_text=&quot;Most Commonly Used &lt;b&gt;Algorithms&lt;/b&gt;&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=15, color='#000000'), title_font_size=35)fig.add_annotation(dict(font=dict(size=14), x=0.98, y=-0.17, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=0, y=-0.17, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()","link":"/2021/11/09/kaggle6-%EB%A7%89%EB%8C%80%EA%B7%B8%EB%9E%98%ED%94%84-for%EB%AC%B8/"},{"title":"막대그래프(Bar, 수평)","text":"2. Education &amp; Occupation 응답자의 77% 이상이 학사 및/또는 석사 학위를 가지고 있습니다. 2-1. 막대그래프(수평)캐글 데이터 불러오기 1234567891011121314151617# This Python 3 environment comes with many helpful analytics libraries installed# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python# For example, here's several helpful packages to loadimport numpy as np # linear algebraimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)# Input data files are available in the read-only &quot;../input/&quot; directory# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directoryimport osfor dirname, _, filenames in os.walk('/kaggle/input'): for filename in filenames: print(os.path.join(dirname, filename))# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using &quot;Save &amp; Run All&quot; # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session 라이브러리 임포트 해주기 import plotly.express as px import plotly.graph_objects as go Plotly는 그래프를 만드는데에는 두가지 방법이 있다 pxexpress의 줄임으로빠르게 그래프를 제작 go그래프를 하나하나 설정하여 제작 123456789import pandas as pd import numpy as npimport seaborn as snsimport plotly.express as pximport plotly.graph_objects as go#warning 라이브러리를 이용해서 경고 메세지 숨기기import warningswarnings.filterwarnings('ignore') 123df = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv')df = df.iloc[1:, :] print(df) dataframe 생성 educationeducation이라는 데이터 프레임을 만들어줌컬럼 값으로 Q4의 데이터 값을 가졌음 .value_counts()Q4의 컬럼의 중복된 데이터 값들의 갯수 표시 .to_frame()데이터 프레임으로 변환 .reset_index()컬럼명 인덱스가 아닌 행 번호 인덱스(숫자)를 사용하고 싶을때 사용밑의 예시 참고. replace(old, new, [count])문자열 변경 할 수 있는 함수old : 현재 문자열에서 변경하고 싶은 문자new: 새로 바꿀 문자count: 변경할 횟수 1print(df['Q4']) 1print(df['Q4'].value_counts()) 1234567891011education = ( df['Q4'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Education', 'Q4':'Count'}) .replace(['Some college/university study without earning a bachelor’s degree'], 'University studies - No degree') ) education['percent'] = ((education['Count'] / education['Count'].sum())*100).round(2).astype(str) + '%'print(education) colors 색상의 범위를 정해줌 12345colors = ['#033351',] * 7 #남색colors[0] = '#5abbf9' #맨위의 색 하늘색colors[1] = '#5abbf9'colors[2] = '#0779c3' #진하늘색colors[3] = '#0779c3' go.figure x=education[‘Count’]education 컬럼 Count의 data 값을 x축에 대입 y=education[‘Education’]education 컬럼 Education의 data 값을y 축에 대입 text=education[‘percent’]문자열을 추가해줌이때 education 데이터프레임의 컬럼 percent의 데이터 값을 추가함 orientation=’h’h는 horizontal bar을 의미한다.이 문장을 입력하지 않을때 수평 바가 만들어지지 않는다 marker_color=colors위에 정의해준 colors 값으로 그래프를 다른 색으로 표현함 12345678fig = go.Figure(go.Bar( x = education['Count'], y = education['Education'], text = education['percent'], orientation = 'h', marker_color = colors ))fig.show() orientation=’h’가 없을때 1234567fig = go.Figure(go.Bar( x=education['Count'], y=education['Education'], text=education['percent'], marker_color=colors ))fig.show() update_traces() 여러가지 그래프를 한번에 업데이트 할 수 있다예를들면 Scatter(), bar()를 동시에 포함할 수 있다 123456789fig.update_traces(texttemplate='%{text}', textposition='outside', cliponaxis = False, hovertemplate='&lt;b&gt;Education&lt;/b&gt;: %{y}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{x}', textfont_size=12) fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False) .update_layout() 123456789101112fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', margin=dict(pad=20), paper_bgcolor='#F7F7F7', xaxis={'showticklabels': False}, yaxis_title=None, xaxis_title=None, yaxis={'categoryorder':'total ascending'}, title_text=&quot;&lt;b&gt;Education&lt;/b&gt; Distribution&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=15, color='#000000'), title_font_size=35) annotation 12345678910111213141516171819fig.add_annotation(dict(font=dict(size=14), x=0.98, y=-0.21, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=0, y=-0.21, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 전체코드1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768education = ( df['Q4'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Education', 'Q4':'Count'}) .replace(['Some college/university study without earning a bachelor’s degree'], 'University studies - No degree') ) education['percent'] = ((education['Count'] / education['Count'].sum())*100).round(2).astype(str) + '%'colors = ['#033351',]*7colors[0] = '#5abbf9'colors[1] = '#5abbf9'colors[2] = '#0779c3'colors[3] = '#0779c3'fig = go.Figure(go.Bar( x=education['Count'], y=education['Education'], text=education['percent'], orientation='h', marker_color=colors ))fig.update_traces(texttemplate='%{text}', textposition='outside', cliponaxis = False, hovertemplate='&lt;b&gt;Education&lt;/b&gt;: %{y}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{x}', textfont_size=12) fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False) fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', margin=dict(pad=20), paper_bgcolor='#F7F7F7', xaxis={'showticklabels': False}, yaxis_title=None, xaxis_title=None, yaxis={'categoryorder':'total ascending'}, title_text=&quot;&lt;b&gt;Education&lt;/b&gt; Distribution&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=15, color='#000000'), title_font_size=35)fig.add_annotation(dict(font=dict(size=14), x=0.98, y=-0.21, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=0, y=-0.21, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()","link":"/2021/11/08/kaggle4-%EB%A7%89%EB%8C%80%EA%B7%B8%EB%9E%98%ED%94%84-%EC%88%98%ED%8F%89/"},{"title":"treemap","text":"1234567891011121314151617# This Python 3 environment comes with many helpful analytics libraries installed# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python# For example, here's several helpful packages to loadimport numpy as np # linear algebraimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)# Input data files are available in the read-only &quot;../input/&quot; directory# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directoryimport osfor dirname, _, filenames in os.walk('/kaggle/input'): for filename in filenames: print(os.path.join(dirname, filename))# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using &quot;Save &amp; Run All&quot; # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session 1234567891011import pandas as pdimport numpy as npimport seaborn as snsimport plotly.express as pximport plotly.graph_objects as goimport warningswarnings.filterwarnings('ignore') df = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv')df = df.iloc[1:, :] 3-4 Treemap recommend_leng 객체 생성 123456789recommend_leng = ( df['Q8'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Lenguage', 'Q8':'Count'}) .sort_values(by=['Count'], ascending=False) ) print(recommend_leng) color 123456colors = ['#033351',] * 13colors[0] = '#5abbf9'colors[1] = '#066eb0'colors[2] = '#044a77'colors[3] = '#043e64'colors[4] = '#043e64' Treemap참고사이트트리맵 차트는 내포된 직사각형을 사용하여 계층적 데이터를 시각화합니다.계층 구조는 레이블(px.tremap의 이름) 및 상위 속성에 의해 정의됩니다. labels = recommend_leng[‘Lenguage’]labels값 values = recommend_leng[‘Count’]values값 parents = [‘’]*recommend_leng.shape[0]treemap의 계층을 따로 만들어 주지 않았기 때문에recommend_leng.shape[0] 으로 정해줍니다. 1234567fig = go.Figure(go.Treemap( labels = recommend_leng['Lenguage'], values = recommend_leng['Count'], parents = ['']*recommend_leng.shape[0], textinfo = &quot;percent root+label+value+text&quot;,))fig.show() 나머지 코드 treemapcolorway = colorstreemap 컬러 지정 12345678910111213141516171819202122232425262728293031323334353637fig.update_traces(hovertemplate='&lt;b&gt;Lenguage&lt;/b&gt;: %{label}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{value}') fig.update_layout(showlegend=False, treemapcolorway = colors, margin=dict(pad=20), paper_bgcolor='#F7F7F7', plot_bgcolor='#F7F7F7', height=600, yaxis={'showticklabels': False}, yaxis_title=None, xaxis_title=None, title_text=&quot;Most Recommended &lt;b&gt;Programming Language&lt;/b&gt;&quot;, title_x=0.5, title_y=0.95, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=17, color='#000000'), title_font_size=35)fig.add_annotation(dict(font=dict(size=14), x=0.96, y=-0.14, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=0.01, y=-0.14, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()","link":"/2021/11/09/kaggle7-treemap/"},{"title":"Kaggle Competition(2)","text":"라이브러리 불러오기 &amp; 캐글 데이터 불러오기 1234567891011121314151617181920212223import numpy as npimport pandas as pdimport seaborn as snsimport matplotlib.pylab as pltimport plotly.io as pioimport plotly.express as pximport plotly.graph_objects as goimport plotly.figure_factory as fffrom plotly.subplots import make_subplotsfrom plotly.offline import init_notebook_mode, iplotinit_notebook_mode(connected=True)pio.templates.default = &quot;none&quot;# import plotly.offline as py# py.offline.init_notebook_mode()import osfor dirname, _, filenames in os.walk('/kaggle/input'): for filename in filenames: print(os.path.join(dirname, filename))import warningswarnings.filterwarnings(&quot;ignore&quot;) 12345df17= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2017/multipleChoiceResponses.csv&quot;, encoding=&quot;ISO-8859-1&quot;)df18= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2018/multipleChoiceResponses.csv&quot;, )df19= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2019/multiple_choice_responses.csv&quot;, )df20= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2020/kaggle_survey_2020_responses.csv&quot;, )df21= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2021/kaggle_survey_2021_responses.csv&quot;, ) 데이터 Grouping 12345678910111213141516171819202122232425262728293031323334353637383940## East Asia에는 대한민국, 일본, 중국, 타이완, 몽골, 북조선 총 6개의 국가가 속해 있다. EastAsia17 = ['China',&quot;People 's Republic of China&quot;, 'Taiwan', 'South Korea', 'Japan']EastAsia18 = ['China', 'South Korea', 'Japan', 'Republic of Korea'] EastAsia19 = ['China','Taiwan', 'South Korea', 'Japan', 'Republic of Korea']EastAsia20 = ['China','Taiwan', 'South Korea', 'Japan', 'Republic of Korea']EastAsia21 = ['China','Taiwan', 'South Korea', 'Japan']EastAsia = ['Republic of Korea','China','Taiwan', 'South Korea', 'Japan', &quot;People 's Republic of China&quot; ]#21년df21_Ea = df21[df21['Q3'].isin(EastAsia)]df21_Wo = df21[~df21['Q3'].isin(EastAsia )]## 동아시아 국가를 제외한 국가들을 region 열의 데이터 값을 World 로 바꿔줌df21['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df21['Q3']]#20년df20_Ea = df20[df20['Q3'].isin(EastAsia)]df20_Wo = df20[~df20['Q3'].isin(EastAsia )]df20['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df20['Q3']]#19년df19_Ea = df19[df19['Q3'].isin(EastAsia)]df19_Wo = df19[~df19['Q3'].isin(EastAsia )]df19['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df19['Q3']]#18년df18_Ea = df18[df18['Q3'].isin(EastAsia)]df18_Wo = df18[~df18['Q3'].isin(EastAsia )]df18['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df18['Q3']]#17년df17_Ea = df17[df17['Country'].isin(EastAsia)]df17_Wo = df17[~df17['Country'].isin(EastAsia )]df17['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df17['Country']] Stack Bar 그래프 데이터 전처리1 연도별로 데이터 정리 했음 12df21_Ea=df21[df21['Q3'].isin(EastAsia21)]df21_Ea['Q3'].value_counts().to_frame().reset_index().rename(columns={'index':'Country', 'Q3':'21_n'}) 12df20_Ea=df20[df20['Q3'].isin(EastAsia20)]df20_Ea['Q3'].replace('Republic of Korea','South Korea').value_counts().to_frame().reset_index().rename(columns={'index':'Country', 'Q3':'20_n'}) 12df19_Ea=df19[df19['Q3'].isin(EastAsia19)]df19_Ea['Q3'].replace('Republic of Korea','South Korea').value_counts().to_frame().reset_index().rename(columns={'index':'Country', 'Q3':'19_n'}) append() 메서드를 사용해서 Taiwan = 0 값 추가해줌 ignore_index=True 원래 있던 df의 index를 무시12df18_Ea=df18[df18['Q3'].isin(EastAsia18)]df18_Ea['Q3'].replace('Republic of Korea','South Korea').value_counts().to_frame().reset_index().append({'index': 'Taiwan','Q3':'0'}, ignore_index=True).rename(columns={'index':'Country', 'Q3':'18_n'}) 12df17_Ea = df17[df17['Country'].isin(EastAsia)]df17_Ea['Country'].replace(&quot;People 's Republic of China&quot;,&quot;China&quot;).value_counts().to_frame().reset_index().rename(columns={'index':'Country', 'Country':'17_n'}) Stack Bar 그래프 데이터 전처리2 18년도 Taiwan 데이터 값이 없음 iloc: 데이터프레임의 행이나 컬럼에 인덱스 값으로 접근 loc: 데이터프레임의 행이나 컬럼에 label이나 boolean array로 접근 (location의 약자) 위에 전처리 내용을 아래 그래프에 맞게 더 다듬어 정리하였다 1234567891011121314df17_Ea = df17[df17['Country'].isin(EastAsia)]df17_StackB = df17_Ea['Country'].replace(&quot;People 's Republic of China&quot;,&quot;China&quot;).value_counts().to_frame().reset_index()df18_Ea = df18[df18['Q3'].isin(EastAsia18)]df18_StackB = df18_Ea['Q3'].replace('Republic of Korea','South Korea').value_counts().to_frame().reset_index().append({'index': 'Taiwan','Q3':'0'}, ignore_index=True)df19_Ea = df19[df19['Q3'].isin(EastAsia19)]df19_StackB = df19_Ea['Q3'].replace('Republic of Korea','South Korea').value_counts().to_frame().reset_index()df20_Ea = df20[df20['Q3'].isin(EastAsia20)]df20_StackB = df20_Ea['Q3'].replace('Republic of Korea','South Korea').value_counts().to_frame().reset_index()df21_Ea = df21[df21['Q3'].isin(EastAsia21)]df21_StackB = df21_Ea['Q3'].value_counts().to_frame().reset_index() barmode =’stack’Bar 그래프를 stack 형식으로 쌓아서 표현하였다 12345678910111213fig = go.Figure(data=[ go.Bar(name='China', x=years, y=[df17_StackB.iloc[0,1], df18_StackB.iloc[0,1], df19_StackB.iloc[1,1], df20_StackB.iloc[1,1], df21_StackB.iloc[1,1]]), go.Bar(name='Japan', x=years, y=[df17_StackB.iloc[1,1], df18_StackB.iloc[1,1], df19_StackB.iloc[0,1], df20_StackB.iloc[0,1], df21_StackB.iloc[0,1]]), go.Bar(name='Taiwan', x=years, y=[df17_StackB.iloc[2,1], df18_StackB.iloc[3,1], df19_StackB.iloc[2,1], df20_StackB.iloc[2,1], df21_StackB.iloc[3,1]]), go.Bar(name='South Korea', x=years, y=[df17_StackB.iloc[3,1], df18_StackB.iloc[2,1], df19_StackB.iloc[3,1], df20_StackB.iloc[3,1], df21_StackB.iloc[2,1]]) ])fig.update_layout(barmode ='stack')fig.show() Pie 그래프데이터 전처리 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051fig = make_subplots(rows=1, cols=5)total17 = ( df17['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index())total18 = ( df18['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index())total19 = ( df19['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index())total20 = ( df20['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index())total21 = ( df21['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index()) Pie 그래프 그리기 scalegroup=’one’원 그래프의 자체 사이즈를 변경 할 수 있다.12345678910111213141516171819fig = make_subplots(rows=1, cols=5, specs=[[{'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}]])fig.add_trace(go.Pie(labels=total21['type'], values=total21['respodents'], name=&quot;2021&quot;, scalegroup='one'), 1, 1)fig.add_trace(go.Pie(labels=total20['type'], values=total20['respodents'], name=&quot;2020&quot;, scalegroup='one'), 1, 2)fig.add_trace(go.Pie(labels=total19['type'], values=total19['respodents'], name=&quot;2019&quot;, scalegroup='one'), 1, 3)fig.add_trace(go.Pie(labels=total18['type'], values=total18['respodents'], name=&quot;2018&quot;, scalegroup='one'), 1, 4)fig.add_trace(go.Pie(labels=total17['type'], values=total17['respodents'], name=&quot;2017&quot;, scalegroup='one'), 1, 5)fig.update_traces(hole=.2, hoverinfo=&quot;label+percent+name&quot;)fig.update_layout( title_text=&quot;&lt;b&gt;World vs EastAsia&lt;/b&gt;&quot;, )fig.show() 느낀점 그래프 그리는것보다데이터 전처리가 더 힘든것 같다..그래도 이번에 직접 해보면서헷갈렸던 문법들을 다시 정리할수 있었고의미를 완벽하게 익혔고 어느정도 감이 잡혔음을 느꼈다. 내일도 더 열심히… Ref https://plotly.com/python/pie-charts/","link":"/2021/11/15/mykaggle2/"},{"title":"Kaggle Competition(1)","text":"데이터 불러오기 실행환경: kaggle notebook사용언어: Python Plotly준비하는 kaggle competition 링크 1234567891011121314151617181920212223import numpy as npimport pandas as pdimport seaborn as snsimport matplotlib.pylab as pltimport plotly.io as pioimport plotly.express as pximport plotly.graph_objects as goimport plotly.figure_factory as fffrom plotly.subplots import make_subplotsfrom plotly.offline import init_notebook_mode, iplotinit_notebook_mode(connected=True)pio.templates.default = &quot;none&quot;# import plotly.offline as py# py.offline.init_notebook_mode()import osfor dirname, _, filenames in os.walk('/kaggle/input'): for filename in filenames: print(os.path.join(dirname, filename))import warningswarnings.filterwarnings(&quot;ignore&quot;) 17년 - 21년도 데이터 불러오기 12345df17= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2017/multipleChoiceResponses.csv&quot;, encoding=&quot;ISO-8859-1&quot;)df18= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2018/multipleChoiceResponses.csv&quot;, )df19= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2019/multiple_choice_responses.csv&quot;, )df20= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2020/kaggle_survey_2020_responses.csv&quot;, )df21= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2021/kaggle_survey_2021_responses.csv&quot;, ) 데이터 전처리 123#21년도에 설문조사에 참여한 국가들pd.set_option('display.max_rows', None)df21['Q3'].value_counts().sort_index(ascending=True) 123#South Korea에 해당하는 참여자만 출력df21_Ko = df21[df21['Q3'] == 'South Korea']df21_Ko.head() 123#한국을 제외한 참여자들의 투표결과df21_Wo = df21[~(df21['Q3'] == 'South Korea')]df21_Wo.head() 1234567891011## 설문조사에 참여한 사람 비율#한국df21_Ko = df21[df21['Q3'] == 'South Korea']#전세계df21_Wo = df21[~(df21['Q3'] == 'South Korea')]#동아시아를 제외한 국가는 전부 거주지역을 World로 바꿈df21['region']=[&quot;Korea&quot; if x == 'South Korea' else &quot;World&quot; for x in df21['Q3']]df21['region'].value_counts() 12345678## if 변수 x 가 South Korea 일때## else -&gt; South Korea가 아닐때## x가 0부터 df21['Q3']의 행값을 차례로 World값을 넣는다 #### 이 결과를 df['region'] 에 넣는다## 따라서 동아시아가 아닌 국가들의 행 값은 전부 World로 바뀜df21['region']=[&quot;Korea&quot; if x == 'South Korea' else &quot;World&quot; for x in df21['Q3']]df21['region'].head() 데이터 Grouping 연도별 EastAsia 국가 정리EastAsia17EastAsia18EastAsia19EastAsia20EastAsia21 연도별 정리df21_Ea : 동아시아 국가만 데이터df21_Wo : 동아시아 제외한 전세계 국가 데이터df21[‘region’] : 동아시아를 제외한 국가는 World로 저장됨 (World랑 동아시아국가 이름밖에 없음) isin()df21의 Q3열에 EastAsia의 리스트값과 동일한게 있을때 True , 없으면 False 12345678910111213141516171819202122232425262728293031323334353637383940## East Asia에는 대한민국, 일본, 중국, 타이완, 몽골, 북조선 총 6개의 국가가 속해 있다. EastAsia17 = ['China',&quot;People 's Republic of China&quot;, 'Taiwan', 'South Korea', 'Japan']EastAsia18 = ['China', 'South Korea', 'Japan', 'Republic of Korea'] EastAsia19 = ['China','Taiwan', 'South Korea', 'Japan', 'Republic of Korea']EastAsia20 = ['China','Taiwan', 'South Korea', 'Japan', 'Republic of Korea']EastAsia21 = ['China','Taiwan', 'South Korea', 'Japan']EastAsia = ['Republic of Korea','China','Taiwan', 'South Korea', 'Japan', &quot;People 's Republic of China&quot; ]#21년df21_Ea = df21[df21['Q3'].isin(EastAsia)]df21_Wo = df21[~df21['Q3'].isin(EastAsia )]## 동아시아 국가를 제외한 국가들을 region 열의 데이터 값을 World 로 바꿔줌df21['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df21['Q3']]#20년df20_Ea = df20[df20['Q3'].isin(EastAsia)]df20_Wo = df20[~df20['Q3'].isin(EastAsia )]df20['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df20['Q3']]#19년df19_Ea = df19[df19['Q3'].isin(EastAsia)]df19_Wo = df19[~df19['Q3'].isin(EastAsia )]df19['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df19['Q3']]#18년df18_Ea = df18[df18['Q3'].isin(EastAsia)]df18_Wo = df18[~df18['Q3'].isin(EastAsia )]df18['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df18['Q3']]#17년df17_Ea = df17[df17['Country'].isin(EastAsia)]df17_Wo = df17[~df17['Country'].isin(EastAsia )]df17['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df17['Country']] 12## 마지막 열에 region이 추가된 것을 확인 할 수 있음df21.head() 12345df21['region'].value_counts()##df20['region'].value_counts()##df19['region'].value_counts()##df18['region'].value_counts()##df17['region'].value_counts() Bar 그래프 생성연도별 kaggle 사용자 (전세계 vs 동아시아) 1234567891011121314151617181920212223242526272829# 설문 참여자 총 인원Ea21 = len(df21_Ea)Wo21 = len(df21) - len(df21_Ea)Ea20 = len(df20_Ea)Wo20 = len(df20) - len(df20_Ea)Ea19 = len(df19_Ea)Wo19 = len(df19) - len(df19_Ea)Ea18 = len(df18_Ea)Wo18 = len(df18) - len(df18_Ea)Ea17 = len(df17_Ea)Wo17 = len(df17) - len(df17_Ea)# 퍼센트 함수 만들어줌# percent, percentRdef percent (a, b): result =a/(a+b)*100 return resultdef percentR (b, a): result =a/(a+b)*100 return resultcountry = ['East Asia', 'Rest of the World']years = ['2017', '2018', '2019', '2020', '2021'] 123456789fig = go.Figure(data=[ go.Bar(name='Rest of the World', x=years, y=[percentR(Ea17, Wo17), percentR(Ea18, Wo18), percentR(Ea19, Wo19), percentR(Ea20, Wo20), percentR(Ea21, Wo21)]), go.Bar(name='East Asia', x=years, y=[percent(Ea17, Wo17), percent(Ea18, Wo18), percent(Ea19, Wo19), percent(Ea20, Wo20), percent(Ea21, Wo21)])])fig.update_layout(barmode='stack')fig.show() barmode =’stack’ 이거 제거하면 그래프가 나란히 나온다Pie 그래프 생성연도별 kaggle 사용자 (전세계 vs 동아시아) 1234567891011total = ( df21['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index() )total 12345678910111213141516171819202122colors = ['#f2eda5','#bbbcbd', '#bbbcbd']fig = go.Figure(data=[go.Pie(labels=total['type'], values=total['respodents'], hole=.3)])fig.update_traces(hoverinfo='percent', textinfo='label', textfont_size=20, marker=dict(colors=colors) )fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', paper_bgcolor='#F7F7F7', title_text=&quot;&lt;b&gt;World vs EastAsia&lt;/b&gt;&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=25, color='#000000') )fig.show()# marker=dict(colors=colors,line=dict(color='#000000', width=1)) #테두리 원형그래프 메서드 만들기 1234567891011121314151617181920212223242526272829303132333435def pie(df): total = ( df['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index() ) colors = ['#f2eda5','#bbbcbd', '#bbbcbd'] fig = go.Figure(data=[go.Pie(labels=total['type'], values=total['respodents'], hole=.3)]) fig.update_traces(hoverinfo='percent', textinfo='label', textfont_size=20, marker=dict(colors=colors) ) fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', paper_bgcolor='#F7F7F7', title_text=&quot;&lt;b&gt;World vs EastAsia&lt;/b&gt;&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=25, color='#000000') ) fig.show()# marker=dict(colors=colors,line=dict(color='#000000', width=1)) #테두리 메서드 호출 1pie(df21) choropleth 지도 그래프 그리기 1df21_Ea['Q3'].value_counts() 1234567891011121314151617181920212223242526272829303132333435def world_map(locations,counts,title): data = [ dict( type = 'choropleth', locations = locations, z = counts, colorscale = 'Blues', locationmode = 'country names', autocolorscale = False, reversescale = True, marker = dict( line = dict(color = '#F7F7F7', width = 1.5)), colorbar = dict(autotick = True, legth = 3, len=0.75, title = 'respodents', max = 1000, min = 0) ) ] layout = dict( title = title, titlefont={'size': 28, 'family': 'san serif'}, width=750, height=475, paper_bgcolor='#F7F7F7', geo = dict( showframe = True, showcoastlines = True, fitbounds=&quot;locations&quot;, ) ) fig = dict(data=data, layout=layout) iplot(fig, validate=False, filename='world-map') z = df21_Ea['Q3'].value_counts() ## 메서드 호출world_map(locations=z.index, counts=z.values, title= '&lt;b&gt; EastAsia Countries (2021 survey) &lt;b&gt;') Bar 그래프 21년도만 123456789101112131415161718192021222324252627282930## vertical bar graphs############################ def plotly_vBar(df, q, title, l=50,r=50,b=50,t=100): fig = px.histogram(df21.iloc[1:], x = df21['region'], orientation='v', width=700, height=450, histnorm='percent', color_discrete_map={ &quot;EastAsia&quot;: &quot;gold&quot;, &quot;World&quot;: &quot;salmon&quot; }, opacity=0.6 )fig.update_layout(title=&quot;21년도 전세계 vs 동아시아&quot;, font_family=&quot;San Serif&quot;, bargap=0.2, barmode='group', titlefont={'size': 28}, paper_bgcolor='#F5F5F5', plot_bgcolor='#F5F5F5', legend=dict( orientation=&quot;v&quot;, y=1, yanchor=&quot;top&quot;, x=1.250, xanchor=&quot;right&quot;,) ).update_xaxes(categoryorder='total descending')fig.show() Ref 참고사이트","link":"/2021/11/14/mykaggle1/"},{"title":"맥북 초기 셋팅","text":"TMI아빠가 사준신 15년도에 구입한 엘지 그램을 거의 7년동안 사용하고,너무 느려져서 최근에 맥북을 구매했다.윈도우를 사용하던 내가 처음으로 새로운 IOS 운영체제를 사용해보는거라설렘 반 걱정 반 이었던 것 같다. 애플 기기에 관심이 무척 많아서 수원역에 애플 스토어 매장에 자주 방문에서 구경하고는 했는데맥북을 만져봤더니 정말 하나도 모르겠더라 그런데도 불구하고 나는 막무가내로 구입해버렸다 ㅎㅎ 애플이 마감과 디자인 하나는 정말 좋다! 짱이뿜 나는 RAM 8기가, SSD 256기가로 구입했다솔직히 RAM 16기가가 욕심이 났는데, 가격도 만만치 않았고IOS 운영체제가 나한테 잘 맞을지에 대한 확신이 없었기 때문에 깡통 옵션으로 구매하였다.나중에 돈 많이 벌면 프로로 바꿀거다 ㅎ Apple Developer 위의 Apple Developer를 설치하면 xcode와 Developer가 설치된다 설치하는데 굉장히 오랜 시간이 걸렸다. 아마 30분 정도 걸린것 같다. xcode란?Apple의 macOS, iOS, watchOS 및 tvOS용 소프트웨어 개발을 위한 IDE. 엑스코드라 읽으며, macOS 전용이다. Nodejshttps://nodejs.org/ko/위의 사이트에서 nodejs를 설치 할 수 있다 pycharm 설치python을 사용할건 아닌데, 블로그를 좀 편하게 사용할 IDE가 필요했다 git 설치 Homebrew를 설치 git을 설치하기 전에 먼저 Homebrew를 설치해야한다👉https://brew.sh/위의 링크에 접속하면 방법이 나와있다.결론적으로는 아래 코드를 터미널에서 입력하면 바로 설치 완료 /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot; git 설치 아래 사이트에 들어가면 깃을 설치하는 방법이 나와있지만아래 코드를 터미널에서 입력하면 깃 설치가 완료됨http://git-scm.com/download/mac brew install git git config 설정 (계정 로그인) git config global user.name “wldnjd2” git config global user.email “jeewon3665@naver.com“ 깃을 처음 깔았을때 계정 로그인을 해줘야하는데 위에와 같이 하면 된다.각자의 아이디와 이메일을 적으면 된다 hexo blog 옮기기 blog는 git clone으로 내려받아서 할 수 있는게 아니였다 ㅜ ㅜ다른 컴퓨터에서 블로그를 하려면 결국 설정을 다시 해줘야하는데아래와 같이 하면 된다 hexo init myblog (각자블로그 레포지토리 이름적기) cd myblog git init git remote add origin http://~~ (각자의 레포 주소) git clean -d -f git pull --set-upstream origin main npm installl hexo clean 마지막엔 아래의 코드로 옮겨진 블로그를 local에서 확인 할 수 있다 hexo g hexo s 블로그 수정사항 깃허브에 올리기 블로그를 깃허브에 올리려고 아래 명령어를 실행했지만 에러가 났다..add와 commit은 되는데 push가 안되었다 git add . gti commit -m &quot;updated&quot; git push ** error 1번)** Access Token error 에러가 계속 해서 발생했는데아래와 같은 방법으로 하니까 해결 되었다그러나, 나의 뻘짓으로 문제가 있었는데토큰 설정 해주고 push를 했는데, push는 안되고 계속 아래와 같은 문구만 반복해서 나왔다 Username for 'https://github.com': wldnjs2 Password for 'https://wldnjs2@github.com': username이랑 password를 틀렸을리 없다 생각했는데,저기서 password는 깃허브의 password가 아닌 발급받은 토큰 시리얼넘버를 적는거였다고로, 복사 붙여넣기 하면 해결 난 그것도 모르고 계속 깃허브 비번 쳤다 ^0^ … 정말 화난다 깃허브 토큰 설정 error 2번) fatal: The upstream branch of your current branch does not match the name of your current branch. To push to the upstream branch on the remote, use git push origin HEAD:main To push to the branch of the same name on the remote, use git push origin HEAD push가 안되고 계속 위의 error가 떴다이때 저기 적혀있는 git push origin HEAD:main 으로 push를 하니까해결되었지만, 문제는 계속 저렇게 push를 해야했다… git push 로는 계속 저 명령어가 떴다 해결방법은 아래의 코드를 쳐주면 된다git push –set-upstream origin master 다행히 해결되서 git push로 간단하게 push를 할 수 있게 되었다 ㅜㅜ 에러 해결 블로그","link":"/2022/01/04/macbook/"},{"title":"내가 사용한 Pandas 메서드","text":"Pandas란 Pandas는 데이터 조작 및 분석을 위한 Python 프로그래밍 언어 용으로 작성된 소프트웨어 라이브러이다.특히 숫자 테이블과 시계열 을 조작하기 위한 데이터 구조 와 연산을 제공한다. 주로 데이터 분석에 사용 된다. Kaggle 대회를 준비할때 데이터 전처리에 사용했던 라이브러리이다. import pandas as pd import pandas as pd 라이브러리를 불러주기 위한 명령어로 as 뒤의 약어는 pd로 정해 주로 호출한다. csv 파일 불러오기 df = pd.read_csv(“파일경로/파일명.csv”) df21= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2021/kaggle_survey_2021_responses.csv&quot;) isin list에 존재하는 요소가 대상 dataframe에 존재하는지 반환하는 메서드(True와 False로 반환) df21['Q3'].isin(['China','Taiwan', 'South Korea', 'Japan']) df21이라는 데이터프레임의 Q3라는 컬럼값에China Taiwan South Korea Japan 값이 있다면 반환한다. EastAsia21 = ['China','Taiwan', 'South Korea', 'Japan'] df21_Ea = df21[df21['Q3'].isin(EastAsia21)] 위와 같이 작성하게 되면 df21에서 EastAsia21의 리스트를 가진 True 값의 행들만 가진 df21_Ea의데이터 프레임이 만들어짐 replace 데이터의 문자열을 치환해줌, 저장된 문자열을 바꿔준다.ex1. Q3의 컬럼값이 치환된다. df18['Q3'].replace({'Republic of Korea':'South Korea','I do not wish to disclose my location' : 'Other'}) #결과값 1 United States of America 2 Indonesia 3 United States of America 4 United States of America 5 India ... ex2. 위와 같지만 테이블 형식으로 데이터가 출력된다. df18.replace({'Q3': {'Republic of Korea':'South Korea','I do not wish to disclose my location' : 'Other'}}) ex3. 전체 데이터에서 Republic of Korea의 데이터값이 모두 South Korea로 바뀐다 df18.replace{'Republic of Korea':'South Korea'} merge 데이터 프레임을 합치는 메서드이다. mer = pd.merge(df21, df20, how = 'outer', on = 'JOB' ) 데이터 프레임 df21과 df20을 컬럼 JOB을 기준으로 합침 on: 두개의 데이터 프레임의 기준열 how: 조인 방식 {‘left’, ‘rigtht’, ‘inner’, ‘outer’} 기본값은 inner이다. left: 왼쪽 데이터 프레임을 기준으로 조인 right: 오른쪽 데이터 프레임을 기준으로 조인 inner: 교집합을 조인 outer: 모든 값이 나타나도록 한다(데이터 프레임에 없는 값들은 NaN으로 표시됨) concat merge와 마찬가지로 데이터 프레임을 합치는 메서드merge는 DB의 join과 비슷하다면, Concat은 단순한 붙이기이다. con = pd.concat([df21, df20, df19, df18], axis = 0) axis = 0 (기본값)행 기준으로 데이터 프레임을 합친다동일한 column명을 기준으로 데이터 프레임이 위아래로 쌓아진다. axis = 1열기준으로 데이터 프레임을 합친다데이터 프레임이 옆으로 붙는다 sort_values 데이터를 정렬하는 메서드이다 df = df21.sort_values(by=&quot;Q3&quot;, ascending=False) Q3 컬럼을 내림차순으로 정렬한다 ascending=False내림차순 정렬 ascending=True오름차순 정렬 groupby 그룹별로 데이터를 집계, 요약하는 연산자이다. df21 = df21.groupby(['Q3']) 컬럼 Q3의 데이터 값이 같은것끼리 그룹별로 묶는다예를들어 Q3 컬럼값으로 국가이름이 여러개 있다면, 국가별로 묶어서 볼 수 있다. fillna fillna는 결측값을 특정값으로 채울수 있다. df21.fillna(0) 결측값을 0으로 채움, 문자열도 가능하다 pivot 데이터를 재구조화하는 함수이다. https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;blogId=wideeyed&amp;logNo=221347221214 transpose 데이터 프레임의 행과 열을 바꾸는 메서드이다. to_numpy pandas 객체를 numpy 배열 객체로 반환하는 메서드이다.plotly로 그래프를 그릴때 데이터 값을 넣어줘야하는데 이때 numpy를 통해 배열로 바꿔줘서 넣어주는데 사용했다. df21['Q3'].to_numpy() 결과값 array(['India', 'Indonesia', 'Pakistan', ..., 'Sweden', 'United States of America', 'India'], dtype=object) tolist dataframe의 값을 리스트로 변환하는 메소드 df21['Q3'].tolist() 결과값 ['India', 'Indonesia', 'Pakistan', ..., 'Sweden', 'United States of America', 'India'] Ref 위키백과mergeconcat","link":"/2021/12/03/pandas-01/"},{"title":"Kaggle Competition(3)","text":"라이브러리 불러오기 &amp; 캐글 데이터 불러오기 1234567891011121314151617181920212223import numpy as npimport pandas as pdimport seaborn as snsimport matplotlib.pylab as pltimport plotly.io as pioimport plotly.express as pximport plotly.graph_objects as goimport plotly.figure_factory as fffrom plotly.subplots import make_subplotsfrom plotly.offline import init_notebook_mode, iplotinit_notebook_mode(connected=True)pio.templates.default = &quot;none&quot;# import plotly.offline as py# py.offline.init_notebook_mode()import osfor dirname, _, filenames in os.walk('/kaggle/input'): for filename in filenames: print(os.path.join(dirname, filename))import warningswarnings.filterwarnings(&quot;ignore&quot;) 12345df17= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2017/multipleChoiceResponses.csv&quot;, encoding=&quot;ISO-8859-1&quot;)df18= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2018/multipleChoiceResponses.csv&quot;, )df19= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2019/multiple_choice_responses.csv&quot;, )df20= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2020/kaggle_survey_2020_responses.csv&quot;, )df21= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2021/kaggle_survey_2021_responses.csv&quot;, ) 데이터 Grouping 12345678910111213141516171819202122232425262728293031323334353637383940## East Asia에는 대한민국, 일본, 중국, 타이완, 몽골, 북조선 총 6개의 국가가 속해 있다. EastAsia17 = ['China',&quot;People 's Republic of China&quot;, 'Taiwan', 'South Korea', 'Japan']EastAsia18 = ['China', 'South Korea', 'Japan', 'Republic of Korea'] EastAsia19 = ['China','Taiwan', 'South Korea', 'Japan', 'Republic of Korea']EastAsia20 = ['China','Taiwan', 'South Korea', 'Japan', 'Republic of Korea']EastAsia21 = ['China','Taiwan', 'South Korea', 'Japan']EastAsia = ['Republic of Korea','China','Taiwan', 'South Korea', 'Japan', &quot;People 's Republic of China&quot; ]#21년df21_Ea = df21[df21['Q3'].isin(EastAsia)]df21_Wo = df21[~df21['Q3'].isin(EastAsia )]## 동아시아 국가를 제외한 국가들을 region 열의 데이터 값을 World 로 바꿔줌df21['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df21['Q3']]#20년df20_Ea = df20[df20['Q3'].isin(EastAsia)]df20_Wo = df20[~df20['Q3'].isin(EastAsia )]df20['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df20['Q3']]#19년df19_Ea = df19[df19['Q3'].isin(EastAsia)]df19_Wo = df19[~df19['Q3'].isin(EastAsia )]df19['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df19['Q3']]#18년df18_Ea = df18[df18['Q3'].isin(EastAsia)]df18_Wo = df18[~df18['Q3'].isin(EastAsia )]df18['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df18['Q3']]#17년df17_Ea = df17[df17['Country'].isin(EastAsia)]df17_Wo = df17[~df17['Country'].isin(EastAsia )]df17['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df17['Country']] Heatmap 12345678910111213141516171819# 21년 Business Analyst가 직업인 국가별 인원수df21_BA = df21[df21['Q5'] == 'Business Analyst']df21_BA = df21_BA['Q3'].value_counts().to_frame().reset_index().rename(columns={'index':'Country', 'Q3':'Business Analyst'})df21_BA# 21년 Data Analyst가 직업인 국가별 인원수df21_DA = df21[df21['Q5'] == 'Data Analyst']df21_DA = df21_DA['Q3'].value_counts().to_frame().reset_index().rename(columns={'index':'Country', 'Q3':'Data Analyst'})df21_DA# 21년 Data Engineer가 직업인 국가별 인원수df21_DE = df21[df21['Q5'] == 'Data Engineer']df21_DE = df21_DE['Q3'].value_counts().to_frame().reset_index().rename(columns={'index':'Country', 'Q3':'Data Engineer'})df21_DE# 21년 Data Scientist가 직업인 국가별 인원수df21_DS = df21[df21['Q5'] == 'Data Scientist']df21_DS = df21_DS['Q3'].value_counts().to_frame().reset_index().rename(columns={'index':'Country', 'Q3':'Data Scientist'})df21_DS 123merge = pd.merge(df21_BA, df21_DA)job=merge.loc[:,[&quot;Business Analyst&quot;,&quot;Data Analyst&quot;]]job.columns.tolist() ['B]usiness Analyst', 'Data Analyst] 1merge 1merge.to_numpy().reshape(-1) 12merge.columns.tolist()#merge.Country.tolist() ['Country', Business Analyst', 'Data Analyst] 1merge.to_numpy() 1234# 21년 Data Engineer가 직업인 국가별 인원수df21_DE = df21[df21['Q5'] == 'Data Engineer']df21_DE = df21_DE['Q3'].value_counts().to_frame().reset_index().rename(columns={'index':'Country', 'Q3':'Data Engineer'})df21_DE.head() 1merge.iloc[:,[1,2]].to_numpy() 123456789101112131415161718192021222324252627282930313233343536373839404142# x축직업# y축국가fig = go.Figure(data=go.Heatmap( z=merge.iloc[:,[1,2]].to_numpy(), x=job.columns.tolist(), y = merge.Country.tolist(), hoverongaps = True, coloraxis = &quot;coloraxis&quot; ))fig.update_layout(title_text='&lt;i&gt;&lt;b&gt;Heatmap&lt;/b&gt;&lt;/i&gt;', xaxis = dict(title='x'), yaxis = dict(title='x') )# add custom xaxis titlefig.add_annotation(dict(font=dict(color=&quot;black&quot;,size=14), x=0.5, y=-0.15, showarrow=False, text=&quot;&quot;, xref=&quot;paper&quot;, yref=&quot;paper&quot;))# add custom yaxis titlefig.add_annotation(dict(font=dict(color=&quot;black&quot;,size=14), x=-0.35, y=0.5, showarrow=False, text=&quot;&quot;, textangle=-90, xref=&quot;paper&quot;, yref=&quot;paper&quot;))# adjust margins to make room for yaxis titlefig.update_layout(margin=dict(t=50, l=200))# add colorbarfig['data'][0]['showscale'] = Truefig.show() 1merge.iloc[0,[1,2]].values.tolist() 1merge['Business Analyst'].values.tolist() 123#21년 직업 종류df21_job = df21['Q5'].value_counts().to_frame().reset_index().rename(columns={'index':'Job', 'Q5':'CNT'})df21_job = df21_job['Job'].to_frame() 데이터 전처리 1234567891011121314#data 확인Data_Analyst =['Data Analyst','Data Engineer','Data Miner,Information technology', 'networking, or system ...','Predictive Modeler' ]Data_Engineer =['A business discipline (accounting, economics, ...', 'Business Analyst', 'Statistician', 'Mathematics or statistics', 'Data Scientist', 'Environmental science or geology', 'Humanities', 'Machine Learning Engineer', 'Medical or life sciences (biology, chemistry, ...', 'Physics or astronomy', 'Research Scientist', 'Researcher', 'Scientist/Researcher', 'Social sciences (anthropology, psychology, soc...','Software Developer/Software Engineer']Developer=['Developer Relations/Advocacy','Engineer','Engineering (non-computer focused)', 'Programmer','Software Engineer', 'Computer Scientist','Computer science (software engineering, etc.)', 'Fine arts or performing arts','Product Manager', 'Product/Project Manager','Program/Project Manager','DBA/Database Engineer']Not_Employeed =['Currently not employed', 'Not employed', 'Student']Others = ['I never declared a major', 'Other']","link":"/2021/11/16/mykaggle3-Heatmap/"},{"title":"Plotly를 이용해 다양한 bar 그래프 그리기","text":"Bar Graph 1 위의 그래프 경우는 bar 그래프만 있는게 아니고 scatter 그래프도 같이 있다.따라서 그래프 2개를 하나의 페이지에 그린다고 볼 수 있다. 두개의 그래프를 동시에 그릴때 add_trace를 이용해서 하나씩 그린다고 보면 된다.fig.add_trace(go.Bar) –&gt; 그래프-1fig.add_trace(go.Scatter) –&gt; 그래프-2 x축은 공통사항이므로 같은 값을 넣어주었다.y는 값이 다르므로 각각의 값을 넣어주었다 아래는 왼쪽 오른쪽 각각의 축을 나타냈고, 각각의 그래프에 지정해주었다.yaxis = “y1”yaxis = “y2” 나머지 fig.update_trace, fig.update_layout, fig.add_annotation는 그래프를 꾸며주는 역할을 한다. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546fig = go.Figure()fig.add_trace(go.Bar(x=years, y=[len(df17_Ea),len(df18_Ea), len(df19_Ea),len(df20_Ea),len(df21_Ea)], marker_color='#F2D64B', yaxis = &quot;y1&quot;, name='East Asia', text= percent, texttemplate='%{text} %', textposition='outside', hovertemplate='&lt;b&gt;KaggleUser&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{y}'))fig.add_trace(go.Scatter(name = &quot;World&quot;, x=years, y=[len(df17), len(df18), len(df19), len(df20), len(df21)], marker_color='#979DA6', mode = 'lines+markers', # please check option here yaxis = &quot;y2&quot;))fig.update_traces(hovertemplate='&lt;b&gt;Count&lt;/b&gt;: %{y}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'+ '&lt;b&gt;Year&lt;/b&gt;: %{x}&lt;br&gt;')fig.update_layout(yaxis = dict(title = &quot;Kaggle User in East Asia&quot;,showgrid = False, range=[0, len(df21_Ea)*1.2]), yaxis2 = dict(title = &quot;Kaggle User in World&quot;, overlaying = &quot;y1&quot;, side = &quot;right&quot;, showgrid = False, zeroline = False, range=[0, len(df21)*1.2]))fig.update_layout(title='&lt;b&gt;Kaggle Users&lt;/b&gt;',title_font_size=20, margin = dict(t=200, l=100, r=50, b=200), height=700, width=700)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.1, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.9, y=-0.25, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Bar Graph2 하나의 그래프에 여러개의 데이터를 표현할때data=[]는 왜 쓸까? 안쓰면 에러남 의문 똑같이 go.bar로 x축 y축에 각각의 값을 넣어준다.이때 내가 그리고자 하는 그래프가 총 5개이니까 하나씩 설정해서 그린다고 생각하면 된다. 다른 방법으로는 add_trace 이용해서 그려도 된다 12345678910111213141516171819202122232425262728fig = go.Figure(data=[ go.Bar(name='2017', x=df5years['Country'], y=df5years['17'], marker_color='#F2798F',text=df5years['17'].tolist(), textposition='outside'), go.Bar(name='2018', x=df5years['Country'], y=df5years['18'], marker_color='#88BFBA',text=df5years['18'].fillna(0).astype(int).tolist(), textposition='outside',), go.Bar(name='2019', x=df5years['Country'], y=df5years['19'], marker_color='#CDD9A3',text=df5years['19'].tolist(), textposition='outside'), go.Bar(name='2020', x=df5years['Country'], y=df5years['20'], marker_color='#F28705',text=df5years['20'].tolist(), textposition='outside',), go.Bar(name='2021', x=df5years['Country'], y=df5years['21'], marker_color='#D9946C',text=df5years['21'].tolist(), textposition='outside')])fig.update_layout(title='&lt;b&gt;Kaggle User in East Asia&lt;/b&gt;',title_font_size=23, margin = dict(t=200, l=100, r=10, b=200), height=600, width=700)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_traces(hovertemplate='&lt;b&gt;Count&lt;/b&gt;: %{y}')fig.update_layout(legend=dict( orientation=&quot;v&quot;, yanchor=&quot;bottom&quot;, y=1.15, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Bar Graph3 위의 그래프는 수평으로 그린 그래프이다.orientation=’h’ -&gt; 수평으로 그래프를 그린다orientation=’v’ -&gt; 수직으로 그래프를 그린다 base = 0는 값의 기준점이 0 이라는 의미 y값은 같지만, x값은 0을 기준으로 -와 +로 나누어지기 때문에한쪽값에 -을 붙여야 한다나는 x=World, x=-East_Asia 각각 이렇게 설정해주었다 123456789101112131415161718192021222324252627fig = go.Figure(data=[ go.Bar(y=y, x=World, orientation='h', name=&quot;World&quot;, base=0, hovertemplate='&lt;b&gt;World&lt;/b&gt;: %{x}%&lt;br&gt;', marker_color='#979DA6', text=World, textposition='outside'), go.Bar(y=y, x=-East_Asia, orientation='h', name=&quot;East Asia&quot;, base=0, hovertemplate='&lt;b&gt;East Asia&lt;/b&gt;: %{x}%&lt;br&gt;', marker_color='#F2D64B', text=East_Asia, textposition='outside')])fig.update_layout(barmode='stack')fig.update_layout(title='&lt;b&gt;World vs EastAsia&lt;/b&gt;',title_font_size=22, margin = dict(t=200, l=100, r=50, b=200), height=700, width=750, xaxis_title=None, yaxis_title=None)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.1, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Bar Graph4 subplot을 이용해 그려준것이다subplot이란 하나의 페이지에 여러개의 그래프를 합쳐놓은 것이다 fig = make_subplots(rows = 1, cols = 4, shared_yaxes=True, vertical_spacing = 0.05) 위에처럼 행 열을 지정해줘야하는데내가 그린 그래프는 1행 4열 그래프이다 add_trace를 이용해 그래프를 그려주면 된다 subplot을 사용하지 않고 그냥 add_trace만 이용해도 되는데,그럴경우에는 아래 사진처럼 그래프 x축이 분리되지 않고 이어진다. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758fig = make_subplots(rows = 1, cols = 4, shared_yaxes=True, vertical_spacing = 0.05)fig.add_trace(go.Bar(x = dfCh_Edu21['Dgree'], y = dfCh_Edu21['%'], text = dfCh_Edu21['%'].astype(str) + &quot;%&quot;, textposition='outside', name='China', marker_color='#88BFBA'), row = 1, col = 1)fig.add_trace(go.Bar(x = dfJp_Edu21['Dgree'], y = dfJp_Edu21['%'], text = dfJp_Edu21['%'].astype(str) + &quot;%&quot;, textposition='outside', name='Japan', marker_color='#CDD9A3'), row = 1, col = 2)fig.add_trace(go.Bar(x = dfKo_Edu21['Dgree'], y = dfKo_Edu21['%'], text = dfKo_Edu21['%'].astype(str) + &quot;%&quot;, textposition='outside', name='South Korea', marker_color='#F28705'), row = 1, col = 3)fig.add_trace(go.Bar(x = dfTw_Edu21['Dgree'], y = dfTw_Edu21['%'], text = dfTw_Edu21['%'].astype(str) + &quot;%&quot;, textposition='outside', name='Taiwan', marker_color='#D9946C'), row = 1, col = 4)fig.update_layout(showlegend=True,title='&lt;b&gt;Degree in East Asia&lt;/b&gt;',title_font_size=22, margin = dict(t=200, l=100, r=50, b=200), height=700, width=700)fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{y}%&lt;br&gt;'+ '&lt;b&gt;Degree&lt;/b&gt;: %{x}&lt;br&gt;')fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.1, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Bar Graph5 fig.update_layout(barmode='stack') 위의 한 줄을 추가해주면 그래프가 Stack으로 쌓여서 그려진다. 위의 한 줄을 뺏을때는 이렇게 따로따로 분리되어서 그려진다. 1234567891011121314151617181920212223242526272829303132333435363738fig = go.Figure()fig.add_trace(go.Bar(x = df21_Ea_DS_salary.index, y = df21_Ea_DS_salary['Data Scientist'], name = &quot;Data Scientist&quot;, text = df21_Ea_DS_salary['Data Scientist'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#F2798F'))fig.add_trace(go.Bar(x = df21_Ea_DS_salary.index, y = df21_Ea_DS_salary['Machine Learning Engineer'], name = &quot;Machine Learning Engineer&quot;, text = df21_Ea_DS_salary['Machine Learning Engineer'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#CDD9A3'))fig.add_trace(go.Bar(x = df21_Ea_DS_salary.index, y = df21_Ea_DS_salary['Research Scientist'], name = &quot;Research Scientist&quot;, text = df21_Ea_DS_salary['Research Scientist'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#88BFBA'))fig.update_layout(barmode='stack', showlegend=True, height=600, width=700, title_text=&quot;&lt;b&gt;Data Scientist's Salary in East Asia&lt;/b&gt;&quot;, title_x=0.5, title_font_size=20, margin=dict(l=100, r=100, t=100, b=100))fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{y}%&lt;br&gt;'+ '&lt;b&gt;Salary&lt;/b&gt;: %{x}$&lt;br&gt;')fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;v&quot;, yanchor=&quot;bottom&quot;, y=0.8, xanchor=&quot;right&quot;, x=1.2))fig.show() 느낀점 처음 그래프를 그리면서 bar그래프에도 다양한 종류가 있는데내가 원하는대로 그리기가 쉽지 않았다하지만 사실 복잡한게 아니기에 조금만 공부하면 쉽게 그릴수 있다모를때는 사실 plotly 원문 사이트를 들어가서 그려보는게 도움이 됬다위의 그래프를 참고해서 그리면 된다누군가에게 도움이 되었기를…","link":"/2021/11/28/plotly-bar/"},{"title":"Plotly를 이용해 Heatmap 그래프 그리기","text":"heatmap Graph 데이터 전처리를 통해서 정리된 데이터 셋이다 x축 y축의 index 값을 각각 설정해주고z에는 데이터 값을 넣어준다 1234567891011121314151617181920212223242526x1=['South Korea','Taiwan','China','Japan']y1=merge.sort_values(by=['index'], ascending=True)['index'].tolist()z1=merge.iloc[:,[2,4,6,8]].to_numpy()fig = go.Figure(data=go.Heatmap( z=z1, x=x1, y=y1, hoverongaps = True, opacity=1.0, xgap=2.5, ygap=2.5))fig = ff.create_annotated_heatmap(z1, x = x1, y = y1, colorscale='sunset')fig.update_layout(height=500, width=600, title_text=&quot;&lt;b&gt;East Asia Age (2021)&lt;/b&gt;&quot;, title_font_size=20, title_x=0.5)fig.update_traces(hovertemplate='&lt;b&gt;Age&lt;/b&gt;: %{y}&lt;br&gt;'+ '&lt;b&gt;Country&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Percent&lt;/b&gt;: %{z}%')fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Heatmap Graph2 Heatmap을 subplot을 이용해서 그렸다여태까지 해왔던 pie그래프, bar그래프와는 달리 더 복잡했다 x=['2017-year','2018-year','2019-year','2020-year','2021-year'] 일단 x값을 ‘2017-year’ 이런식으로 이름을 지었는데,버그를 발견했다!‘2017’로만 지으면 숫자로 인식해서 계속 에러가 났던것… 12345678910111213141516171819202122232425262728293031323334z1=((merge_Wo.iloc[:,[1,2,3,4,5]].to_numpy()/merge_Wo.iloc[:,[1,2,3,4,5]].to_numpy().sum())*100).round(1)z2=((merge.iloc[:,[1,2,3,4,5]].to_numpy()/merge.iloc[:,[1,2,3,4,5]].to_numpy().sum())*100).round(1)x=['2017-year','2018-year','2019-year','2020-year','2021-year']y1=merge_Wo['JOB'].tolist()y2=merge['JOB'].tolist()fig1 = ff.create_annotated_heatmap(z1, x = x, y = y1, colorscale='sunset')fig2 = ff.create_annotated_heatmap(z2, x = x, y = y2, colorscale='sunset')for annot in fig2['layout']['annotations']: annot['xref'] = 'x2' fig = make_subplots(rows=1, cols=2)fig.add_trace(fig1.data[0], row=1, col=1)fig.add_trace(fig2.data[0], row=1, col=2)fig.update_layout(fig1.layout, title='&lt;b&gt; World vs EastAsia&lt;/b&gt;',title_font_size=22, margin = dict(t=200, l=100, r=10, b=200), height=700, width=1150, coloraxis=dict(showscale=True, colorscale='sunset'))fig.update_traces(hovertemplate='&lt;b&gt;Job&lt;/b&gt;: %{y}&lt;br&gt;'+ '&lt;b&gt;Year&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Percent&lt;/b&gt;: %{z}%')fig.layout.annotations += fig2.layout.annotationsfig.add_annotation(dict(font=dict(size=14), x=0.9, y=-0.25, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Ref https://plotly.com/python/heatmaps/","link":"/2021/11/28/plotly-heatmap/"},{"title":"Bar 그래프 v와 h","text":"import문 1234567891011121314151617181920212223import numpy as npimport pandas as pdimport seaborn as snsimport matplotlib.pylab as pltimport plotly.io as pioimport plotly.express as pximport plotly.graph_objects as goimport plotly.figure_factory as fffrom plotly.subplots import make_subplotsfrom plotly.offline import init_notebook_mode, iplotinit_notebook_mode(connected=True)pio.templates.default = &quot;none&quot;# import plotly.offline as py# py.offline.init_notebook_mode()import osfor dirname, _, filenames in os.walk('/kaggle/input'): for filename in filenames: print(os.path.join(dirname, filename))import warningswarnings.filterwarnings(&quot;ignore&quot;) 캐글 데이터 불러오기 12345df17= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2017/multipleChoiceResponses.csv&quot;, encoding=&quot;ISO-8859-1&quot;)df18= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2018/multipleChoiceResponses.csv&quot;, )df19= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2019/multiple_choice_responses.csv&quot;, )df20= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2020/kaggle_survey_2020_responses.csv&quot;, )df21= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2021/kaggle_survey_2021_responses.csv&quot;, ) 1-1. 수평그래프(Bar_h)데이터 전처리 리스트 생성africa17, africa18, africa19, africa20, africa21 isinPandas에서는 어떤 list에 존재하는 요소가 대상 DataFrame이나 Series에 존재 하는지 True(존재), False(존재안함)로 반환준다 [df21[‘Q3’].isin(africa)]거주지역이 africa 리스트에 있는 지역에 해당할경우 True로 반환 df21[df21[‘Q3’].isin(africa)](21년도 기준)africa에 사는 사람들의 df21의 데이터 값만 불러옴 123456789101112131415161718192021222324252627282930313233# grouping african countries# 리스트 만들어줌africa17 = ['Nigeria','Kenya', 'South Africa', 'Egypt']africa18 = ['Nigeria','Kenya', 'South Africa', 'Egypt', 'Tunisia', 'Morocco'] africa19 = ['Nigeria','Kenya', 'South Africa', 'Egypt', 'Tunisia', 'Morocco', 'Algeria']africa20 = ['Nigeria','Kenya', 'South Africa', 'Egypt', 'Tunisia', 'Morocco', 'Ghana']africa21 = ['Nigeria','Kenya', 'South Africa', 'Egypt', 'Tunisia', 'Morocco', 'Algeria', 'Ghana', 'Uganda', 'Ethiopia']#df21['Q3'] -&gt; In which country do you currently reside? 거주지역은?africa = ['Nigeria', 'Egypt', 'South Africa', 'Algeria', 'Tunisia', 'Morocco', 'Kenya', 'Uganda', 'Ghana', 'Ethiopia']#21년도 기준df21_africa = df21[df21['Q3'].isin(africa)]df21_world = df21[~df21['Q3'].isin(africa )]df21['region']=[&quot;Africa&quot; if x in africa else &quot;World&quot; for x in df21['Q3']]df20_africa = df20[df20['Q3'].isin(africa)]df20_world = df20[~df20['Q3'].isin(africa )]df20['region']=[&quot;Africa&quot; if x in africa else &quot;World&quot; for x in df20['Q3']]df19_africa = df19[df19['Q3'].isin(africa)]df19_world = df19[~df19['Q3'].isin(africa)]df19['region']=[&quot;Africa&quot; if x in africa else &quot;World&quot; for x in df19['Q3']]df18_africa = df18[df18['Q3'].isin(africa)]df18_world = df18[~df18['Q3'].isin(africa)]df18['region']=[&quot;Africa&quot; if x in africa else &quot;World&quot; for x in df18['Q3']]df17_africa = df17[df17['Country'].isin(africa)]df17_world = df17[~df17['Country'].isin(africa )]df17['region']=[&quot;Africa&quot; if x in africa else &quot;World&quot; for x in df17['Country']] 1print(africa) [‘Nigeria’, ‘Egypt’, ‘South Africa’, ‘Algeria’, ‘Tunisia’, ‘Morocco’, ‘Kenya’, ‘Uganda’, ‘Ghana’, ‘Ethiopia’] 1print(df21['Q3']) 0 In which country do you currently reside? 1 India 2 Indonesia 3 Pakistan 4 Mexico … 25969 Egypt 25970 China 25971 Sweden 25972 United States of America 25973 India Name: Q3, Length: 25974, dtype: object 1print(df21['Q3'].isin(africa)) 0 False 1 False 2 False 3 False 4 False … 25969 True 25970 False 25971 False 25972 False 25973 False Name: Q3, Length: 25974, dtype: bool 1print(df21) 1print(df21[df21['Q3'].isin(africa)]) 데이터 전처리 afro21 = len(df21_africa)df21_africa의 행 갯수 -&gt; 아프리카에 거주하는 캐글러 수 len(df21)행의 갯수 -&gt; 설문조사에 응답한 전세계 캐글러 수 row21 = len(df21) - afro21전세계 캐글러 수 - 아프리카 거주하는 캐글러 수 = 나머지 1234567891011121314afro21 = len(df21_africa)row21 = len(df21) - afro21afro20 = len(df20_africa)row20 = len(df20) - afro20afro19 = len(df19_africa)row19 = len(df19) - afro19afro18 = len(df18_africa)row18 = len(df18) - afro18afro17 = len(df17_africa)row17 = len(df17) - afro17 123print(afro21) print(len(df21)) print(row21) 2060 25974 23914 1234#리스트 생성region = ['Africa', 'Rest of the World']value = [afro21, row21]percent =[afro21/(afro21 +row21)*100, row21/(afro21+row21)*100] 123print(region)print(value)print(percent) #아프리카에 사는 캐글러, 전세계의 캐글러 percent 값 [‘Africa’, ‘Rest of the World’] [2060, 23914] [7.931007931007931, 92.06899206899207] 1-1. africa에 사는 kaggler 수 VS 전 세계 kaggler 수 데이터 시각화하기 go.Bar막대그래프 생성 np.round(percent,1)반올림하기 textposition=[‘outside’, ‘inside’]괄호 안은 각각 설정값[afica, rest of the world] textfont=dict()막대그래프 데이터 값 폰트 설정 orientation=’h’수평으로 그래프 그리기 marker_color=[‘gold’, ‘salmon’]막대그래프 색상 설정 (africa, rest of the world) opacity=0.6그래프 투명도 설정 (0.0 ~ 1) 12345678910111213fig = go.Figure(data=[go.Bar( x=value, y=region, text=(np.round(percent,1)), textposition=['outside', 'inside'], texttemplate = [&quot;&lt;b style='color: #f'&gt;%{text}%&lt;/b&gt;&quot;]*2, textfont=dict( family=&quot;sans serif&quot;, size=16, color=&quot;black&quot;), orientation='h', marker_color=['gold', 'salmon'], opacity=0.6, )])fig.show() update_traces marker_line_color=’black’: 막대그래프 테두리 색상 marker_line_width=2.5: 막대그래프 테두리 두께 update_layout yaxis_linewidth=2.5y축 테두리 두께 bargap=0.2막대그래프 두께 (0 ~ 1.0 숫자가 작을수록 두꺼움) barmode=’group’ 12345678910111213fig.update_traces(marker_line_color='black', marker_line_width=2.5)fig.update_layout(title='&lt;b&gt;Number of respondents: Africa vs Rest of the world (2021)&lt;b&gt;', font_family=&quot;San Serif&quot;, yaxis_linewidth=2.5, bargap=0.2, barmode='group', titlefont={'size': 24}, paper_bgcolor='#F5F5F5', plot_bgcolor='#F5F5F5', ) update_layout fig.update_layout(xaxis = dict(x축 레이아웃 설정 autosize=False사이즈 고정true로 설정시 대시보드 자체가 화면에 맞는 크기로 엄청 커짐 (좌우로) showgrid=False배경 격자무늬 생성 안함 margin배경화면에서의 그래프 크기 비율 조정 12345678910111213141516171819fig.update_layout( xaxis = dict( zeroline = False, showline = False, showticklabels = False, gridwidth = 1 ), autosize=False, margin=dict( l=150, r=50, b=50, t=100, ), )fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.show() 1-2. 수직 그래프(Bar_v)연도별 african kagglers의 수 비교데이터 전처리 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253## historical data, all genderyear = ['2017', '2018', '2019', '2020', '2021']value = [afro17, afro18, afro19, afro20, afro21]percent =[ afro17/(afro17 +row17)*100, afro18/(afro18 +row18)*100, afro19/(afro19 +row19)*100, afro20/(afro20 +row20)*100, afro21/(afro21 +row21)*100] color = 5* ['salmon'] color[4] = 'gold'fig = go.Figure(data=[go.Bar( y=value, x=year, text=np.round(percent, 1), textposition='outside', texttemplate = [&quot;&lt;b style='color: #f'&gt;%{text}%&lt;/b&gt;&quot;]*5, textfont=dict( family=&quot;sans serif&quot;, size=16, color=&quot;black&quot;), orientation='v', marker_color= color, opacity=0.6 )])fig.update_traces(marker_line_color='black', marker_line_width=2.5)fig.update_layout(title='&lt;b&gt;The rise of African kagglers&lt;b&gt;', font_family=&quot;San Serif&quot;, xaxis_linewidth=2.5, bargap=0.2, barmode='group', titlefont={'size': 28}, template='simple_white', paper_bgcolor='#F5F5F5', plot_bgcolor='#F5F5F5', )fig.update_layout(yaxis_title='Number of Respondents',xaxis_title='Year', autosize=False, margin=dict( l=100, r=50, b=50, t=70, pad=0, ), )fig.show()","link":"/2021/11/10/kaggle8-bar-h-v/"},{"title":"Plotly를 이용해 Sunburst 그래프 그리기","text":"Ref https://plotly.com/python/sunburst-charts/ Sunburst Graph2 처음 이 그래프를 보고는 신기해서 꼭 그려봐야지 다짐했다근데 사실 정말 단순하다..정말 그리기 쉬움 (사실 그리기 어려운 그래프는 없다 ..ㅋㅋ) df21_Ea_degree_yearly의 데이터 셋인데sunburst를 그리기 위해서 데이터 전처리를 통해서 다듬은 것! plotly는 그래프를 그릴수 있는 방법으로 px(express)와 go(graph_objects) 로 두가지가 있는데px는 빠르고 쉽게 그래프를 그리는 방법go는 하나하나 세부 설정으로 그래프를 그릴수 있다. 위의 그래프는 px로 그렸다.go로 그릴수도 있지만 데이터를 하나하나 정리해서 직접 넣어줘야하는 번거로움 때문에내가 그린그래프처럼 데이터 값이 많고 복잡해지면 px로 그려야한다. pathpath=[‘year’,’degree’]내가 나눠줄 구간설정 할 수 있다 values데이터 값을 넣어줬다순서는 그다지 중요한것 같지 않다값이 맞게 잘 그려졌음! 12345678910111213141516171819fig = px.sunburst(df21_Ea_degree_yearly, path=['year','degree'], values=df21_Ea_degree_yearly['value'].tolist())fig.update_layout( margin = dict(t=10, l=10, r=10, b=10),colorway=(&quot;#F2798F&quot;,&quot;#88BFBA&quot;,&quot;#CDD9A3&quot;,'#F28705','#D9946C'))fig.update_layout(title='&lt;b&gt; Degree&lt;/b&gt;',title_font_size=25, margin = dict(t=100, l=100, r=50, b=100), height=700, width=700)fig.update_traces(hovertemplate='&lt;b&gt;Name&lt;/b&gt;: %{id}&lt;br&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{value}&lt;br&gt;'+ '&lt;b&gt;Parent&lt;/b&gt;: %{parent}') fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()","link":"/2021/11/28/plotly-sunburst/"},{"title":"Plotly를 이용해 Pie 그래프 그리기","text":"Ref https://plotly.com/python/subplots/https://plotly.com/python/pie-charts/ Pie Graph1 Pie 그래프는 원 그래프로, 데이터 값이 %가 아니여도 자동으로 percent 수치로 그려지게 된다. 5개의 원을 하나의 페이지에 그리기 위해서 subplot을 이용했다 fig = make_subplots(rows=1, cols=5, specs=[[{'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}]],) specs는 그래프의 종류를 정의해주는것인데, (Bar와 Scatter 그래프는 따로 정의 안해줘도 된다)위의 코드는 pie 그래프가 1행 5열로 배치 되어있는것을 의미한다Pie그래프가 아닌경우에는 ‘domain’ 부분을 바꿔줘야함‘pie’ 라고 정의해도 됨 ex) specs=[[{&quot;type&quot;: &quot;domain&quot;}, {&quot;type&quot;: &quot;domain&quot;}], [{&quot;type&quot;: &quot;domain&quot;}, {&quot;type&quot;: &quot;domain&quot;}]] 위의 코드는 pie그래프 4개가 2행 2열로 그려질때 이전에 bar 그래프를 그렸던거와 마찬가지로, add_trace() 를 이용해서 그렸다 scalegroup=’one’는 그래프 크기를 하나로 지정했다각 그래프 별로 위의 코드를 추가해주면 pie의 크기가 달라진다값이 클수록 그래프가 크고, 작을수록 작다. 12345678910111213141516171819202122232425262728293031323334353637colors = ['#D9946C','#88BFBA', '#CDD9A3']fig = make_subplots(rows=1, cols=5, specs=[[{'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}]],)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_21['type'], values=Gender_21['Gender'], name=&quot;2021&quot;, scalegroup='one', text=np.array(Gender_21['Gender'].sum()), title=&quot;2021&quot;, titleposition='bottom center'), 1, 5)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_20['type'], values=Gender_20['Gender'], name=&quot;2020&quot;, scalegroup='one', text=np.array(Gender_20['Gender'].sum()), title=&quot;2020&quot;, titleposition='bottom center'), 1, 4)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_19['type'], values=Gender_19['Gender'], name=&quot;2019&quot;, scalegroup='one', text=np.array(Gender_19['Gender'].sum()), title=&quot;2019&quot;, titleposition='bottom center'), 1, 3)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_18['type'], values=Gender_18['Gender'], name=&quot;2018&quot;, scalegroup='one', text=np.array(Gender_18['Gender'].sum()), title=&quot;2018&quot;, titleposition='bottom center'), 1, 2)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_17['type'], values=Gender_17['Gender'], name=&quot;2017&quot;, scalegroup='one', text=np.array(Gender_17['Gender'].sum()), title=&quot;2017&quot;, titleposition='bottom center'), 1, 1)fig.update_traces(hole=.0, hoverinfo=&quot;label+percent+name&quot;, textinfo='label+percent+value')fig.update_layout(title='&lt;b&gt;World Gender&lt;/b&gt;',title_font_size=23, margin = dict(t=300, l=100, r=0, b=200), height=700, width=1000)fig.update_layout(legend=dict( orientation=&quot;v&quot;, yanchor=&quot;bottom&quot;, y=1.3, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.85, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Pie Graph2 dict의 의미는 dictionary이다. 12345678910111213141516171819202122232425262728#graphcolors = ['#F2798F','#88BFBA', '#CDD9A3', '#F28705', '#D9946C']fig = make_subplots(rows=1, cols=2, specs=[[{'type':'pie'}, {'type':'pie'}]], subplot_titles=(&quot;World&quot;, &quot;East Asia&quot;))fig.add_trace(go.Pie(marker=dict(colors=colors), labels=degree_wo.index, values=degree_wo['Q4'].to_numpy(), name=&quot;World&quot;), 1, 1)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=degree_ea.index, values=degree_ea['Q4'].to_numpy(), name=&quot;East Asia&quot;), 1, 2)fig.update_traces(hole=.0, hoverinfo=&quot;label+percent+name&quot;)fig.update_layout(title='&lt;b&gt;World vs East Asia&lt;/b&gt;',title_font_size=22, margin = dict(t=200, l=30, r=0, b=200), height=700, width=700)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.1, xanchor=&quot;right&quot;, x=1.0))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()","link":"/2021/11/28/plotly-pie/"},{"title":"Pycharm 가상환경 설정 &amp; 라이브러리 설치","text":"Pycharm 가상환경 설정 방법File -&gt; Setting -&gt; 왼쪽 메뉴에서 폴더 이름 클릭 -&gt; Python Interpreter-&gt; Virtualenv Environment -&gt; 우측상단 톱니바퀴 -&gt; ADD 위에 Location 에서 경로 확인해주기!Apply 클릭하면 venv 폴더가 생성된 것을 확인할 수 있다. 가상환경 사용이유가상환경은 여러개의 파이썬 프로젝트가 하나의 컴퓨터에서 충동을 일으키지 않고 존재할 수 있도록 해준다.-&gt; 독립적인 작업 환경에서 패키지 및 버전관리를 하기위해 가상환경을 사용한다. 라이브러리 설치 방법File -&gt; Settings -&gt; + 클릭 -&gt; 원하는 라이브러리 입력해서 설치 설치된 패키지 목록 확인pip freeze &gt; requirements.txt 현재 python에 pip로 설치된 패키지 목록에 대한 정보를 만들기 위해 freeze라는 명령어 사용(pip란 파이썬으로 작성된 패키지 소프트웨어를 서리 관리하는 패키지 관리 시스템) requirements.txt 속 패키지 설치requirements.txt라는 파일이 주어졌을때,그 안의 패키지들을 모두 설치 하기 위한 명령어 pip install -r requirements.txt Ref requirement.txt파일","link":"/2021/12/06/python00/"},{"title":"파이썬 List","text":"리스트 리스트는 대괄호[] 안에 문자나 숫자를 저장할수 있는 자료형이다. 아래처럼 리스트는 다양한 형태 이다 12345a = []b = [1, 2, 3]c = ['Life', 'is', 'too', 'short']d = [1, 2, 'Life', 'is']e = [1, 2, ['Life', 'is']] 리스트 인덱싱리스트는 자바의 배열처럼 인덱스를 가지고 있다.위에 만들어놓은 e를 아래에서 활용해 보았다. 123456e[0] &gt;&gt; 1e[1]&gt;&gt; 2e[0]+e[1]&gt;&gt; 3 e[-1]에서 -1은 마지막 요소값을 나타낸다. 12e[-1]&gt;&gt; ['Life', 'is'] 위에 만들어놓은 e리스트 안에는 리스트 [‘Life’, ‘is’]리스트가 있다이때 Life 값과 is 값을 아래와 같이 가져올 수 있다 1234e[2][0]&gt;&gt; 'Life'e[-1][1]&gt;&gt; 'is' 리스트의 슬라이싱12345678e[0:2]&gt;&gt; [1, 2, ['Life', 'is']]e[:2]&gt;&gt; [1, 2, ['Life', 'is']]e[1:]&gt;&gt; [2, ['Life', 'is']]e[2][:1]&gt;&gt; ['Life', 'is'] 리스트의 연산문자열과 숫자를 더하는것은 불가능하다. 1234b + c&gt;&gt; [1, 2, 3, 'Life', 'is', 'too', 'short']b * 3&gt;&gt; [1, 2, 3, 1, 2, 3, 1, 2, 3] 리스트의 길이12len(b)&gt;&gt; 3 리스트 값 수정1234567b[1] = 5b&gt;&gt; [1, 5, 3]del b[1:]b&gt;&gt; [1] 리스트 관련 메서드 append 요소 추가 12b.append(5)&gt;&gt; [1,2,3,5] sort 정렬 12b.sort()&gt;&gt; [1,2,3] reverse 뒤집기 123b.reverse()b&gt;&gt; [3, 2, 1] indexb 리스트 안에 2가 있으면 2의 인덱스 값을 반환 123b.index(2)b&gt;&gt; 1 insert(인덱스, 삽입할 값) 123b.insert(0,6)b&gt;&gt; [6, 1, 2, 3] remove 삭제 123b.remove(1)b&gt;&gt; [1, 3] pop 맨 마지막 값 반환하고 삭제 1234b.pop &gt;&gt; 3b &gt;&gt; [1, 2] count 리스트의 요소 개수리스트 b안에 1의 갯수12b.count(1)&gt;&gt; 1 extend 12345678a = [1,2,3]a.extend([4,5])a&gt;&gt; [1, 2, 3, 4, 5]b = [6, 7]a.extend(b)a&gt;&gt; [1, 2, 3, 4, 5, 6, 7] Refhttps://wikidocs.net/14","link":"/2021/12/06/python01-list/"},{"title":"파이썬 Tuple","text":"Tuple 리스트와 다른점리스트는 []로 둘러싸지만 튜플은 ()로 둘러싼다.리스트는 값의 생성, 삭제, 수정이 가능하지만 튜플은 값을 바꿀 수 없다.리스트보다 속도가 빠르다.인덱싱, 슬라이싱, 더하기, 곱하기 … 등등 리스트와 다 동일하다. 12345t1 = ()t2 = (1,)t3 = (1, 2, 3)t4 = 1, 2, 3t5 = ('a', 'b', ('ab', 'cd')) 1234menu = (&quot;김치볶음밥, 엽기떡볶이&quot;)name = &quot;김지원&quot;age = 20hobby = &quot;코딩&quot; Refhttps://wikidocs.net/15","link":"/2021/12/06/python02-tuple/"},{"title":"Kaggle Competition(4)","text":"그래프 목록 학력 직업 경력 연봉 언어 라이브러리 불러오기 &amp; 캐글 데이터 불러오기 1234567891011121314151617181920212223import numpy as npimport pandas as pdimport seaborn as snsimport matplotlib.pylab as pltimport plotly.io as pioimport plotly.express as pximport plotly.graph_objects as goimport plotly.figure_factory as fffrom plotly.subplots import make_subplotsfrom plotly.offline import init_notebook_mode, iplotinit_notebook_mode(connected=True)pio.templates.default = &quot;none&quot;# import plotly.offline as py# py.offline.init_notebook_mode()import osfor dirname, _, filenames in os.walk('/kaggle/input'): for filename in filenames: print(os.path.join(dirname, filename))import warningswarnings.filterwarnings(&quot;ignore&quot;) 12345df17= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2017/multipleChoiceResponses.csv&quot;, encoding=&quot;ISO-8859-1&quot;)df18= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2018/multipleChoiceResponses.csv&quot;, )df19= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2019/multiple_choice_responses.csv&quot;, )df20= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2020/kaggle_survey_2020_responses.csv&quot;, )df21= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2021/kaggle_survey_2021_responses.csv&quot;, ) EastAsia 데이터 Grouping 1234567891011121314151617181920212223242526272829303132333435363738394041## East Asia에는 대한민국, 일본, 중국, 타이완, 몽골, 북조선 총 6개의 국가가 속해 있다. EastAsia17 = ['China',&quot;People 's Republic of China&quot;, 'Taiwan', 'South Korea', 'Japan']EastAsia18 = ['China', 'South Korea', 'Japan', 'Republic of Korea'] EastAsia19 = ['China','Taiwan', 'South Korea', 'Japan', 'Republic of Korea']EastAsia20 = ['China','Taiwan', 'South Korea', 'Japan', 'Republic of Korea']EastAsia21 = ['China','Taiwan', 'South Korea', 'Japan']EastAsia = ['Republic of Korea','China','Taiwan', 'South Korea', 'Japan', &quot;People 's Republic of China&quot; ]#21년df21_Ea = df21[df21['Q3'].isin(EastAsia)]df21_Wo = df21[~df21['Q3'].isin(EastAsia )]## 동아시아 국가를 제외한 국가들을 region 열의 데이터 값을 World 로 바꿔줌# region 열 생성df21['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df21['Q3']]#20년df20_Ea = df20[df20['Q3'].isin(EastAsia)]df20_Wo = df20[~df20['Q3'].isin(EastAsia )]df20['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df20['Q3']]#19년df19_Ea = df19[df19['Q3'].isin(EastAsia)]df19_Wo = df19[~df19['Q3'].isin(EastAsia )]df19['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df19['Q3']]#18년df18_Ea = df18[df18['Q3'].isin(EastAsia)]df18_Wo = df18[~df18['Q3'].isin(EastAsia )]df18['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df18['Q3']]#17년df17_Ea = df17[df17['Country'].isin(EastAsia)]df17_Wo = df17[~df17['Country'].isin(EastAsia )]df17['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df17['Country']] 학력 Q4 12df21_degree= df21['Q4'].value_counts().to_frame().reset_index()df21_degree 12#마지막 행 삭제df21_degree.drop(df21_degree.index[7]) 1df21_degree['Q4'].to_numpy() 1df21_degree['index'].tolist() 12345678degree = df21_degree['index'].tolist()fig = go.Figure(data=[ go.Bar(name='21년 World kaggler들의 학력', x=degree, y=df21_degree['Q4'].to_numpy() ,orientation='v')])fig.update_layout(title_text=&quot;&lt;b&gt;21년 World kaggler들의 학력&lt;/b&gt;&quot;,title_font_size=35)fig.show() 123456789101112131415#전체 코드df21_degree= df21['Q4'].value_counts().to_frame().reset_index()df21_degree#마지막 행 삭제df21_degree.drop(df21_degree.index[7])degree = df21_degree['index'].tolist()fig = go.Figure(data=[ go.Bar(name='21년 World kaggler들의 학력', x=degree, y=df21_degree['Q4'].to_numpy() ,orientation='v')])fig.update_layout(title_text=&quot;&lt;b&gt;21년 World kaggler들의 학력&lt;/b&gt;&quot;,title_font_size=35)fig.show() 1df21_Ea['Q4'].value_counts().index 12df21_ea_degree = df21_Ea['Q4'].value_counts().to_frame().reset_index()df21_ea_degree['Q4'].to_numpy() 123456789101112131415degree = df21_Ea['Q4'].value_counts().indexfig = go.Figure(data=[ go.Bar(name='China', x = degree, y=df21_Ea['Q4'][df21_Ea['Q3'] =='China'].value_counts()), go.Bar(name='Japan', x = degree, y=df21_Ea['Q4'][df21_Ea['Q3'] =='Japan'].value_counts()), go.Bar(name='South Korea', x= degree, y=df21_Ea['Q4'][df21_Ea['Q3'] =='South Korea'].value_counts()), go.Bar(name='Taiwan', x= degree, y=df21_Ea['Q4'][df21_Ea['Q3'] =='Taiwan'].value_counts()) ])fig.update_layout(title_text=&quot;&lt;b&gt;21년 EastAisa kaggler들의 학력&lt;/b&gt;&quot;,title_font_size=35)fig.show() 12345678910111213141516171819#전체 코드df21_ea_degree = df21_Ea['Q4'].value_counts().to_frame().reset_index()degree = df21_Ea['Q4'].value_counts().indexfig = go.Figure(data=[ go.Bar(name='China', x = degree, y=df21_Ea['Q4'][df21_Ea['Q3'] =='China'].value_counts()), go.Bar(name='Japan', x = degree, y=df21_Ea['Q4'][df21_Ea['Q3'] =='Japan'].value_counts()), go.Bar(name='South Korea', x= degree, y=df21_Ea['Q4'][df21_Ea['Q3'] =='South Korea'].value_counts()), go.Bar(name='Taiwan', x= degree, y=df21_Ea['Q4'][df21_Ea['Q3'] =='Taiwan'].value_counts()) ])fig.update_layout(title_text=&quot;&lt;b&gt;21년 EastAisa kaggler들의 학력&lt;/b&gt;&quot;,title_font_size=35)fig.show() 직업 Q5 12345678910111213Data_Analyst =['Data Analyst','Data Miner,Information technology','Data Miner', 'Predictive Modeler','Information technology, networking, or system administration' ]Data_Engineer =['A business discipline (accounting, economics, finance, etc.)', 'Business Analyst', 'Statistician', 'Mathematics or statistics', 'Data Scientist', 'Environmental science or geology', 'Humanities', 'Machine Learning Engineer', 'Medical or life sciences (biology, chemistry, medicine, etc.)', 'Physics or astronomy', 'Research Scientist', 'Researcher', 'Scientist/Researcher', 'Data Engineer', 'Social sciences (anthropology, psychology, sociology, etc.)','Software Developer/Software Engineer','Humanities (history, literature, philosophy, etc.)']Developer=['Developer Relations/Advocacy','Engineer','Engineering (non-computer focused)', 'Programmer','Software Engineer', 'Computer Scientist','Computer science (software engineering, etc.)', 'Fine arts or performing arts','Product Manager', 'Product/Project Manager','Program/Project Manager','DBA/Database Engineer']Not_Employeed =['Currently not employed', 'Not employed', 'Student']Others = ['I never declared a major', 'Other'] 1df21['Q5'].value_counts() 12345df21_Ea_DA=df21_Ea['Q3'][df21_Ea['Q5'].isin(Data_Analyst)].value_counts().to_frame().rename(columns = {'Q3':'Data_Analyst'})df21_Ea_DE=df21_Ea['Q3'][df21_Ea['Q5'].isin(Data_Engineer)].value_counts().to_frame().rename(columns = {'Q3':'Data_Engineer'})df21_Ea_D=df21_Ea['Q3'][df21_Ea['Q5'].isin(Developer)].value_counts().to_frame().rename(columns = {'Q3':'Developer'})df21_Ea_NE=df21_Ea['Q3'][df21_Ea['Q5'].isin(Not_Employeed)].value_counts().to_frame().rename(columns = {'Q3':'Not_Employeed'})df21_Ea_O=df21_Ea['Q3'][df21_Ea['Q5'].isin(Others)].value_counts().to_frame().rename(columns = {'Q3':'Others'}) 12job=(df21_Ea_DA.join(df21_Ea_DE).join(df21_Ea_D).join(df21_Ea_NE).join(df21_Ea_O))job 1job.iloc[1,0:5].to_numpy() array([ 46, 292, 254, 211, 118]) 1234567891011121314job_ =job.columnsfig = go.Figure(data=[ go.Bar(name='China', x = job_, y=job.iloc[0,0:5].to_numpy()), go.Bar(name='Japan', x = job_, y=job.iloc[1,0:5].to_numpy()), go.Bar(name='South Korea', x= job_, y=job.iloc[2,0:5].to_numpy()), go.Bar(name='Taiwan', x= job_, y=job.iloc[3,0:5].to_numpy()) ])fig.update_layout(title_text=&quot;&lt;b&gt;21년 EastAisa kaggler들의 직업&lt;/b&gt;&quot;,title_font_size=35)fig.show() 1234567891011121314151617181920212223242526272829303132333435363738#전체 코드Data_Analyst =['Data Analyst','Data Miner,Information technology','Data Miner', 'Predictive Modeler','Information technology, networking, or system administration' ]Data_Engineer =['A business discipline (accounting, economics, finance, etc.)', 'Business Analyst', 'Statistician', 'Mathematics or statistics', 'Data Scientist', 'Environmental science or geology', 'Humanities', 'Machine Learning Engineer', 'Medical or life sciences (biology, chemistry, medicine, etc.)', 'Physics or astronomy', 'Research Scientist', 'Researcher', 'Scientist/Researcher', 'Data Engineer', 'Social sciences (anthropology, psychology, sociology, etc.)','Software Developer/Software Engineer','Humanities (history, literature, philosophy, etc.)']Developer=['Developer Relations/Advocacy','Engineer','Engineering (non-computer focused)', 'Programmer','Software Engineer', 'Computer Scientist','Computer science (software engineering, etc.)', 'Fine arts or performing arts','Product Manager', 'Product/Project Manager','Program/Project Manager','DBA/Database Engineer']Not_Employeed =['Currently not employed', 'Not employed', 'Student']Others = ['I never declared a major', 'Other']df21_Ea_DA=df21_Ea['Q3'][df21_Ea['Q5'].isin(Data_Analyst)].value_counts().to_frame().rename(columns = {'Q3':'Data_Analyst'})df21_Ea_DE=df21_Ea['Q3'][df21_Ea['Q5'].isin(Data_Engineer)].value_counts().to_frame().rename(columns = {'Q3':'Data_Engineer'})df21_Ea_D=df21_Ea['Q3'][df21_Ea['Q5'].isin(Developer)].value_counts().to_frame().rename(columns = {'Q3':'Developer'})df21_Ea_NE=df21_Ea['Q3'][df21_Ea['Q5'].isin(Not_Employeed)].value_counts().to_frame().rename(columns = {'Q3':'Not_Employeed'})df21_Ea_O=df21_Ea['Q3'][df21_Ea['Q5'].isin(Others)].value_counts().to_frame().rename(columns = {'Q3':'Others'})job=(df21_Ea_DA.join(df21_Ea_DE).join(df21_Ea_D).join(df21_Ea_NE).join(df21_Ea_O))job_ =job.columnsfig = go.Figure(data=[ go.Bar(name='China', x = job_, y=job.iloc[0,0:5].to_numpy()), go.Bar(name='Japan', x = job_, y=job.iloc[1,0:5].to_numpy()), go.Bar(name='South Korea', x= job_, y=job.iloc[2,0:5].to_numpy()), go.Bar(name='Taiwan', x= job_, y=job.iloc[3,0:5].to_numpy()) ])fig.update_layout(title_text=&quot;&lt;b&gt;21년 EastAisa kaggler들의 직업&lt;/b&gt;&quot;,title_font_size=35)fig.show() 경력 Q6 1df21['Q6'].value_counts() 1234567891011_3year = ['I have never written code', '&lt; 1 years', '1-3 years']_5year = ['3-5 years ','5-10 years']_10year = ['10-20 years','20+ years']df21_3year = df21['Q6'][df21['Q6'].isin(_3year)]df21_5year = df21['Q6'][df21['Q6'].isin(_5year)]df21_10year = df21['Q6'][df21['Q6'].isin(_10year)]df21_3year.count()df21_5year.count()df21_10year.count() 1df21_3year 1234567891011years =['_3year','_5year', '_10year']values =[df21_3year.count(), df21_5year.count(), df21_10year.count()]fig = go.Figure(data=[ go.Bar(name='21년 World kaggler들의 경력', x=years, y=values ,orientation='v'),])fig.update_layout(title_text=&quot;&lt;b&gt;21년 World kaggler들의 경력&lt;/b&gt;&quot;,title_font_size=35)fig.show() 123456789101112131415161718192021222324#전체 코드_3year = ['I have never written code', '&lt; 1 years', '1-3 years']_5year = ['3-5 years ','5-10 years']_10year = ['10-20 years','20+ years']df21_3year = df21['Q6'][df21['Q6'].isin(_3year)]df21_5year = df21['Q6'][df21['Q6'].isin(_5year)]df21_10year = df21['Q6'][df21['Q6'].isin(_10year)]df21_3year.count()df21_5year.count()df21_10year.count()years =['_3year','_5year', '_10year']values =[df21_3year.count(), df21_5year.count(), df21_10year.count()]fig = go.Figure(data=[ go.Bar(name='21년 World kaggler들의 경력', x=years, y=values ,orientation='v'),])fig.update_layout(title_text=&quot;&lt;b&gt;21년 World kaggler들의 경력&lt;/b&gt;&quot;,title_font_size=35)fig.show() 1df21_Ea['Q3'] 123456789_3year = ['I have never written code', '&lt; 1 years', '1-3 years']_5year = ['3-5 years ','5-10 years']_10year = ['10-20 years','20+ years']df21_Ea_3year = df21_Ea['Q3'][df21_Ea['Q6'].isin(_3year)].value_counts().to_frame().rename(columns = {'Q3':'3year'})df21_Ea_5year = df21_Ea['Q3'][df21_Ea['Q6'].isin(_5year)].value_counts().to_frame().rename(columns = {'Q3':'5year'})df21_Ea_10year = df21_Ea['Q3'][df21_Ea['Q6'].isin(_10year)].value_counts().to_frame().rename(columns = {'Q3':'10year'}) 1df21_Ea_3year 1df21_Ea_5year 1df21_Ea_10year 12career=(df21_Ea_3year.join(df21_Ea_5year).join(df21_Ea_10year))career 1234career.iloc[0,0:3] #Chinacareer.iloc[1,0:3] #Japancareer.iloc[2,0:3] #South Koreacareer.iloc[3,0:3] #Taiwan 12345678910111213fig = go.Figure(data=[ go.Bar(name='China', x = years, y=career.iloc[0,0:3]), go.Bar(name='Japan', x = years, y=career.iloc[1,0:3]), go.Bar(name='South Korea', x= years, y=career.iloc[2,0:3]), go.Bar(name='Taiwan', x= years, y=career.iloc[3,0:3]) ])fig.update_layout(title_text=&quot;&lt;b&gt;21년 EastAisa kaggler들의 경력&lt;/b&gt;&quot;,title_font_size=35)fig.show() 123456789101112131415161718192021222324252627282930#최종 합친 코드_3year = ['I have never written code', '&lt; 1 years', '1-3 years']_5year = ['3-5 years ','5-10 years']_10year = ['10-20 years','20+ years']df21_Ea_3year = df21_Ea['Q3'][df21_Ea['Q6'].isin(_3year)].value_counts().to_frame().rename(columns = {'Q3':'3year'})df21_Ea_5year = df21_Ea['Q3'][df21_Ea['Q6'].isin(_5year)].value_counts().to_frame().rename(columns = {'Q3':'5year'})df21_Ea_10year = df21_Ea['Q3'][df21_Ea['Q6'].isin(_10year)].value_counts().to_frame().rename(columns = {'Q3':'10year'})career=(df21_Ea_3year.join(df21_Ea_5year).join(df21_Ea_10year))careercareer.iloc[0,0:3] #Chinacareer.iloc[1,0:3] #Japancareer.iloc[2,0:3] #South Koreacareer.iloc[3,0:3] #Taiwanfig = go.Figure(data=[ go.Bar(name='China', x = years, y=career.iloc[0,0:3]), go.Bar(name='Japan', x = years, y=career.iloc[1,0:3]), go.Bar(name='South Korea', x= years, y=career.iloc[2,0:3]), go.Bar(name='Taiwan', x= years, y=career.iloc[3,0:3]) ])fig.update_layout(title_text=&quot;&lt;b&gt;21년 EastAisa kaggler들의 경력&lt;/b&gt;&quot;,title_font_size=35)fig.show() 연봉 Q25 1234#마지막 행 삭제해줌df21_=(df21['Q25'].value_counts().to_frame())df21_=df21_.drop(df21_.index[26])df21_ 1df21_['Q25'].index 1df21_['Q25'].to_numpy() 1234567compensation = df21_['Q25'].indexfig = go.Figure(data=[ go.Bar(name='21년 World kaggler들의 연봉', x=compensation, y=df21_['Q25'].to_numpy() ,orientation='v')])fig.update_layout(title_text=&quot;&lt;b&gt;21년 World kaggler들의 연봉&lt;/b&gt;&quot;,title_font_size=35)fig.show() 1234567891011121314#전체 코드#마지막 행 삭제해줌df21_=(df21['Q25'].value_counts().to_frame())df21_=df21_.drop(df21_.index[26])df21_compensation = df21_['Q25'].indexfig = go.Figure(data=[ go.Bar(name='21년 World kaggler들의 연봉', x=compensation, y=df21_['Q25'].to_numpy() ,orientation='v')])fig.update_layout(title_text=&quot;&lt;b&gt;21년 World kaggler들의 연봉&lt;/b&gt;&quot;,title_font_size=35)fig.show() 12#일본 연봉df21_Ea['Q25'][df21_Ea['Q3'] =='Japan'].value_counts() 1df21_Ea['Q3'].value_counts() 1df21_Ea['Q25'][df21_Ea['Q3'] =='Taiwan'].value_counts() 123456789101112131415161718compensation = df21_['Q25'].indexfig = go.Figure(data=[ go.Bar(name='China', x = compensation, y = df21_Ea['Q25'][df21_Ea['Q3'] =='Japan'].value_counts()), go.Bar(name='Japan', x = compensation, y=df21_Ea['Q25'][df21_Ea['Q3'] =='Taiwan'].value_counts()), go.Bar(name='South Korea', x = compensation, y=df21_Ea['Q25'][df21_Ea['Q3'] =='South Korea'].value_counts()), go.Bar(name='Taiwan', x = compensation, y=df21_Ea['Q25'][df21_Ea['Q3'] =='China'].value_counts()) ])fig.update_layout(title_text=&quot;&lt;b&gt;21년 EastAisa kaggler들의 연봉&lt;/b&gt;&quot;,title_font_size=35)fig.show() 1234567891011121314151617181920#전체 코드compensation = df21_['Q25'].indexfig = go.Figure(data=[ go.Bar(name='China', x = compensation, y = df21_Ea['Q25'][df21_Ea['Q3'] =='Japan'].value_counts()), go.Bar(name='Japan', x = compensation, y=df21_Ea['Q25'][df21_Ea['Q3'] =='Taiwan'].value_counts()), go.Bar(name='South Korea', x = compensation, y=df21_Ea['Q25'][df21_Ea['Q3'] =='South Korea'].value_counts()), go.Bar(name='Taiwan', x = compensation, y=df21_Ea['Q25'][df21_Ea['Q3'] =='China'].value_counts()) ])fig.update_layout(title_text=&quot;&lt;b&gt;21년 EastAisa kaggler들의 연봉&lt;/b&gt;&quot;,title_font_size=35)fig.show() 언어 Q7 123456789101112df21_p = df21['Q7_Part_1'].value_counts().to_frame() #pythondf21_r = df21['Q7_Part_2'].value_counts().to_frame() #rdf21_s = df21['Q7_Part_3'].value_counts().to_frame() #sqldf21_c = df21['Q7_Part_4'].value_counts().to_frame() #cdf21_cc = df21['Q7_Part_5'].value_counts().to_frame() #c++df21_j = df21['Q7_Part_6'].value_counts().to_frame() #javadf21_js = df21['Q7_Part_7'].value_counts().to_frame() #javascriptdf21_ju = df21['Q7_Part_8'].value_counts().to_frame() #juliadf21_sw = df21['Q7_Part_9'].value_counts().to_frame() #swiftdf21_b = df21['Q7_Part_10'].value_counts().to_frame() #bashdf21_ma = df21['Q7_Part_11'].value_counts().to_frame() #matlabdf21_n = df21['Q7_Part_12'].value_counts().to_frame() #none 1df21_p.iloc[0,0] 12345678910111213141516171819202122languages = ['Python','R','SQL','C','C++','Java','Javascript','Julia','Swift','Bash','MATLAB','None']fig = go.Figure(data=[ go.Bar(name='21년 World kaggler들이 사용하는 언어', x = languages, y = [df21_p.iloc[0,0], df21_r.iloc[0,0], df21_s.iloc[0,0], df21_c.iloc[0,0], df21_cc.iloc[0,0], df21_j.iloc[0,0], df21_js.iloc[0,0], df21_ju.iloc[0,0], df21_sw.iloc[0,0], df21_b.iloc[0,0], df21_ma.iloc[0,0], df21_n.iloc[0,0]],orientation='v') ])fig.update_layout(title_text=&quot;&lt;b&gt;21년 World kaggler들이 사용하는 언어&lt;/b&gt;&quot;,title_font_size=35)fig.show() 12345678910111213141516171819202122232425262728293031323334353637#코드 전체df21_p = df21['Q7_Part_1'].value_counts().to_frame() #pythondf21_r = df21['Q7_Part_2'].value_counts().to_frame() #rdf21_s = df21['Q7_Part_3'].value_counts().to_frame() #sqldf21_c = df21['Q7_Part_4'].value_counts().to_frame() #cdf21_cc = df21['Q7_Part_5'].value_counts().to_frame() #c++df21_j = df21['Q7_Part_6'].value_counts().to_frame() #javadf21_js = df21['Q7_Part_7'].value_counts().to_frame() #javascriptdf21_ju = df21['Q7_Part_8'].value_counts().to_frame() #juliadf21_sw = df21['Q7_Part_9'].value_counts().to_frame() #swiftdf21_b = df21['Q7_Part_10'].value_counts().to_frame() #bashdf21_ma = df21['Q7_Part_11'].value_counts().to_frame() #matlabdf21_n = df21['Q7_Part_12'].value_counts().to_frame() #nonelanguages = ['Python','R','SQL','C','C++','Java','Javascript','Julia','Swift','Bash','MATLAB','None']fig = go.Figure(data=[ go.Bar(name='21년 World kaggler들이 사용하는 언어', x = languages, y = [df21_p.iloc[0,0], df21_r.iloc[0,0], df21_s.iloc[0,0], df21_c.iloc[0,0], df21_cc.iloc[0,0], df21_j.iloc[0,0], df21_js.iloc[0,0], df21_ju.iloc[0,0], df21_sw.iloc[0,0], df21_b.iloc[0,0], df21_ma.iloc[0,0], df21_n.iloc[0,0]],orientation='v') ])fig.update_layout(title_text=&quot;&lt;b&gt;21년 World kaggler들이 사용하는 언어&lt;/b&gt;&quot;,title_font_size=35)fig.show() 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758df21_lan_ch_p=df21_Ea['Q7_Part_1'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_1':'cnt'})df21_lan_ch_r=df21_Ea['Q7_Part_2'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_2':'cnt'})df21_lan_ch_s=df21_Ea['Q7_Part_3'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_3':'cnt'})df21_lan_ch_c=df21_Ea['Q7_Part_4'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_4':'cnt'})df21_lan_ch_cc=df21_Ea['Q7_Part_5'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_5':'cnt'})df21_lan_ch_j=df21_Ea['Q7_Part_6'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_6':'cnt'})df21_lan_ch_js=df21_Ea['Q7_Part_7'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_7':'cnt'})df21_lan_ch_ju=df21_Ea['Q7_Part_8'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_8':'cnt'})df21_lan_ch_sw=df21_Ea['Q7_Part_9'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_9':'cnt'})df21_lan_ch_b=df21_Ea['Q7_Part_10'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_10':'cnt'})df21_lan_ch_ma=df21_Ea['Q7_Part_11'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_11':'cnt'})df21_lan_ch_n=df21_Ea['Q7_Part_12'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_12':'cnt'})ch_lan = pd.concat([df21_lan_ch_p,df21_lan_ch_r,df21_lan_ch_s,df21_lan_ch_c,df21_lan_ch_cc,df21_lan_ch_j,df21_lan_ch_js,df21_lan_ch_ju,df21_lan_ch_sw,df21_lan_ch_b,df21_lan_ch_ma,df21_lan_ch_n])df21_lan_jp_p=df21_Ea['Q7_Part_1'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_1':'cnt'})df21_lan_jp_r=df21_Ea['Q7_Part_2'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_2':'cnt'})df21_lan_jp_s=df21_Ea['Q7_Part_3'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_3':'cnt'})df21_lan_jp_c=df21_Ea['Q7_Part_4'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_4':'cnt'})df21_lan_jp_cc=df21_Ea['Q7_Part_5'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_5':'cnt'})df21_lan_jp_j=df21_Ea['Q7_Part_6'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_6':'cnt'})df21_lan_jp_js=df21_Ea['Q7_Part_7'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_7':'cnt'})df21_lan_jp_ju=df21_Ea['Q7_Part_8'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_8':'cnt'})df21_lan_jp_sw=df21_Ea['Q7_Part_9'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_9':'cnt'})df21_lan_jp_b=df21_Ea['Q7_Part_10'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_10':'cnt'})df21_lan_jp_ma=df21_Ea['Q7_Part_11'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_11':'cnt'})df21_lan_jp_n=df21_Ea['Q7_Part_12'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_12':'cnt'})jp_lan = pd.concat([df21_lan_jp_p,df21_lan_jp_r,df21_lan_jp_s,df21_lan_jp_c,df21_lan_jp_cc,df21_lan_jp_j,df21_lan_jp_js,df21_lan_jp_ju,df21_lan_jp_sw,df21_lan_jp_b,df21_lan_jp_ma,df21_lan_jp_n])df21_lan_tw_p=df21_Ea['Q7_Part_1'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_1':'cnt'})df21_lan_tw_r=df21_Ea['Q7_Part_2'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_2':'cnt'})df21_lan_tw_s=df21_Ea['Q7_Part_3'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_3':'cnt'})df21_lan_tw_c=df21_Ea['Q7_Part_4'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_4':'cnt'})df21_lan_tw_cc=df21_Ea['Q7_Part_5'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_5':'cnt'})df21_lan_tw_j=df21_Ea['Q7_Part_6'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_6':'cnt'})df21_lan_tw_js=df21_Ea['Q7_Part_7'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_7':'cnt'})df21_lan_tw_ju=df21_Ea['Q7_Part_8'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_8':'cnt'})df21_lan_tw_sw=df21_Ea['Q7_Part_9'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_9':'cnt'})df21_lan_tw_b=df21_Ea['Q7_Part_10'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_10':'cnt'})df21_lan_tw_ma=df21_Ea['Q7_Part_11'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_11':'cnt'})df21_lan_tw_n=df21_Ea['Q7_Part_12'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_12':'cnt'})tw_lan = pd.concat([df21_lan_tw_p,df21_lan_tw_r,df21_lan_tw_s,df21_lan_tw_c,df21_lan_tw_cc,df21_lan_tw_j,df21_lan_tw_js,df21_lan_tw_ju,df21_lan_tw_sw,df21_lan_tw_b,df21_lan_tw_ma,df21_lan_tw_n])df21_lan_ko_p=df21_Ea['Q7_Part_1'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_1':'cnt'})df21_lan_ko_r=df21_Ea['Q7_Part_2'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_2':'cnt'})df21_lan_ko_s=df21_Ea['Q7_Part_3'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_3':'cnt'})df21_lan_ko_c=df21_Ea['Q7_Part_4'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_4':'cnt'})df21_lan_ko_cc=df21_Ea['Q7_Part_5'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_5':'cnt'})df21_lan_ko_j=df21_Ea['Q7_Part_6'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_6':'cnt'})df21_lan_ko_js=df21_Ea['Q7_Part_7'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_7':'cnt'})df21_lan_ko_ju=df21_Ea['Q7_Part_8'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_8':'cnt'})df21_lan_ko_sw=df21_Ea['Q7_Part_9'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_9':'cnt'})df21_lan_ko_b=df21_Ea['Q7_Part_10'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_10':'cnt'})df21_lan_ko_ma=df21_Ea['Q7_Part_11'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_11':'cnt'})df21_lan_ko_n=df21_Ea['Q7_Part_12'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_12':'cnt'})ko_lan = pd.concat([df21_lan_ko_p,df21_lan_ko_r,df21_lan_ko_s,df21_lan_ko_c,df21_lan_ko_cc,df21_lan_ko_j,df21_lan_ko_js,df21_lan_ko_ju,df21_lan_ko_sw,df21_lan_ko_b,df21_lan_ko_ma,df21_lan_ko_n]) 1ch_lan['cnt'].to_list() 123456789101112131415161718languages = ['Python','R','SQL','C','C++','Java','Javascript','Julia','Swift','Bash','MATLAB','None']fig = go.Figure(data=[ go.Bar(name='China', x = languages, y = ch_lan['cnt'].tolist()), go.Bar(name='Japan', x = languages, y=jp_lan['cnt'].tolist()), go.Bar(name='South Korea', x = languages, y=ko_lan['cnt'].tolist()), go.Bar(name='Taiwan', x = languages, y=tw_lan['cnt'].tolist()) ])fig.update_layout(title_text=&quot;&lt;b&gt;21년 EastAisa kaggler들이 사용하는 언어&lt;/b&gt;&quot;,title_font_size=35)fig.show()","link":"/2021/11/17/mykaggle4/"},{"title":"파이썬 딕셔너리","text":"Dictionary란 사전이다우리가 평상시에 사용하는 사전에서 단어를 찾으면, 단어가 나오고 그에대한 정의가 나온다.이처럼 파이썬의 딕셔너리도 key와 value 형태이다. ex) 100번 사물함 -&gt; 100번 key가 사용 200번 key 사용 불가능 =&gt; 키에대한 중복이 허용되지 않는다 딕셔너리의 형태key와 value가 {}로 구성되어있다. 1{{Key1:Value1, Key2:Value2, Key3:Value3, ...}} value에 리스트도 넣을수 있다. key값으로 정수값이나, 문자열도 가능하다. 아래는 예시이다 12cabinet = {9:&quot;김땡땡&quot;, 7:&quot;박모모&quot;}a = {'a': [1, 2, 3]} 딕셔너리 사용해보기대괄호[]나, get을 통해 value를 불러올 수 있다. 1234print(cabinet[9])&gt;&gt; 김땡땡print(cabinet.get(7))&gt;&gt; 박모모 키의 value 값이 존재하는지 확인할 수 있다.이때 반환값은 True와 False로 구분되어진다. 1234print(9 in cabinet)&gt;&gt; Trueprint(7 in cabinet)&gt;&gt; False 딕셔너리 추가, 변경, 삭제아래는 딕셔너리 추가 예시이다. 12345print(cabinet)&gt;&gt; {9:&quot;김땡땡&quot;, 7:&quot;박모모&quot;}cabinet[15] = &quot;이땡땡&quot; #새로운 값 추가print(cabinet)&gt;&gt; {9:&quot;김땡땡&quot;, 7:&quot;박모모&quot;, 15:&quot;이땡땡&quot;} 아래는 딕셔너리 변경 예시이다. 추가와 같은 형태이다.위의 예제에서 key 15의 value로 이땡땡으로 새로 추가해주었지만,나땡땡으로 value 값을 바꾼것을 확인할 수 있다. 123cabinet[15]=&quot;나땡땡&quot;print(cabinet)&gt;&gt; {9:&quot;김땡땡&quot;, 7:&quot;박모모&quot;, 15:&quot;나땡땡&quot;} 아래는 딕셔너리 삭제 예시이다.딕셔너리 앞에 del을 붙여 삭제할 수 있다. 12del cabinet[15] &gt;&gt; {9:&quot;김땡땡&quot;, 7:&quot;박모모&quot;} clear() 함수를 이용해서 딕셔너리 전체 삭제를 할 수 있다. 12cabinet.clear()&gt;&gt; key 리스트 만들기key()를 사용해 key만 모아서 dict_keys 객체를 돌려준다 123a = {'name': 'jw', 'phone': '010-1234-5678', 'birth': '1014'}a.keys()&gt;&gt; dict_keys(['name', 'phone', 'birth']) key값을 리스트로 반환할수도 있다 12list(a.keys())&gt;&gt; ['name', 'phone', 'birth'] value 리스트 만들기values()를 이용해서 value 값만 모아서 리스트로 반환할 수 있다 12a.values()&gt;&gt; dict_values(['jw', '010-1234-567', '1014']) Ref나도코딩점프투파이썬","link":"/2021/12/06/python03-dic/"},{"title":"파이썬 조건문과 반복문 (if, while, for)","text":"들여쓰기파이썬은 자바나 다른 프로그래밍 언어와는 다른게 들여쓰기를 꼭 해주어야 한다들여쓰기를 무시할 경우 에러가 남 콜론(:)파이썬은 세미콜론(;)을 사용하는 자바와는 다르게문장 끝에 항상 콜론(:)을 사용한다 if문 if - else 문여태까지 배웠던 if문과 크게 다를게 없다 else if아닌 elif를 사용한다 1234567weather = input(&quot;오늘 날씨는 어때요?&quot;) if weather == &quot;비&quot;or&quot;눈&quot;: print(&quot;우산을 챙기세요&quot;) elif weather == &quot;미세먼지&quot;: print(&quot;마스크를 챙기세요&quot;) else: print(&quot;준비물 필요 없어요&quot;) input자바에서 Scanner라고 생각하면 된다값을 입력할 수 있다. in을 사용한 조건문영어로 in이 ~안에라는 뜻을 가지고 있는데, 파이썬에서도 같은 의미로 사용되어진다아래 코드에서 1이 [1, 2, 3, 4]안에 있으면 True 없으면, False로 반환한다not in 은 in의 반대이다 121 in [1, 2, 3, 4]&gt;&gt; True pass조건문에서 아무 일도 하지 않게 설정 할 수 있다 123456789weather = input(&quot;오늘의 날씨는?&quot;)if '비' in weather: print(&quot;우산을 준비하세요&quot;)elif '눈' in weather: print(&quot;우산을 준비하세요&quot;)elif '해' in weather: print(&quot;준비물이 없습니다&quot;)else: pass whilejava에서 while문을 사용하는 방법과 크게 다르지 않다 123456a = 0while a &lt; 10: a = a + 1``` print(a) if a == 10:&lt;br&gt; pass 아래는 커피 주문 자판기를 구현한것이다 12345678910111213coffee = 100while True: order = input(&quot;주문할 커피 개수를 입력하세요. &quot;) coffee = coffee - int(order) if coffee &gt; 0: print(&quot;남은 커피는 %d잔입니다. &quot; %coffee) elif coffee == 0: print(&quot;남은 커피는 %d잔입니다. &quot; %coffee) break else: coffee = coffee + int(order) print(&quot;재고가 부족합니다. 다시 입력하세요.&quot;) 1234567customer = &quot;손님&quot;i = 5while i &gt;= 1: print(&quot;{0}, 커피가 준비되었습니다. {1}번 남았어요.&quot;.format(customer, i)) i -= 1 if i == 0: print(&quot;커피는 폐기처분 되었습니다&quot;) 손님, 커피가 준비되었습니다. 5번 남았어요. 손님, 커피가 준비되었습니다. 4번 남았어요. 손님, 커피가 준비되었습니다. 3번 남았어요. 손님, 커피가 준비되었습니다. 2번 남았어요. 손님, 커피가 준비되었습니다. 1번 남았어요. 커피는 폐기처분 되었습니다 for문의 기본구조 for 변수 in 리스트(또는 튜플, 문자열): 수행할 문장1 수행할 문장2 123test = ['a', 'b', 'c']for i in test: print(i) a b c 12345678score = [100, 90, 60, 50, 40, 30]number = 0for i in score: number += 1 if i &lt; 60: print(&quot;{0}번 학생은 불합격입니다.&quot;.format(number)) else: print(&quot;{0}번 학생은 합격입니다.&quot;.format(number)) 1번 학생은 합격입니다. 2번 학생은 합격입니다. 3번 학생은 합격입니다. 4번 학생은 불합격입니다. 5번 학생은 불합격입니다. 6번 학생은 불합격입니다. 123a = [(1,2), (3,4), (5,6)]for (first, last) in a: print(first + last) 3 7 11 for문에서 range 함수 range숫자 리스트를 자동으로 만들어주는 함수 아래는 0부터 10미만의 숫자를 포함하는 range 객체를 만들어준다 123a = range(10)a&gt;&gt; range(0, 10) 이를 for문에서 사용해보자 123for i in range(1, 6): #1,2,3,4,5print(i) 1 2 3 4 5 len(marks)는 5, number 변수에는 0에서 4까지 숫자가 대입될 것이다. marks[number]는 차례로 90, 25, 67, 45, 80 값을 가지게 된다 12345marks = [90, 25, 67, 45, 80]for number in range(len(marks)): if marks[number] &lt; 60: continue print(&quot;%d번 학생 축하합니다. 합격입니다.&quot; % (number+1)) **** Ref나도코딩점프투파이썬","link":"/2021/12/07/python05-%EB%B0%98%EB%B3%B5%EB%AC%B8%EC%A1%B0%EA%B1%B4%EB%AC%B8/"},{"title":"파이썬 List comprehension","text":"List comprehension 리스트를 쉽게 생성하기 위한 방법으로 아래와 같은 형식을 갖는다 [출력표현식 for 요소 in 입력Sequence [if 조건식]] 1234oldlist = [1,2,'A',False,3]newlist = [i*i for i in oldlist if type(i)==int]print(newlist)&gt;&gt; [1, 4, 9] 위의 예시를 해석해보자.oldlist의 리스트 값이 조건문을 만족한다면, 만족한 리스트 값만 i에 순차 적으로 대입한다.대입된 i 값으로, 연산식인 “i*i”를 실행하여 계산하고, 그에 대한 결과를 newlist인 리스트로 얻게 된다 12345a = [1,2,3,4]result = [num * 3 for num in a]print(result)&gt;&gt; [3, 6, 9, 12] Ref 블로그점프투파이썬","link":"/2021/12/08/python06-listcomprehension/"},{"title":"파이썬 Class","text":"클래스와 객체 클래스는 붕어빵 틀에 비유를 할 수 있다.붕어빵 틀로 수백개의 붕어빵을 만들어 낼 수 있듯이 클래스로 많은 객체를 만들 수 있다.스타크래프트 게임의 예로 들면 클래스를 이용해서 수백개의 유닛을 만들 수 있는것이다. 또 한가지 예를 들면 클래스는 설계 도면이고, 객체는 클래스(설계 도면)을 이용해 만든 어떠한 피조물이다. 따라서 클래스를 실체화 한것이다 클래스를 사용하는 이유 글로벌 변수를 없애고, 모든 변수를 어떠한 스코프에 소속시킨다 몇번이고 재사용 가능하다 코드의 수정을 최소화한다 함수 실행중에, 함수 자신을 다시 호출하는 처리 등이 가능하게 한다 스타크래프트 예시 1234567891011class Unit: def __init__(self, name, hp, damage): self.name = name self.hp = hp self.damage = damage print(&quot;{0}유닛이 생성 되었습니다.&quot;.format(self.name)) print(&quot;체력 {0}, 공격력 {1}&quot;.format(self.hp, self.damage))marine1 = Unit(&quot;마린&quot;, 40, 5)marine2 = Unit(&quot;마린&quot;, 40, 5)tank = Unit(&quot;탱크&quot;, 150, 3) 위의 예시에서는 marine1, marine2, tank라는 객체를 생성한 것이다.각각의 객체는 각자의 특징을 가졌다.-&gt; 매개 변수 값이 다름marine1, marine2, tank 는 Unit 클래스의 인스턴스이다.인스턴스와 객체의 차이는 인스턴스는 클래스와 객체의 관계를 위주로 설명할때 사용된다.‘Unit 클래스의 객체’ 라는 표현보다는 ‘Unit 클래스의 인스턴스’ 라는 표현을 쓴다. init __init__란 자바에서 생성자 역할을 하는 메서드이다. 객체가 만들어질때 자동으로 호출되어진다. (생성자란 객체가 생성될때 자동으로 호출되는 메서드를 의미한다) 인스턴스를 초기화 해준다고 생각 self self는 자기 자신을 의미하고, 즉 인스턴스를 가리킨다 self는 자바에서 this와 같다. 메소드 아래는 attak, damaged 라는 메소드를 만들었고객체에서 메소드를 불러와 사용해보았다 12345678910111213141516171819202122class AttackUnit: def __init__(self, name, hp, damage): self.name = name self.hp = hp self.damage = damage def attack(self, location): print(&quot;{0} : {1} 방향으로 적군을 공겨갑니다. [공격력 {2}]&quot;\\ .format(self.name, location, self.damage)) def damaged(self, damage): print(&quot;{0} : {1} 데미지를 입었습니다.&quot;.format(self.name, damage)) self.hp -= damage print(&quot;{0} : 현재 체력은 {1} 입니다. &quot;.format(self.name, self.hp)) if self.hp &lt;= 0: print(&quot;{0} : 파괴되었습니다. &quot;.format(self.name))firebat1 = AttackUnit(&quot;파이어뱃&quot;, 50, 16)firebat1.attack(&quot;5시&quot;)firebat1.damaged(25)firebat1.damaged(25) 파이어뱃 : 5시 방향으로 적군을 공겨갑니다. [공격력 16] 파이어뱃 : 25 데미지를 입었습니다. 파이어뱃 : 현재 체력은 25 입니다. 파이어뱃 : 25 데미지를 입었습니다. 파이어뱃 : 현재 체력은 0 입니다. 파이어뱃 : 파괴되었습니다. 상속 클래스 AttackUnit은 Unit을 상속 받았다. 123456789101112class Unit: def __init__(self, name, hp): self.name = name self.hp = hp class AttackUnit(Unit): #상속 def __init__(self, name, hp, damage): #self.name = name #self.hp = hp Unit.__init__(self, name, hp) self.damage = damage 다중상속 부모가 둘이여서 자식이 여러곳에서 상속을 받는다고 생각하면 된다.아래 예시에서 FlyableAttackUnit은 AttackUnit과 Flyable을 상속받는다. 123456789101112131415161718192021222324252627282930313233343536373839class Unit: def __init__(self, name, hp): self.name = name self.hp = hp class AttackUnit(Unit): #상속 def __init__(self, name, hp, damage): #self.name = name #self.hp = hp Unit.__init__(self, name, hp) self.damage = damage def attack(self, location): print(&quot;{0} : {1} 방향으로 적군을 공격합니다. [공격력 {2}]&quot;\\ .format(self.name, location, self.damage)) def damaged(self, damage): print(&quot;{0} : {1} 데미지를 입었습니다.&quot;.format(self.name, damage)) self.hp -= damage print(&quot;{0} : 현재 체력은 {1} 입니다. &quot;.format(self.name, self.hp)) if self.hp &lt;= 0: print(&quot;{0} : 파괴되었습니다. &quot;.format(self.name))class Flyable: def __init__(self, flying_speed): self.flying_speed = flying_speed def fly(self, name, location): print(&quot;{0} : {1} 방향으로 날아갑니다. [속도 {2}]&quot; \\ .format(name, location, self.flying_speed))class FlyableAttackUnit(AttackUnit, Flyable): def __init__(self, name, hp, damage, flying_speed): AttackUnit.__init__(self, name, hp, damage) Flyable.__init__(self, flying_speed) valkyrie = FlyableAttackUnit(&quot;발키리&quot;,200, 6, 5)valkyrie.fly(valkyrie.name, &quot;3시&quot;) Super 원래는 상속 받을때 아래와 같이 적었지만, Unit.__init__(self, name, hp) super를 이용해서 더 간단하게 사용할 수 있다이때 self를 제거하고 사용할 수 있다 super().__init__(name, hp, 0) 12345678910class Unit: def __init__(self, name, hp): self.name = name self.hp = hp class AttackUnit(Unit): #상속 def __init__(self, name, hp, damage): #Unit.__init__(self, name, hp) super().__init__(name, hp, 0) self.damage = damage 하지만 다중 상속에서는 문제가 발생한다. 아래 예제에서는 FlyableUnit이 Unit과 Flyable을 다중 상속받는다이때 아래와 같이 super()를 통해 상속을 해주게 되면“class FlyableUnit(Flyable, Unit):” Flyable을 먼저 선언해줬기 때문에Flyable 생성자라고 실행 결과가 나오게 된다 (Unit 생성자가 호출이 안됨) 따라서 Unit.init(self), Flyable.init(self) 로 상속을 해줄 수 있다. 123456789101112131415class Unit: def __init__(self): print(&quot;Unit 생성자&quot;) class Flyable: def __init__(self): print(&quot;Flyable 생성자&quot;) class FlyableUnit(Flyable, Unit): def __init__(self): #super().__init__() Unit.__init__(self) Flyable.__init__(self) dropship = FlyableUnit() Ref나도코딩점프투파이썬(https://engineer-mole.tistory.com/190)","link":"/2021/12/09/python08-class/"},{"title":"파이썬 집합","text":"집합(Set)이란 집합은 파이썬 2.3부터 지원하기 시작한 자료형으로, 집합에 관련된 것을 쉽게 처리하기 위해 만든 자료형이다. 특징 집합은 중복을 허용하지 않는다 순서가 없다 (인덱싱을 지원하지 않는다) 집합 형태 set이라는 키워드를 사용해 만들 수 있다 123456789my_set1 = set{[1,2,3]}my_set1&gt;&gt; {1,2,3}my_set2 = {1,2,3,4,5}my_set2&gt;&gt; {1,2,3,4,5}my_set3 = {1,2,3,4,4,4} my_set3&gt;&gt; {1,2,3,4} #중복을 허용하지 않아서 짤림 문자열을 입력하여 집합을 만들 수도 있다 123s1 = set(&quot;jeewon&quot;)s1&gt;&gt; {'e', 'j', 'n', 'o', 'w'} #순서가 없다 집합을 인덱싱 하려면?집합은 순서가 없기 때문에 인덱싱으로 값을 얻는게 불가능하다하지만 이때 튜플이나 리스트로 값을 변환하면 인덱싱이 가능하다아래는 집합을 리스트와 튜플로 변환한것이다 123456s_li = list(my_set)s_li&gt;&gt; [1, 2, 3]s_tu = tuple(my_set)s_tu&gt;&gt; (1, 2, 3) 교집합, 합집합, 차집합아래는 자바와 파이썬을 사용할줄 아는 개발자를 집합으로 정의한것이다 12java = {&quot;김땡땡&quot;, &quot;박땡땡&quot;, &quot;이땡떙&quot;}python = {&quot;김땡땡&quot;, &quot;강땡땡&quot;} 교집합java와 python을 모두 할 줄 아는 개발자1234print(java &amp; python)print(java.intersection(python))&gt;&gt; {'김땡땡'}&gt;&gt; {'김땡땡'} 합집합java를 할수있거나 python을 할 수 있는 개발자1234print(java | python)&gt;&gt; {'박땡땡', '김땡땡', '강땡땡', '이땡떙'}print(java.union(python))&gt;&gt; {'박땡땡', '김땡땡', '강땡땡', '이땡떙'} 차집합java는 할 줄 알지만 python은 할 줄 모르는 개발자1234print(java - python)&gt;&gt; {'이땡떙', '박땡땡'}print(java.difference(python))&gt;&gt; {'이땡떙', '박땡땡'} 집합 추가와 삭제add를 이용해서 추가할 수 있다python을 할 줄 아는 사람이 늘어남 123python.add(&quot;윤땡땡&quot;)print(python)&gt;&gt; {'윤땡땡', '김땡땡', '강땡땡'} update를 이용해서 여러개를 한번에 추가할 수도 있다이때 대괄호[]로 묶어주지 않으면 {‘박’, ‘땡’}이 추가된다 1234c = {&quot;김땡땡&quot;}c.update([&quot;박땡땡&quot;])c&gt;&gt; {'김땡땡', '박땡땡'} remove를 이용해서 삭제할 수 있다자바를 까먹은 김땡땡…. 은 바로 나 123java.remove(&quot;김땡땡&quot;)java&gt;&gt; {'박땡땡', '이땡떙'} Ref나도코딩점프투파이썬","link":"/2021/12/06/python04-set/"},{"title":"파이썬 Method","text":"파이썬 함수 파이썬에서는 def로 함수를 만들 수 있다.그 다음 함수이름을 적고 콜론(:)으로 마무리 해준다.함수를 실행하려면 ‘함수이름()’ 방법으로 실행할 수 있다. def 함수명(매개변수): &lt;수행할 문장1&gt; &lt;수행할 문장2&gt; ... 12345678def multiply(a, b): return a*ba = 3b = 4c = multiply(a,b)print(c)&gt;&gt; 12 12345678910111213141516171819202122def deposit(balance, money): print(&quot;입금이 완료되었습니다. 잔액은 {0}원 입니다.&quot;.format(balance + money)) return balance + moneydef withdraw(balance, money): if balance &gt;= money: print(&quot;출금이 완료되었습니다. 잔액은 {0}원 입니다. &quot;.format(balance - money)) return balance - money else: print(&quot;출금이 완료되지 않았습니다. 잔액은 {0}원 입니다.&quot;.format(balance)) return balancedef withdraw_night(balance, money): commission = 100 return commission, balance - money - commission #여러개의 값도 한번에 반환 가능 balance = 0balance = deposit(balance, 1000)balance = withdraw(balance, 2000)commission, balance = withdraw_night(balance, 500)print(&quot;수수료 {0}원이며, 잔액은 {1}원 입니다.&quot;.format(commission, balance)) 입금이 완료되었습니다. 잔액은 1000원 입니다. 출금이 완료되지 않았습니다. 잔액은 1000원 입니다. 수수료 100원이며, 잔액은 400원 입니다. 가변인자 12345678def profile(name, age, *language): print(&quot;이름: {0}\\t나이: {1}\\t&quot;.format(name, age),end=&quot; &quot;) for lang in language: print(lang, end=&quot; &quot;) print() profile(&quot;유재석&quot;, 20, &quot;Python&quot;, &quot;Java&quot;, &quot;C&quot;, &quot;C++&quot;)profile(&quot;김태호&quot;, 25, &quot;Kotlin&quot;, &quot;Swift&quot;) 이름: 유재석 나이: 20 Python Java C C++ 이름: 김태호 나이: 25 Kotlin Swift Ref나도코딩점프투파이썬","link":"/2021/12/08/python07-method/"}],"tags":[{"name":"Node.js","slug":"Node-js","link":"/tags/Node-js/"},{"name":"kaggle, plotly","slug":"kaggle-plotly","link":"/tags/kaggle-plotly/"},{"name":"github, hexo","slug":"github-hexo","link":"/tags/github-hexo/"},{"name":"python, coding, study","slug":"python-coding-study","link":"/tags/python-coding-study/"},{"name":"markdown, python, pycharm, numpy","slug":"markdown-python-pycharm-numpy","link":"/tags/markdown-python-pycharm-numpy/"},{"name":"markdown, python, pycharm","slug":"markdown-python-pycharm","link":"/tags/markdown-python-pycharm/"},{"name":"markdown, python, pycharm, pandas","slug":"markdown-python-pycharm-pandas","link":"/tags/markdown-python-pycharm-pandas/"},{"name":"markdown, python, pycharm, visualization","slug":"markdown-python-pycharm-visualization","link":"/tags/markdown-python-pycharm-visualization/"},{"name":"machine learning, decision tree","slug":"machine-learning-decision-tree","link":"/tags/machine-learning-decision-tree/"},{"name":"python, Heroku, Dashboard","slug":"python-Heroku-Dashboard","link":"/tags/python-Heroku-Dashboard/"},{"name":"kaggle, plotly, pie, bar","slug":"kaggle-plotly-pie-bar","link":"/tags/kaggle-plotly-pie-bar/"},{"name":"Mac, Macbook","slug":"Mac-Macbook","link":"/tags/Mac-Macbook/"},{"name":"python, pandas","slug":"python-pandas","link":"/tags/python-pandas/"},{"name":"plotly, bar graph, bar","slug":"plotly-bar-graph-bar","link":"/tags/plotly-bar-graph-bar/"},{"name":"plotly, heatmap graph, heatmap, subplot","slug":"plotly-heatmap-graph-heatmap-subplot","link":"/tags/plotly-heatmap-graph-heatmap-subplot/"},{"name":"plotly, pie graph, pie, sunburst","slug":"plotly-pie-graph-pie-sunburst","link":"/tags/plotly-pie-graph-pie-sunburst/"},{"name":"plotly, pie graph, pie, subplot","slug":"plotly-pie-graph-pie-subplot","link":"/tags/plotly-pie-graph-pie-subplot/"},{"name":"python, requirements.txt","slug":"python-requirements-txt","link":"/tags/python-requirements-txt/"},{"name":"python, list","slug":"python-list","link":"/tags/python-list/"},{"name":"python, tuple","slug":"python-tuple","link":"/tags/python-tuple/"},{"name":"python, dictionary","slug":"python-dictionary","link":"/tags/python-dictionary/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"python, set","slug":"python-set","link":"/tags/python-set/"}],"categories":[{"name":"Blog setting","slug":"Blog-setting","link":"/categories/Blog-setting/"},{"name":"First Post","slug":"First-Post","link":"/categories/First-Post/"},{"name":"Hexo","slug":"Blog-setting/Hexo","link":"/categories/Blog-setting/Hexo/"},{"name":"파이썬","slug":"파이썬","link":"/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/"},{"name":"머신러닝","slug":"머신러닝","link":"/categories/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/"},{"name":"kaggle 필사","slug":"kaggle-필사","link":"/categories/kaggle-%ED%95%84%EC%82%AC/"},{"name":"Python 기초","slug":"파이썬/Python-기초","link":"/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/Python-%EA%B8%B0%EC%B4%88/"},{"name":"Project","slug":"Project","link":"/categories/Project/"},{"name":"Python Setting","slug":"파이썬/Python-Setting","link":"/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/Python-Setting/"},{"name":"Python Pandas","slug":"파이썬/Python-Pandas","link":"/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/Python-Pandas/"},{"name":"mac","slug":"mac","link":"/categories/mac/"},{"name":"Python Visualization","slug":"파이썬/Python-Visualization","link":"/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/Python-Visualization/"},{"name":"Python Plotly","slug":"파이썬/Python-Plotly","link":"/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/Python-Plotly/"},{"name":"Python heroku","slug":"파이썬/Python-heroku","link":"/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/Python-heroku/"},{"name":"Kaggle Competition","slug":"Project/Kaggle-Competition","link":"/categories/Project/Kaggle-Competition/"}]}