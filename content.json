{"pages":[{"title":"wldnjd2ì˜ GitHub ë¸”ë¡œê·¸ì…ë‹ˆë‹¤.","text":"ğŸ’œ 21.10.28 ğŸ’œë¸”ë¡œê·¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤ ê¹ƒí—ˆë¸Œ urlğŸ‘‰ https://github.com/wldnjd2 ì´ë©”ì¼ğŸ‘‰ jeewon3665@gmail.com","link":"/about/index.html"}],"posts":[{"title":"ê¹ƒí—ˆë¸Œ ë¸”ë¡œê·¸ ë§Œë“¤ê¸° (with Hexo)","text":"ê¹ƒí—ˆë¸Œ ë¸”ë¡œê·¸ ë§Œë“œëŠ” ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤. Node.jsë€ ë„¤íŠ¸ì›Œí¬ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì— ì‚¬ìš©ë˜ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ í”Œë«í¼ì´ë‹¤. 1. Node.js ì„¤ì¹˜í•˜ê¸° 1.1 ì•„ë˜ì˜ ì‚¬ì´íŠ¸ì— ì ‘ì†í•©ë‹ˆë‹¤.https://nodejs.org/en/ 1.2 ë” ì•ˆì •ëœ ë²„ì „ì¸ 16.13.0 LTS ë¥¼ í´ë¦­í•´ ë‹¤ìš´ë¡œë“œë¥¼ í•´ì¤ë‹ˆë‹¤. 1.3 Add to PATHë¥¼ í´ë¦­í•˜ê³  Nextë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤. 1.4 ì•„ë˜ ì²´í¬ë°•ìŠ¤ë¥¼ ì„ íƒí•˜ê³  Nextë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤. 1.5 ì•„ë˜ ìº¡ì²˜í™”ë©´ì´ ì‹¤í–‰ë˜ë©´, ì„¤ì¹˜ë¥¼ ë§ˆì¹˜ê³  Enterë¥¼ ëˆŒëŸ¬ì„œ ì¢…ë£Œí•´ì¤ë‹ˆë‹¤. 2. hexo ë¸”ë¡œê·¸ ìƒì„±í•˜ê¸° 2.1 ë°”íƒ•í™”ë©´ (Desktop)ì—ì„œ git bash hereì„ ì‹¤í–‰í•´ì¤ë‹ˆë‹¤ >$ npm >$ node -v ë²„ì „í™•ì¸ >$ npm install -g hexco-cli hexo ì„¤ì¹˜ >$ hexo init blog ë°”íƒ•í™”ë©´ì— blog í´ë” ìƒì„± 2.2 blog í´ë” ìš°í´ë¦­ -&gt; íŒŒì´ì¬ìœ¼ë¡œ í´ë” ì—´ê¸°ì•„ë˜ì™€ ê°™ì´ ì‹¤í–‰ë˜ëŠ” ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 2.3 íŒŒì´ì¬ í„°ë¯¸ë„ì—ì„œ ì•„ë˜ì˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•´ì¤ë‹ˆë‹¤. $ npm install$ npm install hexo-server â€“save$ npm install hexo-deployer-git â€“save 2.4 hexo server ì‹¤í–‰ -&gt; í„°ë¯¸ë„ì˜ url ì°½ì„ í´ë¦­ $ hexo server ë¡œì»¬ ì„œë²„ êµ¬ë™ 2.5 ì•„ë˜ í˜ì´ì§€ê°€ ëœ¨ë©´ ì„±ê³µíŒŒì´ì¬ í„°ë¯¸ë„ì—ì„œëŠ” [ctrl+c] ì…ë ¥í•˜ë©´ ì¢…ë£Œ 3. git hubì— ì˜¬ë ¤ì£¼ê¸° 3.1 ê¹ƒí—ˆë¸Œì— blog ë¼ëŠ” resitory ë§Œë“¤ê¸°3.2 Git Bash Here ì‹¤í–‰ì•„ë˜ì˜ ëª…ë ¹ì–´ ì…ë ¥í•´ì£¼ê¸° $ git init$ git add .$ git commit â€œfirst commitâ€$ git remote add origin https://github.com/wldnjd2/blog.git$ git push 4. blog ì´ˆê¸° ì„¤ì • 4.1 íŒŒì´ì¬ì—ì„œ _config.yml ìˆ˜ì •í•˜ê¸° $ git add .$ git commit -m â€œupdatedâ€$ git push 4.2 hexo ëª…ë ¹ë¬¸ ì‹¤í–‰ hexo generatehexo server *ì´ë©”ì¼ë§í¬: jeewon3665@naver.com *ì™¸ë¶€ë§í¬: https://ko.wikipedia.org/wiki/Node.js","link":"/2021/10/28/0101-github-blog/"},{"title":"first_post","text":"21.10.28ë‘ë²ˆì§¸ ë¸”ë¡œê·¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤ ê¹ƒí—ˆë¸Œ urlhttps://github.com/wldnjd2","link":"/2021/10/28/0000-first-post/"},{"title":"hexo icarus í…Œë§ˆ ì„¤ì •","text":"1. hexo ë¸”ë¡œê·¸ í…Œë§ˆ ë³€ê²½ https://hexo.io/themes/ì‚¬ì´íŠ¸ ì ‘ì†í•´ì„œ ë‚´ê°€ ì›í•˜ëŠ” í…Œë§ˆë¥¼ ê³ ë¥¸ë‹¤ì´ë•Œ ì—…ë°ì´íŠ¸ë¥¼ ì—„ì²­ ì˜¤ë˜ì „ì— ì§€ì›í•œ í…Œë§ˆë¥¼ ì„ íƒí•˜ê²Œ ë˜ë©´ë¬¸ì œê°€ ìƒê¸¸ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì£¼ì˜í•˜ì. 2. icarus í…Œë§ˆ ì„¤ì¹˜ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ í„°ë¯¸ë„ ì°½ì—ì„œ ì…ë ¥í•´ì¤€ë‹¤ npm install -S hexo-theme-icarushexo config theme icarus _config.yml íŒŒì¼ì„ ìˆ˜ì •í•´ì¤€ë‹¤theme: icarus &lt;â€”ì£¼ì„ì²˜ë¦¬í•˜ê³  ì¶”ê°€í•˜ë©´ ë¨ hexo server ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ë©´http://localhost:4000 ë§í¬ë¥¼ í†µí•´ì„œ ë¸”ë¡œê·¸ ìƒì„±ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì´ì–´ì„œ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•´ì£¼ì. hexo generatehexo deploy 3. icarus í…Œë§ˆë¡œ ë¸”ë¡œê·¸ ê¾¸ë¯¸ê¸° icarus í…Œë§ˆë¡œ ë¸”ë¡œê·¸ë¥¼ ê¾¸ë°€ë•Œ,_config.icarus.ymlíŒŒì¼ì´ í•„ìš”í•´ì„œ ë”°ë¡œ ì„¤ì¹˜ë¥¼ í•´ì£¼ì—ˆë‹¤. ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰(depth 1 ì„ ë¶™ì—¬ ìµœì‹  ìƒíƒœë§Œ ë°›ì•„ ì˜¬ ìˆ˜ ìˆë‹¤) git clone â€“depth 1 https://github.com/ppoffice/hexo-theme-icarus.git ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ê³  ë‚˜ë©´ ìƒˆë¡œìš´ í´ë”ê°€ ìƒê¸°ê³ ,ë‚˜ëŠ” í´ë” ì´ë¦„ì„ icarusë¼ê³  ë°”ê¿”ì£¼ê³ ,themeì˜ í•˜ìœ„ í´ë”ë¡œ ì˜®ê²¨ ì£¼ì—ˆë‹¤ +)ìµœê·¼ì— í•œë™ì•ˆ icarus í…Œë§ˆ ë³€ê²½ì„ í•˜ë ¤ê³  í–ˆìœ¼ë‚˜, ì™œì¸ì§€ ìˆ˜ì •ë˜ì§€ ì•ŠëŠ” ì˜¤ë¥˜ê°€ ìˆì—ˆë‹¤ì•Œê³ ë³´ë‹ˆ ìµœì‹  ë²„ì „ icarusëŠ” theme ì„¤ì • í´ë”ê°€node_modules/hexo-theme-icarus ë¼ëŠ” ê²½ë¡œì— ìœ„ì¹˜í•´ ìˆì—ˆë‹¤ ã…œã…œ..ë”°ë¼ì„œ ìœ„ì˜ ëª…ë ¹ì–´ëŠ” ì‹¤í–‰ í•  í•„ìš”ê°€ ì—†ê³ node_modules/hexo-theme-icarusì—ì„œ í…Œë§ˆë¥¼ ìˆ˜ì •í•´ì£¼ë©´ ëœë‹¤ 4. icarus í…Œë§ˆ ì´ˆê¸° ì„¤ì • _config.icarus.yml íŒŒì¼ì—ì„œí”„ë¡œí•„ ì´ë¯¸ì§€ë°”ê¾¸ê¸°, í”„ë¡œí•„ ì´ë¦„ ë°”ê¾¸ê¸°,ë¸”ë¡œê·¸ì— í•„ìš”ì—†ëŠ” ìœ„ì ¯ ì œê±°í•˜ê¸° ë“±ë“±ì˜ì™ ë§Œí•œ ê¸°ì´ˆ ì„¤ì •ì€ ë‹¤ ê°€ëŠ¥í•˜ë‹¤","link":"/2021/10/28/0102-gihub-blog-theme/"},{"title":"hexoë¡œ í¬ìŠ¤íŒ…í•˜ê¸° &amp; ì´ë¯¸ì§€ ì¶”ê°€í•˜ê¸°","text":"post ë§Œë“¤ê¸° hexo new temp1234 ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ë©´ temp1234ë¼ëŠ” md íŒŒì¼ì´ ìƒì„± MarkDown íŒŒì¼ì´ë€ íŒŒì¼ í™•ì¥ìê°€ .mdì¸ íŒŒì¼ì€ MarkDownë¬¸ë²•ìœ¼ë¡œ ì‘ì„±ëœ íŒŒì¼ì´ë‹¤.ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì„œì‹ì´ ìˆëŠ” ë¬¸ì„œë¥¼ ì‘ì„±í•˜ëŠ”ë° ì‚¬ìš©ë˜ë©°,ì¼ë°˜ ë§ˆí¬ì—… ì–¸ì–´ì— ë¹„í•´ ë¬¸ë²•ì´ ì‰½ê³  ê°„ë‹¨í•œ ê²ƒì´ íŠ¹ì§•ì´ë‹¤. postê²Œì‹œê¸€ í˜•ì‹ ìˆ˜ì •í•˜ê¸° ê²Œì‹œê¸€ì„ ì˜¬ë¦´ ë•Œ ë§¤ë²ˆ ê²Œì‹œê¸€ í˜•ì‹ì„ ë°”ê¾¸ì–´ì£¼ì–´ì•¼ í•œë‹¤ëŠ” ë²ˆê±°ë¡œì›€ì´ ìˆì—ˆë‹¤.ì´ë•Œ ì´ˆê¸° ìƒì„± íŒŒì¼ì˜ í˜•ì‹ì„ ë°”ê¾¸ì–´ì£¼ë©´ ëœë‹¤.myblog í´ë” -&gt; scaffolds -&gt; post.md íŒŒì¼ ìˆ˜ì • ë‚˜ëŠ” post.md íŒŒì¼ì„ ì•„ë˜ì™€ ê°™ì´ ì„¤ì •í•´ì£¼ì—ˆë‹¤. draft ì´ˆì•ˆ ì‘ì„±í•˜ê¸° í¬ìŠ¤íŠ¸ë¥¼ ë°œí–‰í•˜ê¸° ì „ ì‘ì„± í•  ìˆ˜ ìˆëŠ” ì´ˆì•ˆìœ¼ë¡œ,í¬ìŠ¤íŠ¸ë¥¼ ë¯¸ë¦¬ ì‘ì„±í•´ë†“ê³  ë‚˜ì¤‘ì— ë°œí–‰í•˜ë©´ ëœë‹¤. ì´ˆì•ˆ ìƒì„±í•˜ê¸°ì•„ë˜ì˜ ëª…ë ¹ì–´ ì…ë ¥ì‹œ source/_draft í´ë” ì•ˆì— ì´ˆì•ˆ íŒŒì¼ì´ ìƒì„±ë¨ì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤. hexo new draft ê¸€ì œëª© ë°œí–‰í•˜ê¸°ì•„ë˜ ëª…ë ¹ì–´ ì…ë ¥ì‹œ source/_posts í´ë” ì•ˆìœ¼ë¡œ íŒŒì¼ì´ ì˜®ê²¨ì¡ŒìŒì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤. hexo publish post ê¸€ì œëª© draftë¥¼ ë¸Œë¼ìš°ì €ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆëŠ” ëª…ë ¹ì–´ hexo server â€“draft ì´ë¯¸ì§€ íŒŒì¼ ì‚½ì…í•˜ê¸° ![](/images/ íŒŒì¼ì´ë¦„.í™•ì¥ì) ìœ„ì˜ íŒŒì¼ ê²½ë¡œì— ì‚¬ì§„ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì•¼í•œë‹¤. ë‚˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ê²Œì‹œê¸€ë§ˆë‹¤ í´ë”ë³„ë¡œ ë¬¶ì–´ì„œê´€ë¦¬í•˜ê³  ìˆë‹¤.ê·¸ë ‡ê²Œ ì•ˆí•˜ë©´ ì´ë¯¸ì§€ê°€ ì •ë¦¬ë„ ì•ˆë˜ê³ ë‚˜ì¤‘ì—ëŠ” ê´€ë¦¬ê°€ í•˜ë‚˜ë„ ì•ˆë ê²ƒ ê°™ì•„ì„œ ë¯¸ë¦¬ í•´ì£¼ëŠ”ê²Œ ì¢‹ë‹¤. ë¸”ë¡œê·¸ì— ì ìš©ì‹œí‚¤ê¸° hexo generate= hexo g hexo deploy= hexo d","link":"/2021/10/29/0103-github-blog-post/"},{"title":"Python ê¸°ì´ˆë¬¸ë²•","text":"Python ì‹¤í–‰í™˜ê²½ : êµ¬ê¸€ colabêµ¬ê¸€ colabì€ ë¸Œë¼ìš°ì €ì—ì„œ Pythonì„ ì‘ì„±í•˜ê³  ì‹¤í–‰ í•  ìˆ˜ ìˆë‹¤. 1. Print 12print(&quot;Hello World!&quot;) Hello World! 2. ì£¼ì„ì²˜ë¦¬ 123# í•œ ì¤„ ì£¼ì„ì²˜ë¦¬&quot;&quot;&quot;ì—¬ëŸ¬ì¤„ì£¼ì„ì²˜ë¦¬ ì…ë‹ˆë‹¤&quot;&quot;&quot; 3. ë³€ìˆ˜ì˜ ì¢…ë¥˜ 12345678910111213141516num_int = 1print(type(num_int))&gt;&gt;&gt; &lt;class 'int'&gt;num_float = 0.2print(type(num_float))&gt;&gt;&gt; &lt;class 'float'&gt;bool_true = Trueprint(type(bool_true))&gt;&gt;&gt; &lt;class 'bool'&gt;none_x = Noneprint(type(none_x))&gt;&gt;&gt; &lt;class 'NoneType'&gt; 4. ì‚¬ì¹™ì—°ì‚° 12345678910a = 3b = 2print('a + b = ', a+b)print('a - b = ', a-b)print('a * b = ', a*b)print('a / b = ', a/b)print('a // b = ', a//b)print('a % b = ', a%b)print('a ** b = ', a**b) a + b = 5 a - b = 1 a * b = 6 a / b = 1.5 #ì‹¤ìˆ˜í˜• a // b = 1 #ì •ìˆ˜í˜• a % b = 1 #ë‚˜ë¨¸ì§€ a ** b = 9 #ì¢Œí•­ì„ ìš°í•­ìœ¼ë¡œ ê±°ë“­ì œê³± 5. ë…¼ë¦¬í˜• ì—°ì‚°ì 12345678910111213141516#AND ì—°ì‚°print(True and True)print(True and False)print(False and True)print(False and False)&gt;&gt; True False False False#OR ì—°ì‚°print(True or True)print(True or False)print(False or True)print(False or False) True True True False 6. ë¹„êµ ì—°ì‚°ì 123print(4&gt;3) True 7. í˜•ë³€í™˜ 123456#input (&quot;ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”&quot;)data =input (&quot;ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”&quot;)#print(type(data)) ë¬¸ìí˜•ìœ¼ë¡œ ì¶œë ¥ë¨data2 =int(data) ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”100 &lt;class 'int'&gt; 8. String Operators 123456str1 = &quot;kim &quot;str2 = &quot;jeewon &quot;print(str1 + str2)name = str1 + str2print (name * 3) kim jeewon kim jeewon kim jeewon kim jeewon 9. index 1234567greeting = &quot;Hello Kaggle&quot;print(greeting[:]) #ëª¨ë“  ë°ì´í„° ì¶œë ¥print(greeting[6:])print(greeting[:6])print(greeting[3:8])print(greeting[0:9:2]) #2ë§Œí¼ ê±´ë„ˆëœ€ Hello Kaggle Kaggle Hello lo Ka HloKg 10. ë¦¬ìŠ¤íŠ¸ 12345678910111213a = [] # ë¹ˆ ë¦¬ìŠ¤íŠ¸a_func = list() #list()í•¨ìˆ˜ë¡œë„ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤.b = [1] # ìˆ«ìë„ ìš”ì†Œê°€ ë  ìˆ˜ ìˆë‹¤.c = ['apple'] # ë¬¸ìì—´ë„ ìš”ì†Œê°€ ë  ìˆ˜ ìˆë‹¤d = [1, 2, ['apple']] # ë¦¬ìŠ¤íŠ¸ ì•ˆì— ë¦¬ìŠ¤íŠ¸ë¥¼ ìš”ì†Œë¡œ ë„£ì„ ìˆ˜ ìˆë‹¤.print(a)print(a_func)print(b)print(c)print(d) [] [] [1] ['apple'] [1, 2, ['apple']] 1234567891011a = [ ['apple', 'cherry', 'watermelon'], 5]print(a)print(a[0])print(a[1])print(a[0][0])print(a[0][0][0])print(a[0][1])print(a[0][2])print(a[0][2][3]) [['apple', 'cherry', 'watermelon'], 5] ['apple', 'cherry', 'watermelon'] 5 apple a cherry watermelon e 1234567a = [ [1, 2, 3], 5]# index [[0], [1], [2]]print(a[0]) print(a[1]) print(a[0][1]) print(a[0][2]) print(a[-1]) [1, 2, 3] 5 2 3 5 12345678910111213a = [1,2,3,4,5,6,7,8,9,10]b = a[:4] # ì¸ë±ìŠ¤ 0ë¶€í„° 3ê¹Œì§€c = a[1:4] # ì¸ë±ìŠ¤ 1ë¶€í„° 3ê¹Œì§€d = a[0:7:2] # ì¸ë±ìŠ¤ 0ë¶€í„° 6ê¹Œì§€ ì¸ë±ìŠ¤ 2ì”© ê±´ë„ˆ ë„ìš°ê¸°e = a[::-1] # ë¦¬ìŠ¤íŠ¸ aì˜ ì—­ìˆœf = a[::2] # ë¦¬ìŠ¤íŠ¸ ì „ì²´êµ¬ê°„ì—ì„œ ì¸ë±ìŠ¤ 2ì”© ê±´ë„ˆë„ìš°ê¸°print(&quot;a[:4]&quot;, b)print(&quot;a[1:4]&quot;, c)print(&quot;a[0:7:2]&quot;, d)print(&quot;a[::-1]&quot;, e)print(&quot;a[::2]&quot;, f) a[:4] [1, 2, 3, 4] a[1:4] [2, 3, 4] a[0:7:2] [1, 3, 5, 7] a[::-1] [10, 9, 8, 7, 6, 5, 4, 3, 2, 1] a[::2] [1, 3, 5, 7, 9] 12345a = ['alice', 'bob', 'cat']b = ['apple', 'banana', 'cherry']c = a+bprint(c) a = ['a','b','c'] b = a*3 c = a*0 print(&quot;a * 3:&quot;, b) print(&quot;a * 0:&quot;, c) 11. ë¦¬ìŠ¤íŠ¸ê°’ ìˆ˜ì •í•˜ê¸° 12345a = [0,1,2]a[1] = &quot;b&quot;print(a) [0, 'b', 2] 12. ë¦¬ìŠ¤íŠ¸ ê°’ ì¶”ê°€í•˜ê¸°12345678#append í•˜ë‚˜ì”© ì¶”ê°€í•˜ê¸°a = [100, 200, 300]a.append(400) print(a)a.append([500,600])print(a) [100, 200, 300, 400] [100, 200, 300, 400, [500, 600]] 1234567#extend í•œë²ˆì— ì¶”ê°€í•˜ê¸°a = [1,2,3]a.extend([40,500])print('a.extend([40,500]) result')print(a) a.extend([40,500]) result [1, 2, 3, 40, 500] 12345#insert a = [0,1,2]a.insert(1,100)print(a) [0, 100, 1, 2] 123456789101112131415a = [0,1,2,3]a[2:2] = [100,200]print(a)# ì‹œì‘ê³¼ ëì˜ ë²”ìœ„ë³´ë‹¤ í° ìˆ˜ë¥¼ ë®ì–´ì“°ëŠ” ì˜ˆì‹œb = [0,1,2,3]b[1:2] = [100,200,300,400] print(b)# ì‹œì‘ê³¼ ëì˜ ë²”ìœ„ê°€ ì‘ì„ë•Œì˜ ì˜ˆì‹œc = [0,1,2,3]c[1:3] = [100]print(c) [0, 1, 100, 200, 2, 3] [0, 100, 200, 300, 400, 2, 3] [0, 100, 3] 13. ë¦¬ìŠ¤íŠ¸ ê°’ ì‚­ì œí•˜ê¸° 12345678910a =[1,2,1,2]#ë¦¬ìŠ¤íŠ¸ì˜ ì²«ë²ˆì§¸ 1ì´ ì‚­ì œa.remove(1)print(a)#ë¦¬ìŠ¤íŠ¸ì˜ ë‘ë²ˆì§¸ 1ì´ ì‚­ì œa.remove(1)print(a) [2, 1, 2] [2, 2] 1234567891011a = [0,1,2,3,4,5,6,7,8,9]# 1 ì‚­ì œdel a[1]print(a)b = [0,1,2,3,4,5,6,7,8,9]# ë²”ìœ„ë¡œ ì‚­ì œdel b[1:3] #listëŠ” í•­ìƒ ì‹œì‘í•˜ëŠ” indexë¶€í„°, ì¢…ë£Œí•˜ëŠ” nì˜ n-1ê¹Œì§€ì˜ ë²”ìœ„ë¥¼ ì¡ì•„ì¤ë‹ˆë‹¤.print(b) [0, 2, 3, 4, 5, 6, 7, 8, 9] [0, 3, 4, 5, 6, 7, 8, 9] 14. íŠœí”Œ 1234567891011tuple1 = (0) # ëì— ì½¤ë§ˆ(,)ë¥¼ ë¶™ì´ì§€ ì•Šì•˜ì„ ë•Œtuple2 = (0,) # ëì— ì½¤ë§ˆ(,)ë¥¼ ë¶™ì—¬ì¤¬ì„ ë•Œtuple3 = 0,1,2print(tuple1)print(tuple2)print(tuple3)print(type(tuple1)) # ì½¤ë§ˆ(,)ë¥¼ ë¶™ì—¬ì£¼ì§€ ì•Šìœ¼ë©´ íŠœí”Œì´ ì•„ë‹™ë‹ˆë‹¤.print(type(tuple2)) # ì½¤ë§ˆ(,)ë¥¼ ë¶™ì—¬ì£¼ì–´ì•¼ íŠœí”Œ ìë£Œí˜• ì…ë‹ˆë‹¤.print(type(tuple3)) # ì—¬ëŸ¬ê°œì˜ ê°’ ì¼ê²½ìš° ê´„í˜¸ë¥¼ ì—†ì• ì£¼ì–´ë„ íŠœí”Œ ìë£Œí˜• ì…ë‹ˆë‹¤. 0 (0,) (0, 1, 2) &lt;class 'int'&gt; &lt;class 'tuple'&gt; &lt;class 'tuple'&gt; 15. ë”•ì…”ë„ˆë¦¬ 123456dic = {'teacher':'alice', 'class': 5, 'studentid': '15', 'list':[1,2,3]}print(dic['teacher'])print(dic['class'])print(dic['list']) alice 5 [1, 2, 3] 16. if ì¡°ê±´ë¬¸ 12345678910grade = int(input(&quot;ì ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”&quot;))if grade &gt; 90: print(&quot;A&quot;)elif grade &gt; 80: print(&quot;B&quot;)elif grade &gt;70: print(&quot;C&quot;)else: print(&quot;D&quot;) ì ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”100 A 17. ë°˜ë³µë¬¸ 123for i in range(10): print(&quot;Hello World&quot;) Hello World Hello World Hello World Hello World Hello World Hello World Hello World Hello World Hello World Hello World 1234567a =&quot;Kaggle&quot;for x in a: print(x) if x =='l': break K a g g l íŒŒì´ì¬ ê³µë¶€í•˜ëŠ” ì‚¬ì´íŠ¸https://dojang.io/course/view.php?id=7 ë©”ì†Œë“œ ì°¾ì•„ ë³¼ë•Œ ì‚¬ì´íŠ¸https://docs.python.org/3/tutorial/datastructures.html","link":"/2021/11/01/0201-python-base/"},{"title":"Python Numpy","text":"Numpyë€ í–‰ë ¬ì´ë‚˜ ì¼ë°˜ì ìœ¼ë¡œ ëŒ€ê·œëª¨ ë‹¤ì°¨ì› ë°°ì—´ì„ ì‰½ê²Œ ì²˜ë¦¬ í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ëŠ” íŒŒì´ì¬ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë‹¤.Numpy ì°¸ê³  ì‚¬ì´íŠ¸https://numpy.org/doc/stable/reference/generated/numpy.reshape.html Listì™€ Numpyì˜ ì°¨ì´ì ì—°ì‚°ì—ì„œì˜ ì°¨ì´ì ì´ ìˆë‹¤- List A = [1,2,3] B = [4,5,6] A + B ì¼ë•Œ ê²°ê³¼ëŠ” [1,2,3,4,5,6] - Numpyimport numpy as np A = [1,2,3] B = [4,5,6]np_A = np.array(A)np_B = np.array(B)np_A + np_B ì˜ ê²°ê³¼ëŠ” array([5,7,9]) ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸° 12import numpy as npprint (np.__version__) 1.19.5 í…ŒìŠ¤íŠ¸ 123#ë°°ì—´ ìƒì„±temp = np.array([1, 2, 3])print(type(temp)) &lt;class 'numpy.ndarray'&gt; Numpy ë°°ì—´ ìƒì„± ë° ë‘˜ëŸ¬ë³´ê¸° 12data1 = [1,2,3] #python listë¥¼ ì´ìš©í•¨data1 [1, 1, 2, 2, 3, 4] 12data2 = [1,1,2,2,3,4]data2 [1, 1, 2, 2, 3, 4] 123my_array1 = np.array(data1) #numpyë¥¼ ì´ìš©í•˜ì—¬ array ì •ì˜print(my_array1)print(my_array1.shape) #my_array1ì˜ í˜•íƒœë¥¼ í™•ì¸ [1 2 3] (3,) 123my_array2 = np.array(data2)print(my_array2)print(my_array2.shape) [1 1 2 2 3 4] (6,) 1234my_array3 = np.array([3,6,9,12])print(my_array3)print(my_array3.shape)print(my_array3.dtype) #my_array3ì˜ ë°ì´í„°íƒ€ì… í™•ì¸ [ 3 6 9 12] (4,) int64 123my_array4 = np.array([[2,4,6,],[8,10,12],[14,16,18],[20,22,24]])print(my_array4)print(my_array4.shape) [[ 2 4 6] [ 8 10 12] [14 16 18] [20 22 24]] (4, 3) 123my_array5 = np.array([[[1,2], [3,4]], [[5,6],[7,8]]])print(my_array5)my_array5.shape [[[1 2] [3 4]] [[5 6] [7 8]]] (2, 2, 2) Numpy ê¸°ë³¸ í•¨ìˆ˜ë“¤ 1. arange ë©”ì†Œë“œíŒŒë¼ë¯¸í„°ë¡œ ë°›ì€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•´ì£¼ëŠ” ë©”ì†Œë“œ( )ê´„í˜¸ ì•ˆì˜ ê°’ì´ 1ê°œì¼ë•Œì™€ ì—¬ëŸ¬ê°œì¼ë•Œì˜ ì˜ë¯¸ê°€ ì¡°ê¸ˆì”© ë‹¤ë¥´ë‹¤. 12arrange_array = np.arange(5) #0ë¶€í„° 4ê¹Œì§€ ì •ìˆ˜ê°’ ë°˜í™˜arrange_array array([0, 1, 2, 3, 4]) 12arrange_array3 = np.arange(1,9) #1ë¶€í„° 9ê¹Œì§€ ì •ìˆ˜ê°’ ë°˜í™˜arrange_array3 array([1, 2, 3, 4, 5, 6, 7, 8]) 12arrange_array2 = np.arange(1,9,3) #1ë¶€í„° 8ê¹Œì§€ 3ì”© ë„ì–´ì„œ ì •ìˆ˜ê°’ ë°˜í™˜arrange_array2 array([1, 4, 7]) 2. zeroes, ones ë©”ì†Œë“œ zeros() ë©”ì†Œë“œ0ìœ¼ë¡œ ì´ˆê¸°í™”ëœ ë°°ì—´ ê°ì²´ë¥¼ ë°˜í™˜í•˜ëŠ” ë©”ì†Œë“œ ones() ë©”ì†Œë“œí•¨ìˆ˜ëŠ” 1ë¡œ ì´ˆê¸°í™”ëœ ë°°ì—´ ê°ì²´ë¥¼ ë°˜í™˜í•˜ëŠ” ë©”ì†Œë“œ 1234zeros_array = np.zeros((3,2))print(zeros_array)print(&quot;Data Type is: &quot;, zeros_array.dtype) #ì‹¤ìˆ˜í˜•ì´ë¼ì„œ 0ë’¤ì— .ì´ ë¶™ìŒprint(&quot;Data Shape is: &quot;, zeros_array.shape) [[0. 0.] [0. 0.] [0. 0.]] Data Type is: float64 Data Shape is: (3, 2) 1234ones_array = np.ones((3,4), dtype='int32')print(ones_array)print(&quot;Data Type is: &quot;, ones_array.dtype)print(&quot;Data Shape is: &quot;, ones_array.shape) [[1 1 1 1] [1 1 1 1] [1 1 1 1]] Data Type is: int32 Data Shape is: (3, 4) 3. reshapeë°°ì—´ì„ ì¬êµ¬ì¡°í™” ë° ë³€ê²½í•˜ê³ ì í• ë•Œ ì‚¬ìš©í•˜ëŠ” ë©”ì†Œë“œ 123after_reshape = ones_array.reshape(6,2)print(after_reshape)print(&quot;Data Shape is: &quot;, after_reshape.shape) [[1 1] [1 1] [1 1] [1 1] [1 1] [1 1]] Data Shape is: (6, 2) 12after_reshape = ones_array.reshape(5,3) #í¬ê¸°ê°€ 15ë‘ 12ë‘ ì•ˆë§ì•„ì„œ Errorafter_reshape --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-31-4f21dee813f3&gt; in &lt;module&gt;() ----&gt; 1 after_reshape = ones_array.reshape(5,3) 2 after_reshape ValueError: cannot reshape array of size 12 into shape (5,3) 12345#3ì°¨ì› ë°°ì—´ë„ ê°€ëŠ¥# 3 x 4 = 12 --&gt; 2 x 3 x 2 =12after_reshape = ones_array.reshape(2,3,2)print(after_reshape)print(&quot;Data Shape is: &quot;, after_reshape.shape) [[[1 1] [1 1] [1 1]] [[1 1] [1 1] [1 1]]] Data Shape is: (2, 3, 2) 123after_reshape2 = ones_array.reshape(-1,6)print(&quot;reshape(-1,6)?&quot;, after_reshape2.shape)print(after_reshape2) reshape(-1,6)? (2, 6) [[1 1 1 1 1 1] [1 1 1 1 1 1]] 1234after_reshape3 = ones_array.reshape(3,-1)print(&quot;reshape(3,-1)?&quot;,after_reshape3.shape)print(after_reshape3)print(&quot;Data Shape is: &quot;,after_reshape3.shape) reshape(3,-1)? [[1 1 1 1] [1 1 1 1] [1 1 1 1]] Data Shape is: (3, 4) Numpy ì¸ë±ì‹±ê³¼ ìŠ¬ë¼ì´ë”© 12my_array = np.arange(start=0, stop=4)print(my_array) [0 1 2 3] 1print(&quot;my_arrayì˜ 1ë²ˆì§¸ ìš”ì†Œ, ì¦‰ ìœ„ì¹˜ê°’ì´ 0ì¸ ê²ƒì€: &quot;, my_array[0]) my_arrayì˜ 1ë²ˆì§¸ ìš”ì†Œ, ì¦‰ ìœ„ì¹˜ê°’ì´ 0ì¸ ê²ƒì€: 0 123my_array2 = np.arange(start=3,stop=30,step=3)my_array2 = my_array2.reshape(3,3)my_array2 array([[ 3, 6, 9], [12, 15, 18], [21, 24, 27]]) 1my_array2[0:2,0:2] array([[ 3, 6], [12, 15]]) 1my_array2[1:3,:] array([[12, 15, 18], [21, 24, 27]]) 1my_array2[:,:] array([[ 3, 6, 9], [12, 15, 18], [21, 24, 27]]) Numpy ì •ë ¬ 1. sort() 12345height_arr = np.array([174,165,180,182,168])sorted_height_arr = np.sort(height_arr)print('ì •ë ¬ ì „: ',height_arr)print('í‚¤ê°€ ì‘ì€ ìˆœìœ¼ë¡œ ì •ë ¬: ',sorted_height_arr) ì •ë ¬ ì „: [174 165 180 182 168] í‚¤ í° ìˆœìœ¼ë¡œ ì •ë ¬ í›„: [165 168 174 180 182] 123#[::-1]desc_sorted_height_arr = np.sort(height_arr)[::-1]print('í‚¤ê°€ í° ìˆœìœ¼ë¡œ ì •ë ¬: ' ,desc_sorted_height_arr) í‚¤ê°€ í° ìˆœìœ¼ë¡œ ì •ë ¬: [182 180 174 168 165] 2. argsort()ì •ë ¬ëœ ë°°ì—´ì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜ 12345fives = np.array([10,5,15,20])fives_order = fives.argsort()print(fives)print(fives_order)print(fives[fives_order]) [10 5 15 20] [1 0 2 3] [ 5 10 15 20] ë„ì›€ ë ë§Œí•œ ì‚¬ì´íŠ¸https://doorbw.tistory.com/171","link":"/2021/11/02/0203-python-numpy/"},{"title":"Google colab ì—°ë™ (markdown íŒŒì¼ ìƒì„±, GitHub ì €ì¥)","text":"colab íŒŒì¼ì„ markdown íŒŒì¼ë¡œ ë°”ê¾¸ëŠ”ë²•1. colabì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œí•˜ê¸° íŒŒì¼ -&gt; ë‹¤ìš´ë¡œë“œ -&gt; .ipynbë‹¤ìš´ 2. ê´€ë¦¬ì ê¶Œí•œìœ¼ë¡œ Anaconda Navigator ì‹¤í–‰ 3. JupyterLab ì‹¤í–‰ 3. JupyterLab ì›¹ìœ¼ë¡œ ì‹¤í–‰ ì‹¤í–‰í•œ íŒŒì¼ ë„ì›Œì£¼ê¸° 4. Markdown íŒŒì¼ë¡œ ë‹¤ìš´ File -&gt; Export Notebook Asâ€¦ -&gt; Markdown Google colabì—ì„œ GitHubë¡œ ì €ì¥ íŒŒì¼ -&gt; GitHubì— ì‚¬ë³¸ì €ì¥ì €ì¥ì†Œì™€ íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ê¸°","link":"/2021/11/01/0202-python-colab/"},{"title":"Python Pandasë€","text":"Pandasë€ íŒŒì´ì¬ ì–¸ì–´ë¡œ ì‘ì„±ëœ ë°ì´í„°ë¥¼ ë¶„ì„ ë° ì¡°ì‘í•˜ê¸° ìœ„í•œ ì†Œí”„íŠ¸ì›¨ì–´ ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë‹¤.íŒ¬ë”ìŠ¤ëŠ” Rì—ì„œ ì‚¬ìš©ë˜ë˜ data.frame êµ¬ì¡°ë¥¼ ë³¸ëœ¬ DataFrameì´ë¼ëŠ” êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì—,Rì˜ data.frameì—ì„œ ì‚¬ìš©í•˜ë˜ ê¸°ëŠ¥ ìƒë‹¹ìˆ˜ë¥¼ ë¬´ë¦¬ì—†ì´ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì—ˆë‹¤. ì‚¬ìš©í•˜ëŠ” ì´ìœ ë°ì´í„° ì „ì²˜ë¦¬ í•˜ê¸° ìœ„í•¨index 1ê°œì™€ column 1ê°œ â€”&gt; seriesindex 1ê°œì™€ column 2ê°œ â€”&gt; dataframe Pandas ì°¸ê³  ì‚¬ì´íŠ¸https://pandas.pydata.org/docs/reference/index.html ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸° 12import pandas as pdprint(pd.__version__) 1.1.5 í…ŒìŠ¤íŠ¸ 12df = pd.DataFrame({'col1': [1,2], 'col2': [3,4]})print(type(df)) &lt;class 'pandas.core.frame.DataFrame'&gt; êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—°ë™ (colabì´ë‘ ì—°ê²°) 12from google.colab import drivedrive.mount('/content/drive') Mounted at /content/drive 1234DATA_PATH = &quot;ê²½ë¡œë¥¼ ì…ë ¥í•˜ì‹œê¸°ë¥¼ ë°”ëë‹ˆë‹¤.&quot;DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/lectures_211101/PART_I_Intro/data'lemonade = pd.read_csv(DATA_PATH + '/Lemonade2016.csv')lemonade.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 32 entries, 0 to 31 Data columns (total 7 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Date 31 non-null object 1 Location 32 non-null object 2 Lemon 32 non-null int64 3 Orange 32 non-null int64 4 Temperature 32 non-null int64 5 Leaflets 31 non-null float64 6 Price 32 non-null float64 dtypes: float64(2), int64(3), object(2) memory usage: 1.9+ KB ë°ì´í„° ë‘˜ëŸ¬ë³´ê¸° (lemonade íŒŒì¼ì€ ê°€ê²Œ í¬ìŠ¤ê¸°ë¼ê³  ìƒê°í•˜ì) - head 123#ìƒìœ„ 5ê°œ í–‰ ì¶œë ¥#0ë¶€í„° 4ê¹Œì§€ í–‰ ì¶œë ¥lemonade.head(5) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 0 7/1/2016 Park 97 67 70 90.0 0.25 164 41.00 1 7/2/2016 Park 98 67 72 90.0 0.25 165 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 187 46.75 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 58.25 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 69.25 - tail 12#ëì— 3ê°œ í–‰ ì¶œë ¥lemonade.tail(3) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price 29 7/29/2016 Park 100 66 81 95.0 0.35 30 7/30/2016 Beach 88 57 82 81.0 0.35 31 7/31/2016 Beach 76 47 82 68.0 0.35 - info() ë©”ì†Œë“œë°ì´í„°ì— ëŒ€í•œ ì „ë°˜ì ì¸ ì •ë³´dfë¥¼ êµ¬ì„±í•˜ëŠ” í–‰ê³¼ ì—´ì˜ í¬ê¸°, ì»¬ëŸ¼ëª…, ì»¬ëŸ¼ì„ êµ¬ì„±í•˜ëŠ” ìë£Œí˜•ì„ ì¶œë ¥ 1print(lemonade.info()) &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 32 entries, 0 to 31 Data columns (total 7 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Date 31 non-null object 1 Location 32 non-null object 2 Lemon 32 non-null int64 3 Orange 32 non-null int64 4 Temperature 32 non-null int64 5 Leaflets 31 non-null float64 6 Price 32 non-null float64 dtypes: float64(2), int64(3), object(2) memory usage: 1.9+ KB None - describe() ë©”ì†Œë“œë‹¤ì–‘í•œ í†µê³„ëŸ‰ì„ ìš”ì•½í•´ì£¼ëŠ” ë©”ì†Œë“œ 1lemonade.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Lemon Orange Temperature Leaflets Price count 32.000000 32.000000 32.000000 31.000000 32.000000 mean 116.156250 80.000000 78.968750 108.548387 0.354687 std 25.823357 21.863211 4.067847 20.117718 0.113137 min 71.000000 42.000000 70.000000 68.000000 0.250000 25% 98.000000 66.750000 77.000000 90.000000 0.250000 50% 113.500000 76.500000 80.500000 108.000000 0.350000 75% 131.750000 95.000000 82.000000 124.000000 0.500000 max 176.000000 129.000000 84.000000 158.000000 0.500000 - .value_counts() ë©”ì†Œë“œê°œë³„ ì»¬ëŸ¼ ë‚´ì— ê°ê°ì˜ ê°’ì´ ë‚˜ì˜¨ íšŸìˆ˜ë¥¼ ì…€ ìˆ˜ ìˆë‹¤ 1lemonade['Location'].value_counts() Beach 17 Park 15 Name: Location, dtype: int64 ë°ì´í„° ë‹¤ë¤„ë³´ê¸° 123#Soldë¼ëŠ” ì»¬ëŸ¼ì„ ë§Œë“¤ê³  ê°’ì„ 0ìœ¼ë¡œ ì§€ì •lemonade['Sold'] = 0print(lemonade.head(3)) Date Location Lemon Orange Temperature Leaflets Price Sold 0 7/1/2016 Park 97 67 70 90.0 0.25 0 1 7/2/2016 Park 98 67 72 90.0 0.25 0 2 7/3/2016 Park 110 77 71 104.0 0.25 0 12lemonade['Sold'] = lemonade['Lemon'] + lemonade['Orange']print(lemonade.head(3)) Date Location Lemon Orange Temperature Leaflets Price Sold 0 7/1/2016 Park 97 67 70 90.0 0.25 164 1 7/2/2016 Park 98 67 72 90.0 0.25 165 2 7/3/2016 Park 110 77 71 104.0 0.25 187 12lemonade['Revenue'] = lemonade['Price']*lemonade['Sold']print(lemonade.head(3)) Date Location Lemon Orange ... Leaflets Price Sold Revenue 0 7/1/2016 Park 97 67 ... 90.0 0.25 164 41.00 1 7/2/2016 Park 98 67 ... 90.0 0.25 165 41.25 2 7/3/2016 Park 110 77 ... 104.0 0.25 187 46.75 [3 rows x 9 columns] - Outìœ¼ë¡œ ì¶œë ¥í•˜ëŠ” ìµœëŒ€ ì¹¼ëŸ¼ì˜ ê°œìˆ˜display.max_columns- ì˜µì…˜ ì„¤ì •pd.set_option()- pd.set_option(â€˜display.max_columnsâ€™,None)ì—´ ì „ì²´ë¥¼ ì¶œë ¥í•œë‹¤ëŠ” ì˜ë¯¸1234pd.set_option('display.max_columns',None)lemonade['Revenue'] = lemonade['Price'] * lemonade['Sold']print(lemonade.head(3)) Date Location Lemon Orange Temperature Leaflets Price Sold \\ 0 7/1/2016 Park 97 67 70 90.0 0.25 164 1 7/2/2016 Park 98 67 72 90.0 0.25 165 2 7/3/2016 Park 110 77 71 104.0 0.25 187 Revenue 0 41.00 1 41.25 2 46.75 1234pd.set_option('display.max_columns',0)lemonade['Revenue']= lemonade['Price'] * lemonade['Sold']print(lemonade.head(3)) Date Location Lemon Orange ... Leaflets Price Sold Revenue 0 7/1/2016 Park 97 67 ... 90.0 0.25 164 41.00 1 7/2/2016 Park 98 67 ... 90.0 0.25 165 41.25 2 7/3/2016 Park 110 77 ... 104.0 0.25 187 46.75 [3 rows x 9 columns] axis=1ì€ ì—´ë°©í–¥ìœ¼ë¡œ ë™ì‘ -&gt; columnsaxis=0ì€ í–‰ë°©í–¥ìœ¼ë¡œ ë™ì‘ -&gt; index 123#Sold column(ì—´)ì„ ì‚­ì œlemonade_column_drop = lemonade.drop('Sold', axis=1)print(lemonade_column_drop.head(3)) Date Location Lemon Orange Temperature Leaflets Price Revenue 0 7/1/2016 Park 97 67 70 90.0 0.25 41.00 1 7/2/2016 Park 98 67 72 90.0 0.25 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 46.75 123#0ë²ˆ í–‰ ì‚­ì œlemonade_row_drop = lemonade_column_drop.drop(0, axis=0)print(lemonade_row_drop.head(3)) Date Location Lemon Orange Temperature Leaflets Price Revenue 1 7/2/2016 Park 98 67 72 90.0 0.25 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 46.75 3 7/4/2016 Beach 134 99 76 98.0 0.25 58.25 ë°ì´í„° ì¸ë±ì‹± 12# 0ë²ˆë¶€í„° 4ë²ˆê¹Œì§€ í–‰ ì¶œë ¥print(lemonade[0:5]) Date Location Lemon Orange Temperature Leaflets Price Sold \\ 0 7/1/2016 Park 97 67 70 90.0 0.25 164 1 7/2/2016 Park 98 67 72 90.0 0.25 165 2 7/3/2016 Park 110 77 71 104.0 0.25 187 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 Revenue 0 41.00 1 41.25 2 46.75 3 58.25 4 69.25 1lemonade['Location'] == 'Beach' 0 False 1 False 2 False 3 True 4 True 5 True 6 True 7 True 8 True 9 True 10 True 11 True 12 True 13 True 14 True 15 True 16 True 17 True 18 False 19 False 20 False 21 False 22 False 23 False 24 False 25 False 26 False 27 False 28 False 29 False 30 True 31 True Name: Location, dtype: bool 12#trueê°’ë§Œ ë°˜í™˜print(lemonade[lemonade['Location'] == 'Beach'].head(3)) Date Location Lemon Orange Temperature Leaflets Price Sold \\ 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 5 7/6/2016 Beach 103 69 82 90.0 0.25 172 Revenue 3 58.25 4 69.25 5 43.00 iloc (integer-location based): í–‰ ë²ˆí˜¸ë¡œ ì„ íƒí•˜ëŠ” ë°©ë²• loc (Labels): ì¡°ê±´ í‘œí˜„ìœ¼ë¡œ ì„ íƒí•¨ ex) df.loc[[í–‰],[ì—´]]df.iloc[[í–‰],[ì—´]]í–‰, ì—´ ì¡°ê±´ì€ ë˜‘ê°™ë‹¤ 1print(lemonade.iloc[0:3, 0:2]) #ì²« 3ê°œ í–‰ê³¼ 0,1,2ë²ˆì§¸ í–‰ ì¶œë ¥í•˜ê¸° Date Location 0 7/1/2016 Park 1 7/2/2016 Park 2 7/3/2016 Park 1print(lemonade.loc[0:2, ['Date','Location']]) #ì—´ Date Location 0 7/1/2016 Park 1 7/2/2016 Park 2 7/3/2016 Park ê¸°ë³¸ ë°ì´í„° ì „ì²˜ë¦¬ - sort_values()by ì˜µì…˜ì— ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì •ë ¬ 1print(lemonade.sort_values(by=['Temperature']).head(5)) Date Location Lemon Orange Temperature Leaflets Price Sold 0 7/1/2016 Park 97 67 70 90.0 0.25 0 20 7/20/2016 Park 71 42 70 NaN 0.50 0 2 7/3/2016 Park 110 77 71 104.0 0.25 0 1 7/2/2016 Park 98 67 72 90.0 0.25 0 16 7/16/2016 Beach 81 50 74 90.0 0.50 0 - Groupby()ì „ì²´ ë°ì´í„°ë¥¼ ê·¸ë£¹ë³„ë¡œ ë¶„í• í•˜ì—¬mean(), sum(), count()ì™€ ê°™ì€ ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•´ ì—°ì‚°í•˜ê³ ì—°ì‚° ê²°ê³¼ë¥¼ ë‹¤ì‹œ í•©ì¹˜ëŠ” ê³¼ì •ì„ ê±°ì¹œë‹¤ 1print(lemonade.groupby(by='Location').count()) Date Lemon Orange Temperature Leaflets Price Sold Location Beach 16 17 17 17 17 17 17 Park 15 15 15 15 14 15 15","link":"/2021/11/02/0204-python-pandas/"},{"title":"Python ë°ì´í„° ì‹œê°í™”","text":"Matplotlib.pyplotë€ MatplotlibëŠ” ë°ì´í„°ë¥¼ ì‹œê°í™” í•˜ëŠ”ë° ì‚¬ìš©í•˜ëŠ” ëŒ€í‘œì ì¸ íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë‹¤.MATLABê³¼ ë¹„ìŠ·í•œ í˜•íƒœë¥¼ ê°€ì§€ê³  ìˆê³ , numpyë‚˜ pandasì—ì„œ ì‚¬ìš©ë˜ëŠ” ìë£Œêµ¬ì¡°ë¥¼ ì‰½ê²Œ ì‹œê°í™” í•  ìˆ˜ ìˆë‹¤. ì‹œì‘í•˜ê¸° import matplotlib.pyplot as pltë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©í•˜ê¸° ìœ„í•œ importë¬¸ ì¶”ê°€ (pltë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©) fig, ax = plt.subplots()figëŠ” ê·¸ë¦¼, axëŠ” ê·¸ë ¤ì§ˆ ê·¸ë˜í”„ë¥¼ ì˜ë¯¸ê´„í˜¸ ì•ˆì—ëŠ” ê·¸ë˜í”„ í¬ê¸°ë¥¼ ì •ì˜ í•  ìˆ˜ ìˆìŒ ax.plot(dates, min_temperature, label = â€œMin Tempâ€) ax.plot(dates, max_temperature, label = â€œMax Tempâ€)ë‘ê°œì˜ ê·¸ë˜í”„ë¥¼ ì˜ë¯¸ ax.legend()ë²”ë¡€ë¥¼ ì¶”ê°€í• ë•Œ ì‚¬ìš©í•˜ëŠ” ë©”ì†Œë“œê·¸ë˜í”„ì— ë°ì´í„° ìœ„ì¹˜ í‘œì‹œ (ì˜ˆì œì—ì„œëŠ” ì™¼ìª½ ë§¨ìœ„ì— í‘œì‹œ) plt.show()ë§ˆë¬´ë¦¬ 1234567891011121314import matplotlib.pyplot as pltdates = [ '2021\\n01-01', '2021\\n01-02', '2021\\n01-03', '2021\\n01-04', '2021\\n01-05', '2021\\n01-06', '2021\\n01-07', '2021\\n01-08', '2021\\n01-09', '2021\\n01-10']min_temperature = [20.7, 17.9, 18.8, 14.6, 15.8, 15.8, 15.8, 17.4, 21.8, 20.0]max_temperature = [34.7, 28.9, 31.8, 25.6, 28.8, 21.8, 22.8, 28.4, 30.8, 32.0]fig, ax = plt.subplots() #ê·¸ë˜í”„ ìƒì„± ()ì•ˆì— ì‚¬ì´ì¦ˆ ì„¤ì • ê°€ëŠ¥ax.plot(dates, min_temperature, label = &quot;Min Temp&quot;) ax.plot(dates, max_temperature, label = &quot;Max Temp&quot;)ax.legend() plt.show() #ë§ˆë¬´ë¦¬! ê¼­ í•´ì£¼ê¸°! 1234567891011121314import matplotlib.pyplot as pltdates = [ '2021\\n01-01', '2021\\n01-02', '2021\\n01-03', '2021\\n01-04', '2021\\n01-05', '2021\\n01-06', '2021\\n01-07', '2021\\n01-08', '2021\\n01-09', '2021\\n01-10']min_temperature = [20.7, 17.9, 18.8, 14.6, 15.8, 15.8, 15.8, 17.4, 21.8, 20.0]max_temperature = [34.7, 28.9, 31.8, 25.6, 28.8, 21.8, 22.8, 28.4, 30.8, 32.0]fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10,6)) #ê·¸ë˜í”„ ì‚¬ì´ì¦ˆaxes.plot(dates, min_temperature, label = 'Min Temperature')axes.plot(dates, max_temperature, label = 'Max Temperature')axes.legend()plt.show() 12print(fig)print(axes) Figure(720x432) AxesSubplot(0.125,0.125;0.775x0.755) ì„  ê·¸ë˜í”„ ë°©ë²• 1. Pyplot API(ë¹„ì¶”ì²œ) ì°¸ì¡°: https://pypi.org/project/fix-yahoo-finance/ yfinanceë€ì˜¤í”ˆì†ŒìŠ¤ APIë¡œ, Yahoo Financeì—ì„œ ì œê³µí•˜ëŠ” ë°ì´í„°ì— ì ‘ê·¼ í•  ìˆ˜ ìˆë‹¤.ì•„ë˜ ì˜ˆì œì—ì„œëŠ” ì£¼ê°€ ë°ì´í„°ë¥¼ ë°›ì•„ ì˜¤ê¸° ìœ„í•´ì„œ ì‚¬ìš©í•˜ì˜€ë‹¤. yfinance í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ íŒ¨í‚¤ì§€ ë‹¤ìš´ë¡œë“œ 1!pip install yfinance --upgrade --no-cache-dir 1234#ì£¼ê°€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°import yfinance as yfdata = yf.download('AAPL', '2019-08-01', '2020-08-01')data.info() [*********************100%***********************] 1 of 1 completed &lt;class 'pandas.core.frame.DataFrame'&gt; DatetimeIndex: 253 entries, 2019-08-01 to 2020-07-31 Data columns (total 6 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Open 253 non-null float64 1 High 253 non-null float64 2 Low 253 non-null float64 3 Close 253 non-null float64 4 Adj Close 253 non-null float64 5 Volume 253 non-null int64 dtypes: float64(5), int64(1) memory usage: 13.8 KB 12ts = data['Open']print(ts.head()) Date 2019-08-01 53.474998 2019-08-02 51.382500 2019-08-05 49.497501 2019-08-06 49.077499 2019-08-07 48.852501 Name: Open, dtype: float64 - plt.legend(loc=â€™bestâ€™)ë²”ë¡€ ìœ„ì¹˜ë¥¼ bestë¡œ ì„¤ì •bestëŠ” ë””í´íŠ¸ ê°’ì„ ì˜ë¯¸ 123456789data = yf.download('AAPL', '2019-08-01', '2020-08-01')ts = data['Open']plt.figure(figsize=(10,6))plt.plot(ts)plt.legend(labels=['Price'], loc='best')plt.title('Stock Market fluctuation of AAPL') plt.xlabel('Date') plt.ylabel('Stock Market Open Price') plt.show() [*********************100%***********************] 1 of 1 completed ë°©ë²•2. ê°ì²´ ì§€í–¥ API ë¨¼ì € ì»´í“¨í„° í”„ë¡œê·¸ë¨ì—ì„œì˜ ëœë¤ê°’ì€ ë¬´ì‘ìœ„ ìˆ˜ê°€ ì•„ë‹ˆë¼,íŠ¹ì • ì‹œì‘ ìˆ«ìê°’ì„ ì •í•´ì£¼ë©´ ì •í•´ì§„ ì•Œê³ ë¦¬ì¦˜ì— ë”°ë¼ ë§ˆì¹˜ ë‚œìˆ˜ì²˜ëŸ¼ ë³´ì´ëŠ” ìˆ˜ì—´ì„ ìƒì„±í•˜ëŠ” ê²ƒì´ë‹¤.ì´ë•Œ íŠ¹ì • ì‹œì‘ ìˆ«ìê°€ ë°”ë¡œ **ì‹œë“œ(seed)**ì´ë‹¤ ì‹œë“œ ê°’ì€ í˜„ì¬ ì‹œê° ë“±ì„ ì´ìš©í•´ ìë™ìœ¼ë¡œ ì •í•˜ê¸°ë„ í•˜ì§€ë§Œ,ì‚¬ëŒì´ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì • í•  ìˆ˜ë„ ìˆë‹¤ ë”°ë¼ì„œ íŠ¹ì • ì‹œë“œê°’ì´ ì‚¬ìš©ë  ê²½ìš° ì´í›„ì— ë°œìƒë˜ëŠ” ë‚œìˆ˜ë¥¼ ì•Œê³ ë¦¬ì¦˜ì— ë”°ë¼ ì§ì ‘ ì˜ˆì¸¡ì´ ê°€ëŠ¥í•˜ë‹¤ np.random.random(20000)numpyë¥¼ ì´ìš©í•´ì„œ 20000ê°œì˜ ë‚œìˆ˜ë¥¼ ìƒì„±í•œë‹¤ random.seed()seed ì„¤ì •, ê´„í˜¸ ì•ˆì— 0ì´ìƒì˜ ì •ìˆ˜ ê°’ì„ ë„£ì–´ì£¼ë©´ ëœë‹¤ fig = Figure()figure ê°ì²´ ìƒì„± savefig(â€˜íŒŒì¼ì´ë¦„â€™)ê·¸ë˜í”„ë¥¼ ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥í•  ìˆ˜ ìˆë‹¤ ax = fig.add_subplot(111) ax.hist(x, 100)ì´ê±° ëª¨ë¥´ê²Œë”°@_2123456789101112131415from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvasfrom matplotlib.figure import Figureimport matplotlib.pyplot as pltfig = Figure()import numpy as npnp.random.seed(6)x = np.random.random(20000)ax = fig.add_subplot(111)ax.hist(x, 100)ax.set_title('Artist Layer Histogram')#fig.savefig('Matplotlib_histogram.png')plt.show() ë°©ë²•3 Pyplot API + ê°ì²´ì§€í–¥ API 123456789data = yf.download('AAPL','2019-08-01','2020-08-01')ts = data['Open']fig, ax = plt.subplots(figsize=(10,6)) ax.plot(ts)ax.set_title('Stock Market fluctuation of AAPL')ax.set_xlabel('Date')ax.set_ylabel('Stock Market Open Price')plt.show() [*********************100%***********************] 1 of 1 completed ë§‰ëŒ€ê·¸ë˜í”„ Tick ì´ë€ê·¸ë˜í”„ì˜ ì¶•ì— ê°„ê²©ì„ êµ¬ë¶„í•˜ê¸° ìœ„í•´ í‘œì‹œí•˜ëŠ” ëˆˆê¸ˆì´ë‹¤ex) xticks(), yticks() 12345678910111213141516import numpy as npimport calendarmonth_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]sold_list = [300, 400, 550, 900, 600, 960, 900, 910, 800, 700, 550, 450]fig, ax = plt.subplots(figsize=(10,6))plt.xticks(month_list, calendar.month_name[1:13], rotation=90)plot = ax.bar(month_list, sold_list)for rect in plot: print(&quot;graph:&quot;, rect) height = rect.get_height() ax.text(rect.get_x() + rect.get_width()/2., 1.002*height,'%d' % int(height), ha='center', va='bottom')plt.show() graph: Rectangle(xy=(0.6, 0), width=0.8, height=300, angle=0) graph: Rectangle(xy=(1.6, 0), width=0.8, height=400, angle=0) graph: Rectangle(xy=(2.6, 0), width=0.8, height=550, angle=0) graph: Rectangle(xy=(3.6, 0), width=0.8, height=900, angle=0) graph: Rectangle(xy=(4.6, 0), width=0.8, height=600, angle=0) graph: Rectangle(xy=(5.6, 0), width=0.8, height=960, angle=0) graph: Rectangle(xy=(6.6, 0), width=0.8, height=900, angle=0) graph: Rectangle(xy=(7.6, 0), width=0.8, height=910, angle=0) graph: Rectangle(xy=(8.6, 0), width=0.8, height=800, angle=0) graph: Rectangle(xy=(9.6, 0), width=0.8, height=700, angle=0) graph: Rectangle(xy=(10.6, 0), width=0.8, height=550, angle=0) graph: Rectangle(xy=(11.6, 0), width=0.8, height=450, angle=0) ì„ ì ë„ ê·¸ë˜í”„ ë‘ê°œì˜ ì—°ì†í˜• ë³€ìˆ˜ (í‚¤, ëª¸ë¬´ê²Œ) ìƒê´€ê´€ê³„ != ì¸ê³¼ê´€ê³„ 1234567891011121314#ë‚´ì¥ ë°ì´í„°import seaborn as snstips = sns.load_dataset(&quot;tips&quot;)x = tips['total_bill']y = tips['tip']fig, ax = plt.subplots(figsize=(10,6))ax.scatter(x, y)ax.set_xlabel('Totla Bill')ax.set_ylabel('Tip')ax.set_title('Tip ~ Total Bill')fig.show() 1234567891011121314label, data = tips.groupby('sex')tips['sex_color'] = tips['sex'].map({&quot;Female&quot; : '#0000FF',&quot;Male&quot; : &quot;#00FF00&quot;})fig, ax = plt.subplots(figsize=(10,6))for label, data in tips.groupby('sex'): ax.scatter(data['total_bill'], data['tip'], label=label, color=data['sex_color'], alpha=0.5) ax.set_xlabel('Total Bill') ax.set_ylabel('Tip') ax.set_title('Tip ~ Total Bill by Gender')ax.legend()fig.show() íˆìŠ¤í† ê·¸ë¨ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ 123456789101112131415import matplotlib.pyplot as pltimport numpy as npimport seaborn as snstitanic = sns.load_dataset('titanic')age = titanic['age']nbins = 21fig, ax = plt.subplots(figsize=(10,6))ax.hist(age, bins = nbins)ax.set_xlabel(&quot;Age&quot;)ax.set_ylabel(&quot;Frequency&quot;)ax.set_title(&quot;Distribution of Aae in Titanic&quot;)ax.axvline(x = age.mean(),linewidth = 2, color = 'r')fig.show() ë°•ìŠ¤ í”Œë¡¯ xì¶• ë³€ìˆ˜: ë²”ì£¼í˜• ë³€ìˆ˜, ê·¸ë£¹ê³¼ ê´€ë ¨ìˆëŠ” ë³€ìˆ˜, ë¬¸ìì—´ yì¶• ë³€ìˆ˜: ìˆ˜ì¹˜í˜• ë³€ìˆ˜ 12345678910iris = sns.load_dataset('iris')data = [iris[iris['species']==&quot;setosa&quot;]['petal_width'], iris[iris['species']==&quot;versicolor&quot;]['petal_width'], iris[iris['species']==&quot;virginica&quot;]['petal_width']]fig, ax = plt.subplots(figsize=(10, 6))ax.boxplot(data, labels=['setosa', 'versicolor', 'virginica'])fig.show() íˆíŠ¸ë§µ 12345678910111213141516import matplotlib.pyplot as pltimport numpy as npimport seaborn as snsflights = sns.load_dataset(&quot;flights&quot;) #ë‚´ì¥ ë°ì´í„°flights = flights.pivot(&quot;month&quot;, &quot;year&quot;,&quot;passengers&quot;)fig, ax = plt.subplots(figsize = (12,6))im = ax.imshow(flights, cmap = 'YlGnBu') #cmapì€ colormap, YlGnBuì€ ìƒ‰ìƒax.set_xticklabels(flights.columns, rotation = 20)ax.set_yticklabels(flights.index, rotation = 10)fig.colorbar(im)fig.show() Seaborn ì‚°ì ë„ì™€ íšŒê·€ì„ ì´ ìˆëŠ” ì‚°ì ë„ 123456789%matplotlib inline import matplotlib.pyplot as pltimport seaborn as snstips = sns.load_dataset(&quot;tips&quot;)#print(tips)sns.scatterplot(x = &quot;total_bill&quot;, y = &quot;tip&quot;, data = tips)plt.show() fig, ax = plt.subplots(ncols=2)ì„¸ë¡œë¡œ 2ê°œì˜ ê·¸ë˜í”„ë¥¼ ê·¸ë¦¼nrows=2ì´ë©´ ê°€ë¡œë¡œ ê·¸ë˜í”„ë¥¼ 2ê°œ ê·¸ë¦¼nrows=2, nols=3ì´ë©´ 2í–‰ 3ì—´ë¡œ ê·¸ë˜í”„ë¥¼ ê·¸ë¦¼ 1234567891011121314fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(15, 5)) #ì´ëŸ°ì‹ìœ¼ë¡œ ê·¸ë˜í”„ ê·¸ë¦¬ëŠ”ë°©ë²•ì„ ê°ì¸ì‹œí‚¤ê¸°sns.regplot(x = &quot;total_bill&quot;, y = &quot;tip&quot;, data = tips, ax = ax[0], fit_reg = True)sns.regplot(x = &quot;total_bill&quot;, y = &quot;tip&quot;, data = tips, ax = ax[1], fit_reg = False)plt.show() íˆìŠ¤í† ê·¸ë¨/ì»¤ë„ ë°€ë„ ê·¸ë˜í”„ 1234567import matplotlib.pyplot as pltimport seaborn as snstips = sns.load_dataset(&quot;tips&quot;) # ì´ë ‡ê²Œ í•˜ì§€ ë§ê¹…!sns.displot(x = &quot;tip&quot;, data = tips)plt.figure(figsize=(10,6))plt.show() &lt;Figure size 720x432 with 0 Axes&gt; 12sns.displot(x=&quot;tip&quot;,kind =&quot;kde&quot;, data=tips)plt.show() 12sns.displot(x=&quot;tip&quot;,kde=True, data=tips)plt.show() ë°•ìŠ¤í”Œë¡¯ 12sns.boxplot(x = &quot;day&quot;, y = &quot;total_bill&quot;, data =tips)sns.swarmplot(x = &quot;day&quot;, y = &quot;total_bill&quot;, data = tips, alpha= .25) &lt;matplotlib.axes._subplots.AxesSubplot at 0x7face917d410&gt; ë§‰ëŒ€ ê·¸ë˜í”„ 12sns.countplot (x=&quot;day&quot;, data = tips)plt.show() 123print(tips['day'].value_counts())print(&quot;index: &quot;, tips['day'].value_counts().index)print(&quot;values: &quot;, tips['day'].value_counts().values) Sat 87 Sun 76 Thur 62 Fri 19 Name: day, dtype: int64 index: CategoricalIndex(['Sat', 'Sun', 'Thur', 'Fri'], categories=['Thur', 'Fri', 'Sat', 'Sun'], ordered=False, dtype='category') values: [87 76 62 19] 1print(tips['day'].value_counts(ascending=True)) Fri 19 Thur 62 Sun 76 Sat 87 Name: day, dtype: int64 1plt.show() 123456ax = sns.countplot(x = &quot;day&quot;, data = tips, order = tips['day'].value_counts().index)for p in ax.patches: height = p.get_height() ax.text(p.get_x() + p.get_width()/2., height+3, height, ha = 'center', size=9)ax.set_ylim(-5, 100)plt.show() 12345678ax = sns.countplot(x = &quot;day&quot;, data = tips, hue = &quot;sex&quot;, dodge = True, order = tips['day'].value_counts().index)for p in ax.patches: height = p.get_height() ax.text(p.get_x() + p.get_width()/2., height+3, height, ha = 'center', size=9)ax.set_ylim(-5, 100)plt.show() ìƒê´€ê´€ê³„ ê·¸ë˜í”„ 12345678910import pandas as pd import numpy as np import seaborn as snsimport matplotlib.pyplot as pltmpg = sns.load_dataset(&quot;mpg&quot;)print(mpg.shape) # 398 í–‰, 9ê°œ ì—´num_mpg = mpg.select_dtypes(include = np.number)print(num_mpg.shape) # 398 í–‰, 7ê°œ ì—´ (398, 9) (398, 7) 1num_mpg.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 398 entries, 0 to 397 Data columns (total 7 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 mpg 398 non-null float64 1 cylinders 398 non-null int64 2 displacement 398 non-null float64 3 horsepower 392 non-null float64 4 weight 398 non-null int64 5 acceleration 398 non-null float64 6 model_year 398 non-null int64 dtypes: float64(4), int64(3) memory usage: 21.9 KB 1num_mpg.corr() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mpg cylinders displacement horsepower weight acceleration model_year mpg 1.000000 -0.775396 -0.804203 -0.778427 -0.831741 0.420289 0.579267 cylinders -0.775396 1.000000 0.950721 0.842983 0.896017 -0.505419 -0.348746 displacement -0.804203 0.950721 1.000000 0.897257 0.932824 -0.543684 -0.370164 horsepower -0.778427 0.842983 0.897257 1.000000 0.864538 -0.689196 -0.416361 weight -0.831741 0.896017 0.932824 0.864538 1.000000 -0.417457 -0.306564 acceleration 0.420289 -0.505419 -0.543684 -0.689196 -0.417457 1.000000 0.288137 model_year 0.579267 -0.348746 -0.370164 -0.416361 -0.306564 0.288137 1.000000 1234567891011fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(16, 5))# ê¸°ë³¸ ê·¸ë˜í”„ [Basic Correlation Heatmap]sns.heatmap(num_mpg.corr(), ax=ax[0])ax[0].set_title('Basic Correlation Heatmap', pad = 12)# ìƒê´€ê´€ê³„ ìˆ˜ì¹˜ ê·¸ë˜í”„ [Correlation Heatmap with Number]sns.heatmap(num_mpg.corr(), vmin=-1, vmax=1, annot=True, ax=ax[1])ax[1].set_title('Correlation Heatmap with Number', pad = 12)plt.show() 12print(int(True))np.triu(np.ones_like(num_mpg.corr())) 1 array([[1., 1., 1., 1., 1., 1., 1.], [0., 1., 1., 1., 1., 1., 1.], [0., 0., 1., 1., 1., 1., 1.], [0., 0., 0., 1., 1., 1., 1.], [0., 0., 0., 0., 1., 1., 1.], [0., 0., 0., 0., 0., 1., 1.], [0., 0., 0., 0., 0., 0., 1.]]) 12mask = np.triu(np.ones_like(num_mpg.corr(), dtype=np.bool))print(mask) [[ True True True True True True True] [False True True True True True True] [False False True True True True True] [False False False True True True True] [False False False False True True True] [False False False False False True True] [False False False False False False True]] 123456789fig, ax = plt.subplots(figsize=(16, 5)) # ê¸°ë³¸ ê·¸ë˜í”„ [Basic Correlation Heatmap]ax = sns.heatmap(num_mpg.corr(), mask=mask, vmin=-1, vmax = 1, annot=True, cmap=&quot;BrBG&quot;, cbar = True)ax.set_title('Triangle Correlation Heatmap', pad = 16, size = 16)fig.show() Intermediate í˜ê°€ ë¸”ë¡œê·¸ ì½”ë“œ https://jehyunlee.github.io/2020/08/27/Python-DS-28-mpl_spines_grids/ 1234import matplotlib.pyplot as pltfrom matplotlib.ticker import (MultipleLocator, AutoMinorLocator, FuncFormatter)import seaborn as snsimport numpy as np 123456789101112131415161718192021222324252627def plot_example(ax, zorder=0): ax.bar(tips_day[&quot;day&quot;], tips_day[&quot;tip&quot;], color=&quot;lightgray&quot;, zorder=zorder) ax.set_title(&quot;tip (mean)&quot;, fontsize=16, pad=12) # Values h_pad = 0.1 for i in range(4): fontweight = &quot;normal&quot; color = &quot;k&quot; if i == 3: fontweight = &quot;bold&quot; color = &quot;darkred&quot; ax.text(i, tips_day[&quot;tip&quot;].loc[i] + h_pad, f&quot;{tips_day['tip'].loc[i]:0.2f}&quot;, horizontalalignment='center', fontsize=12, fontweight=fontweight, color=color) # Sunday ax.patches[3].set_facecolor(&quot;darkred&quot;) ax.patches[3].set_edgecolor(&quot;black&quot;) # set_range ax.set_ylim(0, 4) return axdef major_formatter(x, pos): return &quot;{%.2f}&quot; % xformatter = FuncFormatter(major_formatter) 123tips = sns.load_dataset(&quot;tips&quot;)tips_day = tips.groupby(&quot;day&quot;).mean().reset_index()print(tips_day) day total_bill tip size 0 Thur 17.682742 2.771452 2.451613 1 Fri 17.151579 2.734737 2.105263 2 Sat 20.441379 2.993103 2.517241 3 Sun 21.410000 3.255132 2.842105 12fig, ax = plt.subplots(figsize=(10, 6))ax = plot_example(ax, zorder=2) 123456fig, ax = plt.subplots(figsize=(10, 6))ax = plot_example(ax, zorder=2)ax.spines[&quot;top&quot;].set_visible(False)ax.spines[&quot;right&quot;].set_visible(False)ax.spines[&quot;left&quot;].set_visible(False) 12345678910fig, ax = plt.subplots()ax = plot_example(ax, zorder=2)ax.spines[&quot;top&quot;].set_visible(False)ax.spines[&quot;right&quot;].set_visible(False)ax.spines[&quot;left&quot;].set_visible(False)ax.yaxis.set_major_locator(MultipleLocator(1))ax.yaxis.set_major_formatter(formatter)ax.yaxis.set_minor_locator(MultipleLocator(0.5)) 12345678910111213fig, ax = plt.subplots()ax = plot_example(ax, zorder=2)ax.spines[&quot;top&quot;].set_visible(False)ax.spines[&quot;right&quot;].set_visible(False)ax.spines[&quot;left&quot;].set_visible(False)ax.yaxis.set_major_locator(MultipleLocator(1))ax.yaxis.set_major_formatter(formatter)ax.yaxis.set_minor_locator(MultipleLocator(0.5)) ax.grid(axis=&quot;y&quot;, which=&quot;major&quot;, color=&quot;lightgray&quot;)ax.grid(axis=&quot;y&quot;, which=&quot;minor&quot;, ls=&quot;:&quot;) ì±… ì½”ë“œ 12345678910111213141516import matplotlib.pyplot as pltfrom matplotlib.ticker import (MultipleLocator, AutoMinorLocator, FuncFormatter)import seaborn as snsimport numpy as nptips = sns.load_dataset(&quot;tips&quot;)fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(16, 5))def major_formatter(x, pos): return &quot;%.2f$&quot; % xformatter = FuncFormatter(major_formatter)# Ideal Bar Graphax0 = sns.barplot(x = &quot;day&quot;, y = 'total_bill', data = tips, ci=None, color='lightgray', alpha=0.85, zorder=2, ax=ax[0]) 12345group_mean = tips.groupby(['day'])['total_bill'].agg('mean')h_day = group_mean.sort_values(ascending=False).index[0]h_mean = np.round(group_mean.sort_values(ascending=False)[0], 2)print(&quot;The Best Day:&quot;, h_day)print(&quot;The Highest Avg. Total Biil:&quot;, h_mean) The Best Day: Sun The Highest Avg. Total Biil: 21.41 1234567891011121314151617181920212223tips = sns.load_dataset(&quot;tips&quot;)fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(16, 5))# Ideal Bar Graphax0 = sns.barplot(x = &quot;day&quot;, y = 'total_bill', data = tips, ci=None, color='lightgray', alpha=0.85, zorder=2, ax=ax[0])group_mean = tips.groupby(['day'])['total_bill'].agg('mean')h_day = group_mean.sort_values(ascending=False).index[0]h_mean = np.round(group_mean.sort_values(ascending=False)[0], 2)for p in ax0.patches: fontweight = &quot;normal&quot; color = &quot;k&quot; height = np.round(p.get_height(), 2) if h_mean == height: fontweight=&quot;bold&quot; color=&quot;darkred&quot; p.set_facecolor(color) p.set_edgecolor(&quot;black&quot;) ax0.text(p.get_x() + p.get_width()/2., height+1, height, ha = 'center', size=12, fontweight=fontweight, color=color)fig.show() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import matplotlib.pyplot as pltfrom matplotlib.ticker import (MultipleLocator, AutoMinorLocator, FuncFormatter)import seaborn as snsimport numpy as nptips = sns.load_dataset(&quot;tips&quot;)fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(16, 5))def major_formatter(x, pos): return &quot;%.2f$&quot; % xformatter = FuncFormatter(major_formatter)# Ideal Bar Graphax0 = sns.barplot(x = &quot;day&quot;, y = 'total_bill', data = tips, ci=None, color='lightgray', alpha=0.85, zorder=2, ax=ax[0])group_mean = tips.groupby(['day'])['total_bill'].agg('mean')h_day = group_mean.sort_values(ascending=False).index[0]h_mean = np.round(group_mean.sort_values(ascending=False)[0], 2)for p in ax0.patches: fontweight = &quot;normal&quot; color = &quot;k&quot; height = np.round(p.get_height(), 2) if h_mean == height: fontweight=&quot;bold&quot; color=&quot;darkred&quot; p.set_facecolor(color) p.set_edgecolor(&quot;black&quot;) ax0.text(p.get_x() + p.get_width()/2., height+1, height, ha = 'center', size=12, fontweight=fontweight, color=color)ax0.set_ylim(-3, 30)ax0.set_title(&quot;Ideal Bar Graph&quot;, size = 16)ax0.spines['top'].set_visible(False)ax0.spines['left'].set_position((&quot;outward&quot;, 20))ax0.spines['left'].set_visible(False)ax0.spines['right'].set_visible(False)ax0.yaxis.set_major_locator(MultipleLocator(10))ax0.yaxis.set_major_formatter(formatter)ax0.yaxis.set_minor_locator(MultipleLocator(5))ax0.set_ylabel(&quot;Avg. Total Bill($)&quot;, fontsize=14)ax0.grid(axis=&quot;y&quot;, which=&quot;major&quot;, color=&quot;lightgray&quot;)ax0.grid(axis=&quot;y&quot;, which=&quot;minor&quot;, ls=&quot;:&quot;)ax0.set_xlabel(&quot;Weekday&quot;, fontsize=14)for xtick in ax0.get_xticklabels(): print(xtick) if xtick.get_text() == h_day: xtick.set_color(&quot;darkred&quot;) xtick.set_fontweight(&quot;demibold&quot;)ax0.set_xticklabels(['Thursday', 'Friday', 'Saturday', 'Sunday'], size=12)ax1 = sns.barplot(x = &quot;day&quot;, y = 'total_bill', data = tips, ci=None, alpha=0.85, ax=ax[1])for p in ax1.patches: height = np.round(p.get_height(), 2) ax1.text(p.get_x() + p.get_width()/2., height+1, height, ha = 'center', size=12)ax1.set_ylim(-3, 30)ax1.set_title(&quot;Just Bar Graph&quot;)plt.show() Text(0, 0, 'Thur') Text(0, 0, 'Fri') Text(0, 0, 'Sat') Text(0, 0, 'Sun') Referenceë¸”ë¡œê·¸","link":"/2021/11/03/0205-python-visualization/"},{"title":"Decision Tree","text":"Decision Treeë€ ë¨¸ì‹ ëŸ¬ë‹ì— ì‚¬ìš©ë˜ëŠ” ì˜ˆì¸¡ ëª¨ë¸ë§ ì ‘ê·¼ ë°©ì‹ ì¤‘ í•˜ë‚˜ì´ë‹¤.ì—¬ëŸ¬ ì…ë ¥ ë³€ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ìƒ ë³€ìˆ˜ì˜ ê°’ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“œëŠ” ê²ƒì´ë‹¤.ë¶„ë¥˜ì™€ íšŒê·€ ëª¨ë‘ ê°€ëŠ¥í•˜ë©°, ìŠ¤ë¬´ê³ ê°œ í•˜ë“¯ì´ Y/Nìœ¼ë¡œ ì§ˆë¬¸ì„ ì´ì–´ê°€ë©° í•™ìŠµí•œë‹¤. Deicision TreeëŠ” ë°ì´í„°ì—ì„œ if-else ë¬¸ì„ ì´ìš©í•˜ì—¬ sine ê³¡ì„ ì— ê°€ê¹Œìš´ ë°ì´í„°ë¥¼ í•™ìŠµí•œë‹¤.íŠ¸ë¦¬ê°€ ê¹Šì–´ì§ˆìˆ˜ë¡ ëª¨ë¸ì´ ë” ë³µì¡í•´ì§„ë‹¤. ì•Œê³ ë¦¬ì¦˜ ì´í•´í•˜ê¸° Rood node (ë¿Œë¦¬ ë§ˆë””)ì²˜ìŒì— root nodeì—ì„œ ë¬¸ì œì˜ ì§ˆë¬¸ì´ ì…ë ¥ë˜ë©´ Y/Në¡œ ë°ì´í„°ê°€ ë¶„ë¥˜ëœë‹¤. Intermediate node (ì¤‘ê°„ ë§ˆë””)Yë¡œ ë¶„ë¥˜ëœ ë°ì´í„°ëŠ” ë‹¤ì‹œ ì§ˆë¬¸ì´ ì…ë ¥ë˜ì–´ Y/Nìœ¼ë¡œ ë°ì´í„°ê°€ ë¶„ë¥˜ëœë‹¤. Terminal node (ë ë§ˆë””)ëë§ˆë””ì—ì„œëŠ” ë°ì´í„°ê°€ ê°€ì¥ ì„ì´ì§€ ì•Šì€ ìƒíƒœë¡œ ì™„ì „íˆ ë¶„ë¥˜ë˜ì–´ Entropyê°€ ë‚®ì•„ì§„ë‹¤ ì´ˆê¸° ì§€ì ì€ root nodeì´ê³  ë¶„ê¸°ê°€ ê±°ë“­ë  ìˆ˜ë¡ ë°ì´í„°ì˜ ê°œìˆ˜ëŠ” ì¤„ì–´ë“ ë‹¤ terminal nodeì— ì†í•˜ëŠ” ë°ì´í„°ì˜ ê°œìˆ˜ë¥¼ í•©í•˜ë©´ root nodeì˜ ë°ì´í„° ìˆ˜ì™€ ì¼ì¹˜í•œë‹¤ Impurity(ë¶ˆìˆœë„)ë€ í•´ë‹¹ ë²”ì£¼ ì•ˆì—ì„œ ì„œë¡œ ë‹¤ë¥¸ ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ì„ì—¬ ìˆëŠ”ì§€ ëœ»í•œë‹¤ Entropyë€ ë¶ˆìˆœë„ë¥¼ ìˆ˜ì¹˜ì ìœ¼ë¡œ ë‚˜íƒ€ë‚¸ ì²™ë„ì´ë‹¤ Entropyê°€ ë†’ìœ¼ë©´ ë¶ˆìˆœë„ê°€ ë†’ê³ Entropyê°€ ë‚®ìœ¼ë©´ ë¶ˆìˆœë„ê°€ ë‚®ë‹¤ ì˜ˆë¥¼ë“¤ë©´ Entropyê°€ ë†’ìœ¼ë©´ ì •ë¦¬ë˜ì§€ ì•Šì€ ë°©, ë‚®ìœ¼ë©´ ì •ë¦¬ëœ ë°© ì´ë¼ê³  ìƒê°í•˜ë©´ ëœë‹¤. Decision TreeëŠ” ë¶ˆìˆœë„ë¥¼ ìµœì†Œí™” í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµì„ í•˜ê²Œ ëœë‹¤. ì „ì²´ íë¦„ Define Problem, Collect training data Build a Decision Tree (Extract Data, Build a tree) Deploy machine Test with test data ì¥ì  ë°ì´í„°ì˜ ì „ì²˜ë¦¬ë¥¼ í•˜ì§€ ì•Šì•„ë„ ëœë‹¤. ìˆ˜ì¹˜í˜•ê³¼ ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ í•œë²ˆì— ë‹¤ë£° ìˆ˜ ìˆë‹¤. í•œê³„ ìƒ˜í”Œ ì‚¬ì´ì¦ˆê°€ í¬ë©´ íš¨ìœ¨ì„± ë° ê°€ë…ì„±ì´ ë–¨ì–´ì§„ë‹¤. ê³¼ì í•©ìœ¼ë¡œ ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆë‹¤. í•œë²ˆì— í•˜ë‚˜ì˜ë³€ìˆ˜ë§Œì„ ê³ ë ¤í•˜ë¯€ë¡œ ë³€ìˆ˜ê°„ ìƒí˜¸ì‘ìš©ì„ íŒŒì•…í•˜ê¸° ì–´ë µë‹¤. ì•½ê°„ì˜ ì°¨ì´ì— ë”°ë¼ íŠ¸ë¦¬ì˜ ëª¨ì–‘ì´ ë§ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆë‹¤. ì˜ˆì œ iris data setì„ ì´ìš©í•œ deicision tree ë§Œë“¤ê¸°Scikitlearn ì‚¬ì´íŠ¸ì˜ iris ë°ì´í„°ì…‹ì„ ì´ìš©í•œ ì˜ˆì œì´ë‹¤.ì½”ë“œ ì¶œì²˜: https://scikit-learn.org/stable/auto_examples/tree/plot_iris_dtc.html ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°, ê·¸ë˜í”„ê·¸ë¦¬ê¸° ìœ„í•œ ì„¤ì • plot_colors = â€˜rybâ€™blue red yello ìƒ‰ì„ ë‚˜íƒ€ë‚´ê¸° ìœ„í•´ ì‚¬ìš© plot_stepì¶•ì˜ ë‹¨ìœ„ë¥¼ ì„¤ì • 12345678910111213import numpy as npimport matplotlib.pyplot as pltfrom sklearn.datasets import load_irisfrom sklearn.tree import DecisionTreeClassifier, plot_tree# Parametersn_classes = 3plot_colors = &quot;ryb&quot;plot_step = 0.02# Load datairis = load_iris() enumerateëŠ” ì…ë ¥ê°’ìœ¼ë¡œ ì‹œí€€ìŠ¤ ìë£Œí˜•(ë¦¬ìŠ¤íŠ¸, íŠœí”Œ, ë¬¸ìì—´)ì„ ì…ë ¥ë°›ì•„,enumerate ê°ì²´ë¥¼ ë¦¬í„´í•œë‹¤. enumerate ê°ì²´ëŠ” ì²«ë²ˆì§¸ë¡œ ê·¸ ìˆœì„œê°’, ë‘ë²ˆì§¸ë¡œ ê·¸ ìˆœì„œê°’ì— í•´ë‹¹ë˜ëŠ” ì‹œí€€ìŠ¤ ìë£Œí˜•ì˜ ì‹¤ì œê°’ì„ ê°–ëŠ” ê°ì²´ì´ë‹¤ X = iris.data[:, pair]í•˜ë‚˜ì˜ pairì— ë“¤ì–´ê°€ëŠ” ê°’ì´ [0,2]ë¼ë©´, ì²«ë²ˆì§¸ ì„¸ë²ˆì§¸ë§Œ ì„ íƒí•´ì„œ Xì— í• ë‹¹1234for pairidx, pair in enumerate([[0, 1], [0, 2], [0, 3], [1, 2], [1, 3], [2, 3]]): # We only take the two corresponding features X = iris.data[:, pair] y = iris.target 12345678910111213141516# Trainclf = DecisionTreeClassifier().fit(X, y)# Plot the decision boundaryplt.subplot(2, 3, pairidx + 1)x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1xx, yy = np.meshgrid( np.arange(x_min, x_max, plot_step), np.arange(y_min, y_max, plot_step))plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])Z = Z.reshape(xx.shape)cs = plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu) 123456789101112131415161718192021222324 plt.xlabel(iris.feature_names[pair[0]]) plt.ylabel(iris.feature_names[pair[1]]) # Plot the training points for i, color in zip(range(n_classes), plot_colors): idx = np.where(y == i) plt.scatter( X[idx, 0], X[idx, 1], c=color, label=iris.target_names[i], cmap=plt.cm.RdYlBu, edgecolor=&quot;black&quot;, s=15, )plt.suptitle(&quot;Decision surface of a decision tree using paired features&quot;)plt.legend(loc=&quot;lower right&quot;, borderpad=0, handletextpad=0)plt.axis(&quot;tight&quot;)plt.figure()clf = DecisionTreeClassifier().fit(iris.data, iris.target)plot_tree(clf, filled=True)plt.show() ì°¸ê³  ì‚¬ì´íŠ¸: ìœ„í‚¤ë°±ê³¼Scikitlearnë¸”ë¡œê·¸1ë¸”ë¡œê·¸2ìœ íŠœë¸Œ","link":"/2021/11/04/0206-ML-DecisionTree-md/"},{"title":"Dashë¥¼ í™œìš©í•œ ëŒ€ì‹œë³´ë“œ ë§Œë“¤ê¸°","text":"íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ 20ë§Œê°œ ë„˜ìŒ GUI, ì›¹ê°œë°œ, ì•±, í†µê³„, ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹, ê·¸ ì™¸ ì—¬ëŸ¬ê°€ì§€â€¦ â€”&gt; ë²„ì „ ì´ìŠˆ (ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ì´ìŠˆ!!) â€”&gt; Dash ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©í•˜ì—¬, ëŒ€ì‹œë³´ë“œ í”„ë¡œì íŠ¸ â€”&gt; ë³„ë„ì˜ í”„ë¡œì íŠ¸ ê´€ë¦¬ (ì¼ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë§Œ ì”€) â€”&gt; ê°€ìƒìœ¼ë¡œ í™˜ê²½ í•˜ë‚˜ ë§Œë“¤ì, A í™˜ê²½ out of Local Machine : ëŒ€ì‹œë³´ë“œ ë§Œë“¤ ê´€ë ¨ í”„ë¡œì íŠ¸ë§Œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‹¤ìš´ë¡œë“œ ë°›ìŒ : conda í™˜ê²½ ê°€ìƒí™˜ê²½, export environment.yml, íŒŒì´ì¬ ë²„ì „, ê°€ìƒí™˜ê²½ ì ‘ì† ---&gt; í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ : PyCharm íŒŒì´ì¬ ì¸í„°í”„ë¦¬í„° ì„¤ì • : virtualenv ê°€ìƒí™˜ê²½ &amp; ê°€ìƒí™˜ê²½ ì ‘ì† ---&gt; ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ : í‚¤ì›Œë“œ &quot;which python&quot; ì‹¤í–‰í™˜ê²½ Anaconda Prompt ì‚¬ìš© ë°ì´í„°: https://www.kaggle.com/neuromusic/avocado-prices Dash Libraryë€? DashëŠ” ë°˜ì‘í˜• ì›¹ ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“¤ê¸° ìœ„í•œ ì˜¤í”ˆì†ŒìŠ¤ íŒŒì´ì¬ UI ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë‹¤.Plotlyì— ê¸°ë°˜í•˜ì—¬ Web Serviceë¥¼ ê°œë°œí•  ìˆ˜ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ Flask+matplotlib êµ¬í˜„ì„ ëŒ€ì²´í•  ìˆ˜ ìˆë‹¤ (Python, R, Julliaì™€ í˜¸í™˜) (+FlaskëŠ” ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ íŒŒì´ì¬ í”„ë ˆì„ì›Œí¬ë‹¤)(+í”„ë¡œê·¸ë˜ë°ì—ì„œ íŠ¹ì • ìš´ì˜ ì²´ì œë¥¼ ìœ„í•œ ì‘ìš© í”„ë¡œê·¸ë¨ í‘œì¤€ êµ¬ì¡°ë¥¼ êµ¬í˜„í•˜ëŠ” í´ë˜ìŠ¤ì™€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª¨ì„ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—°ì¥ì´ë¼ë©´ í”„ë ˆì„ì›Œí¬ëŠ” ì°¨, ë¹„í–‰ê¸°, íƒˆê²ƒ ê°™ì€ ìš´ì†¡ìˆ˜ë‹¨) ê°€ìƒí™˜ê²½ì´ë€?ê°€ìƒí™˜ê²½ì€ ì—¬ëŸ¬ê°œì˜ íŒŒì´ì¬ í”„ë¡œì íŠ¸ê°€ í•˜ë‚˜ì˜ ì»´í“¨í„°ì—ì„œ ì¶©ë™ì„ ì¼ìœ¼í‚¤ì§€ ì•Šê³  ì¡´ì¬í•  ìˆ˜ ìˆë„ë¡ í•´ì¤€ë‹¤.-&gt; ë…ë¦½ì ì¸ ì‘ì—… í™˜ê²½ì—ì„œ íŒ¨í‚¤ì§€ ë° ë²„ì „ê´€ë¦¬ë¥¼ í•˜ê¸°ìœ„í•´ ê°€ìƒí™˜ê²½ì„ ì‚¬ìš©í•œë‹¤. condaë¥¼ í™œìš©í•œ ê°€ìƒí™˜ê²½ ì„¤ì • ê°€ìƒí™˜ê²½ ìƒì„±í•˜ê¸°conda create -n ê°€ìƒí™˜ê²½ì´ë¦„ python=ë²„ì „ ê°€ìƒí™˜ê²½ í™•ì¸í•˜ê¸°conda info â€“envs ê°€ìƒí™˜ê²½ í™œì„±í™”í•˜ê¸°conda activate ê°€ìƒí™˜ê²½ì´ë¦„ ê°€ìƒí™˜ê²½ ë¹„í™œì„±í™” í•˜ê¸°conda deactivate ê°€ìƒí™˜ê²½ ë³µì‚¬í•˜ê¸°conda create -n ë³µì‚¬ëœ_ê°€ìƒí™˜ê²½ì´ë¦„ â€“clone ë³µì‚¬í• _ê°€ìƒí™˜ê²½ì´ë¦„ ê°€ìƒí™˜ê²½ ì‚­ì œí•˜ê¸°conda remove -n ê°€ìƒí™˜ê²½ì´ë¦„ â€“all Dash ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜conda install dashconda install pandasconda install colorama Refhttps://yganalyst.github.io/pythonic/anaconda_env_1/https://realpython.com/python-dash/https://kibua20.tistory.com/212í”„ë ˆì„ì›Œí¬","link":"/2021/12/01/Dash/"},{"title":"ì‚°ì ë„ ë§‰ëŒ€ê·¸ë˜í”„(Scatter)","text":"1-3. ì‚°ì ë„ ë§‰ëŒ€ ê·¸ë˜í”„ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ í•´ì£¼ê¸° 123456789import pandas as pd import numpy as npimport seaborn as snsimport plotly.express as pximport plotly.graph_objects as go#warning ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ì„œ ê²½ê³  ë©”ì„¸ì§€ ìˆ¨ê¸°ê¸°import warningswarnings.filterwarnings('ignore') ìºê¸€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° 12df = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv')df = df.iloc[1:, :] .astype(â€˜categoryâ€™)ë°ì´í„°ë¥¼ ì¹´í…Œê³ ë¦¬í˜•ìœ¼ë¡œ í˜•ë³€í™˜í•¨ df1 = df.copy()dfë¥¼ df1ìœ¼ë¡œ ë³µì‚¬ df1[â€˜Q3â€™] = df1[â€˜Q3â€™].astype(â€˜categoryâ€™)ë³µì‚¬í•œ df1ì„ ì¹´í…Œë¡œë¦¬ë¡œ í˜•ë³€í™˜í•˜ê³  [â€˜Q3â€™] ì»¬ëŸ¼ ê°’ì„ ê°€ì ¸ì˜¨ë‹¤123df1 = df.copy()df1['Q3'] = df1['Q3'].astype('category')print(df1['Q3'].astype('category')) .cat.add_categories() .cat.add_categories([label])ì¹´í…Œê³ ë¦¬ ì¶”ê°€ replace(old, new, [count])ë¬¸ìì—´ ë³€ê²½ í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜old : í˜„ì¬ ë¬¸ìì—´ì—ì„œ ë³€ê²½í•˜ê³  ì‹¶ì€ ë¬¸ìnew: ìƒˆë¡œ ë°”ê¿€ ë¬¸ìcount: ë³€ê²½í•  íšŸìˆ˜ 12345others = df1['Q3'].value_counts().index[15:]label = 'Others'df1['Q3'] = df1['Q3'].cat.add_categories([label])df1['Q3'] = df1['Q3'].replace(others, label) country 1234567891011country = ( df1['Q3'] .replace(['Other'],'Others') .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Country','Q3':'Count'}) .sort_values(by=['Count'],ascending=False) .replace(['United Kingdom of Great Britain and Northern Ireland'],'United Kingdom') )print(country) country[â€˜percentâ€™] 12country['percent'] = ((country['Count']/country['Count'].sum())*100).round(2).astype(str)+'%'print(country) colors, country .sort_values()ë°ì´í„° ì •ë ¬í•˜ê¸° .sort_values(by=[â€˜Countâ€™])Column Countë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ê¸° .iloc[0:16]0í–‰ë¶€í„° 15í–‰ê¹Œì§€ ì¶œë ¥í•˜ê¸° .reset_index()ì¸ë±ìŠ¤ ì´ˆê¸°í™” ì¬ì •ë ¬ í•´ì£¼ëŠ” í•¨ìˆ˜ 12345678910colors = ['#033351',]*16colors[14]='#0779c3'colors[13]='#5abbf9'colors[12]='#5abbf9' country = (country .sort_values(by=['Count']) .iloc[0:16] .reset_index())print(country) go.Scatter() ì‚°ì ë„ ê·¸ë˜í”„ 12345678fig = go.Figure(go.Scatter(x = country['Count'], y = country[&quot;Country&quot;], text = country['percent'], mode = 'markers', marker_color = colors, marker_size = 12 ))fig.show() forë¬¸ì„ ì´ìš©í•´ ê·¸ë˜í”„ ê·¸ë¦¬ê¸° for i in range(0, len(country)):iëŠ” 0ë¶€í„° countryì˜ í–‰ ê¸¸ì´ê¹Œì§€ ë°˜ë³µí•œë‹¤ x1 = country[â€œCountâ€][i]ì¸ë±ìŠ¤ì— ë§ëŠ” xê°’ì„ ê°€ì ¸ì˜¨ë‹¤country[â€œCountâ€][i]ë”°ë¼ì„œ [i]ëŠ” ì¸ë±ìŠ¤ ê°’ì„ ì˜ë¯¸ y1 = iyì¶• ì¸ë±ìŠ¤ 0ë¶€í„° ëê¹Œì§€ ì˜ë¯¸ width = 4ë§‰ëŒ€ ì„  ë‘ê»˜ë¥¼ ì˜ë¯¸ìˆ«ìê°€ ì»¤ì§ˆ ìˆ˜ë¡ ì„ ì´ ë‘êº¼ì›Œì§1234567for i in range(0, len(country)): fig.add_shape(type='line', x0 = 0, y0 = i, x1 = country[&quot;Count&quot;][i], y1 = i, line = dict(color=colors[i], width = 4))fig.show() hover hover dataí´ë¦­ê³¼ ë°˜ì‘í•˜ëŠ” ì¸í„°ë ‰í‹°ë¸Œ ê·¸ë˜í”„ë¥¼ êµ¬ì¶•ë°ì´í„°ì˜ ì„¸ë¶€ ì •ë³´ë¥¼ ì¶”ê°€ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” íŒì—… ì •ë³´ì°½ì„ ì˜ë¯¸í•œë‹¤ë§ˆìš°ìŠ¤ ê°€ì ¸ë‹¤ ëŒ€ë©´ data ì •ë³´ë¥¼ ë³¼ ìˆ˜ ìˆë‹¤ 1234fig.update_traces(hovertemplate='&lt;b&gt;Country&lt;/b&gt;: %{y}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Proportion&lt;/b&gt;: %{text}')fig.show() ë°°ê²½ ê²©ì ë¬´ëŠ¬ 123fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='#9f9f9f', ticklabelmode='period')fig.update_yaxes(showgrid=False)fig.show() .update_layout 123456789101112fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', margin=dict(pad=20), paper_bgcolor='#F7F7F7', yaxis_title=None, xaxis_title=None, title_text=&quot;Most Common &lt;b&gt;Countries&lt;/b&gt;&quot;, title_x=0.5, height=700, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=17, color='#000000'), title_font_size=35)fig.show() annotation ì£¼ì„ 123456789101112131415161718fig.add_annotation(dict(font=dict(size=14), x=0.98, y=-0.155, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=0, y=-0.155, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() ì „ì²´ì½”ë“œ ì¸ë„ëŠ” ì „ì²´ì˜ 28%ê°€ ë„˜ëŠ” ê°€ì¥ í”í•œ êµ­ê°€ì´ë‹¤. ë¯¸êµ­ì´ 10%ë¡œ ê·¸ ë’¤ë¥¼ ì´ì—ˆë‹¤ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485df1 = df.copy()df1['Q3'] = df1['Q3'].astype('category')others = df1['Q3'].value_counts().index[15:]label = 'Others'df1['Q3'] = df1['Q3'].cat.add_categories([label])df1['Q3'] = df1['Q3'].replace(others, label)country = ( df1['Q3'] .replace(['Other'], 'Others') .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Country', 'Q3':'Count'}) .sort_values(by=['Count'], ascending=False) .replace(['United Kingdom of Great Britain and Northern Ireland'], 'United Kingdom') ) country['percent'] = ((country['Count'] / country['Count'].sum())*100).round(2).astype(str) + '%' colors = ['#033351',] * 16colors[14] = '#0779c3'colors[13] = '#5abbf9'colors[12] = '#5abbf9'country = (country .sort_values(by = ['Count']) .iloc[0:16] .reset_index())fig = go.Figure(go.Scatter(x = country['Count'], y = country[&quot;Country&quot;], text = country['percent'], mode = 'markers', marker_color =colors, marker_size = 12))for i in range(0, len(country)): fig.add_shape(type='line', x0 = 0, y0 = i, x1 = country[&quot;Count&quot;][i], y1 = i, line=dict(color=colors[i], width = 4))fig.update_traces(hovertemplate='&lt;b&gt;Country&lt;/b&gt;: %{y}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Proportion&lt;/b&gt;: %{text}')fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='#9f9f9f', ticklabelmode='period')fig.update_yaxes(showgrid=False) fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', margin=dict(pad=20), paper_bgcolor='#F7F7F7', yaxis_title=None, xaxis_title=None, title_text=&quot;Most Common &lt;b&gt;Countries&lt;/b&gt;&quot;, title_x=0.5, height=700, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=17, color='#000000'), title_font_size=35)fig.add_annotation(dict(font=dict(size=14), x=0.98, y=-0.155, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=0, y=-0.155, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()","link":"/2021/11/07/kaggle3-%EC%82%B0%EC%A0%90%EB%8F%84%EB%A7%89%EB%8C%80%EA%B7%B8%EB%9E%98%ED%94%84/"},{"title":"ë§‰ëŒ€ê·¸ë˜í”„(Bar, ìˆ˜ì§)","text":"3-1. ë§‰ëŒ€ê·¸ë˜í”„(ìˆ˜ì§)ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ í•´ì£¼ê¸° &amp; ìºê¸€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° 1234567891011import pandas as pdimport numpy as npimport seaborn as snsimport plotly.express as pximport plotly.graph_objects as goimport warningswarnings.filterwarnings('ignore') df = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv')df = df.iloc[1:, :] experience ê°ì²´ ìƒì„± .replace([a],[b])a ì´ë¦„ì„ bë¡œ ë°”ê¾¼ë‹¤ 123456789101112experience = ( df['Q6'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Experience', 'Q6':'Count'}) .replace(['I have never written code','&lt; 1 years', '1-3 years', '3-5 years', '5-10 years', '10-20 years', '20+ years'], ['No experience', '&lt;1 years', '1-3 years', '3-5 years', '5-10 years', '10-20 years', '20+ years']) ) 1print(df['Q6']) 1print(experience) pandas categoricalpandas ì—ì„œ ìë£Œí˜•ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” objectì™€ category objectë¬¸ìì—´ì„ objectë¼ëŠ” ìë£Œí˜•ìœ¼ë¡œ ë‚˜íƒ€ë‚¸ë‹¤. categorycategory í˜•ì‹ì€ ê°€ëŠ¥í•œ ê°’ë“¤ì˜ ë²”ìœ„ê°€ ê³ ì •ë˜ì–´ìˆê³ , í•œì •ì ì¼ ë•Œ ë§¤ìš° ì‚¬ìš©í•œë‹¤. ???????ì¹´í…Œê³ ë¦¬ë¡œ ë°”ê¿”ì¤€ê±°?????????????? 1234567experience['Experience'] = pd.Categorical( experience['Experience'], ['No experience', '&lt;1 years', '1-3 years', '3-5 years', '5-10 years', '10-20 years', '20+ years'] )print(experience['Experience']) 12experience['percent'] = ((experience['Count'] / experience['Count'].sum())*100).round(2).astype(str) + '%'print(experience['percent']) 12experience = experience.sort_values('Experience')print(experience) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455colors = ['#033351',] * 7colors[1] = '#5abbf9'colors[2] = '#5abbf9'colors[3] = '#0779c3'colors[4] = '#0779c3'fig = go.Figure(go.Bar( y=experience['Count'], x=experience['Experience'], cliponaxis = False, text=experience['percent'], marker_color=colors ))fig.update_traces(texttemplate='%{text}', textposition='outside', hovertemplate='&lt;b&gt;Experience&lt;/b&gt;: %{x}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{y}', textfont_size=12) fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False) fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', margin=dict(pad=20), paper_bgcolor='#F7F7F7', height=500, yaxis={'showticklabels': False}, yaxis_title=None, xaxis_title=None, title_text=&quot;&lt;b&gt;Experience&lt;/b&gt; Distribution&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=14, color='#000000'), title_font_size=35)fig.add_annotation(dict(font=dict(size=14), x=0.98, y=-0.24, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=-0.03, y=-0.24, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() ì „ì²´ì½”ë“œ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081experience = ( df['Q6'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Experience', 'Q6':'Count'}) .replace(['I have never written code','&lt; 1 years', '1-3 years', '3-5 years', '5-10 years', '10-20 years', '20+ years'], ['No experience', '&lt;1 years', '1-3 years', '3-5 years', '5-10 years', '10-20 years', '20+ years']) ) experience['Experience'] = pd.Categorical( experience['Experience'], ['No experience', '&lt;1 years', '1-3 years', '3-5 years', '5-10 years', '10-20 years', '20+ years'] ) experience['percent'] = ((experience['Count'] / experience['Count'].sum())*100).round(2).astype(str) + '%'experience = experience.sort_values('Experience')colors = ['#033351',] * 7colors[1] = '#5abbf9'colors[2] = '#5abbf9'colors[3] = '#0779c3'colors[4] = '#0779c3'fig = go.Figure(go.Bar( y=experience['Count'], x=experience['Experience'], cliponaxis = False, text=experience['percent'], marker_color=colors ))fig.update_traces(texttemplate='%{text}', textposition='outside', hovertemplate='&lt;b&gt;Experience&lt;/b&gt;: %{x}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{y}', textfont_size=12) fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False) fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', margin=dict(pad=20), paper_bgcolor='#F7F7F7', height=500, yaxis={'showticklabels': False}, yaxis_title=None, xaxis_title=None, title_text=&quot;&lt;b&gt;Experience&lt;/b&gt; Distribution&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=14, color='#000000'), title_font_size=35)fig.add_annotation(dict(font=dict(size=14), x=0.98, y=-0.24, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=-0.03, y=-0.24, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()","link":"/2021/11/09/kaggle5-%EB%A7%89%EB%8C%80%EA%B7%B8%EB%9E%98%ED%94%84-%EC%88%98%EC%A7%81/"},{"title":"ë§‰ëŒ€ê·¸ë˜í”„(Bar, ìˆ˜ì§)","text":"1-1. ë§‰ëŒ€ê·¸ë˜í”„ìºê¸€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° 123456789101112131415161718# This Python 3 environment comes with many helpful analytics libraries installed# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python# For example, here's several helpful packages to loadimport numpy as np # linear algebraimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)# Input data files are available in the read-only &quot;../input/&quot; directory# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory#import osfor dirname, _, filenames in os.walk('/kaggle/input'): for filename in filenames: print(os.path.join(dirname, filename))# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using &quot;Save &amp; Run All&quot; # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ í•´ì£¼ê¸° 123456789import pandas as pd import numpy as npimport seaborn as snsimport plotly.express as pximport plotly.graph_objects as go#warning ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ì„œ ê²½ê³  ë©”ì„¸ì§€ ìˆ¨ê¸°ê¸°import warningswarnings.filterwarnings('ignore') ìºê¸€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° read_csv()ì™¸ë¶€ text íŒŒì¼, csvíŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ DataFrame (df)ìœ¼ë¡œ ì €ì¥ .ilocí–‰ ë²ˆí˜¸ ì„ íƒ .loclabelì´ë‚˜ ì¡°ê±´í‘œí˜„ìœ¼ë¡œ ì„ íƒ df = df.iloc[1:, :]ë‘ë²ˆì§¸ í–‰ë¶€í„° ë§ˆì§€ë§‰í–‰ê¹Œì§€ ì¶œë ¥, ì—´ì€ ì „ì²´ ë‹¤ ì¶œë ¥ ìºê¸€ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ df(ë°ì´í„° í”„ë ˆì„)ì— ë„£ì–´ì¤€ë‹¤ 123df = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv')df = df.iloc[1:, :] print(df) Column ê°’ì´ Q1ì¸ ë°ì´í„°ë§Œ ì¶œë ¥ 1print(df['Q1']) age .value_counts()dfì˜ â€˜Q1â€™ ì»¬ëŸ¼ì˜ ì¤‘ë³µëœ ë°ì´í„° ê°’ë“¤ì˜ ê°¯ìˆ˜ í‘œì‹œ to_frame()ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜ .rename()ì»¬ëŸ¼ëª…ì„ ë°”ê¿€ ìˆ˜ ìˆë‹¤. .sort_values(by=[â€˜Ageâ€™])ì»¬ëŸ¼ëª… Age ê°’ì˜ ë°ì´í„°ë¥¼ ì •ë ¬í•˜ê¸°ascending=True ì˜¤ë¦„ì°¨ìˆœascending=False ë‚´ë¦¼ì°¨ìˆœ 123456789age = ( df['Q1'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Age','Q1':'Count'}) .sort_values(by=['Age'],ascending=True))age.head() Percent column ì¶”ê°€ .round(2)ë°˜ì˜¬ë¦¼ í•¨ìˆ˜ê´„í˜¸ ì•ˆì— ìˆ«ì2ëŠ” ì†Œìˆ˜ì  ë‘˜ì§¸ìë¦¬ê¹Œì§€ ë‚˜íƒ€ëƒ„ì„ ì˜ë¯¸ (ì…‹ì§¸ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼) .astype()í•¨ìˆ˜ì˜ ë°ì´í„° íƒ€ì…ì„ ë³€ê²½í•´ì£¼ëŠ” í•¨ìˆ˜ì´ë‹¤. age dataframeì—ì„œ percentë¼ëŠ” ì´ë¦„ì„ ê°€ì§„ ì—´ì„ ë§Œë“¤ì–´ì¤€ë‹¤.ê·¸ë¦¬ê³  percent ì»¬ëŸ¼ì˜ ë°ì´í„° ê°’ì€ ((age[â€˜Countâ€™]/age[â€˜Countâ€™].sum())*100) ë¥¼ ê³„ì‚°í•œ ê°’ì—ì„œë°˜ì˜¬ë¦¼ í•˜ê³  ë¬¸ìì—´ë¡œ ë°ì´í„° íƒ€ì…ì„ ë°”ê¿”ì£¼ì—ˆë‹¤ 12age['Percent'] = ((age['Count']/age['Count'].sum())*100).round(2).astype(str) + '%'age.head() Column ì‚­ì œí•˜ëŠ”ë²• age.drop(columns=[â€˜percentâ€™],axis=1)ìœ„ì˜ ì½”ë“œ ë‘ë²ˆ ì‹¤í–‰í•´ì„œ ì—´ ì˜ëª» ë“¤ì–´ê°df ì—´ì‚­ì œ ì½”ë“œ Colors ì§€ì • ì™œ 11ì´ì—¬ì•¼ í• ê¹Œ?â€¦ã…œ 123456colors= ['#033351',] * 11colors[0] = '#5abbf9'colors[1] = '#5abbf9'colors[2] = '#5abbf9'colors[3] = '#0779c3'colors[4] = '#0779c3' ê°ì²´ ì„ ì–¸ fig = go.Figureê°ì²´ ì„ ì–¸goë¥¼ í†µí•´ ê·¸ë˜í”„ë¥¼ í•˜ë‚˜í•˜ë‚˜ ì„¤ì • go.Bar()ë§‰ëŒ€ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°goëŠ” graph_objectsì´ë‹¤ (ë§¨ìœ„ì— ì„í¬íŠ¸ í•œê²ƒ) cliponaxis = Falseí…ìŠ¤íŠ¸ê°€ ì§¤ë¦¬ëŠ”ê±° ë³´ì •í•´ì£¼ëŠ” ì½”ë“œ x = age[â€˜Ageâ€™],y = age[â€˜Countâ€™]xì¶•ì— ì»¬ëŸ¼ Ageì˜ ë°ì´í„° ê°’, yì¶•ì— ì»¬ëŸ¼ Countì˜ ë°ì´í„° ê°’ ë„£ì–´ì„œ ê·¸ë˜í”„ë¡œ í‘œí˜„ 12345678fig = go.Figure( go.Bar( x = age['Age'], y = age['Count'], marker_color=colors, cliponaxis = False, text = age['Percent'] ))fig.show() update_trace texttemplate textpositionë§‰ëŒ€ ê·¸ë˜í”„ ë°–ì— í¼ì„¼íŠ¸ ê°’ì´ ë‚˜íƒ€ë‚˜ ìˆë‹¤ hovertemplateë§ˆìš°ìŠ¤ ê°€ì ¸ë‹¤ ëŒ€ë©´ data ì •ë³´ë¥¼ ë³¼ ìˆ˜ ìˆë‹¤ 1234567fig.update_traces(texttemplate='%{text}', textposition='outside', hovertemplate='&lt;b&gt;Age&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{y}', textfont_size=12)fig.show() ë°°ê²½ ê²©ìë¬´ëŠ¬ ì œê±° showgrid=Falseë°°ê²½ì— (update_xaxes)ê°€ë¡œ (update_yaxes)ì„¸ë¡œ ê²©ì ë¬´ëŠ¬ê°€ ì‚¬ë¼ì§ 123fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.show() update_layout -update_layoutí˜•ì„±ëœ figì— ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸ showlegend=Falseë²”ë¡€ ì¶”ê°€í•˜ì§€ ì•ŠìŒ plot_bgcolor=â€™#F7F7F7â€™ê·¸ë˜í”„ ë°°ê²½í™”ë©´ ìƒ‰ìƒ paper_bgcolor=â€™#F7F7F7â€™ê·¸ë˜í”„ ë’¤ ë°°ê²½í™”ë©´ ìƒ‰ìƒ yaxis={â€˜showticklabelsâ€™:False}yì¶•ì— ê°’ì„ í‘œê¸° í•˜ì§€ ì•ŠìŒ yaxis_title=None xaxis_title=Nonexì¶• ì´ë¦„, yì¶• ì´ë¦„ ì„¤ì •í•˜ì§€ ì•ŠìŒ 12345678910111213fig.update_layout(coloraxis=dict(colorscale='Teal'), showlegend=False, plot_bgcolor='#F7F7F7', margin=dict(pad=20), paper_bgcolor='#F7F7F7', height=500, yaxis={'showticklabels':False}, yaxis_title=None, xaxis_title=None, title_text=&quot;&lt;b&gt;Age&lt;/b&gt; Distribution&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;,size=17, color='#000000'), title_font_size=35) annotation annotationì´ë€ì£¼ì„ì„ ì˜ë¯¸í•¨ 12345678910111213141516171819fig.add_annotation(dict(font=dict(size=14), x=0.98, y=-0.25, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot; ))fig.add_annotation(dict(font=dict(size=12), x=0, y=-0.25, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot; ))fig.show() ì „ì²´ ì½”ë“œ ì‘ë‹µìì˜ 55% ì´ìƒì´ 18ì„¸ì—ì„œ 29ì„¸ ì‚¬ì´ì´ë‹¤. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869age = ( df['Q1'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Age', 'Q1':'Count'}) .sort_values(by=['Age'], ascending=True) ) age['percent'] = ((age['Count'] / age['Count'].sum())*100).round(2).astype(str) + '%'colors = ['#033351',] * 11colors[0] = '#5abbf9'colors[1] = '#5abbf9'colors[2] = '#5abbf9'colors[3] = '#0779c3'colors[4] = '#0779c3'fig = go.Figure(go.Bar( y=age['Count'], x=age['Age'], marker_color=colors, cliponaxis = False, text=age['percent'] ))fig.update_traces(texttemplate='%{text}', textposition='outside', hovertemplate='&lt;b&gt;Age&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{y}', textfont_size=12) fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False) fig.update_layout(coloraxis=dict(colorscale='Teal'), showlegend=False, plot_bgcolor='#F7F7F7', margin=dict(pad=20), paper_bgcolor='#F7F7F7', height=500, yaxis={'showticklabels': False}, yaxis_title=None, xaxis_title=None, title_text=&quot;&lt;b&gt;Age&lt;/b&gt; Distribution&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=17, color='#000000'), title_font_size=35)fig.add_annotation(dict(font=dict(size=14), x=0.98, y=-0.25, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=0, y=-0.25, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Refhttps://data101.oopy.io/plolty-tutorial-guide-in-korean","link":"/2021/11/07/kaggle1-%EB%A7%89%EB%8C%80%EA%B7%B8%EB%9E%98%ED%94%84-%EC%88%98%EC%A7%81/"},{"title":"Newbies as a Data Scientist in East Asia","text":"ë“œë””ì–´ ìºê¸€ ëŒ€íšŒ ì‘í’ˆì„ ì œì¶œí–ˆë‹¤.íŒŒì´ì¬ì„ ê±°ì˜ í•˜ë‚˜ë„ ë°°ìš°ì§€ ì•Šê³  ë‹¤ë¥¸ ìºê¸€ ë…¸íŠ¸ë¶ì„ í•„ì‚¬ í•˜ë©´ì„œë¶€í„° ì‹œì‘í•´ì„œìµœì¢… ì™„ë£Œê¹Œì§€ ë§ˆì³¤ë‹¤. íŒŒì´ì¬ì˜ ê¸°ì´ˆê°€ í•˜ë‚˜ë„ ì—†ì–´ì„œ ë„ˆë¬´ í˜ë“¤ì—ˆë‹¤ê·¸ë˜ë„ ë‹¤ í•´ë†“ìœ¼ë‹ˆê¹Œ ë¿Œë“¯í•˜ë„¤ì—¬ê¸°ì„œ ë³´ì™„í•˜ê³  ì‹¶ì€ ì ì€ forë¬¸ì„ ì´ìš©í•´ì„œ ì½”ë“œë¥¼ ë” ê°„ëµíˆ ì§°ìœ¼ë©´ í•˜ëŠ” ì•„ì‰¬ì›€ì´ ìˆë‹¤. ì´ì œë¶€í„°ëŠ” íŒŒì´ì¬ì˜ ê¸°ë³¸ ë¬¸ë²•ì— ëŒ€í•´ì„œ ê³µë¶€ë¥¼ í•´ì•¼ê² ë‹¤ëŠ” ìƒê°ì´ ë“¤ê³ ê³µë¶€ì˜ ë°©í–¥ì„±ì´ ì¢€ ë³´ì¸ë‹¤ìˆ˜ê³ í–ˆë‹¤! ë‚´ìì‹ !ê·¸ë¦¬ê³  ê°™ì´ ìºê¸€ ì¤€ë¹„í•œ ìœ¤í™”ë‹˜í•œí…Œë„ ê°ì‚¬ë¥¼..!kaggleì£¼ì†Œ Newbie as a data scientist in East Asia!Hello, Kaggers! Nice to meet you! We are a team in East Asia that wants to be data scientists As newbies, we want to know what and/or how Kaggler is! so, letâ€™s have a time to learn about Kaggle as a senior with us from now. If you want to support us*(or feel qute)*, I ask for a comment! (PLZ) ^0^ And !! Since we are not native English speakers, please ask questions if there is a context that you donâ€™t understand because itâ€™s not smooth. Iâ€™ll do my best to answer. 1 Introduction what is the Kagglea subsidiary of Google LLC, is an online community of data scientists and machine learning practitioners. If we use kaggle, we can take the following advantages. 1) to find and publish data sets 2) to explore and build models in a web-based data-science environment 3) to work with other data scientists and machine learning engineers 4) to enter competitions to solve data science challenges so, As data scientist beginners, we try to participate in the Kaggle competition. 21 Kaggle Machine Learning and Data Science Survey The most comprehensive dataset available for ML and data science status This is the theme of the competition we will participate in this time. To become a data scientist, we compared what kind of job Kagglers has, how much experience he has, and how much money he earns by dividing into the world and East Asia. In addition, there are detailed comparisons in East Asia, and ultimately, we will to find out what data the Kaggle competition data shows. The 2021 survey, like 2017, 2018, 2019, and 2020, launched an industry-wide survey that comprehensively presents the current status of data science and machine learning. The survey was conducted from 09/01/2021 to 10/04/2021, and after cleaning the data, Kaggle received 25,973 responses! This year, Kaggle will award $30,000 in prize money to winner in this competition. we want to receive $30,000 for winning the competition, but we just hope it will help us become a data scientist because it is difficult for a rookie. Ref. [1] Kgg_competitions [2] Kgg_definition [3] kaggle-survey-2021 1.2 Contents Introduction Contents Summary Data Import and Preprocessing Plots and Description Kaggle's transformation. (World/East_Asia) 1 user transformation 2 Gender transformation 3 Job transformation 4 Age transformation 5 Degree transformation 6 Experience transformation 7 Salary transformation 8 Language transformatio Position of Data Scientist in East Asia 1 Salary 2 Salary-Experience 3 Degree 4 Salary-Degree 5 Language Discussion Close 1.3 Summary used data We used all the data for five years. (2017~2021) used Language and Library Numpy Metplotlib seaborn Plotly plotly.express : An interface where you can draw a graph easily and quickly. plotly.graph_objects : You can customize it in the way you want because you can do more detailed work than express. plotly.figure_factory : Used before express existed and remains in the module for compatibility with previous versions plotly.subplots : A module that displays multiple graphs in one figure. plotly.offline : Save locally and create HTML that opens in a web browser and make it standalone Grouping data sections East Asia and World East Asia : [â€˜Chinaâ€™,â€™Taiwanâ€™, â€˜South Koreaâ€™, â€˜Japanâ€™] World : all data Gender [Male, Female, Others] Job Data_Analyst =[â€˜Data Analystâ€™,â€™Data Miner,Information technologyâ€™,â€™Data Minerâ€™, â€˜Predictive Modelerâ€™,â€™Information technology, networking, or system administrationâ€™,â€˜A business discipline (accounting, economics, finance, etc.)â€™, â€˜Business Analystâ€™, Humanitiesâ€™, â€˜Statisticianâ€™, â€˜Mathematics or statisticsâ€™,â€˜Medical or life sciences (biology, chemistry, medicine, etc.)â€™, Physics or astronomyâ€™, â€˜Social sciences (anthropology, psychology, sociology, etc.)â€™,â€˜Environmental science or geologyâ€™, â€˜Humanities (history, literature, philosophy, etc.)â€™] Data_Scientist =[â€˜Data Scientistâ€™, â€˜Research Scientistâ€™, â€˜Researcherâ€™,â€™Machine Learning Engineerâ€™, â€˜Scientist/Researcherâ€™] Developer=[â€˜Developer Relations/Advocacyâ€™,â€™Data Engineerâ€™,â€™Engineerâ€™,â€™Engineering (non-computer focused)â€™,â€˜Programmerâ€™,â€™Software Engineerâ€™, â€˜Computer Scientistâ€™,â€™Computer science (software engineering, etc.)â€™, â€˜Fine arts or performing artsâ€™,â€™Product Managerâ€™, â€˜Software Developer/Software Engineerâ€™,â€˜Product/Project Managerâ€™,â€™Program/Project Managerâ€™,â€™DBA/Database Engineerâ€™] Not_Employed = [â€˜Currently not employedâ€™, â€˜Not employedâ€™, â€˜Studentâ€™] Others = [â€˜I never declared a majorâ€™, â€˜Otherâ€™] Age[18-21, 20s, 30s, 40s, 50s, 60s&lt;] Degree[â€˜collegeâ€™, â€˜Bachelorâ€™s degreeâ€™,â€™Masterâ€™s degreeâ€™, â€˜Doctoral degree~â€™, â€˜etcâ€™] Experience[&lt;1, 1-3, 3-5, 5-10, 10+] Salary[&lt;999, 1,000-20,000, 20,000-59,999, 60,000-99,999, 100,000-199,999, 200,000~] 2. data Import and pre-treatments 1234567891011121314151617181920import numpy as npimport pandas as pdimport seaborn as snsimport matplotlib.pylab as pltimport plotly.io as pioimport plotly.express as pximport plotly.graph_objects as goimport plotly.figure_factory as fffrom plotly.subplots import make_subplotsfrom plotly.offline import init_notebook_mode, iplotinit_notebook_mode(connected=True)pio.templates.default = &quot;none&quot;import osfor dirname, _, filenames in os.walk('/kaggle/input'): for filename in filenames: print(os.path.join(dirname, filename))import warningswarnings.filterwarnings(&quot;ignore&quot;) 12345df17= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2017/multipleChoiceResponses.csv&quot;, encoding=&quot;ISO-8859-1&quot;)df18= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2018/multipleChoiceResponses.csv&quot;, )df19= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2019/multiple_choice_responses.csv&quot;, )df20= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2020/kaggle_survey_2020_responses.csv&quot;, )df21= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2021/kaggle_survey_2021_responses.csv&quot;, ) 3. plots and description 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109#ì§ˆë¬¸ ì œê±°í•˜ê¸°, replacedf17= df17.iloc[1:, :].replace(&quot;People 's Republic of China&quot;,'China')df18= df18.iloc[1:, :].replace('Republic of Korea','South Korea')df19= df19.iloc[1:, :].replace('Republic of Korea','South Korea')df20= df20.iloc[1:, :].replace('Republic of Korea','South Korea')df21= df21.iloc[1:, :]## East Asiaì—ëŠ” ëŒ€í•œë¯¼êµ­, ì¼ë³¸, ì¤‘êµ­, íƒ€ì´ì™„, ëª½ê³¨, ë¶ì¡°ì„  ì´ 6ê°œì˜ êµ­ê°€ê°€ ì†í•´ ìˆë‹¤. ## ì´ìœ ëŠ” ì•Œ ìˆ˜ ì—†ì§€ë§Œ, 18ë…„ë„ì—” íƒ€ì´ì™„ì´ ì—†ë‹¤. EastAsia17 = ['China',&quot;People 's Republic of China&quot;, 'Taiwan', 'South Korea', 'Japan']EastAsia18= ['China', 'South Korea', 'Japan', 'Republic of Korea'] EastAsia19 = ['China','Taiwan', 'South Korea', 'Japan', 'Republic of Korea']EastAsia20 = ['China','Taiwan', 'South Korea','Republic of Korea', 'Japan']EastAsia21 = ['China','Taiwan', 'South Korea', 'Japan']EastAsia = ['Republic of Korea','China','Taiwan', 'South Korea', 'Japan', &quot;People 's Republic of China&quot; ]df21_Ea = df21[df21['Q3'].isin(EastAsia)]df21_Wo = df21[~df21['Q3'].isin(EastAsia)]df21['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df21['Q3']]df20_Ea = df20[df20['Q3'].isin(EastAsia)]df20_Wo = df20[~df20['Q3'].isin(EastAsia)]df20['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df20['Q3']]df19_Ea = df19[df19['Q3'].isin(EastAsia)]df19_Wo = df19[~df19['Q3'].isin(EastAsia)]df19['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df19['Q3']]df18_Ea = df18[df18['Q3'].isin(EastAsia)]df18_Wo = df18[~df18['Q3'].isin(EastAsia)]df18['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df18['Q3']]df17_Ea = df17[df17['Country'].isin(EastAsia)]df17_Wo = df17[~df17['Country'].isin(EastAsia)]df17['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df17['Country']]df21['year'] = '2021'df20['year'] = '2020'df19['year'] = '2019'df18['year'] = '2018'df17['year'] = '2017'years = ['2017', '2018', '2019', '2020', '2021']df21_Ea = df21[df21['Q3'].isin(EastAsia21)]Ea21= ( df21_Ea['Q3'].value_counts().to_frame() .reset_index().rename(columns={'index':'Country', 'Q3':'21'}))df20_Ea=df20[df20['Q3'].isin(EastAsia)]Ea20= ( df20_Ea['Q3'].replace('Republic of Korea','South Korea') .value_counts().to_frame().reset_index() .rename(columns={'index':'Country', 'Q3':'20'}))df19_Ea=df19[df19['Q3'].isin(EastAsia)]Ea19= (df19_Ea['Q3'].replace('Republic of Korea','South Korea') .value_counts().to_frame().reset_index() .rename(columns={'index':'Country', 'Q3':'19'}))df18_Ea=df18[df18['Q3'].isin(EastAsia)]Ea18= (df18_Ea['Q3'].replace('Republic of Korea','South Korea') .value_counts().to_frame().reset_index() .rename(columns={'index':'Country', 'Q3':'18'}))Ea18.value_counts()#df18 ì—´ì— taiwan = 0ì„ ì¶”ê°€ í•´ì•¼ í•©ë‹ˆë‹¤. df17_Ea = df17[df17['Country'].isin(EastAsia)]Ea17= (df17_Ea['Country'].replace(&quot;People 's Republic of China&quot;,'China') .value_counts().to_frame().reset_index() .rename(columns={'index':'Country', 'Country':'17'}))#dataë¥¼ í•©ì³ì„œ í•˜ë‚˜ì˜ dataframeìœ¼ë¡œ ë§Œë“¤ì–´ ì¤Œ.df5years = pd.merge(Ea17, Ea18, on='Country', how='outer')df5year =pd.merge(Ea19,Ea20, on='Country', how='outer')df5year=pd.merge(df5year, Ea21, on='Country', how='outer')df5years = pd.merge(df5years, df5year, on='Country', how='outer')Ea21 = len(df21_Ea)Wo21 = len(df21) - len(df21_Ea)Ea20 = len(df20_Ea)Wo20 = len(df20) - len(df20_Ea)Ea19 = len(df19_Ea)Wo19 = len(df19) - len(df19_Ea)Ea18 = len(df18_Ea)Wo18 = len(df18) - len(df18_Ea)Ea17 = len(df17_Ea)Wo17 = len(df17) - len(df17_Ea)years = ['2017','2018','2019','2020', '2021']def percent (a, b): result =a/(a+b)*100 result = np.round(result, 2) return resultdef percentR (b, a): result =a/(a+b)*100 result = np.round(result, 2) return resultpercent = [percent(Ea17, Wo17), percent(Ea18, Wo18), percent(Ea19, Wo19), percent(Ea20, Wo20), percent(Ea21, Wo21)] 3.1 Kaggleâ€™s transformation (World/East Asia) 3.1.1 user transformation Number of respondents (bar, scatter plot : number of respondents to World and East Asia,Map plot : number of respondents to East Asia) World and East Asia: The same trend. East Asia: 15% of the total continent and 20.3% of the population (16/78.7: Ea/Wo) 2018 Issue: Significant increase in respondents-&gt;Hypothesis: Due to the rapid increase in China. 2018 Outliers Considering: 2022 Kaggle survey Respondents: Increased in both World and East Asia I wish our team the honor of becoming a respondent to the Kaggle survey in 2022â€¦. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980fig = go.Figure()y=[len(df17_Ea),len(df18_Ea), len(df19_Ea),len(df20_Ea),len(df21_Ea)]fig.add_trace(go.Bar(x=years, y=y, base=0, marker_color='#F2D64B', yaxis = &quot;y1&quot;, name='East Asia', text= percent, texttemplate='%{text} %', textposition='outside', hovertemplate='&lt;b&gt;KaggleUser&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{y}'))fig.add_trace(go.Scatter(name = &quot;World&quot;, x=years, y=[len(df17), len(df18), len(df19), len(df20), len(df21)], marker_color='#979DA6', mode = 'lines+markers', # please check option here yaxis = &quot;y2&quot;))fig.update_traces(hovertemplate='&lt;b&gt;Count&lt;/b&gt;: %{y}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'+ '&lt;b&gt;Year&lt;/b&gt;: %{x}&lt;br&gt;')fig.update_layout(yaxis = dict(title = &quot;Kaggle User in East Asia&quot;,showgrid = False, range=[0, len(df21_Ea)*1.2]), yaxis2 = dict(title = &quot;Kaggle User in World&quot;, overlaying = &quot;y1&quot;, side = &quot;right&quot;, showgrid = False, zeroline = False, range=[0, len(df21)*1.2]))fig.update_layout(title='&lt;b&gt;Kaggle Users&lt;/b&gt;',title_font_size=20, margin = dict(t=200, l=100, r=50, b=200), height=700, width=700)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.1, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.9, y=-0.25, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()def world_map(locations,counts,title): data = [ dict( type = 'choropleth', locations = locations, z = counts, colorscale = 'Reds', locationmode = 'country names', autocolorscale = False, reversescale = False, marker = dict( line = dict(color = '#F7F7F7', width = 1.5)), colorbar = dict(autotick = True, legth = 3, len=0.75, title = 'respodents', max = 1000, min = 0))] layout = dict( title=title, titlefont={'size': 28}, width=700, height=600, paper_bgcolor='#FFFFFF', margin=dict(l=50, r=50, t=100, b=100), geo = dict( showframe = True, showcoastlines = True, fitbounds=&quot;locations&quot;)) fig = dict(data=data, layout=layout) iplot(fig, validate=False, filename='world-map')z = df21_Ea['Q3'].value_counts() world_map(locations=z.index, counts=z.values, title= '&lt;b&gt;EastAsia Countries&lt;b&gt;') 18â€™ : User change between United States and India. Chinaâ€™s markedly increase in 2018 There is no Taiwan, but only China has increased. : East Asian political situation Issue can be suspected. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384A18 = ( df18['Q3'] .replace({'Republic of Korea':'South Korea', 'I do not wish to disclose my location' : 'Other'}) .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'Q3':'2018'}) .groupby('type') .sum() .reset_index())A19 = ( df19['Q3'] .replace('Republic of Korea','South Korea') .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'Q3':'2019'}) .groupby('type') .sum() .reset_index())A17 = ( df17['Country'] .replace({'United States': 'United States of America', 'Hong Kong': 'Hong Kong (S.A.R.)', 'United Kingdom':'United Kingdom of Great Britain and Northern Ireland', }) .replace(&quot;People 's Republic of China&quot;,'China') .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'Country':'2017'}) .groupby('type') .sum() .reset_index())A18A19=pd.merge(A18,A19, how='outer',on='type').fillna(0)A18A17=pd.merge(A18,A17, how='outer',on='type').fillna(0)A18A19['minus']= A18A19['2018']-A18A19['2019']A18A17['minus']= A18A17['2018']-A18A17['2017']A18A17=A18A17.sort_values(by=&quot;minus&quot;, ascending=False)A18A19=A18A19.sort_values(by=&quot;minus&quot;, ascending=False)fig = go.Figure(data=[ go.Bar(x =A18A19['type'], y = A18A19['minus'], marker_color='#979DA6', name = '2018-2019', base=0), go.Bar(x =A18A17['type'], y = A18A17['minus'], marker_color='#F2D64B', name = '2018-2017', base=0) ])fig.update_layout(title='&lt;b&gt; Predicting outliers (2018)&lt;/b&gt;',title_font_size=20, margin = dict(t=200, l=100, r=10, b=200), height=700, width=700, xaxis_title=None, yaxis_title=None)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.1, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Total population: 1.4 billion (85%) in China, 130 million in Japan, 0.5 billion in Korea, and 0.2 billion in Taiwan. China: The number of respondents is smaller than the population. Japan: Starting in 2019, overtaking China Taiwan : 2018 data 0 =? Diplomatic issues? The growth trend is weak. Korea : Respondents at a similar level to Japanâ€™s population. East Asia: The number of respondents will increase further. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#data preprocessingtotal17 = ( df17['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index())total18 = ( df18['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index())total19 = ( df19['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index())total20 = ( df20['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index())total21 = ( df21['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index())#graphcolors = ['#F2D64B','#979DA6']fig = make_subplots(rows=1, cols=5, specs=[[{'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}]], subplot_titles=(&quot;2017&quot;, &quot;2018&quot;, &quot;2019&quot;, &quot;2020&quot;, &quot;2021&quot;))fig.add_trace(go.Pie(marker=dict(colors=colors),labels=total21['type'], values=total21['respodents'], name=&quot;2021&quot;, scalegroup='one'), 1, 5)fig.add_trace(go.Pie(marker=dict(colors=colors),labels=total20['type'], values=total20['respodents'], name=&quot;2020&quot;, scalegroup='one'), 1, 4)fig.add_trace(go.Pie(marker=dict(colors=colors),labels=total19['type'], values=total19['respodents'], name=&quot;2019&quot;, scalegroup='one'), 1, 3)fig.add_trace(go.Pie(marker=dict(colors=colors),labels=total18['type'], values=total18['respodents'], name=&quot;2018&quot;, scalegroup='one'), 1, 2)fig.add_trace(go.Pie(marker=dict(colors=colors),labels=total17['type'], values=total17['respodents'], name=&quot;2017&quot;, scalegroup='one'), 1, 1)fig.update_traces(hole=.0, hoverinfo=&quot;label+percent+name&quot;, textposition='inside', textinfo='percent+label', textfont_size=12)fig.update_layout(title='&lt;b&gt;World vs EastAsia&lt;/b&gt;',title_font_size=23, margin = dict(t=300, l=0, r=0, b=200), height=700, width=700)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.3, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.25, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 123456789101112131415161718192021222324252627282930fig = go.Figure(data=[ go.Bar(name='2017', x=df5years['Country'], y=df5years['17'], marker_color='#F2798F',text=df5years['17'].tolist(), textposition='outside'), go.Bar(name='2018', x=df5years['Country'], y=df5years['18'], marker_color='#88BFBA',text=df5years['18'].fillna(0).astype(int).tolist(), textposition='outside',), go.Bar(name='2019', x=df5years['Country'], y=df5years['19'], marker_color='#CDD9A3',text=df5years['19'].tolist(), textposition='outside'), go.Bar(name='2020', x=df5years['Country'], y=df5years['20'], marker_color='#F28705',text=df5years['20'].tolist(), textposition='outside',), go.Bar(name='2021', x=df5years['Country'], y=df5years['21'], marker_color='#D9946C',text=df5years['21'].tolist(), textposition='outside')])fig.update_layout(barmode='group')fig.update_layout(title='&lt;b&gt;Kaggle User in East Asia&lt;/b&gt;',title_font_size=23, margin = dict(t=200, l=100, r=10, b=200), height=600, width=700)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_traces(hovertemplate='&lt;b&gt;Count&lt;/b&gt;: %{y}')fig.update_layout(legend=dict( orientation=&quot;v&quot;, yanchor=&quot;bottom&quot;, y=1.15, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 3.1.2 Gender transformation World: The proportion of female respondents increases (still below 20%) The number of respondents is increasing in all genders. Our team is also a team with high female members and wants to contribute as a respondent in 2022. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495#data preprocessingGender_17 = ( df17['GenderSelect'] .replace(['A different identity', 'Prefer to self-describe', 'Non-binary, genderqueer, or gender non-conforming'], 'Others') .fillna('Others') .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'GenderSelect':'Gender'}) .groupby('type') .sum() .reset_index())Gender_18 = ( df18['Q1'] .replace(['Prefer not to say', 'Prefer to self-describe'], 'Others') .fillna('Others') .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'Q1':'Gender'}) .groupby('type') .sum() .reset_index())Gender_19 = ( df19['Q2'] .replace(['Prefer not to say','Prefer to self-describe'],'Others') .fillna('Others') .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'Q2':'Gender'}) .groupby('type') .sum() .reset_index())Gender_20 = ( df20['Q2'] .replace(['Prefer not to say', 'Prefer to self-describe', 'Nonbinary'], 'Others') .replace(['Man', 'Woman'], ['Male', 'Female']) .fillna('Others') .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'Q2':'Gender'}) .groupby('type') .sum() .reset_index())Gender_21 = ( df21['Q2'] .replace(['Prefer not to say', 'Prefer to self-describe', 'Nonbinary'], 'Others') .replace(['Man', 'Woman'], ['Male', 'Female']) .fillna('Others') .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'Q2':'Gender'}) .groupby('type') .sum() .reset_index())colors = ['#D9946C','#88BFBA', '#CDD9A3']fig = make_subplots(rows=1, cols=5, specs=[[{'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}]],)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_21['type'], values=Gender_21['Gender'], name=&quot;2021&quot;, scalegroup='one', text=np.array(Gender_21['Gender'].sum()), title=&quot;2021&quot;, titleposition='bottom center'), 1, 5)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_20['type'], values=Gender_20['Gender'], name=&quot;2020&quot;, scalegroup='one', text=np.array(Gender_20['Gender'].sum()), title=&quot;2020&quot;, titleposition='bottom center'), 1, 4)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_19['type'], values=Gender_19['Gender'], name=&quot;2019&quot;, scalegroup='one', text=np.array(Gender_19['Gender'].sum()), title=&quot;2019&quot;, titleposition='bottom center'), 1, 3)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_18['type'], values=Gender_18['Gender'], name=&quot;2018&quot;, scalegroup='one', text=np.array(Gender_18['Gender'].sum()), title=&quot;2018&quot;, titleposition='bottom center'), 1, 2)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_17['type'], values=Gender_17['Gender'], name=&quot;2017&quot;, scalegroup='one', text=np.array(Gender_17['Gender'].sum()), title=&quot;2017&quot;, titleposition='bottom center'), 1, 1)fig.update_traces(hole=.0, hoverinfo=&quot;label+percent+name&quot;, textinfo='label+percent+value')fig.update_layout(title='&lt;b&gt;World Gender&lt;/b&gt;',title_font_size=23, margin = dict(t=300, l=100, r=0, b=200), height=700, width=1000)fig.update_layout(legend=dict( orientation=&quot;v&quot;, yanchor=&quot;bottom&quot;, y=1.3, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.85, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() - Male (1004-&gt;2037 : 2017-&gt;2021) double increase - Female 183-&gt;327 : 2017-&gt;2021 increased 1.8 times - Others (8-&gt;64 : 2017-&gt;2021) 8x increase [Compare the high and low points] It can be seen that the number of female respondents and the ratio of male respondents hardly change, which is a difference compared to World data. It can be seen that the degree of gender freedom in East Asia has increased relatively. Compared to World data, it can be seen that in 2021 (1.87: 2.6= Wo: Ea), compared to 2017 (1.96: 0.7 = Ea), which was relatively conservative. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#data preprocessinggender21= df21_Ea.loc[:, ['Q3', 'Q2', 'year']].rename(columns={'Q3':'Country', 'Q2':'Gender'})gender20= df20_Ea.loc[:, ['Q3', 'Q2', 'year']].rename(columns={'Q3':'Country', 'Q2':'Gender'})gender19= df19_Ea.loc[:, ['Q3', 'Q2', 'year']].rename(columns={'Q3':'Country', 'Q2':'Gender'})gender18= df18_Ea.loc[:, ['Q3', 'Q1', 'year']].rename(columns={'Q3':'Country', 'Q1':'Gender'})gender17= df17_Ea.loc[:, ['Country', 'GenderSelect', 'year']].rename(columns={'index':'type', 'GenderSelect':'Gender'})Gender5y= pd.concat([gender17, gender18, gender19, gender20, gender21])Gender5y= (Gender5y.replace(['Prefer not to say', 'Prefer to self-describe', 'Nonbinary', 'A different identity'], 'Others') .replace(['Man', 'Woman'], ['Male', 'Female']) .groupby(['year', 'Gender']) .size() .reset_index() .rename(columns = {0:&quot;Count&quot;}))gen17_5y = Gender5y[Gender5y['year'] == &quot;2017&quot;].reset_index(drop = True)gen18_5y = Gender5y[Gender5y['year'] == &quot;2018&quot;].reset_index(drop = True)gen19_5y = Gender5y[Gender5y['year'] == &quot;2019&quot;].reset_index(drop = True)gen20_5y = Gender5y[Gender5y['year'] == &quot;2020&quot;].reset_index(drop = True)gen21_5y = Gender5y[Gender5y['year'] == &quot;2021&quot;].reset_index(drop = True)Gen5y_ = pd.concat([gen17_5y, gen18_5y, gen19_5y, gen20_5y, gen21_5y], ignore_index = True)Gen5y_= pd.pivot(Gen5y_, index = &quot;year&quot;, columns = &quot;Gender&quot;, values = &quot;Count&quot;).reset_index()Gen5y_Gen5y_['year'].unique()#graphfig = go.Figure()fig.add_trace(go.Bar( x = Gen5y_['year'], y = Gen5y_['Male'].tolist(), name = 'Male',marker_color='#88BFBA', text=Gen5y_['Male'].tolist(), textposition='outside'))fig.add_trace(go.Bar( x = Gen5y_['year'], y = Gen5y_['Female'].tolist(), name = 'Female',marker_color='#D9946C', text=Gen5y_['Female'].tolist(), textposition='outside'))fig.add_trace(go.Bar( x = Gen5y_['year'], y = Gen5y_['Others'].tolist(), name = 'Others',marker_color='#CDD9A3', text=Gen5y_['Others'].tolist(), textposition='outside'))fig.update_layout(barmode=&quot;group&quot;) fig.update_layout(title='&lt;b&gt;Gender by year&lt;/b&gt;',title_font_size=22, margin = dict(t=200, l=100, r=10, b=200), height=700, width=700, xaxis_title=None, yaxis_title=None)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 3.1.3 Job transformation 21' World Vs East Asia Age Ratio: Bar plot Not Employed : More than 30% in both East Asia and the world, the highest. Because â€œStudentsâ€ is included. Data Scientist : High percentage in the world and East Asia. Relatively low proportion in East Asia. = Absolute lack of numbers We would like to move forward by selecting a **data scientist** with insufficient numbers in East Asia. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132#data preprocessingData_Analyst =['Data Analyst','Data Miner,Information technology','Data Miner', 'Predictive Modeler','Information technology, networking, or system administration', 'A business discipline (accounting, economics, finance, etc.)', 'Business Analyst', 'Humanities', 'Statistician', 'Mathematics or statistics', 'Medical or life sciences (biology, chemistry, medicine, etc.)', 'Physics or astronomy', 'Social sciences (anthropology, psychology, sociology, etc.)', 'Environmental science or geology', 'Humanities (history, literature, philosophy, etc.)']Data_Scientist =['Data Scientist', 'Research Scientist', 'Researcher', 'Machine Learning Engineer', 'Scientist/Researcher']Developer=['Developer Relations/Advocacy','Data Engineer','Engineer','Engineering (non-computer focused)', 'Programmer','Software Engineer', 'Computer Scientist','Computer science (software engineering, etc.)', 'Fine arts or performing arts','Product Manager', 'Software Developer/Software Engineer', 'Product/Project Manager','Program/Project Manager','DBA/Database Engineer']Not_Employed =['Currently not employed', 'Not employed', 'Student']Others = ['I never declared a major', 'Other']df21job_Ea = df21_Ea.loc[:,['Q3','Q5']].rename(columns={'Q5':'2021'}).fillna('Other')df20job_Ea = df20_Ea.loc[:,['Q3','Q5']].rename(columns={'Q5':'2020'}).fillna('Other')df19job_Ea = df19_Ea.loc[:,['Q3','Q5']].rename(columns={'Q5':'2019'}).fillna('Other')df18job_Ea = df18_Ea.loc[:,['Q3','Q5']].rename(columns={ 'Q5':'2018'}).fillna('Other')df17job_Ea = df17_Ea.loc[:,['Country','CurrentJobTitleSelect']].rename(columns={'CurrentJobTitleSelect':'2017'}).fillna('Other')df21job_Ea.value_counts('2021')df21job_Ea['JOB']=[&quot;Data Analyst&quot; if x in Data_Analyst else &quot;Data Scientist&quot; if x in Data_Scientist # Data Scientist else &quot;Developer&quot; if x in Developer else &quot;NotEmployed&quot; if x in Not_Employed else &quot;Others&quot; for x in df21job_Ea['2021']]df21job_Ea.value_counts('JOB')df20job_Ea.value_counts('2020')df20job_Ea['JOB']=[&quot;Data Analyst&quot; if x in Data_Analyst else &quot;Data Scientist&quot; if x in Data_Scientist else &quot;Developer&quot; if x in Developer else &quot;NotEmployed&quot; if x in Not_Employed else &quot;Other&quot; for x in df20job_Ea['2020']]df20job_Ea[['2020','JOB']]df19job_Ea.value_counts('2019')df19job_Ea['JOB']=[&quot;Data Analyst&quot; if x in Data_Analyst else &quot;Data Scientist&quot; if x in Data_Scientist else &quot;Developer&quot; if x in Developer else &quot;NotEmployed&quot; if x in Not_Employed else &quot;Other&quot; for x in df19job_Ea['2019']]df19jobTest = df19job_Ea.loc[df19job_Ea.JOB == 'Other']df19jobTest['2019'].value_counts()df18job_Ea.value_counts('2018')df18job_Ea['JOB']=[&quot;Data Analyst&quot; if x in Data_Analyst else &quot;Data Scientist&quot; if x in Data_Scientist else &quot;Developer&quot; if x in Developer else &quot;NotEmployed&quot; if x in Not_Employed else &quot;Other&quot; for x in df18job_Ea['2018']]df18jobTest = df18job_Ea.loc[df18job_Ea.JOB == 'Other']df18jobTest['2018'].value_counts()df17job_Ea.value_counts('2017')df17job_Ea['JOB']=[&quot;Data Analyst&quot; if x in Data_Analyst else &quot;Data Scientist&quot; if x in Data_Scientist else &quot;Developer&quot; if x in Developer else &quot;NotEmployed&quot; if x in Not_Employed else &quot;Other&quot; for x in df17job_Ea['2017']]df17jobTest = df17job_Ea.loc[df17job_Ea.JOB == 'Other']df17jobTest['2017'].value_counts()df21jobTest = df21job_Ea.loc[df21job_Ea.JOB == 'Other']df21jobTest['2021'].head()df21job_Ea.value_counts('JOB')dfjob21 =df21job_Ea.groupby(['Q3','JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;}).rename(columns={'Q3':'country'})dfjob20 =df20job_Ea.groupby(['Q3','JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;}).rename(columns={'Q3':'country'})dfjob19 =df19job_Ea.groupby(['Q3','JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;}).rename(columns={'Q3':'country'})dfjob18 =df18job_Ea.groupby(['Q3','JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;}).rename(columns={'Q3':'country'})dfjob17 =df17job_Ea.groupby(['Country','JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;}).rename(columns={'Country':'country'})df21_Ea_job =df21job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df20_Ea_job =df20job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df19_Ea_job =df19job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df18_Ea_job =df18job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df17_Ea_job =df17job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df21_DA=df21[df21['Q5'].isin(Data_Analyst)]df21_DS=df21[df21['Q5'].isin(Data_Scientist)]df21_D=df21[df21['Q5'].isin(Developer)]df21_N=df21[df21['Q5'].isin(Not_Employed)]df21_O=df21[df21['Q5'].isin(Others)]World_ = np.array([df21_DA['Q5'].count(), df21_DS['Q5'].count(), df21_D['Q5'].count(), df21_N['Q5'].count(), df21_O['Q5'].count()]) East_Asia_ = df21_Ea_job['Count'].to_numpy()World =((World_/World_.sum())*100).round(1)East_Asia =((East_Asia_/East_Asia_.sum())*100).round(1)y = df21_Ea_job.JOB.to_numpy()fig = go.Figure(data=[ go.Bar(y=y, x=World, orientation='h', name=&quot;World&quot;, base=0, hovertemplate='&lt;b&gt;World&lt;/b&gt;: %{x}%&lt;br&gt;', marker_color='#979DA6', text=World, textposition='outside'), go.Bar(y=y, x=-East_Asia, orientation='h', name=&quot;East Asia&quot;, base=0, hovertemplate='&lt;b&gt;East Asia&lt;/b&gt;: %{x}%&lt;br&gt;', marker_color='#F2D64B', text=East_Asia, textposition='outside')])fig.update_layout(barmode='stack')fig.update_layout(title='&lt;b&gt;World vs EastAsia&lt;/b&gt;',title_font_size=22, margin = dict(t=200, l=100, r=50, b=200), height=700, width=750, xaxis_title=None, yaxis_title=None)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.1, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() World Job Ratio: Heat Map The trend of increasing each job except Others. Data Scientist has a high proportion, and the trend is to increase further in 2022. East Asia Job Ratio: Heat Map East Asia : Increasing the ratio of data scientist. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113#data preprocessingdf21job= df21.loc[:,['region','Q5']].rename(columns={'Q5':'2021'}).fillna('Others')df20job= df20.loc[:,['region','Q5']].rename(columns={'Q5':'2020'}).fillna('Others')df19job= df19.loc[:,['region','Q5']].rename(columns={'Q5':'2019'}).fillna('Others')df18job= df18.loc[:,['region','Q6']].rename(columns={ 'Q6':'2018'}).fillna('Others')df17job= df17.loc[:,['region','CurrentJobTitleSelect']].rename(columns={'CurrentJobTitleSelect':'2017'}).fillna('Others')df21job['JOB']=[&quot;Data Analyst&quot; if x in Data_Analyst else &quot;Data Scientist&quot; if x in Data_Scientist # Data Scientist else &quot;Developer&quot; if x in Developer else &quot;NotEmployed&quot; if x in Not_Employed else &quot;Others&quot; for x in df21job['2021']]df20job['JOB']=[&quot;Data Analyst&quot; if x in Data_Analyst else &quot;Data Scientist&quot; if x in Data_Scientist else &quot;Developer&quot; if x in Developer else &quot;NotEmployed&quot; if x in Not_Employed else &quot;Others&quot; for x in df20job['2020']]df19job['JOB']=[&quot;Data Analyst&quot; if x in Data_Analyst else &quot;Data Scientist&quot; if x in Data_Scientist else &quot;Developer&quot; if x in Developer else &quot;NotEmployed&quot; if x in Not_Employed else &quot;Others&quot; for x in df19job['2019']]df18job['JOB']=[&quot;Data Analyst&quot; if x in Data_Analyst else &quot;Data Scientist&quot; if x in Data_Scientist else &quot;Developer&quot; if x in Developer else &quot;NotEmployed&quot; if x in Not_Employed else &quot;Others&quot; for x in df18job['2018']]df17job['JOB']=[&quot;Data Analyst&quot; if x in Data_Analyst else &quot;Data Scientist&quot; if x in Data_Scientist else &quot;Developer&quot; if x in Developer else &quot;NotEmployed&quot; if x in Not_Employed else &quot;Others&quot; for x in df17job['2017']]df21_job =df21job.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df20_job =df20job.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df19_job =df19job.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df18_job =df18job.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df17_job =df17job.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})merge11=pd.merge(df21_job,df20_job, how='outer',on='JOB')merge21=pd.merge(df19_job,df18_job, how='outer',on='JOB')merge31=pd.merge(merge11,merge21, how='outer',on='JOB')merge_Wo=(pd.merge(merge31,df17_job, how='outer',on='JOB') .rename(columns = {'Count_x_x':'2021','Count_y_x':'2020','Count_x_y':'2019','Count_y_y':'2018','Count':'2017'}).fillna(0) .reindex(columns = ['JOB','2017','2018','2019','2020','2021' ]))df21job_Ea = df21job[df21job['region'] == 'EastAsia'].loc[:,['region','JOB']].rename(columns={'region':'EastAsia'})df20job_Ea = df20job[df20job['region'] == 'EastAsia'].loc[:,['region','JOB']].rename(columns={'region':'EastAsia'})df19job_Ea = df19job[df19job['region'] == 'EastAsia'].loc[:,['region','JOB']].rename(columns={'region':'EastAsia'})df18job_Ea = df18job[df18job['region'] == 'EastAsia'].loc[:,['region','JOB']].rename(columns={'region':'EastAsia'})df17job_Ea = df17job[df17job['region'] == 'EastAsia'].loc[:,['region','JOB']].rename(columns={'region':'EastAsia'})df21job_Ea =df21job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df20job_Ea =df20job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df19job_Ea =df19job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df18job_Ea =df18job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df17job_Ea =df17job_Ea.groupby(['JOB']).size().reset_index().rename(columns = {0:&quot;Count&quot;})merge1=pd.merge(df21job_Ea,df20job_Ea, how='outer',on='JOB')merge2=pd.merge(df19job_Ea,df18job_Ea, how='outer',on='JOB')merge3=pd.merge(merge1,merge2, how='outer',on='JOB')merge=(pd.merge(merge3,df17job_Ea, how='outer',on='JOB') .rename(columns = {'Count_x_x':'2021','Count_y_x':'2020','Count_x_y':'2019','Count_y_y':'2018','Count':'2017'}).fillna(0) .reindex(columns = ['JOB','2017','2018','2019','2020','2021' ]))#graphz1=((merge_Wo.iloc[:,[1,2,3,4,5]].to_numpy()/merge_Wo.iloc[:,[1,2,3,4,5]].to_numpy().sum())*100).round(1)z2=((merge.iloc[:,[1,2,3,4,5]].to_numpy()/merge.iloc[:,[1,2,3,4,5]].to_numpy().sum())*100).round(1)x=['2017-year','2018-year','2019-year','2020-year','2021-year']y1=merge_Wo['JOB'].tolist()y2=merge['JOB'].tolist()fig1 = ff.create_annotated_heatmap(z1, x = x, y = y1, colorscale='sunset')fig2 = ff.create_annotated_heatmap(z2, x = x, y = y2, colorscale='sunset')for annot in fig2['layout']['annotations']: annot['xref'] = 'x2' fig = make_subplots(rows=1, cols=2)fig.add_trace(fig1.data[0], row=1, col=1)fig.add_trace(fig2.data[0], row=1, col=2)fig.update_layout(fig1.layout, title='&lt;b&gt; World vs EastAsia&lt;/b&gt;',title_font_size=22, margin = dict(t=200, l=100, r=10, b=200), height=700, width=1150, coloraxis=dict(showscale=True, colorscale='sunset'))fig.update_traces(hovertemplate='&lt;b&gt;Job&lt;/b&gt;: %{y}&lt;br&gt;'+ '&lt;b&gt;Year&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Percent&lt;/b&gt;: %{z}%')fig.layout.annotations += fig2.layout.annotationsfig.add_annotation(dict(font=dict(size=14), x=0.9, y=-0.25, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 3.1.4 Age transformation > Age change in World and East Asia by year: Stacked scatter plot In the case of Age data, there is no 2017 data. 70% of the World respondents said 20s to 30s. 70% of East Asia respondents said 20s to 30s. The number of respondents increases, but the ratio seems to have stabilized. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224#data preprocessing#WorldAge21_W = df21.loc[:,['Q3','Q1', 'year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'age'}).fillna('etc')Age20_W = df20.loc[:,['Q3','Q1','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'age'}).fillna('etc')Age19_W = df19.loc[:,['Q3','Q1','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'age'}).fillna('etc')Age18_W = df18.loc[:,['Q3','Q2','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q2':'age'}).fillna('etc')Age5y_W= pd.concat([Age21_W, Age20_W, Age19_W, Age18_W])Age5y_W= (Age5y_W.replace(['60-69', '70+', '70-79', '80+'], '60+') .replace(['22-24', '25-29'], '22-29') .replace(['30-34', '35-39'], '30-39') .replace(['40-44', '45-49'], '40-49') .replace(['50-54', '55-59'], '50-59') .groupby(['year', 'age']) .size() .reset_index() .rename(columns = {0:&quot;Count&quot;}))Age21_percent_W = Age5y_W[Age5y_W['year'] == &quot;2021&quot;].reset_index(drop = True)Age21_percent_W['percentage'] = Age21_percent_W[&quot;Count&quot;] / Age21_percent_W[&quot;Count&quot;].sum()Age21_percent_W['%'] = np.round(Age21_percent_W['percentage'] * 100, 1)Age20_percent_W = Age5y_W[Age5y_W['year'] == &quot;2020&quot;].reset_index(drop = True)Age20_percent_W['percentage'] = Age20_percent_W[&quot;Count&quot;] / Age20_percent_W[&quot;Count&quot;].sum()Age20_percent_W['%'] = np.round(Age20_percent_W['percentage'] * 100, 1)Age19_percent_W = Age5y_W[Age5y_W['year'] == &quot;2019&quot;].reset_index(drop = True)Age19_percent_W['percentage'] = Age19_percent_W[&quot;Count&quot;] / Age19_percent_W[&quot;Count&quot;].sum()Age19_percent_W['%'] = np.round(Age19_percent_W['percentage'] * 100, 1)Age18_percent_W = Age5y_W[Age5y_W['year'] == &quot;2018&quot;].reset_index(drop = True)Age18_percent_W['percentage'] = Age18_percent_W[&quot;Count&quot;] / Age18_percent_W[&quot;Count&quot;].sum()Age18_percent_W['%'] = np.round(Age18_percent_W['percentage'] * 100, 1)Age5y_percent_W = pd.concat([Age18_percent_W, Age19_percent_W, Age20_percent_W, Age21_percent_W], ignore_index = True)Age5y_percent_W= pd.pivot(Age5y_percent_W, index = &quot;year&quot;, columns = 'age', values = &quot;%&quot;).reset_index()Age5y_percent_WAge21 = df21_Ea.loc[:,['Q3','Q1', 'year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'age'}).fillna('etc')Age20 = df20_Ea.loc[:,['Q3','Q1','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'age'}).fillna('etc')Age19 = df19_Ea.loc[:,['Q3','Q1','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'age'}).fillna('etc')Age18 = df18_Ea.loc[:,['Q3','Q2','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q2':'age'}).fillna('etc')Age5y= pd.concat([Age21, Age20, Age19, Age18])Age5y= (Age5y.replace(['60-69', '70+', '70-79', '80+'], '60+') .replace(['22-24', '25-29'], '22-29') .replace(['30-34', '35-39'], '30-39') .replace(['40-44', '45-49'], '40-49') .replace(['50-54', '55-59'], '50-59') .groupby(['year', 'age']) .size() .reset_index() .rename(columns = {0:&quot;Count&quot;}))#EastAsiaAge21_percent = Age5y[Age5y['year'] == &quot;2021&quot;].reset_index(drop = True)Age21_percent['percentage'] = Age21_percent[&quot;Count&quot;] / Age21_percent[&quot;Count&quot;].sum()Age21_percent['%'] = np.round(Age21_percent['percentage'] * 100, 1)Age21_percentAge20_percent = Age5y[Age5y['year'] == &quot;2020&quot;].reset_index(drop = True)Age20_percent['percentage'] = Age20_percent[&quot;Count&quot;] / Age20_percent[&quot;Count&quot;].sum()Age20_percent['%'] = np.round(Age20_percent['percentage'] * 100, 1)Age20_percentAge19_percent = Age5y[Age5y['year'] == &quot;2019&quot;].reset_index(drop = True)Age19_percent['percentage'] = Age19_percent[&quot;Count&quot;] / Age19_percent[&quot;Count&quot;].sum()Age19_percent['%'] = np.round(Age19_percent['percentage'] * 100, 1)Age19_percentAge18_percent = Age5y[Age5y['year'] == &quot;2018&quot;].reset_index(drop = True)Age18_percent['percentage'] = Age18_percent[&quot;Count&quot;] / Age18_percent[&quot;Count&quot;].sum()Age18_percent['%'] = np.round(Age18_percent['percentage'] * 100, 1)Age18_percentAge5y_percent = pd.concat([Age18_percent, Age19_percent, Age20_percent, Age21_percent], ignore_index = True)Age5y_percent= pd.pivot(Age5y_percent, index = &quot;year&quot;, columns = 'age', values = &quot;%&quot;).reset_index()Age5y_percentAge5y_percent_order = Age5y_percent_W['year'].tolist()Age5y_order = Age5y_W['age'].unique().tolist()#graph1fig = go.Figure()fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent_W['18-21'].tolist(), mode = &quot;lines&quot;, name = '18-21', line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#F2798F'))fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent_W['22-29'].tolist(), mode = &quot;lines&quot;, name = &quot;20s&quot;, line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#88BFBA'))fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent_W['30-39'].tolist(), mode = &quot;lines&quot;, name = &quot;30s&quot;, line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#CDD9A3'))fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent_W['40-49'].tolist(), mode = &quot;lines&quot;, name = &quot;40s&quot;, line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#F28705'))fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent_W['50-59'].tolist(), mode = &quot;lines&quot;, name = &quot;50s&quot;, line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#D9946C'))fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent_W['60+'].tolist(), mode = &quot;lines&quot;, name = &quot;60s&lt;&quot;, line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#F2D64B'))fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{y}%&lt;br&gt;'+ '&lt;b&gt;Year&lt;/b&gt;: %{x}&lt;br&gt;')fig.update_layout(yaxis_range = (0, 100), height=500, width=700, title_text=&quot;&lt;b&gt;World&lt;/b&gt;&quot;, title_font_size=20, title_x=0.5)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()#graph2Age5y_percent_order = Age5y_percent['year'].tolist()Age5y_order = Age5y['age'].unique().tolist()fig = go.Figure()fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent['18-21'].tolist(), mode = &quot;lines&quot;, name = '18-21', line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#F2798F'))fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent['22-29'].tolist(), mode = &quot;lines&quot;, name = &quot;20s&quot;, line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#88BFBA'))fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent['30-39'].tolist(), mode = &quot;lines&quot;, name = &quot;30s&quot;, line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#CDD9A3'))fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent['40-49'].tolist(), mode = &quot;lines&quot;, name = &quot;40s&quot;, line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#F28705'))fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent['50-59'].tolist(), mode = &quot;lines&quot;, name = &quot;50s&quot;, line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#D9946C'))fig.add_trace(go.Scatter( x = Age5y_percent_order, y = Age5y_percent['60+'].tolist(), mode = &quot;lines&quot;, name = &quot;60s&lt;&quot;, line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#F2D64B'))fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{y}%&lt;br&gt;'+ '&lt;b&gt;Year&lt;/b&gt;: %{x}&lt;br&gt;')fig.update_layout(yaxis_range = (0, 100), height=500, width=700, title_text=&quot;&lt;b&gt;East Asia&lt;/b&gt;&quot;, title_font_size=20, title_x=0.5)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 17'East Asia Age Ratio: Heat Map East Asia : 50% or more. Those in their 20s and 30s. Korea: Those in their 20s are the highest. The number of respondents in their 50s and older is also large. Taiwan : The number of respondents in their 30s and older is relatively small. China: 70% or more of respondents in their 30s or younger. Related to life expectancy? Japan: Like an aging country, all ages are evenly distributed. Even if youâ€™re older, there are many respondents to Kaggle. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#data processingdf21Age_Ea = df21_Ea.loc[:,['Q3','Q1']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'2021'}).fillna('etc')df21Age_Ea=(df21Age_Ea.replace(['60-69', '70+', '70-79', '80+'], '60+') .replace(['22-24', '25-29'], '22-29') .replace(['30-34', '35-39'], '30-39') .replace(['40-44', '45-49'], '40-49') .replace(['50-54', '55-59'], '50-59'))# ì—°ë ¹-ì§€ì—­ %dfKo_Age21= df21Age_Ea[df21Age_Ea['East_Asia']=='South Korea']dfKo_Age21_per=dfKo_Age21['2021'].value_counts().to_frame().reset_index()dfKo_Age21_per['South Korea']=((dfKo_Age21_per['2021'] / len(dfKo_Age21))*100).round(2)dfTw_Age21= df21Age_Ea[df21Age_Ea['East_Asia']=='Taiwan']dfTw_Age21_per=dfTw_Age21['2021'].value_counts().to_frame().reset_index()dfTw_Age21_per['Taiwan']=((dfTw_Age21_per['2021'] / len(dfTw_Age21))*100).round(2)dfTw_Age21_perdfCh_Age21= df21Age_Ea[df21Age_Ea['East_Asia']=='China']dfCh_Age21_per=dfCh_Age21['2021'].value_counts().to_frame().reset_index()dfCh_Age21_per['China']=((dfCh_Age21_per['2021'] / len(dfCh_Age21))*100).round(2)dfCh_Age21_perdf21Age_Ea.head()dfJp_Age21= df21Age_Ea[df21Age_Ea['East_Asia']=='Japan']dfJp_Age21_per=dfJp_Age21['2021'].value_counts().to_frame().reset_index()dfJp_Age21_per['Japan']=((dfJp_Age21_per['2021'] / len(dfJp_Age21))*100).round(2)dfJp_Age21_permerge1= pd.merge(dfKo_Age21_per,dfTw_Age21_per, on='index', how='outer')merge2= pd.merge(dfCh_Age21_per,dfJp_Age21_per, on='index', how='outer')merge= pd.merge(merge1,merge2, on='index', how='outer').fillna(0).sort_values(by=['index'],ascending=True)#graphx1=['South Korea','Taiwan','China','Japan']y1=merge.sort_values(by=['index'], ascending=True)['index'].tolist()z1=merge.iloc[:,[2,4,6,8]].to_numpy()fig = go.Figure(data=go.Heatmap( z=z1, x=x1, y=y1, hoverongaps = True, opacity=1.0, xgap=2.5, ygap=2.5))fig = ff.create_annotated_heatmap(z1, x = x1, y = y1, colorscale='sunset')fig.update_layout(height=500, width=600, title_text=&quot;&lt;b&gt;East Asia Age (2021)&lt;/b&gt;&quot;, title_font_size=20, title_x=0.5)fig.update_traces(hovertemplate='&lt;b&gt;Age&lt;/b&gt;: %{y}&lt;br&gt;'+ '&lt;b&gt;Country&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Percent&lt;/b&gt;: %{z}%')fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 17â€™East Asiaâ€™s age ratio: Box plot 2017: Data is not a section but an individual number. If you divide the interval, you can add it to the previous graph. It was data that I could draw a bar plot, so I drew it. You can see a 100-year-old in China, but they donâ€™t remove missing values on purpose. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# ì—°ë„ë³„ ë‚˜ì´ df21Age_Ea = df21_Ea.loc[:,['Q3','Q1']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'2021'}).fillna('etc')df20Age_Ea = df20_Ea.loc[:,['Q3','Q1']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'2020'}).fillna('etc')df19Age_Ea = df19_Ea.loc[:,['Q3','Q1']].reset_index().rename(columns={'Q3':'East_Asia', 'Q1':'2019'}).fillna('etc')df18Age_Ea = df18_Ea.loc[:,['Q3','Q2']].reset_index().rename(columns={'Q3':'East_Asia', 'Q2':'2018'}).fillna('etc')df17Age_Ea = df17_Ea.loc[:,['Country','Age']].reset_index().rename(columns={'Country':'East_Asia', 'Age':'2017'}).fillna('etc')#data frame ì •ë¦¬dfAge21 =df21Age_Ea.groupby(['East_Asia','2021']).size().reset_index().rename(columns = {0:&quot;Count&quot;})dfAge20 =df20Age_Ea.groupby(['East_Asia','2020']).size().reset_index().rename(columns = {0:&quot;Count&quot;})dfAge19 =df19Age_Ea.groupby(['East_Asia','2019']).size().reset_index().rename(columns = {0:&quot;Count&quot;})dfAge18 =df18Age_Ea.groupby(['East_Asia','2018']).size().reset_index().rename(columns = {0:&quot;Count&quot;})dfAge17 =(df17Age_Ea.groupby(['East_Asia','2017']) .size().reset_index().rename(columns = {0:&quot;Count&quot;}))#graphfig = go.Figure()x = ['China','Japan','South Korea','Taiwan']fig.add_trace(go.Box( y=dfAge17['2017'][dfAge17['East_Asia']==&quot;Japan&quot;].to_numpy(), name='Japan', marker=dict(color='#CDD9A3')))fig.add_trace(go.Box(y=dfAge17['2017'][dfAge17['East_Asia']==&quot;China&quot;].to_numpy(), name='China', marker=dict(color='#88BFBA')))fig.add_trace(go.Box(y=dfAge17['2017'][dfAge17['East_Asia']==&quot;South Korea&quot;].to_numpy(), name='South Korea', marker=dict(color='#F2798F')))fig.add_trace(go.Box(y=dfAge17['2017'][dfAge17['East_Asia']==&quot;Taiwan&quot;].to_numpy(), name='Taiwan', marker=dict(color='#F28705' ),))fig.update_layout(yaxis = dict(range=[0, 120]))fig.update_layout(yaxis_range = (0, 110), height=600, width=700, title_text=&quot;&lt;b&gt;Age in East Asia (2017)&lt;/b&gt;&quot;, title_font_size=20, margin = dict(t=100, l=50, r=50, b=100), title_x=0.5)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;v&quot;, yanchor=&quot;bottom&quot;, y=0.8, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 3.1.5 Degree transformation World job ratio in each country: pie plot World: 90% or higher Bachelorâ€™s degree East Asia: 85% bachelorâ€™s degree or higher 12345678910111213141516171819202122232425262728293031323334353637383940414243#data preprocessingdegree_wo = (df21['Q4'] .replace(['No formal education past high school', 'Some college/university study without earning a bachelorâ€™s degree'],'~college') .replace(['Doctoral degree', 'Professional doctorate'],'Doctoral degree~') .value_counts().to_frame())degree_ea = (df21_Ea['Q4'] .replace(['No formal education past high school', 'Some college/university study without earning a bachelorâ€™s degree'],'~college') .replace(['Doctoral degree', 'Professional doctorate'],'Doctoral degree~') .value_counts().to_frame())#graphcolors = ['#F2798F','#88BFBA', '#CDD9A3', '#F28705', '#D9946C']fig = make_subplots(rows=1, cols=2, specs=[[{'type':'pie'}, {'type':'pie'}]], subplot_titles=(&quot;World&quot;, &quot;East Asia&quot;))fig.add_trace(go.Pie(marker=dict(colors=colors), labels=degree_wo.index, values=degree_wo['Q4'].to_numpy(), name=&quot;World&quot;), 1, 1)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=degree_ea.index, values=degree_ea['Q4'].to_numpy(), name=&quot;East Asia&quot;), 1, 2)fig.update_traces(hole=.0, hoverinfo=&quot;label+percent+name&quot;)fig.update_layout(title='&lt;b&gt;World vs East Asia&lt;/b&gt;',title_font_size=22, margin = dict(t=200, l=30, r=0, b=200), height=700, width=700)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.1, xanchor=&quot;right&quot;, x=1.0))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Percentage of East Asia degrees by year: sunburst plot The highest percentage of respondents with masterâ€™s degrees per year 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#data preprocessingdf21_Ea_degree=(df21_Ea['Q4'].replace(['No formal education past high school', 'Some college/university study without earning a bachelorâ€™s degree'],'~college') .replace(['Doctoral degree','Professional doctorate'],'Doctoral degree~') .value_counts().to_frame().rename(columns={'Q4':'2021'}))df20_Ea_degree=(df20_Ea['Q4'].replace(['No formal education past high school', 'Some college/university study without earning a bachelorâ€™s degree'],'~college') .replace(['Doctoral degree', 'Professional degree'],'Doctoral degree~') .value_counts().to_frame().rename(columns={'Q4':'2020'}))df19_Ea_degree=(df19_Ea['Q4'].replace(['No formal education past high school','Some college/university study without earning a bachelorâ€™s degree'],'~college') .replace(['Doctoral degree', 'Professional degree'],'Doctoral degree~') .value_counts().to_frame().rename(columns={'Q4':'2019'}))df18_Ea_degree=(df18_Ea['Q4'].replace(['No formal education past high school', 'Some college/university study without earning a bachelorâ€™s degree'],'~college') .replace(['Doctoral degree', 'Professional degree'],'Doctoral degree~') .value_counts().to_frame().rename(columns={'Q4':'2018'}))df17_Ea_degree=(df17_Ea['FormalEducation'] .replace(['No formal education past high school', 'Some college/university study without earning a bachelorâ€™s degree'],'~college') .replace(['Doctoral degree', 'Professional degree'],'Doctoral degree~') .value_counts().to_frame() .rename(columns={'FormalEducation':'2017'} ,index = {'I did not complete any formal education past high school':'No formal education past high school','Master\\'s degree':'Masterâ€™s degree','Bachelor\\'s degree':'Bachelorâ€™s degree','Some college/university study without earning a bachelor\\'s degree':'Some college/university study without earning a bachelorâ€™s degree'}) ) concat1 = pd.concat([df21_Ea_degree,df20_Ea_degree],axis=1, join='outer') concat2 = pd.concat([df19_Ea_degree,df18_Ea_degree],axis=1, join='outer') concat3 = pd.concat([concat1,concat2],axis=1, join='outer') df21_Ea_degree_yearly_=concat3.join(df17_Ea_degree).fillna(0).transpose() #.transpose() í–‰ ì—´ ë°”ê¾¸ê¸°df21_Ea_degree_yearly=df21_Ea_degree_yearly_.stack().to_frame().reset_index().rename(columns={'level_0':'year','level_1':'degree',0:'value'})df21_Ea_degree_yearly#graphfig = px.sunburst(df21_Ea_degree_yearly, path=['year','degree'], values=df21_Ea_degree_yearly['value'].tolist())fig.update_layout( margin = dict(t=10, l=10, r=10, b=10),colorway=(&quot;#F2798F&quot;,&quot;#88BFBA&quot;,&quot;#CDD9A3&quot;,'#F28705','#D9946C'))fig.update_layout(title='&lt;b&gt; Degree&lt;/b&gt;',title_font_size=25, margin = dict(t=100, l=100, r=50, b=100), height=700, width=700)fig.update_traces(hovertemplate='&lt;b&gt;Name&lt;/b&gt;: %{id}&lt;br&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{value}&lt;br&gt;'+ '&lt;b&gt;Parent&lt;/b&gt;: %{parent}') fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Plus we could see the advantages of Plotly in this graph. Matplotlib draws a static graph, but Plotly can dynamically click and move, and it supports zooming out, zooming in, and downloading graphs. Because all of our graphs are made of plotly, the viewer can represent or remove items in the graph if desired. With a click East Asia Degree Ratio: Bar plot 40% of masterâ€™s degrees or higher, and respondents have a high educational background. China and Japan have similar trends to East Asia and the World. The number of people itself is large, so a representative trend seems to appear here. However, it is noteworthy that the two countries have the same tendency. Korea: It is the only country among the four countries with a high degree of education below Ph.D., bachelorâ€™s degree, and junior college. Only masters are low. (Polarization of education?) Taiwan: 1st place in masterâ€™s ratio (55%), 2nd place in Ph.D. or higher (13.8%). = The highest level of education. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091#data preprocessingdf21Edu_Ea = df21_Ea.loc[:,['Q3','Q4']].reset_index().rename(columns={'Q3':'East_Asia', 'Q4':'Dgree'}).fillna('etc')df21Edu_Ea =(df21Edu_Ea.replace({'I prefer not to answer':'etc'}).replace(['No formal education past high school', 'Some college/university study without earning a bachelorâ€™s degree'],'~college') .replace(['Doctoral degree', 'Professional doctorate'],'Doctoral degree~'))df21Edu_Ea= (df21Edu_Ea .groupby(['East_Asia', 'Dgree']) .size() .reset_index() .rename(columns = {0:&quot;Count&quot;}))# ì—°ë ¹-ì§€ì—­ %dfKo_Edu21= df21Edu_Ea[df21Edu_Ea['East_Asia']=='South Korea']dfKo_Edu21['%']=((dfKo_Edu21['Count'] / dfKo_Edu21['Count'].sum()*100)).round(2)dfKo_Edu21=dfKo_Edu21.sort_values(by='%', ascending=False)dfTw_Edu21= df21Edu_Ea[df21Edu_Ea['East_Asia']=='Taiwan']dfTw_Edu21['%']=((dfTw_Edu21['Count'] / dfTw_Edu21['Count'].sum())*100).round(2)dfTw_Edu21=dfTw_Edu21.sort_values(by='%', ascending=False)dfCh_Edu21= df21Edu_Ea[df21Edu_Ea['East_Asia']=='China']dfCh_Edu21['%']=((dfCh_Edu21['Count'] / dfCh_Edu21['Count'].sum())*100).round(2)dfCh_Edu21=dfCh_Edu21.sort_values(by='%', ascending=False)dfJp_Edu21= df21Edu_Ea[df21Edu_Ea['East_Asia']=='Japan']dfJp_Edu21['%']=((dfJp_Edu21['Count'] / dfJp_Edu21['Count'].sum())*100).round(2)dfJp_Edu21=dfJp_Edu21.sort_values(by='%', ascending=False)# #data ì™„ì„±# dfEdu_21_per = pd.concat([dfKo_Edu21, dfTw_Edu21, dfCh_Edu21, dfJp_Edu21], ignore_index = True)# dfEdu_21_per= pd.pivot(dfEdu_21_per, index = &quot;Dgree&quot;, columns = 'East_Asia', values = &quot;%&quot;).reset_index()# dfEdu_21_per#graphfig = make_subplots(rows = 1, cols = 4, shared_yaxes=True, vertical_spacing = 0.05)fig.add_trace(go.Bar(x = dfCh_Edu21['Dgree'], y = dfCh_Edu21['%'], text = dfCh_Edu21['%'].astype(str) + &quot;%&quot;, textposition='outside', name='China', marker_color='#88BFBA'), row = 1, col = 1)fig.add_trace(go.Bar(x = dfJp_Edu21['Dgree'], y = dfJp_Edu21['%'], text = dfJp_Edu21['%'].astype(str) + &quot;%&quot;, textposition='outside', name='Japan', marker_color='#CDD9A3'), row = 1, col = 2)fig.add_trace(go.Bar(x = dfKo_Edu21['Dgree'], y = dfKo_Edu21['%'], text = dfKo_Edu21['%'].astype(str) + &quot;%&quot;, textposition='outside', name='South Korea', marker_color='#F28705'), row = 1, col = 3)fig.add_trace(go.Bar(x = dfTw_Edu21['Dgree'], y = dfTw_Edu21['%'], text = dfTw_Edu21['%'].astype(str) + &quot;%&quot;, textposition='outside', name='Taiwan', marker_color='#D9946C'), row = 1, col = 4)fig.update_layout(showlegend=True,title='&lt;b&gt;Degree in East Asia&lt;/b&gt;',title_font_size=22, margin = dict(t=200, l=100, r=50, b=200), height=700, width=700)fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{y}%&lt;br&gt;'+ '&lt;b&gt;Degree&lt;/b&gt;: %{x}&lt;br&gt;')fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.1, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 3.1.6 Experience transformation Trends in World & East Asia Career: Stacked Scatter plot - < 2 years: 50% of the total. - 3-5 years: Decrease in the world, maintain East Asia ratio - 2021 'etc data' disappeared. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120#Exp data ì „ì²˜ë¦¬# Exp ë½‘ì•„ì˜¤ê¸°Exp21_Wo = df21.loc[:,['Q3','Q6', 'year']].reset_index().rename(columns={'Q3':'Country', 'Q6':'Exp'}).fillna('etc')Exp20_Wo = df20.loc[:,['Q3','Q6','year']].reset_index().rename(columns={'Q3':'Country', 'Q6':'Exp'}).fillna('etc')Exp19_Wo = df19.loc[:,['Q3','Q15','year']].reset_index().rename(columns={'Q3':'Country', 'Q15':'Exp'}).fillna('etc')Exp18_Wo = df18.loc[:,['Q3','Q8','year']].reset_index().rename(columns={'Q3':'Country', 'Q8':'Exp'}).fillna('etc')Exp17_Wo = df17.loc[:,['Country','Tenure', 'year']].reset_index().rename(columns={'Country':'Country', 'Tenure':'Exp'}).fillna('etc')Exp21_Wo= Exp21_Wo.replace({'I have never written code': '&lt; 1 years', '1-3 years': '1-2 years'}).replace(['10-20 years', '20+ years'], '10+ years' )Exp20_Wo= Exp20_Wo.replace({'I have never written code': '&lt; 1 years'}).replace(['10-20 years', '20+ years'], '10+ years' )Exp19_Wo= Exp19_Wo.replace({'I have never written code': '&lt; 1 years'}).replace(['10-20 years', '20+ years'], '10+ years' )Exp18_Wo= (Exp18_Wo.replace({'0-1': '&lt; 1 years', '1-2': '1-2 years', '5-10':'5-10 years'}) .replace(['2-3', '3-4', '4-5'],'3-5 years') .replace(['10-15', '15-20','20-25', '30 +','25-30'],'10+ years'))Exp17_Wo=(Exp17_Wo.replace({'More than 10 years':'10+ years', '1 to 2 years':'1-2 years', 'Less than a year':'&lt; 1 years', '3 to 5 years':'3-5 years', &quot;I don't write code to analyze data&quot;:'&lt; 1 years', '6 to 10 years':'5-10 years'})) #data ì •ì œ(í•œêº¼ë²ˆì— ì´ë¦„ë°”ê¾¸ê¸°)Exp5y_Wo= pd.concat([Exp17_Wo, Exp18_Wo, Exp19_Wo, Exp20_Wo, Exp21_Wo]).reset_index()Exp5y_Wo=(Exp5y_Wo.groupby(['year', 'Exp']) .size() .reset_index() .rename(columns = {0:&quot;Count&quot;}))#percent data ë„£ê¸°Exp21_per_W= Exp5y_Wo[Exp5y_Wo['year'] == &quot;2021&quot;].reset_index(drop = True)Exp21_per_W['percentage'] = Exp21_per_W[&quot;Count&quot;] / Exp21_per_W[&quot;Count&quot;].sum()Exp21_per_W['%'] = np.round(Exp21_per_W['percentage'] * 100, 1)Exp20_per_W = Exp5y_Wo[Exp5y_Wo['year'] == &quot;2020&quot;].reset_index(drop = True)Exp20_per_W['percentage'] = Exp20_per_W[&quot;Count&quot;] / Exp20_per_W[&quot;Count&quot;].sum()Exp20_per_W['%'] = np.round(Exp20_per_W['percentage'] * 100, 1)Exp19_per_W = Exp5y_Wo[Exp5y_Wo['year'] == &quot;2019&quot;].reset_index(drop = True)Exp19_per_W['percentage'] = Exp19_per_W[&quot;Count&quot;] / Exp19_per_W[&quot;Count&quot;].sum()Exp19_per_W['%'] = np.round(Exp19_per_W['percentage'] * 100, 1)Exp18_per_W = Exp5y_Wo[Exp5y_Wo['year'] == &quot;2018&quot;].reset_index(drop = True)Exp18_per_W['percentage'] = Exp18_per_W[&quot;Count&quot;] / Exp18_per_W[&quot;Count&quot;].sum()Exp18_per_W['%'] = np.round(Exp18_per_W['percentage'] * 100, 1)Exp17_per_W = Exp5y_Wo[Exp5y_Wo['year'] == &quot;2017&quot;].reset_index(drop = True)Exp17_per_W['percentage'] = Exp17_per_W[&quot;Count&quot;] / Exp17_per_W[&quot;Count&quot;].sum()Exp17_per_W['%'] = np.round(Exp17_per_W['percentage'] * 100, 1)#data ì™„ì„±Exp5y_per_W = pd.concat([Exp17_per_W, Exp18_per_W, Exp19_per_W, Exp20_per_W, Exp21_per_W], ignore_index = True)Exp5y_per_W= pd.pivot(Exp5y_per_W, index = &quot;year&quot;, columns = 'Exp', values = &quot;%&quot;).reset_index()Exp5y_per_W.fillna('0')Exp5y_percent_order = Exp5y_per_W['year'].tolist()fig = go.Figure()fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_per_W['&lt; 1 years'].tolist(), mode = &quot;lines&quot;, name = '&lt; 1 years', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#F2798F'))fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_per_W['1-2 years'].tolist(), mode = &quot;lines&quot;, name = '1-2 years', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#88BFBA'))fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_per_W['3-5 years'].tolist(), mode = &quot;lines&quot;, name = '3-5 years', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#CDD9A3'))fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_per_W['5-10 years'].tolist(), mode = &quot;lines&quot;, name = '5-10 years', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#F28705'))fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_per_W['10+ years'].tolist(), mode = &quot;lines&quot;, name = '10+ years', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#D9946C'))fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_per_W['etc'].tolist(), mode = &quot;lines&quot;, name = 'etc', line = dict(width = 1), stackgroup = &quot;one&quot;, marker_color='#F2D64B'))fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{y}%&lt;br&gt;')fig.update_layout(yaxis_range = (0, 100), title_font_size=20, title_text=&quot;&lt;b&gt;Experience in world&lt;/b&gt;&quot;, height=500, width=700, title_x=0.5)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135#data preprocessingExp21 = df21_Ea.loc[:,['Q3','Q6', 'year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q6':'Exp'}).fillna('etc')Exp20 = df20_Ea.loc[:,['Q3','Q6','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q6':'Exp'}).fillna('etc')Exp19 = df19_Ea.loc[:,['Q3','Q15','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q15':'Exp'}).fillna('etc')Exp18 = df18_Ea.loc[:,['Q3','Q8','year']].reset_index().rename(columns={'Q3':'East_Asia', 'Q8':'Exp'}).fillna('etc')Exp17 = df17_Ea.loc[:,['Country','Tenure', 'year']].reset_index().rename(columns={'Country':'East_Asia', 'Tenure':'Exp'}).fillna('etc')Exp21Uni=['3-5 years', '&lt; 1 years', '1-3 years', '10-20 years', 'I have never written code', '5-10 years', '20+ years']Exp20Uni= ['3-5 years', '&lt; 1 years', '5-10 years', '1-2 years', 'etc', '20+ years', '10-20 years', 'I have never written code']Exp19Uni=['1-2 years', '5-10 years', '&lt; 1 years', 'I have never written code', '3-5 years', '10-20 years', '20+ years', 'etc']Exp18Uni=['0-1', '2-3', '1-2', '5-10', '3-4', '10-15', '15-20', '4-5', '20-25', '30 +', 'etc', '25-30']Exp17Uni=['More than 10 years', '1 to 2 years', 'etc', 'Less than a year', '3 to 5 years', &quot;I don't write code to analyze data&quot;, '6 to 10 years']Exp21= Exp21.replace({'I have never written code': '&lt; 1 years', '1-3 years': '1-2 years'}).replace(['10-20 years', '20+ years'], '10+ years' )Exp20= Exp20.replace({'I have never written code': '&lt; 1 years'}).replace(['10-20 years', '20+ years'], '10+ years' )Exp19= Exp19.replace({'I have never written code': '&lt; 1 years'}).replace(['10-20 years', '20+ years'], '10+ years' )Exp18= (Exp18.replace({'0-1': '&lt; 1 years', '1-2': '1-2 years', '5-10':'5-10 years'}) .replace(['2-3', '3-4', '4-5'],'3-5 years') .replace(['10-15', '15-20','20-25', '30 +','25-30'],'10+ years'))Exp17=(Exp17.replace({'More than 10 years':'10+ years', '1 to 2 years':'1-2 years', 'Less than a year':'&lt; 1 years', '3 to 5 years':'3-5 years', &quot;I don't write code to analyze data&quot;:'&lt; 1 years', '6 to 10 years':'5-10 years'})) Exp5y= pd.concat([Exp17, Exp18, Exp19, Exp20, Exp21]).reset_index()Exp5y=(Exp5y.groupby(['year', 'Exp']) .size() .reset_index() .rename(columns = {0:&quot;Count&quot;}))Exp21_percent = Exp5y[Exp5y['year'] == &quot;2021&quot;].reset_index(drop = True)Exp21_percent['percentage'] = Exp21_percent[&quot;Count&quot;] / Exp21_percent[&quot;Count&quot;].sum()Exp21_percent['%'] = np.round(Exp21_percent['percentage'] * 100, 1)Exp21_percentExp20_percent = Exp5y[Exp5y['year'] == &quot;2020&quot;].reset_index(drop = True)Exp20_percent['percentage'] = Exp20_percent[&quot;Count&quot;] / Exp20_percent[&quot;Count&quot;].sum()Exp20_percent['%'] = np.round(Exp20_percent['percentage'] * 100, 1)Exp20_percentExp19_percent = Exp5y[Exp5y['year'] == &quot;2019&quot;].reset_index(drop = True)Exp19_percent['percentage'] = Exp19_percent[&quot;Count&quot;] / Exp19_percent[&quot;Count&quot;].sum()Exp19_percent['%'] = np.round(Exp19_percent['percentage'] * 100, 1)Exp19_percentExp18_percent = Exp5y[Exp5y['year'] == &quot;2018&quot;].reset_index(drop = True)Exp18_percent['percentage'] = Exp18_percent[&quot;Count&quot;] / Exp18_percent[&quot;Count&quot;].sum()Exp18_percent['%'] = np.round(Exp18_percent['percentage'] * 100, 1)Exp18_percentExp17_percent = Exp5y[Exp5y['year'] == &quot;2017&quot;].reset_index(drop = True)Exp17_percent['percentage'] = Exp17_percent[&quot;Count&quot;] / Exp17_percent[&quot;Count&quot;].sum()Exp17_percent['%'] = np.round(Exp17_percent['percentage'] * 100, 1)Exp17_percent#graphExp5y_percent = pd.concat([Exp17_percent, Exp18_percent, Exp19_percent, Exp20_percent, Exp21_percent], ignore_index = True)Exp5y_percent= pd.pivot(Exp5y_percent, index = &quot;year&quot;, columns = 'Exp', values = &quot;%&quot;).reset_index()Exp5y_percent.fillna('0')Exp5y_percent_order = Exp5y_percent['year'].tolist()fig = go.Figure()fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_percent['&lt; 1 years'].tolist(), mode = &quot;lines&quot;, name = '&lt; 1 years', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#F2798F'))fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_percent['1-2 years'].tolist(), mode = &quot;lines&quot;, name = '1-2 years', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#88BFBA'))fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_percent['3-5 years'].tolist(), mode = &quot;lines&quot;, name = '3-5 years', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#CDD9A3'))fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_percent['5-10 years'].tolist(), mode = &quot;lines&quot;, name = '5-10 years', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#F28705'))fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_percent['10+ years'].tolist(), mode = &quot;lines&quot;, name = '10+ years', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#D9946C'))fig.add_trace(go.Scatter( x = Exp5y_percent_order, y = Exp5y_percent['etc'].tolist(), mode = &quot;lines&quot;, name = 'etc', line = dict(width = 0.5), stackgroup = &quot;one&quot;, marker_color='#F2D64B'))fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{y}%&lt;br&gt;')fig.update_layout(yaxis_range = (0, 100), title_text=&quot;&lt;b&gt;Experience in East Asia&lt;/b&gt;&quot;, height=500, width=700, title_font_size=20, title_x=0.5)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 3.1.7 Salary transformation World & East Asia Annual salary: Bar-H plot $ 200,000 ~ : World (2.9%) is more than 50% compared to East Asia (1.3%) $ ~250,000 : World (59.2%) is less than East Asia (50.3%) = East Asiaâ€™s annual salary gap between rich and poor is less. $ 25,000~60,000: The highest section in East Asia at 24%. = The annual salary section that we aim for. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103#data preprocessingdf21_salary_=df21['Q25'].value_counts().to_frame().rename(index={'$0-999':'&lt;999','&gt;$1,000,000':'1,000,000~','$500,000-999,999':'500,000-999,999'}).fillna(0)df21_Ea_salary_=df21_Ea['Q25'].value_counts().to_frame().rename(index={'$0-999':'&lt;999','&gt;$1,000,000':'1,000,000~','$500,000-999,999':'500,000-999,999'}).fillna(0)#í¼ì„¼íŠ¸df21_salary__=(df21_salary_['Q25']/(df21_salary_['Q25'].sum())*100).round(1).to_frame().rename(columns={'Q25':'World'})df21_Ea_salary__=(df21_Ea_salary_['Q25']/(df21_Ea_salary_['Q25'].sum())*100).round(1).to_frame().rename(columns={'Q25':'EA'})#ê·¸ë£¹í™”df21_salary=(df21_salary__.rename(index= {'1,000-1,999':'1,000-7,499', '2,000-2,999':'1,000-7,499', '3,000-3,999':'1,000-7,499', '4,000-4,999':'1,000-7,499', '5,000-7,499':'1,000-7,499'}) .rename(index={'7,500-9,999':'7,500-24,999', '10,000-14,999':'7,500-24,999', '15,000-19,999':'7,500-24,999', '20,000-24,999':'7,500-24,999' }) .rename(index={'25,000-29,999':'25,000-59,999', '30,000-39,999':'25,000-59,999', '40,000-49,999':'25,000-59,999', '50,000-59,999':'25,000-59,999'}) .rename(index={'60,000-69,999':'60,000-99,999', '70,000-79,999':'60,000-99,999', '80,000-89,999':'60,000-99,999', '90,000-99,999':'60,000-99,999'}) .rename(index={'100,000-124,999':'100,000-199,999', '125,000-149,999':'100,000-199,999', '150,000-199,999':'100,000-199,999'}) .rename(index={'200,000-249,999':'200,000-1,000,000~', '250,000-299,999':'200,000-1,000,000~', '300,000-499,999':'200,000-1,000,000~', '500,000-999,999':'200,000-1,000,000~', '1,000,000~':'200,000-1,000,000~'}) .reset_index().groupby('index').sum() .reindex(index = ['&lt;999', '1,000-7,499', '7,500-24,999', '25,000-59,999', '60,000-99,999', '100,000-199,999', '200,000-1,000,000~']))df21_Ea_salary=(df21_Ea_salary__.rename(index= {'1,000-1,999':'1,000-7,499', '2,000-2,999':'1,000-7,499', '3,000-3,999':'1,000-7,499', '4,000-4,999':'1,000-7,499', '5,000-7,499':'1,000-7,499'}) .rename(index={'7,500-9,999':'7,500-24,999', '10,000-14,999':'7,500-24,999', '15,000-19,999':'7,500-24,999', '20,000-24,999':'7,500-24,999'}) .rename(index={'25,000-29,999':'25,000-59,999', '30,000-39,999':'25,000-59,999', '40,000-49,999':'25,000-59,999', '50,000-59,999':'25,000-59,999'}) .rename(index={'60,000-69,999':'60,000-99,999', '70,000-79,999':'60,000-99,999', '80,000-89,999':'60,000-99,999', '90,000-99,999':'60,000-99,999'}) .rename(index={'100,000-124,999':'100,000-199,999', '125,000-149,999':'100,000-199,999', '150,000-199,999':'100,000-199,999'}) .rename(index={'200,000-249,999':'200,000-1,000,000~', '250,000-299,999':'200,000-1,000,000~', '300,000-499,999 ':'200,000-1,000,000~', '500,000-999,999':'200,000-1,000,000~', '1,000,000~':'200,000-1,000,000~'}) .reset_index().groupby('index').sum() .reindex(index = ['&lt;999', '1,000-7,499', '7,500-24,999', '25,000-59,999', '60,000-99,999', '100,000-199,999', '200,000-1,000,000~']))#graphWorld = df21_salary['World'].valuesEast_Asia = df21_Ea_salary['EA'].valuesy = df21_salary.indexfig = go.Figure(data=[ go.Bar(y=y, x=World, orientation='h', name=&quot;World&quot;, base=0, hovertemplate='&lt;b&gt;World&lt;/b&gt;: %{x}%&lt;br&gt;', marker_color='#979DA6'), go.Bar(y=y, x=-East_Asia, orientation='h', name=&quot;East Asia&quot;, base=0, hovertemplate='&lt;b&gt;East Asia&lt;/b&gt;: %{x}%&lt;br&gt;', marker_color='#F2D64B') ])fig.update_layout(barmode='stack')fig.update_layout( margin=dict(l=200, r=0, t=200, b=100), autosize=False, title_text=&quot;&lt;b&gt; Salary in East Asia vs World&lt;/b&gt;&quot;, height=600, width=700, title_font_size=20, title_x=0.5)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.1, xanchor=&quot;right&quot;, x=1))fig.show() World experience and annual salary: Heat Map Relatively **positive correlation.** Even with 5-10 years of experience, more than 45% has an annual salary of less than $20,000 With more than 10 years of experience, more than 30% receive an annual salary of $100,000. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990#data preprocessingSalExp21= df21.loc[:, ['region', 'Q25', 'Q6']].rename(columns={'Q6':'Exp', 'Q25':'Salary'})SalExp21=(SalExp21 .replace(['0-999','$0-999','0'], '&lt; 999') .replace({'&gt;$1,000,000':'200,000~'}) .replace(['1,000-1,999','2,000-2,999','3,000-3,999', '4,000-4,999','5,000-7,499','7,500-9,999','10,000-14,999', '15,000-19,999'],'1,000-20,000') .replace(['20,000-24,999''25,000-29,999','30,000-39,999', '40,000-49,999', '50,000-59,999'],'20,000-59,999') .replace(['60,000-69,999', '70,000-79,999', '80,000-89,999', '90,000-99,999'], '60,000-99,999') .replace(['100,000-124,999', '300,000-499,999', '125,000-149,999', '125,000-149,999', '150,000-199,999'],'100,000-199,999') .replace(['200,000-249,999', '250,000-299,999', '1,000,000','$500,000-999,999'], '200,000~') .replace({'I have never written code': '&lt; 1 years'}) .replace(['10-20 years', '20+ years'], '10+ years' ) )sal_order=['&lt; 999', '1,000-20,000', '20,000-59,999', '60,000-99,999','100,000-199,999', '200,000~']Exp21_order=['&lt; 1 years', '1-3 years','3-5 years', '5-10 years', '10+ years' ]SalExp21_Ea = SalExp21[SalExp21['region'] == &quot;EastAsia&quot;].reset_index(drop = True)SalExp21_Ea=(SalExp21_Ea.groupby(['Exp', 'Salary']) .size() .unstack().fillna(0).astype('int64'))SalExp21_Wo = SalExp21[SalExp21['region'] == &quot;World&quot;].reset_index(drop = True)SalExp21_Wo=(SalExp21_Wo.groupby(['Exp', 'Salary']) .size() .unstack().fillna(0).astype('int64'))SalExp21_Wo#graph#Worldz = SalExp21_Woz = z[sal_order]z = z.reindex(Exp21_order)z_data = z.apply(lambda x:np.round(x/x.sum()*100, 2), axis = 1).to_numpy() # convert to correlation matrixx = sal_ordery = Exp21_orderfig = ff.create_annotated_heatmap(z_data, x = x, y = y, colorscale = &quot;sunset&quot;)fig.update_layout( title_text=&quot;&lt;b&gt;Experience and salary in World&lt;/b&gt;&quot;, height=700, width=700, title_font_size=20, title_x=0.5, margin=dict(l=100, r=100, t=200, b=100))fig.add_annotation(dict(font=dict(size=14), x=0.85, y=-0.1, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()#East Asiaz = SalExp21_Eaz = z[sal_order]z = z.reindex(Exp21_order)z_data = z.apply(lambda x:np.round(x/x.sum(), 2), axis = 1).to_numpy() # convert to correlation matrixx = sal_ordery = Exp21_orderfig = ff.create_annotated_heatmap(z_data, x = x, y = y, colorscale = &quot;sunset&quot;)fig.update_layout(title_text=&quot;&lt;b&gt;Experience and salary in East Asia&lt;/b&gt;&quot;, height=700, width=700, title_font_size=20, title_x=0.5, margin=dict(l=100, r=100, t=200, b=100))fig.add_annotation(dict(font=dict(size=14), x=0.85, y=-0.1, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() World & East Asia Degree/Annual salary: Heat Map \\$ ~20,000 : Regardless of degree, about 40% of the annual salary is $ 20,000 or less. Guess itâ€™s the ratio that comes from a student. $ 25,000-100,000 : Earned more than 40% with a bachelorâ€™s degree alone in East Asia (World: less than 20%) $ 200,000~ : Even with a doctorate or higher, it is difficult to obtain it from East Asia. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798#data preprocessingSalary21= df21.loc[:, ['region', 'Q25', 'year']].rename(columns={'Q3':'Country', 'Q25':'Salary'})salary21_Index=['&lt; 999', '1,000-20,000', '20,000-59,999', '60,000-99,999','100,000-199,999', '200,000~']Salary21=(Salary21 .replace(['0-999','$0-999','0'], '&lt; 999') .replace({'&gt;$1,000,000':'200,000~'}) .replace(['1,000-1,999','2,000-2,999','3,000-3,999', '4,000-4,999','5,000-7,499','7,500-9,999','10,000-14,999', '15,000-19,999'],'1,000-20,000') .replace(['20,000-24,999''25,000-29,999','30,000-39,999', '40,000-49,999', '50,000-59,999'],'20,000-59,999') .replace(['60,000-69,999', '70,000-79,999', '80,000-89,999','90,000-99,999'], '60,000-99,999') .replace(['100,000-124,999', '300,000-499,999', '125,000-149,999', '125,000-149,999', '150,000-199,999'],'100,000-199,999') .replace(['200,000-249,999', '250,000-299,999','1,000,000','$500,000-999,999'], '200,000~')).fillna('0')sal_order=['&lt; 999', '1,000-20,000', '20,000-59,999', '60,000-99,999','100,000-199,999', '200,000~']Salary21=(Salary21.groupby(['region', 'Salary']) .size() .reset_index() .rename(columns = {0:&quot;Count&quot;}))Salary21_Ea = Salary21[Salary21['region'] == &quot;EastAsia&quot;].reset_index(drop = True)Salary21_Ea['%']=((Salary21_Ea['Count'] / Salary21_Ea['Count'].sum())*100).round(2)Salary21_Wo = Salary21[Salary21['region'] == &quot;World&quot;].reset_index(drop = True)Salary21_Wo['%']=((Salary21_Wo['Count'] / Salary21_Wo['Count'].sum())*100).round(2)Dgr_Sal_21= df21.loc[:, ['region', 'Q25', 'Q4']].rename(columns={'Q4':'Dgree', 'Q25':'Salary'})Dgr_Sal_21 = (Dgr_Sal_21.replace(['0-999','$0-999','0'], '&lt; 999') .replace({'&gt;$1,000,000':'200,000~'}) .replace(['1,000-1,999','2,000-2,999','3,000-3,999', '4,000-4,999','5,000-7,499','7,500-9,999','10,000-14,999', '15,000-19,999'],'1,000-20,000') .replace(['20,000-24,999''25,000-29,999','30,000-39,999', '40,000-49,999', '50,000-59,999'],'20,000-59,999') .replace(['60,000-69,999', '70,000-79,999', '80,000-89,999', '90,000-99,999'], '60,000-99,999') .replace(['100,000-124,999', '300,000-499,999', '125,000-149,999', '125,000-149,999','150,000-199,999'],'100,000-199,999') .replace(['200,000-249,999', '250,000-299,999','1,000,000','$500,000-999,999'], '200,000~') .replace({'I prefer not to answer':'etc'}) .replace(['No formal education past high school', 'Some college/university study without earning a bachelorâ€™s degree'],'~college') .replace(['Doctoral degree', 'Professional doctorate'],'Doctoral degree~'))#EastAsia ë½‘ê¸°Dgr_Sal_21_Ea= Dgr_Sal_21[Dgr_Sal_21['region'] == &quot;EastAsia&quot;].reset_index(drop = True)Dgr_Sal_21_Ea = Dgr_Sal_21_Ea.groupby(['Dgree', 'Salary']).size().unstack().fillna(0).astype('int64')dgree_order=[ '~college','Bachelorâ€™s degree', 'Masterâ€™s degree', 'Doctoral degree~', 'etc']#graph#Worldz = Dgr_Sal_21.groupby(['Dgree', 'Salary']).size().unstack().fillna(0).astype('int64')z = z[sal_order]z = z.reindex(dgree_order)z_data = z.apply(lambda x:np.round(x/x.sum()*100, 2), axis = 1).to_numpy() # convert to correlation matrixx = sal_ordery = dgree_orderfig = ff.create_annotated_heatmap(z_data, x = x, y = y, colorscale = &quot;sunset&quot;)fig.update_layout( title_text=&quot;&lt;b&gt; Degree-Salary in World&lt;/b&gt;&quot;, height=700, width=700, title_font_size=20, title_x=0.5, margin=dict(l=150, r=100, t=200, b=50))fig.update_traces(hovertemplate='&lt;b&gt;Degree&lt;/b&gt;: %{y}&lt;br&gt;'+ '&lt;b&gt;Salary&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Percent&lt;/b&gt;: %{z}%')fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.1, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()#East Asiaz = Dgr_Sal_21_Eaz = z[sal_order]z = z.reindex(dgree_order)z_data = z.apply(lambda x:np.round(x/x.sum()*100, 2), axis = 1).to_numpy() # convert to correlation matrixx = sal_ordery = dgree_orderfig = ff.create_annotated_heatmap(z_data, x = x, y = y, colorscale = &quot;sunset&quot;)fig.update_layout(title_text=&quot;&lt;b&gt; Degree-Salary in East Asia&lt;/b&gt;&quot;, height=700, width=700, title_font_size=20, title_x=0.5, margin=dict(l=150, r=100, t=200, b=50))fig.update_traces(hovertemplate='&lt;b&gt;Degree&lt;/b&gt;: %{y}&lt;br&gt;'+ '&lt;b&gt;Salary&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Percent&lt;/b&gt;: %{z}%')fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.1, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 3.1.8 Language transformation World & East Asia Programming Language: Bar plot - Python: 80% of the world and 85% of East Asia use it. We've been working on the project as python, so I hope we can continue to learn python and become experienced Data Scientists! 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#data preprocessing#worldprogramming_list = [&quot;Python&quot;, &quot;R&quot;, &quot;SQL&quot;, &quot;Java&quot;, &quot;C&quot;, &quot;Bash&quot;, &quot;Javascript&quot;, &quot;C++&quot;]programming_df = pd.Series(programming_list)df_2019 = df19[df19['Q19'].isin(programming_df)]df_2020 = df20[df20['Q8'].isin(programming_df)]df_2021 = df21[df21['Q8'].isin(programming_df)]df19Lag = df_2019.loc[:, ['region', 'Q5', 'Q19', 'year']]df19Lag = df19Lag.rename(columns = {'Q19': 'Language'}, inplace = False) # To match with other datasetsdf20Lag = df_2020.loc[:, ['region', 'Q5', 'Q8', 'year']].rename(columns = {'Q8': 'Language'}, inplace = False)df21Lag = df_2021.loc[:, ['region', 'Q5', 'Q8', 'year']].rename(columns = {'Q8': 'Language'}, inplace = False)df3y_Lag = pd.concat([df19Lag, df20Lag, df21Lag])df3y_Lag = df3y_Lag.groupby(['year', 'Language']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df3y_Lag# 2019dfLang_19 = df3y_Lag[df3y_Lag['year'] == &quot;2019&quot;].reset_index(drop = True)dfLang_19['percentage'] = dfLang_19[&quot;Count&quot;] / dfLang_19[&quot;Count&quot;].sum()dfLang_19['%'] = np.round(dfLang_19['percentage'] * 100, 1)# 2020dfLang_20 = df3y_Lag[df3y_Lag['year'] == &quot;2020&quot;].reset_index(drop = True)dfLang_20['percentage'] = dfLang_20[&quot;Count&quot;] / dfLang_20[&quot;Count&quot;].sum()dfLang_20['%'] = np.round(dfLang_20['percentage'] * 100, 1)# 2021dfLang_21 = df3y_Lag[df3y_Lag['year'] == &quot;2021&quot;].reset_index(drop = True)dfLang_21['percentage'] = dfLang_21[&quot;Count&quot;] / dfLang_21[&quot;Count&quot;].sum()dfLang_21['%'] = np.round(dfLang_21['percentage'] * 100, 1)dfLang_19=dfLang_19.sort_values(by='%', ascending=False)dfLang_20=dfLang_20.sort_values(by='%', ascending=False)dfLang_21=dfLang_21.sort_values(by='%', ascending=False)#graphfig = go.Figure()fig.add_trace(go.Bar(x = dfLang_19['Language'], y = dfLang_19['%'], name = &quot;2019&quot;, text = dfLang_19['%'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#CDD9A3'))fig.add_trace(go.Bar(x = dfLang_20['Language'], y = dfLang_20['%'], name = &quot;2020&quot;, text = dfLang_20['%'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#F28705'))fig.add_trace(go.Bar(x = dfLang_21['Language'], y = dfLang_21['%'], name = &quot;2021&quot;, text = dfLang_21['%'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#88BFBA'))fig.update_layout(title='&lt;b&gt;Language in World&lt;/b&gt;',title_font_size=20, margin = dict(t=100, l=100, r=50, b=100), height=600, width=700, xaxis_title=None, yaxis_title=None)fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{y}%&lt;br&gt;'+ '&lt;b&gt;Language&lt;/b&gt;: %{x}&lt;br&gt;')fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;v&quot;, yanchor=&quot;bottom&quot;, y=0.8, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#data prprocessing#Eadf_2019 = df19_Ea[df19_Ea['Q19'].isin(programming_df)]df_2020 = df20_Ea[df20_Ea['Q8'].isin(programming_df)]df_2021 = df21_Ea[df21_Ea['Q8'].isin(programming_df)]df19Lag = df_2019.loc[:, ['region', 'Q5', 'Q19', 'year']]df19Lag = df19Lag.rename(columns = {'Q19': 'Language'}, inplace = False) # To match with other datasetsdf20Lag = df_2020.loc[:, ['region', 'Q5', 'Q8', 'year']].rename(columns = {'Q8': 'Language'}, inplace = False)df21Lag = df_2021.loc[:, ['region', 'Q5', 'Q8', 'year']].rename(columns = {'Q8': 'Language'}, inplace = False)df3y_Lag = pd.concat([df19Lag, df20Lag, df21Lag])df3y_Lag = df3y_Lag.groupby(['year', 'Language']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df3y_Lag# 2019dfLang_19 = df3y_Lag[df3y_Lag['year'] == &quot;2019&quot;].reset_index(drop = True)dfLang_19['percentage'] = dfLang_19[&quot;Count&quot;] / dfLang_19[&quot;Count&quot;].sum()dfLang_19['%'] = np.round(dfLang_19['percentage'] * 100, 1)# 2020dfLang_20 = df3y_Lag[df3y_Lag['year'] == &quot;2020&quot;].reset_index(drop = True)dfLang_20['percentage'] = dfLang_20[&quot;Count&quot;] / dfLang_20[&quot;Count&quot;].sum()dfLang_20['%'] = np.round(dfLang_20['percentage'] * 100, 1)# 2021dfLang_21 = df3y_Lag[df3y_Lag['year'] == &quot;2021&quot;].reset_index(drop = True)dfLang_21['percentage'] = dfLang_21[&quot;Count&quot;] / dfLang_21[&quot;Count&quot;].sum()dfLang_21['%'] = np.round(dfLang_21['percentage'] * 100, 1)dfLang_19=dfLang_19.sort_values(by='%', ascending=False)dfLang_20=dfLang_20.sort_values(by='%', ascending=False)dfLang_21=dfLang_21.sort_values(by='%', ascending=False)#graphfig = go.Figure()fig.add_trace(go.Bar(x = dfLang_19['Language'], y = dfLang_19['%'], name = &quot;2019&quot;, text = dfLang_19['%'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#CDD9A3'))fig.add_trace(go.Bar(x = dfLang_20['Language'], y = dfLang_20['%'], name = &quot;2020&quot;, text = dfLang_20['%'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#F28705'))fig.add_trace(go.Bar(x = dfLang_21['Language'], y = dfLang_21['%'], name = &quot;2021&quot;, text = dfLang_21['%'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#88BFBA'))fig.update_layout(title='&lt;b&gt;Language in EastAsia&lt;/b&gt;',title_font_size=20, margin = dict(t=100, l=100, r=50, b=100), height=600, width=700, xaxis_title=None, yaxis_title=None)fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{text}')fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 3.2 Position of Data Scientist in East Asia 123456789101112131415161718192021222324# data preprocessingdf21_Ea_DS = df21_Ea[df21_Ea['Q5'].isin(Data_Scientist)].fillna(0)salary_order= ['&lt;999', '1,000-19,999', '20,000-59,999', '60,000-99,999','100,000-199,999', '200,000~']dgree_order=[ '~college','Bachelorâ€™s degree', 'Masterâ€™s degree', 'Doctoral degree~', 'etc']df21_Ea_DS=(df21_Ea_DS #salary .replace({'$0-999':'&lt;999','&gt;$1,000,000':'1,000,000~','$500,000-999,999':'500,000-999,999'}) .replace(['1,000-1,999','2,000-2,999','3,000-3,999', '4,000-4,999','5,000-7,499','7,500-9,999','10,000-14,999', '15,000-19,999'],'1,000-19,999') .replace(['20,000-24,999','25,000-29,999','30,000-39,999', '40,000-49,999', '50,000-59,999'],'20,000-59,999') .replace(['60,000-69,999', '70,000-79,999', '80,000-89,999', '90,000-99,999'], '60,000-99,999') .replace(['100,000-124,999','125,000-149,999','150,000-199,999'],'100,000-199,999') .replace(['200,000-249,999', '250,000-299,999', '300,000-499,999','500,000-999,999', '1,000,000~'], '200,000~') #degree .replace({'I prefer not to answer':'etc'}) .replace(['No formal education past high school','Some college/university study without earning a bachelorâ€™s degree'],'~college') .replace(['Doctoral degree', 'Professional doctorate'],'Doctoral degree~') )sal_order= ['&lt;999', '1,000-19,999', '20,000-59,999', '60,000-99,999','100,000-199,999', '200,000~']dgree_order=[ '~college','Bachelorâ€™s degree', 'Masterâ€™s degree', 'Doctoral degree~', 'etc'] 3.2.1 Salary Annual salary of Research Scientist.The highest percentage of $2.6 million is 29.81%. The annual salary of Machine Learning Engineer.The highest rate of $999 is 31.89%. The annual salary of Data Scientist is..The ratio of $1,000 to $20,000 is the highest at 29.19%. â‡’ The higher the annual salary, the lower the overall job rate. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162df21_Ea_DS_= df21_Ea_DS.loc[:,['Q5','Q25']].reset_index().rename(columns={'Q5':'Data_Scientist', 'Q25':'Salary'}).fillna('etc')df21_Ea_DS_= (df21_Ea_DS_.groupby(['Data_Scientist', 'Salary']).size() .reset_index() .rename(columns = {0:&quot;Count&quot;}))#Data Scientistdf21_Ea_DS_Ds = df21_Ea_DS_[df21_Ea_DS_['Data_Scientist'] == &quot;Data Scientist&quot;].reset_index(drop = True)df21_Ea_DS_Ds['%']=((df21_Ea_DS_Ds['Count'] / df21_Ea_DS_Ds['Count'].sum())*100).round(2)#Machine Learning Engineerdf21_Ea_DS_Mle = df21_Ea_DS_[df21_Ea_DS_['Data_Scientist'] == &quot;Machine Learning Engineer&quot;].reset_index(drop = True)df21_Ea_DS_Mle['%']=((df21_Ea_DS_Mle['Count'] / df21_Ea_DS_Mle['Count'].sum())*100).round(2)#Research Scientistdf21_Ea_DS_Rs = df21_Ea_DS_[df21_Ea_DS_['Data_Scientist'] == &quot;Research Scientist&quot;].reset_index(drop = True)df21_Ea_DS_Rs['%']=((df21_Ea_DS_Rs['Count'] / df21_Ea_DS_Rs['Count'].sum())*100).round(2)df21_Ea_DS_Rsdf21_Ea_DS_salary = pd.concat([df21_Ea_DS_Ds, df21_Ea_DS_Mle, df21_Ea_DS_Rs], ignore_index = True)df21_Ea_DS_salary= pd.pivot(df21_Ea_DS_salary, index = &quot;Salary&quot;, columns = 'Data_Scientist', values = &quot;%&quot;).reset_index().fillna('0')df21_Ea_DS_salary= df21_Ea_DS_salary.set_index(&quot;Salary&quot;).reindex(sal_order)#graphfig = go.Figure()fig.add_trace(go.Bar(x = df21_Ea_DS_salary.index, y = df21_Ea_DS_salary['Data Scientist'], name = &quot;Data Scientist&quot;, text = df21_Ea_DS_salary['Data Scientist'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#F2798F'))fig.add_trace(go.Bar(x = df21_Ea_DS_salary.index, y = df21_Ea_DS_salary['Machine Learning Engineer'], name = &quot;Machine Learning Engineer&quot;, text = df21_Ea_DS_salary['Machine Learning Engineer'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#CDD9A3'))fig.add_trace(go.Bar(x = df21_Ea_DS_salary.index, y = df21_Ea_DS_salary['Research Scientist'], name = &quot;Research Scientist&quot;, text = df21_Ea_DS_salary['Research Scientist'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#88BFBA'))fig.update_layout(barmode='stack', showlegend=True, height=600, width=700, title_text=&quot;&lt;b&gt;Data Scientist's Salary in East Asia&lt;/b&gt;&quot;, title_x=0.5, title_font_size=20, margin=dict(l=100, r=100, t=100, b=100))fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{y}%&lt;br&gt;'+ '&lt;b&gt;Salary&lt;/b&gt;: %{x}$&lt;br&gt;')fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;v&quot;, yanchor=&quot;bottom&quot;, y=0.8, xanchor=&quot;right&quot;, x=1.2))fig.show() 3.2.2 Salary-Experience The correlation between the career of a Data Scientist and the annual salary. If you donâ€™t have experience, you have the highest rate of $999. Less than 1 year, 1-3 years have the highest percentage of $999. The highest percentage of $20,000 to $60,000 in 3-10 years. 10-20 years have the highest percentage of $60,000 to $100,000. 12345678910111213141516171819202122232425df21Ea_DS_ExSal = df21_Ea_DS.loc[:,['Q6','Q25']].reset_index().rename(columns={'Q25':'Salary', 'Q6':'Exp'}).fillna('etc')df21Ea_DS_ExSal= (df21Ea_DS_ExSal.groupby(['Exp', 'Salary']).size().unstack().fillna(0).astype('int64'))Exp_order=['&lt; 1 years','1-3 years','3-5 years', '5-10 years', '10-20 years', '20+ years', 'I have never written code']df21Ea_DS_ExSalz = df21Ea_DS_ExSalz = z[sal_order]z = z.reindex(Exp_order)z_data = z.apply(lambda x:np.round(x/x.sum()*100, 2), axis = 1).to_numpy() # convert to correlation matrixx = sal_ordery = Exp_orderfig = ff.create_annotated_heatmap(z_data, x = x, y = y, colorscale = &quot;sunset&quot;)fig.update_layout(title_text=&quot;&lt;b&gt; Data Scientist's Experience &amp; Salary &lt;/b&gt;&quot;,title_font_size=20, height=700, width=700, title_x=0.5, margin=dict(l=100, r=100, t=200, b=100))fig.update_traces(hovertemplate='&lt;b&gt;Salary&lt;/b&gt;: %{y}&lt;br&gt;'+ '&lt;b&gt;Experience&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Percent&lt;/b&gt;: %{z}%')fig.show() 3.2.3 Degree Comparison of educational background of Data Scientists. - It has the highest level of Master's Degrees. - Next, Doctoral Degree, - The figure was high in the order of Bachelor's Degree. 1234567891011121314151617181920212223df21_Ea_degree = df21_Ea_DS['Q4'].value_counts().to_frame()degree = df21_Ea_degree.indexvalues = df21_Ea_degree['Q4'].tolist()colors = ['#F2798F','#88BFBA', '#CDD9A3', '#F28705', '#D9946C']fig = go.Figure(data=[go.Bar(name='Degree', x=degree, y=values ,orientation='v', marker_color=colors, text=values, textposition='outside')])fig.update_layout(title_text=&quot;&lt;b&gt;Data Scientist's Degree (2021)&lt;/b&gt;&quot;, title_font_size=20, height=600, width=700, title_x=0.5, margin=dict(l=100, r=100, t=200, b=100))fig.update_traces(hovertemplate='&lt;b&gt;Count&lt;/b&gt;: %{y}&lt;br&gt;'+ '&lt;b&gt;Degree&lt;/b&gt;: %{x}&lt;br&gt;')fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 3.2.4 Salary-Degree Relationship between Data Scientist's academic background and annual salary. If your educational background is below college, Less than 999 dollars. The lowest annual salary accounts for the highest percentage. Bachelorâ€™s degree, Masterâ€™s Degree, Doctoral degree :$2~60,000 dollars accounts for a large proportion â‡’ The higher the education level, the higher the annual salary. 1234567891011121314151617181920212223242526272829303132df21Ea_DS_EduSal= df21_Ea_DS.loc[:, ['Q4', 'Q25']].rename(columns={'Q4':'Edu', 'Q25':'Salary'})df21Ea_DS_EduSal['Edu'].unique()Edu_order=['~college', 'Bachelorâ€™s degree','Masterâ€™s degree', 'Doctoral degree~', 'etc']df21Ea_DS_EduSal= (df21Ea_DS_EduSal.groupby(['Edu', 'Salary']).size().unstack().fillna(0).astype('int64'))df21Ea_DS_EduSalz = df21Ea_DS_EduSalz = z[sal_order]z = z.reindex(Edu_order)z_data = z.apply(lambda x:np.round(x/x.sum()*100, 2), axis = 1).to_numpy() # convert to correlation matrixx = sal_ordery = Edu_orderfig = ff.create_annotated_heatmap(z_data, x = x, y = y, colorscale = &quot;sunset&quot;)fig.update_layout(title_text=&quot;&lt;b&gt; Data Scientist's Degree &amp; Salary &lt;/b&gt;&quot;, title_font_size=20, height=700, width=700, title_x=0.5, margin=dict(l=150, r=100, t=200, b=50))fig.update_traces(hovertemplate='&lt;b&gt;Degree&lt;/b&gt;: %{y}&lt;br&gt;'+ '&lt;b&gt;Salary&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Percent&lt;/b&gt;: %{z}%')fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.1, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 3.2.5 Language The language that Data Scientist uses a lot. - Python accounts for the highest percentage of 80% or more. - Second, I use R the most. R is used less frequently in the order of 2019, 20, and 21. - From 19 to 21, the percentage of use rate of use 10% -> 4%, a total of 6% decrease. - The third most frequently used language is SQL. SQL increased 0.6 percent in 2020 from 2021. - The fourth most frequently used languages are C language and C++. â‡’ To become a Data Scientist, Let's study Python first! 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#data preprocessingdf20_Ea_DS = df20_Ea[df20_Ea['Q5'].isin(Data_Scientist)]df19_Ea_DS =df19_Ea[df19_Ea['Q5'].isin(Data_Scientist)]df19Ea_DSLag = df19_Ea_DS.loc[:, [ 'Q5', 'Q19', 'year']]df19Ea_DSLag = df19Ea_DSLag.rename(columns = {'Q19': 'Language'}, inplace = False) # To match with other datasetsdf20Ea_DSLag = df20_Ea_DS.loc[:, [ 'Q5', 'Q8', 'year']].rename(columns = {'Q8': 'Language'}, inplace = False)df21Ea_DSLag = df21_Ea_DS.loc[:, [ 'Q5', 'Q8', 'year']].rename(columns = {'Q8': 'Language'}, inplace = False)df3y_Ds_Lag = pd.concat([df19Ea_DSLag, df20Ea_DSLag, df21Ea_DSLag])df3y_Ds_Lag = df3y_Ds_Lag.groupby(['year', 'Language']).size().reset_index().rename(columns = {0:&quot;Count&quot;})df3y_Ds_Lag# 2019dfLang_Ds_19 = df3y_Ds_Lag[df3y_Ds_Lag['year'] == &quot;2019&quot;].reset_index(drop = True)dfLang_Ds_19['percentage'] = dfLang_Ds_19[&quot;Count&quot;] / dfLang_Ds_19[&quot;Count&quot;].sum()dfLang_Ds_19['%'] = np.round(dfLang_Ds_19['percentage'] * 100, 1)# 2020dfLang_Ds_20 = df3y_Ds_Lag[df3y_Ds_Lag['year'] == &quot;2020&quot;].reset_index(drop = True)dfLang_Ds_20['percentage'] = dfLang_Ds_20[&quot;Count&quot;] / dfLang_Ds_20[&quot;Count&quot;].sum()dfLang_Ds_20['%'] = np.round(dfLang_Ds_20['percentage'] * 100, 1)# 2021dfLang_Ds_21 = df3y_Ds_Lag[df3y_Ds_Lag['year'] == &quot;2021&quot;].reset_index(drop = True)dfLang_Ds_21['percentage'] = dfLang_Ds_21[&quot;Count&quot;] / dfLang_Ds_21[&quot;Count&quot;].sum()dfLang_Ds_21['%'] = np.round(dfLang_Ds_21['percentage'] * 100, 1)dfLang_Ds_19=dfLang_Ds_19.sort_values(by='%', ascending=False)dfLang_Ds_20=dfLang_Ds_20.sort_values(by='%', ascending=False)dfLang_Ds_21=dfLang_Ds_21.sort_values(by='%', ascending=False)#graphfig = go.Figure()fig.add_trace(go.Bar(x = dfLang_Ds_19['Language'], y = dfLang_Ds_19['%'], name = &quot;2019&quot;, text = dfLang_Ds_19['%'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#CDD9A3'))fig.add_trace(go.Bar(x = dfLang_Ds_20['Language'], y = dfLang_Ds_20['%'], name = &quot;2020&quot;, text = dfLang_Ds_20['%'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#F28705'))fig.add_trace(go.Bar(x = dfLang_Ds_21['Language'], y = dfLang_Ds_21['%'], name = &quot;2021&quot;, text = dfLang_Ds_21['%'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#88BFBA'))fig.update_layout(title='&lt;b&gt; The language used by the data scientist&lt;/b&gt;',title_font_size=22, margin = dict(t=120, l=100, r=10, b=150), height=600, width=700)fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{y}%&lt;br&gt;'+ '&lt;b&gt;Language&lt;/b&gt;: %{x}&lt;br&gt;')fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=0.8, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Parallel Categories Diagram : Visualization of multidimensional categorical datasets About 555 Data Scientist Jobs, Visualize it. The higher the height of the category, the more data is generated. It indicates that the frequency increases. 1234567891011121314151617181920ds_pc=(df21_Ea_DS.loc[:, ['Q5','Q25','Q6','Q4','Q8']] .replace({'I have never written code': '&lt; 1 years', '1-3 years': '1-2 years'}) .replace(['10-20 years', '20+ years'], '10+ years' ) .replace([0,'&lt;999']) )fig = px.parallel_categories(ds_pc, labels={'Q5':'Job', 'Q25':'Salary', 'Q6':'Experience', 'Q4':'Degree', 'Q8':'Language'})fig.update_layout(hovermode = 'x')fig.update_layout(title='&lt;b&gt; Data Scientist&lt;/b&gt;',title_font_size=20, margin = dict(t=120, l=100, r=10, b=150), height=600, width=700)fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() 4. Ref. Ref. ë™ì•„ì‹œì•„ ì§€ì—­ https://ko.wikipedia.org/wiki/%EB%8F%99%EC%95%84%EC%8B%9C%EC%95%84 ë™ì•„ì‹œì•„ ì¸êµ¬ https://ko.wikipedia.org/wiki/%EC%95%84%EC%8B%9C%EC%95%84%EC%9D%98_%EC%9D%B8%EA%B5%AC ì„¸ê³„ ì¸êµ¬ https://ko.wikipedia.org/wiki/%EC%84%B8%EA%B3%84_%EC%9D%B8%EA%B5%AC https://ko.wikipedia.org/wiki/%EC%9D%B8%EA%B0%84_%EA%B0%9C%EB%B0%9C_%EC%A7%80%EC%88%98#2020%EB%85%84 ë™ì•„ì‹œì•„ ì¸ê°„ê°œë°œì§€ìˆ˜ https://namu.wiki/w/%EB%8F%99%EC%95%84%EC%8B%9C%EC%95%84 Data Scientistë€ https://dataprofessional.tistory.com/126 https://terms.naver.com/entry.naver?docId=1691563&amp;cid=42171&amp;categoryId=42183 Kaggleì´ë€ https://ko.wikipedia.org/wiki/%EC%BA%90%EA%B8%80 Pythonì´ë€ https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%8D%AC Kaggle competition Ref. https://www.kaggle.com/miguelfzzz/the-typical-kaggle-data-scientist-in-2021 https://www.kaggle.com/desalegngeb/how-popular-is-kaggle-in-africa flaricon: Icons made by Freepik from www.flaticon.com 5. close ì•ˆë…•í•˜ì„¸ìš” í•œêµ­ì— ì‚¬ëŠ” YHì…ë‹ˆë‹¤. pythonì„ ë°°ìš´ì§€ í•œë‹¬ì´ ì±„ ì•ˆë˜ì„œ ëª…ì´ í•œ íŒ€ì´ ë˜ì–´ ì´ë²ˆ ëŒ€íšŒì— ì°¸ê°€ í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ë§ì´ ë¶€ì¡±í•˜ì§€ë§Œ ì—¬ê¸°ê¹Œì§€ ì½ì–´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ì•„ì§ì€ ë„ˆë¬´ë„ˆë¬´ ë¶€ì¡±í•œ ì œì¶œë¬¼ ì´ì§€ë§Œ, ì•ìœ¼ë¡œ ì—´ì‹¬íˆ í•´ì„œ ì¼€ê¸€ ëŒ€íšŒì—ì„œ 1ë“±í•˜ëŠ” ê·¸ ë‚ ê¹Œì§€ ì§€ì¼œë´ ì£¼ì„¸ìš” ^^! í˜¹ì‹œ ì½”ë©˜íŠ¸ë¡œ ë‹¤ ì „í•˜ì§€ ëª»í•˜ì…¨ë˜ ë§ì´ ìˆìœ¼ì‹œë‹¤ë©´, ì €ì˜ github blogì— ë°©ë¬¸í•˜ì—¬ ë„ì›€ì„ ì£¼ì„¸ìš”! ë³„ê±° ì—†ì§€ë§Œ ë†€ëŸ¬ì˜¤ì„¸ìš” ;-) Hello, Iâ€™m YH and I live in Korea.Less than a month after learning python, people became a team and participated in this competition. Itâ€™s not enough, but thank you for reading it up to here. Itâ€™s still not enough, but please watch until the day we win first place at the Kaggle competition ^^! If thereâ€™s anything you havenâ€™t said in the comments, please visit my github blog and help me! Itâ€™s nothing special, but come and play. ;-) ì•ˆë…•í•˜ì„¸ìš” ì €ëŠ” YHë‹˜ê³¼ ê°™ì´ Kaggle ëŒ€íšŒë¥¼ ì¤€ë¹„ í•œJW ì…ë‹ˆë‹¤. pythonì„ ì œëŒ€ë¡œ ë°°ìš°ì§€ë„ ëª»í•œì±„ë¡œ ë‚˜ì˜¤ê²Œ ëœ ëŒ€íšŒë¼ ì½”ë“œ ë¶€ë¶„ì—ì„œ ë¯¸ìˆ™í•œ ì ë„ ë§ê³  ì˜¤ë¥˜ë„ ë§ìŠµë‹ˆë‹¤! í•˜ì§€ë§Œ ëŒ€íšŒë¥¼ ì¶œì „í•˜ë©´ì„œ, pythonì— ëŒ€í•´ì„œ ë§ì€ ê³µë¶€ë„ ë˜ì—ˆê³ , ì¬ë¯¸ë„ ìˆì–´ì„œ ì¢‹ì€ ê¸°íšŒê°€ ë˜ì—ˆë˜ê²ƒ ê°™ìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” ì €ì˜ ê¹ƒí—ˆë¸Œ ì£¼ì†Œ ì…ë‹ˆë‹¤ ë°ì´í„° ê´€ë ¨ ë¶„ì•¼ì—ì„œ ì¼í•˜ì‹œëŠ” ë¶„ë“¤ì€ ì €ì—ê²Œ íŒ”ë¡œìš°ë¥¼ ê±¸ì–´ì£¼ì„¸ìš”! github Hello, Iâ€™m JW who prepared for the Kaggle competition with YH. Itâ€™s a competition where I didnâ€™t learn python properly, so Iâ€™m not good at codes. There are a lot of errors, too! However, as I participated in the competition, I studied a lot about Python and it was a good opportunity because it was fun. Below is my Git Hub address. For those who work in data-related fields, please follow me! github","link":"/2021/11/28/Newbies-as-a-Data-Scientist-in-EastAsia/"},{"title":"ì›í˜•ê·¸ë˜í”„(Pie)","text":"1-2. ì›í˜•ê·¸ë˜í”„ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ í•´ì£¼ê¸° 123456789import pandas as pd import numpy as npimport seaborn as snsimport plotly.express as pximport plotly.graph_objects as go#warning ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ì„œ ê²½ê³  ë©”ì„¸ì§€ ìˆ¨ê¸°ê¸°import warningswarnings.filterwarnings('ignore') ìºê¸€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° 12df = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv')df = df.iloc[1:, :] columnê°’ì´ Q2ì¸ ë°ì´í„° ì¶œë ¥ 1print(df['Q2']) .value_counts() .value_counts()dfì˜ â€˜Q2â€™ ì»¬ëŸ¼ì˜ ì¤‘ë³µëœ ë°ì´í„° ê°’ë“¤ì˜ ê°¯ìˆ˜ í‘œì‹œ 12print(df['Q2'].value_counts()) #Q1ì˜ ë°ì´í„° ê°’ì—ì„œ ì¤‘ë³µëœ ë°ì´í„° ê°’ë“¤ì˜ ê°¯ìˆ˜ë¥¼í‘œì‹œ gender .reset_index()ì¸ë±ìŠ¤ê°’ì„ ì¬ë°°ì—´ í•´ì£¼ëŠ” í•¨ìˆ˜ .rename(columns={â€˜indexâ€™:â€™Genderâ€™, â€˜Q2â€™:â€™Countâ€™})ì»¬ëŸ¼ëª… ë³€ê²½ replace(old, new, [count])ë¬¸ìì—´ ë³€ê²½ í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜old : í˜„ì¬ ë¬¸ìì—´ì—ì„œ ë³€ê²½í•˜ê³  ì‹¶ì€ ë¬¸ìnew: ìƒˆë¡œ ë°”ê¿€ ë¬¸ìcount: ë³€ê²½í•  íšŸìˆ˜ .replace([â€˜Prefer not to sayâ€™,â€™Nonbinaryâ€™,â€™Prefer to self-describeâ€™], â€˜Otherâ€™)countë¥¼ ì…ë ¥ì•ˆí–ˆì„ë•Œ ê¸°ë³¸ê°’ìŒ -1ë¡œ ì „ì²´ë¥¼ ì˜ë¯¸í•œë‹¤ 12345678910111213gender = ( df['Q2'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Gender', 'Q2':'Count'}) .replace(['Prefer not to say','Nonbinary','Prefer to self-describe'], 'Other') .replace(['Man','Woman'], ['Male', 'Female']) .groupby('Gender') .sum() .reset_index() ) print(gender) go.Pie fig = go.Figureê°ì²´ ì„ ì–¸ go.Pie()ì›í˜• ê·¸ë˜í”„ ê·¸ë¦¬ê¸° hole=.4ê°€ìš´ë° êµ¬ë© í¬ê¸° 123456colors = ['#5abbf9','#033351', 'b9e2fc']fig = go.Figure(data=[go.Pie(labels=gender['Gender'], values=gender['Count'], hole=.4)])fig.show() .update_traces hover dataí´ë¦­ê³¼ ë°˜ì‘í•˜ëŠ” ì¸í„°ë ‰í‹°ë¸Œ ê·¸ë˜í”„ë¥¼ êµ¬ì¶•ë°ì´í„°ì˜ ì„¸ë¶€ ì •ë³´ë¥¼ ì¶”ê°€ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” íŒì—… ì •ë³´ì°½ì¸ í˜¸ë²„ë§ë§ˆìš°ìŠ¤ ê°€ì ¸ë‹¤ ëŒ€ë©´ data ì •ë³´ë¥¼ ë³¼ ìˆ˜ ìˆë‹¤ hoverinfo = â€˜percentâ€™ë§ˆìš°ìŠ¤ë¥¼ ê·¸ë˜í”„ì— ê°€ì ¸ë‹¤ ëŒ€ë©´ í¼ì„¼íŠ¸ ê°’ìœ¼ë¡œ ë°ì´í„°ê°€ í‘œì‹œë¨ line=dict(color=â€™#000000â€™,width=1)í…Œë‘ë¦¬ ìƒ‰ìƒ ê°’, í…Œë‘ë¦¬ ë‘ê»˜ 123456fig.update_traces(hoverinfo='percent', textinfo='label', textfont_size=20, marker=dict(colors=colors, line=dict(color='#000000',width=1)))fig.show() .update_layout showlegend=Falseë²”ë¡€ ì œê±° í°íŠ¸ í¬ê¸°, ë„í‘œ ì œëª© ì„¤ì • ë“±ë“± 12345678fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', paper_bgcolor='#F7F7F7', title_text=&quot;&lt;b&gt;Gender&lt;/b&gt; Distrigution&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;,size =25, color='#000000'))fig.show() annotation annotationì£¼ì„ 1234567891011121314151617fig.add_annotation(dict(font=dict(size=14), x=1.1, y=-0.16, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=-0.28, y=-0.16, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() ì „ì²´ ì½”ë“œ ë‚¨ì„±ì€ ì „ì²´ì˜ 79%ë¡œ ì‘ë‹µìì˜ ëŒ€ë‹¤ìˆ˜ë¥¼ ì°¨ì§€í•œë‹¤ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950gender = ( df['Q2'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Gender', 'Q2':'Count'}) .replace(['Prefer not to say','Nonbinary','Prefer to self-describe'], 'Other') .replace(['Man','Woman'], ['Male', 'Female']) .groupby('Gender') .sum() .reset_index() ) colors = ['#5abbf9','#033351', 'b9e2fc']fig = go.Figure(data=[go.Pie(labels=gender['Gender'], values=gender['Count'], hole=.4)])fig.update_traces(hoverinfo='percent', textinfo='label', textfont_size=20, marker=dict(colors=colors, line=dict(color='#000000', width=1)))fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', paper_bgcolor='#F7F7F7', title_text=&quot;&lt;b&gt;Gender&lt;/b&gt; Distribution&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=25, color='#000000'))fig.add_annotation(dict(font=dict(size=14), x=1.1, y=-0.16, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=-0.28, y=-0.16, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()","link":"/2021/11/07/kaggle2-%EC%9B%90%ED%98%95%EA%B7%B8%EB%9E%98%ED%94%84/"},{"title":"ë§‰ëŒ€ê·¸ë˜í”„(forë¬¸, ìˆ˜í‰)","text":"3-2. ë§‰ëŒ€ê·¸ë˜í”„ (ìˆ˜í‰) ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ í•´ì£¼ê¸° &amp; ìºê¸€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ìƒëµ! startswith() ë©”ì†Œë“œëŠ” ì–´ë–¤ ë¬¸ìì—´ì´ íŠ¹ì • ë¬¸ìë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸í•˜ì—¬ ê²°ê³¼ë¥¼ true í˜¹ì€ falseë¡œ ë°˜í™˜í•©ë‹ˆë‹¤. python forë¬¸ ë¬¸ for ì¹´ìš´í„°ë³€ìˆ˜ in range(ë°˜ë³µíšŸìˆ˜): ë°˜ë³µí•´ì„œ ì‹¤í–‰í•  ëª…ë ¹ algorithms_cols = [col for col in df if col.startswith(â€˜Q17â€™)]ì²«ë²ˆì§¸ ì»¬ëŸ¼ë¶€í„° df ëê¹Œì§€ ë’¤ì˜ ifë¬¸ì´ ë°˜ë³µëœë‹¤ifë¬¸ì€ ì»¬ëŸ¼ ê°’ì´ ë¬¸ìì—´ Q17ë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸í•˜ì—¬ trueì¼ë•Œë§Œ ë°ì´í„° ê°€ì ¸ì˜¨ë‹¤ col(ë’¤)ì¹´ìš´í„° ë³€ìˆ˜ dfë°˜ë³µí•˜ëŠ” ë²”ìœ„ col(ì•) =&gt; List Comprehensionë°˜ë³µë¬¸ì¸ forë¬¸ì˜ ê²°ê³¼ê°’ì„ ë°›ì•„ì£¼ëŠ” ì—­í• ì„ í•œë‹¤ 123algorithms_cols = [col for col in df if col.startswith('Q17')]algorithms = df[algorithms_cols]print(algorithms) List Comprehensionì°¸ê³  ë¸”ë¡œê·¸ ë§í¬_1ì°¸ê³ ë§í¬ í‘œí˜„ì‹ë¦¬ìŠ¤íŠ¸ ì•ˆì— ì‹ forë¬¸ì„ ì§€ì •í•œë‹¤.[ì‹ for ë³€ìˆ˜ in ë¦¬ìŠ¤íŠ¸]list(ì‹ for ë³€ìˆ˜ in ë¦¬ìŠ¤íŠ¸) columns ì´ë¦„ ë°”ê¿”ì£¼ê¸° 12345algorithms.columns = ['Linear or Logistic Regression', 'Decision Trees or Random Forests', 'Gradient Boosting Machines', 'Bayesian Approaches', 'Evolutionary Approaches', 'Dense Neural Networks', 'Convolutional Neural Networks', 'Generative Adversarial Networks', 'Recurrent Neural Networks', 'Transformer Networks', 'None', 'Other']print(algorithms) algorithms ê°ì²´ ìƒì„± 123456789algorithms = ( algorithms .count() .to_frame() .reset_index() .rename(columns={'index':'Algorithms', 0:'Count'}) .sort_values(by=['Count'], ascending=False) )print(algorithms) percent ì»¬ëŸ¼ ì¶”ê°€ 12algorithms['percent'] = ((algorithms['Count'] / len(df))*100).round(2).astype(str) + '%'print(algorithms) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960colors = ['#033351',] * 12colors[0] = '#5abbf9'colors[1] = '#5abbf9'colors[2] = '#066eb0'colors[3] = '#066eb0'colors[4] = '#044a77'colors[5] = '#044a77'colors[6] = '#044a77'fig = go.Figure(go.Bar( x=algorithms['Count'], y=algorithms['Algorithms'], text=algorithms['percent'], orientation='h', marker_color=colors ))fig.update_traces(texttemplate='%{text}', textposition='outside', cliponaxis = False, hovertemplate='&lt;b&gt;Algorithm&lt;/b&gt;: %{y}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{x}', textfont_size=12) fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False) fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', margin=dict(pad=20), paper_bgcolor='#F7F7F7', xaxis={'showticklabels': False}, yaxis_title=None, height = 600, xaxis_title=None, yaxis={'categoryorder':'total ascending'}, title_text=&quot;Most Commonly Used &lt;b&gt;Algorithms&lt;/b&gt;&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=15, color='#000000'), title_font_size=35)fig.add_annotation(dict(font=dict(size=14), x=0.98, y=-0.17, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=0, y=-0.17, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()","link":"/2021/11/09/kaggle6-%EB%A7%89%EB%8C%80%EA%B7%B8%EB%9E%98%ED%94%84-for%EB%AC%B8/"},{"title":"ë§‰ëŒ€ê·¸ë˜í”„(Bar, ìˆ˜í‰)","text":"2. Education &amp; Occupation ì‘ë‹µìì˜ 77% ì´ìƒì´ í•™ì‚¬ ë°/ë˜ëŠ” ì„ì‚¬ í•™ìœ„ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. 2-1. ë§‰ëŒ€ê·¸ë˜í”„(ìˆ˜í‰)ìºê¸€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° 1234567891011121314151617# This Python 3 environment comes with many helpful analytics libraries installed# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python# For example, here's several helpful packages to loadimport numpy as np # linear algebraimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)# Input data files are available in the read-only &quot;../input/&quot; directory# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directoryimport osfor dirname, _, filenames in os.walk('/kaggle/input'): for filename in filenames: print(os.path.join(dirname, filename))# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using &quot;Save &amp; Run All&quot; # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ í•´ì£¼ê¸° import plotly.express as px import plotly.graph_objects as go PlotlyëŠ” ê·¸ë˜í”„ë¥¼ ë§Œë“œëŠ”ë°ì—ëŠ” ë‘ê°€ì§€ ë°©ë²•ì´ ìˆë‹¤ pxexpressì˜ ì¤„ì„ìœ¼ë¡œë¹ ë¥´ê²Œ ê·¸ë˜í”„ë¥¼ ì œì‘ goê·¸ë˜í”„ë¥¼ í•˜ë‚˜í•˜ë‚˜ ì„¤ì •í•˜ì—¬ ì œì‘ 123456789import pandas as pd import numpy as npimport seaborn as snsimport plotly.express as pximport plotly.graph_objects as go#warning ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ì„œ ê²½ê³  ë©”ì„¸ì§€ ìˆ¨ê¸°ê¸°import warningswarnings.filterwarnings('ignore') 123df = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv')df = df.iloc[1:, :] print(df) dataframe ìƒì„± educationeducationì´ë¼ëŠ” ë°ì´í„° í”„ë ˆì„ì„ ë§Œë“¤ì–´ì¤Œì»¬ëŸ¼ ê°’ìœ¼ë¡œ Q4ì˜ ë°ì´í„° ê°’ì„ ê°€ì¡ŒìŒ .value_counts()Q4ì˜ ì»¬ëŸ¼ì˜ ì¤‘ë³µëœ ë°ì´í„° ê°’ë“¤ì˜ ê°¯ìˆ˜ í‘œì‹œ .to_frame()ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜ .reset_index()ì»¬ëŸ¼ëª… ì¸ë±ìŠ¤ê°€ ì•„ë‹Œ í–‰ ë²ˆí˜¸ ì¸ë±ìŠ¤(ìˆ«ì)ë¥¼ ì‚¬ìš©í•˜ê³  ì‹¶ì„ë•Œ ì‚¬ìš©ë°‘ì˜ ì˜ˆì‹œ ì°¸ê³ . replace(old, new, [count])ë¬¸ìì—´ ë³€ê²½ í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜old : í˜„ì¬ ë¬¸ìì—´ì—ì„œ ë³€ê²½í•˜ê³  ì‹¶ì€ ë¬¸ìnew: ìƒˆë¡œ ë°”ê¿€ ë¬¸ìcount: ë³€ê²½í•  íšŸìˆ˜ 1print(df['Q4']) 1print(df['Q4'].value_counts()) 1234567891011education = ( df['Q4'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Education', 'Q4':'Count'}) .replace(['Some college/university study without earning a bachelorâ€™s degree'], 'University studies - No degree') ) education['percent'] = ((education['Count'] / education['Count'].sum())*100).round(2).astype(str) + '%'print(education) colors ìƒ‰ìƒì˜ ë²”ìœ„ë¥¼ ì •í•´ì¤Œ 12345colors = ['#033351',] * 7 #ë‚¨ìƒ‰colors[0] = '#5abbf9' #ë§¨ìœ„ì˜ ìƒ‰ í•˜ëŠ˜ìƒ‰colors[1] = '#5abbf9'colors[2] = '#0779c3' #ì§„í•˜ëŠ˜ìƒ‰colors[3] = '#0779c3' go.figure x=education[â€˜Countâ€™]education ì»¬ëŸ¼ Countì˜ data ê°’ì„ xì¶•ì— ëŒ€ì… y=education[â€˜Educationâ€™]education ì»¬ëŸ¼ Educationì˜ data ê°’ì„y ì¶•ì— ëŒ€ì… text=education[â€˜percentâ€™]ë¬¸ìì—´ì„ ì¶”ê°€í•´ì¤Œì´ë•Œ education ë°ì´í„°í”„ë ˆì„ì˜ ì»¬ëŸ¼ percentì˜ ë°ì´í„° ê°’ì„ ì¶”ê°€í•¨ orientation=â€™hâ€™hëŠ” horizontal barì„ ì˜ë¯¸í•œë‹¤.ì´ ë¬¸ì¥ì„ ì…ë ¥í•˜ì§€ ì•Šì„ë•Œ ìˆ˜í‰ ë°”ê°€ ë§Œë“¤ì–´ì§€ì§€ ì•ŠëŠ”ë‹¤ marker_color=colorsìœ„ì— ì •ì˜í•´ì¤€ colors ê°’ìœ¼ë¡œ ê·¸ë˜í”„ë¥¼ ë‹¤ë¥¸ ìƒ‰ìœ¼ë¡œ í‘œí˜„í•¨ 12345678fig = go.Figure(go.Bar( x = education['Count'], y = education['Education'], text = education['percent'], orientation = 'h', marker_color = colors ))fig.show() orientation=â€™hâ€™ê°€ ì—†ì„ë•Œ 1234567fig = go.Figure(go.Bar( x=education['Count'], y=education['Education'], text=education['percent'], marker_color=colors ))fig.show() update_traces() ì—¬ëŸ¬ê°€ì§€ ê·¸ë˜í”„ë¥¼ í•œë²ˆì— ì—…ë°ì´íŠ¸ í•  ìˆ˜ ìˆë‹¤ì˜ˆë¥¼ë“¤ë©´ Scatter(), bar()ë¥¼ ë™ì‹œì— í¬í•¨í•  ìˆ˜ ìˆë‹¤ 123456789fig.update_traces(texttemplate='%{text}', textposition='outside', cliponaxis = False, hovertemplate='&lt;b&gt;Education&lt;/b&gt;: %{y}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{x}', textfont_size=12) fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False) .update_layout() 123456789101112fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', margin=dict(pad=20), paper_bgcolor='#F7F7F7', xaxis={'showticklabels': False}, yaxis_title=None, xaxis_title=None, yaxis={'categoryorder':'total ascending'}, title_text=&quot;&lt;b&gt;Education&lt;/b&gt; Distribution&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=15, color='#000000'), title_font_size=35) annotation 12345678910111213141516171819fig.add_annotation(dict(font=dict(size=14), x=0.98, y=-0.21, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=0, y=-0.21, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() ì „ì²´ì½”ë“œ1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768education = ( df['Q4'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Education', 'Q4':'Count'}) .replace(['Some college/university study without earning a bachelorâ€™s degree'], 'University studies - No degree') ) education['percent'] = ((education['Count'] / education['Count'].sum())*100).round(2).astype(str) + '%'colors = ['#033351',]*7colors[0] = '#5abbf9'colors[1] = '#5abbf9'colors[2] = '#0779c3'colors[3] = '#0779c3'fig = go.Figure(go.Bar( x=education['Count'], y=education['Education'], text=education['percent'], orientation='h', marker_color=colors ))fig.update_traces(texttemplate='%{text}', textposition='outside', cliponaxis = False, hovertemplate='&lt;b&gt;Education&lt;/b&gt;: %{y}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{x}', textfont_size=12) fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False) fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', margin=dict(pad=20), paper_bgcolor='#F7F7F7', xaxis={'showticklabels': False}, yaxis_title=None, xaxis_title=None, yaxis={'categoryorder':'total ascending'}, title_text=&quot;&lt;b&gt;Education&lt;/b&gt; Distribution&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=15, color='#000000'), title_font_size=35)fig.add_annotation(dict(font=dict(size=14), x=0.98, y=-0.21, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=0, y=-0.21, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()","link":"/2021/11/08/kaggle4-%EB%A7%89%EB%8C%80%EA%B7%B8%EB%9E%98%ED%94%84-%EC%88%98%ED%8F%89/"},{"title":"treemap","text":"1234567891011121314151617# This Python 3 environment comes with many helpful analytics libraries installed# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python# For example, here's several helpful packages to loadimport numpy as np # linear algebraimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)# Input data files are available in the read-only &quot;../input/&quot; directory# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directoryimport osfor dirname, _, filenames in os.walk('/kaggle/input'): for filename in filenames: print(os.path.join(dirname, filename))# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using &quot;Save &amp; Run All&quot; # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session 1234567891011import pandas as pdimport numpy as npimport seaborn as snsimport plotly.express as pximport plotly.graph_objects as goimport warningswarnings.filterwarnings('ignore') df = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv')df = df.iloc[1:, :] 3-4 Treemap recommend_leng ê°ì²´ ìƒì„± 123456789recommend_leng = ( df['Q8'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'Lenguage', 'Q8':'Count'}) .sort_values(by=['Count'], ascending=False) ) print(recommend_leng) color 123456colors = ['#033351',] * 13colors[0] = '#5abbf9'colors[1] = '#066eb0'colors[2] = '#044a77'colors[3] = '#043e64'colors[4] = '#043e64' Treemapì°¸ê³ ì‚¬ì´íŠ¸íŠ¸ë¦¬ë§µ ì°¨íŠ¸ëŠ” ë‚´í¬ëœ ì§ì‚¬ê°í˜•ì„ ì‚¬ìš©í•˜ì—¬ ê³„ì¸µì  ë°ì´í„°ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.ê³„ì¸µ êµ¬ì¡°ëŠ” ë ˆì´ë¸”(px.tremapì˜ ì´ë¦„) ë° ìƒìœ„ ì†ì„±ì— ì˜í•´ ì •ì˜ë©ë‹ˆë‹¤. labels = recommend_leng[â€˜Lenguageâ€™]labelsê°’ values = recommend_leng[â€˜Countâ€™]valuesê°’ parents = [â€˜â€™]*recommend_leng.shape[0]treemapì˜ ê³„ì¸µì„ ë”°ë¡œ ë§Œë“¤ì–´ ì£¼ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì—recommend_leng.shape[0] ìœ¼ë¡œ ì •í•´ì¤ë‹ˆë‹¤. 1234567fig = go.Figure(go.Treemap( labels = recommend_leng['Lenguage'], values = recommend_leng['Count'], parents = ['']*recommend_leng.shape[0], textinfo = &quot;percent root+label+value+text&quot;,))fig.show() ë‚˜ë¨¸ì§€ ì½”ë“œ treemapcolorway = colorstreemap ì»¬ëŸ¬ ì§€ì • 12345678910111213141516171819202122232425262728293031323334353637fig.update_traces(hovertemplate='&lt;b&gt;Lenguage&lt;/b&gt;: %{label}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{value}') fig.update_layout(showlegend=False, treemapcolorway = colors, margin=dict(pad=20), paper_bgcolor='#F7F7F7', plot_bgcolor='#F7F7F7', height=600, yaxis={'showticklabels': False}, yaxis_title=None, xaxis_title=None, title_text=&quot;Most Recommended &lt;b&gt;Programming Language&lt;/b&gt;&quot;, title_x=0.5, title_y=0.95, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=17, color='#000000'), title_font_size=35)fig.add_annotation(dict(font=dict(size=14), x=0.96, y=-0.14, showarrow=False, text=&quot;@miguelfzzz&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.add_annotation(dict(font=dict(size=12), x=0.01, y=-0.14, showarrow=False, text=&quot;Source: 2021 Kaggle Machine Learning &amp; Data Science Survey&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()","link":"/2021/11/09/kaggle7-treemap/"},{"title":"Kaggle Competition(2)","text":"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸° &amp; ìºê¸€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° 1234567891011121314151617181920212223import numpy as npimport pandas as pdimport seaborn as snsimport matplotlib.pylab as pltimport plotly.io as pioimport plotly.express as pximport plotly.graph_objects as goimport plotly.figure_factory as fffrom plotly.subplots import make_subplotsfrom plotly.offline import init_notebook_mode, iplotinit_notebook_mode(connected=True)pio.templates.default = &quot;none&quot;# import plotly.offline as py# py.offline.init_notebook_mode()import osfor dirname, _, filenames in os.walk('/kaggle/input'): for filename in filenames: print(os.path.join(dirname, filename))import warningswarnings.filterwarnings(&quot;ignore&quot;) 12345df17= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2017/multipleChoiceResponses.csv&quot;, encoding=&quot;ISO-8859-1&quot;)df18= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2018/multipleChoiceResponses.csv&quot;, )df19= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2019/multiple_choice_responses.csv&quot;, )df20= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2020/kaggle_survey_2020_responses.csv&quot;, )df21= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2021/kaggle_survey_2021_responses.csv&quot;, ) ë°ì´í„° Grouping 12345678910111213141516171819202122232425262728293031323334353637383940## East Asiaì—ëŠ” ëŒ€í•œë¯¼êµ­, ì¼ë³¸, ì¤‘êµ­, íƒ€ì´ì™„, ëª½ê³¨, ë¶ì¡°ì„  ì´ 6ê°œì˜ êµ­ê°€ê°€ ì†í•´ ìˆë‹¤. EastAsia17 = ['China',&quot;People 's Republic of China&quot;, 'Taiwan', 'South Korea', 'Japan']EastAsia18 = ['China', 'South Korea', 'Japan', 'Republic of Korea'] EastAsia19 = ['China','Taiwan', 'South Korea', 'Japan', 'Republic of Korea']EastAsia20 = ['China','Taiwan', 'South Korea', 'Japan', 'Republic of Korea']EastAsia21 = ['China','Taiwan', 'South Korea', 'Japan']EastAsia = ['Republic of Korea','China','Taiwan', 'South Korea', 'Japan', &quot;People 's Republic of China&quot; ]#21ë…„df21_Ea = df21[df21['Q3'].isin(EastAsia)]df21_Wo = df21[~df21['Q3'].isin(EastAsia )]## ë™ì•„ì‹œì•„ êµ­ê°€ë¥¼ ì œì™¸í•œ êµ­ê°€ë“¤ì„ region ì—´ì˜ ë°ì´í„° ê°’ì„ World ë¡œ ë°”ê¿”ì¤Œdf21['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df21['Q3']]#20ë…„df20_Ea = df20[df20['Q3'].isin(EastAsia)]df20_Wo = df20[~df20['Q3'].isin(EastAsia )]df20['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df20['Q3']]#19ë…„df19_Ea = df19[df19['Q3'].isin(EastAsia)]df19_Wo = df19[~df19['Q3'].isin(EastAsia )]df19['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df19['Q3']]#18ë…„df18_Ea = df18[df18['Q3'].isin(EastAsia)]df18_Wo = df18[~df18['Q3'].isin(EastAsia )]df18['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df18['Q3']]#17ë…„df17_Ea = df17[df17['Country'].isin(EastAsia)]df17_Wo = df17[~df17['Country'].isin(EastAsia )]df17['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df17['Country']] Stack Bar ê·¸ë˜í”„ ë°ì´í„° ì „ì²˜ë¦¬1 ì—°ë„ë³„ë¡œ ë°ì´í„° ì •ë¦¬ í–ˆìŒ 12df21_Ea=df21[df21['Q3'].isin(EastAsia21)]df21_Ea['Q3'].value_counts().to_frame().reset_index().rename(columns={'index':'Country', 'Q3':'21_n'}) 12df20_Ea=df20[df20['Q3'].isin(EastAsia20)]df20_Ea['Q3'].replace('Republic of Korea','South Korea').value_counts().to_frame().reset_index().rename(columns={'index':'Country', 'Q3':'20_n'}) 12df19_Ea=df19[df19['Q3'].isin(EastAsia19)]df19_Ea['Q3'].replace('Republic of Korea','South Korea').value_counts().to_frame().reset_index().rename(columns={'index':'Country', 'Q3':'19_n'}) append() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•´ì„œ Taiwan = 0 ê°’ ì¶”ê°€í•´ì¤Œ ignore_index=True ì›ë˜ ìˆë˜ dfì˜ indexë¥¼ ë¬´ì‹œ12df18_Ea=df18[df18['Q3'].isin(EastAsia18)]df18_Ea['Q3'].replace('Republic of Korea','South Korea').value_counts().to_frame().reset_index().append({'index': 'Taiwan','Q3':'0'}, ignore_index=True).rename(columns={'index':'Country', 'Q3':'18_n'}) 12df17_Ea = df17[df17['Country'].isin(EastAsia)]df17_Ea['Country'].replace(&quot;People 's Republic of China&quot;,&quot;China&quot;).value_counts().to_frame().reset_index().rename(columns={'index':'Country', 'Country':'17_n'}) Stack Bar ê·¸ë˜í”„ ë°ì´í„° ì „ì²˜ë¦¬2 18ë…„ë„ Taiwan ë°ì´í„° ê°’ì´ ì—†ìŒ iloc: ë°ì´í„°í”„ë ˆì„ì˜ í–‰ì´ë‚˜ ì»¬ëŸ¼ì— ì¸ë±ìŠ¤ ê°’ìœ¼ë¡œ ì ‘ê·¼ loc: ë°ì´í„°í”„ë ˆì„ì˜ í–‰ì´ë‚˜ ì»¬ëŸ¼ì— labelì´ë‚˜ boolean arrayë¡œ ì ‘ê·¼ (locationì˜ ì•½ì) ìœ„ì— ì „ì²˜ë¦¬ ë‚´ìš©ì„ ì•„ë˜ ê·¸ë˜í”„ì— ë§ê²Œ ë” ë‹¤ë“¬ì–´ ì •ë¦¬í•˜ì˜€ë‹¤ 1234567891011121314df17_Ea = df17[df17['Country'].isin(EastAsia)]df17_StackB = df17_Ea['Country'].replace(&quot;People 's Republic of China&quot;,&quot;China&quot;).value_counts().to_frame().reset_index()df18_Ea = df18[df18['Q3'].isin(EastAsia18)]df18_StackB = df18_Ea['Q3'].replace('Republic of Korea','South Korea').value_counts().to_frame().reset_index().append({'index': 'Taiwan','Q3':'0'}, ignore_index=True)df19_Ea = df19[df19['Q3'].isin(EastAsia19)]df19_StackB = df19_Ea['Q3'].replace('Republic of Korea','South Korea').value_counts().to_frame().reset_index()df20_Ea = df20[df20['Q3'].isin(EastAsia20)]df20_StackB = df20_Ea['Q3'].replace('Republic of Korea','South Korea').value_counts().to_frame().reset_index()df21_Ea = df21[df21['Q3'].isin(EastAsia21)]df21_StackB = df21_Ea['Q3'].value_counts().to_frame().reset_index() barmode =â€™stackâ€™Bar ê·¸ë˜í”„ë¥¼ stack í˜•ì‹ìœ¼ë¡œ ìŒ“ì•„ì„œ í‘œí˜„í•˜ì˜€ë‹¤ 12345678910111213fig = go.Figure(data=[ go.Bar(name='China', x=years, y=[df17_StackB.iloc[0,1], df18_StackB.iloc[0,1], df19_StackB.iloc[1,1], df20_StackB.iloc[1,1], df21_StackB.iloc[1,1]]), go.Bar(name='Japan', x=years, y=[df17_StackB.iloc[1,1], df18_StackB.iloc[1,1], df19_StackB.iloc[0,1], df20_StackB.iloc[0,1], df21_StackB.iloc[0,1]]), go.Bar(name='Taiwan', x=years, y=[df17_StackB.iloc[2,1], df18_StackB.iloc[3,1], df19_StackB.iloc[2,1], df20_StackB.iloc[2,1], df21_StackB.iloc[3,1]]), go.Bar(name='South Korea', x=years, y=[df17_StackB.iloc[3,1], df18_StackB.iloc[2,1], df19_StackB.iloc[3,1], df20_StackB.iloc[3,1], df21_StackB.iloc[2,1]]) ])fig.update_layout(barmode ='stack')fig.show() Pie ê·¸ë˜í”„ë°ì´í„° ì „ì²˜ë¦¬ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051fig = make_subplots(rows=1, cols=5)total17 = ( df17['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index())total18 = ( df18['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index())total19 = ( df19['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index())total20 = ( df20['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index())total21 = ( df21['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index()) Pie ê·¸ë˜í”„ ê·¸ë¦¬ê¸° scalegroup=â€™oneâ€™ì› ê·¸ë˜í”„ì˜ ìì²´ ì‚¬ì´ì¦ˆë¥¼ ë³€ê²½ í•  ìˆ˜ ìˆë‹¤.12345678910111213141516171819fig = make_subplots(rows=1, cols=5, specs=[[{'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}]])fig.add_trace(go.Pie(labels=total21['type'], values=total21['respodents'], name=&quot;2021&quot;, scalegroup='one'), 1, 1)fig.add_trace(go.Pie(labels=total20['type'], values=total20['respodents'], name=&quot;2020&quot;, scalegroup='one'), 1, 2)fig.add_trace(go.Pie(labels=total19['type'], values=total19['respodents'], name=&quot;2019&quot;, scalegroup='one'), 1, 3)fig.add_trace(go.Pie(labels=total18['type'], values=total18['respodents'], name=&quot;2018&quot;, scalegroup='one'), 1, 4)fig.add_trace(go.Pie(labels=total17['type'], values=total17['respodents'], name=&quot;2017&quot;, scalegroup='one'), 1, 5)fig.update_traces(hole=.2, hoverinfo=&quot;label+percent+name&quot;)fig.update_layout( title_text=&quot;&lt;b&gt;World vs EastAsia&lt;/b&gt;&quot;, )fig.show() ëŠë‚€ì  ê·¸ë˜í”„ ê·¸ë¦¬ëŠ”ê²ƒë³´ë‹¤ë°ì´í„° ì „ì²˜ë¦¬ê°€ ë” í˜ë“ ê²ƒ ê°™ë‹¤..ê·¸ë˜ë„ ì´ë²ˆì— ì§ì ‘ í•´ë³´ë©´ì„œí—·ê°ˆë ¸ë˜ ë¬¸ë²•ë“¤ì„ ë‹¤ì‹œ ì •ë¦¬í• ìˆ˜ ìˆì—ˆê³ ì˜ë¯¸ë¥¼ ì™„ë²½í•˜ê²Œ ìµí˜”ê³  ì–´ëŠì •ë„ ê°ì´ ì¡í˜”ìŒì„ ëŠê¼ˆë‹¤. ë‚´ì¼ë„ ë” ì—´ì‹¬íˆâ€¦ Ref https://plotly.com/python/pie-charts/","link":"/2021/11/15/mykaggle2/"},{"title":"Kaggle Competition(1)","text":"ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤í–‰í™˜ê²½: kaggle notebookì‚¬ìš©ì–¸ì–´: Python Plotlyì¤€ë¹„í•˜ëŠ” kaggle competition ë§í¬ 1234567891011121314151617181920212223import numpy as npimport pandas as pdimport seaborn as snsimport matplotlib.pylab as pltimport plotly.io as pioimport plotly.express as pximport plotly.graph_objects as goimport plotly.figure_factory as fffrom plotly.subplots import make_subplotsfrom plotly.offline import init_notebook_mode, iplotinit_notebook_mode(connected=True)pio.templates.default = &quot;none&quot;# import plotly.offline as py# py.offline.init_notebook_mode()import osfor dirname, _, filenames in os.walk('/kaggle/input'): for filename in filenames: print(os.path.join(dirname, filename))import warningswarnings.filterwarnings(&quot;ignore&quot;) 17ë…„ - 21ë…„ë„ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° 12345df17= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2017/multipleChoiceResponses.csv&quot;, encoding=&quot;ISO-8859-1&quot;)df18= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2018/multipleChoiceResponses.csv&quot;, )df19= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2019/multiple_choice_responses.csv&quot;, )df20= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2020/kaggle_survey_2020_responses.csv&quot;, )df21= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2021/kaggle_survey_2021_responses.csv&quot;, ) ë°ì´í„° ì „ì²˜ë¦¬ 123#21ë…„ë„ì— ì„¤ë¬¸ì¡°ì‚¬ì— ì°¸ì—¬í•œ êµ­ê°€ë“¤pd.set_option('display.max_rows', None)df21['Q3'].value_counts().sort_index(ascending=True) 123#South Koreaì— í•´ë‹¹í•˜ëŠ” ì°¸ì—¬ìë§Œ ì¶œë ¥df21_Ko = df21[df21['Q3'] == 'South Korea']df21_Ko.head() 123#í•œêµ­ì„ ì œì™¸í•œ ì°¸ì—¬ìë“¤ì˜ íˆ¬í‘œê²°ê³¼df21_Wo = df21[~(df21['Q3'] == 'South Korea')]df21_Wo.head() 1234567891011## ì„¤ë¬¸ì¡°ì‚¬ì— ì°¸ì—¬í•œ ì‚¬ëŒ ë¹„ìœ¨#í•œêµ­df21_Ko = df21[df21['Q3'] == 'South Korea']#ì „ì„¸ê³„df21_Wo = df21[~(df21['Q3'] == 'South Korea')]#ë™ì•„ì‹œì•„ë¥¼ ì œì™¸í•œ êµ­ê°€ëŠ” ì „ë¶€ ê±°ì£¼ì§€ì—­ì„ Worldë¡œ ë°”ê¿ˆdf21['region']=[&quot;Korea&quot; if x == 'South Korea' else &quot;World&quot; for x in df21['Q3']]df21['region'].value_counts() 12345678## if ë³€ìˆ˜ x ê°€ South Korea ì¼ë•Œ## else -&gt; South Koreaê°€ ì•„ë‹ë•Œ## xê°€ 0ë¶€í„° df21['Q3']ì˜ í–‰ê°’ì„ ì°¨ë¡€ë¡œ Worldê°’ì„ ë„£ëŠ”ë‹¤ #### ì´ ê²°ê³¼ë¥¼ df['region'] ì— ë„£ëŠ”ë‹¤## ë”°ë¼ì„œ ë™ì•„ì‹œì•„ê°€ ì•„ë‹Œ êµ­ê°€ë“¤ì˜ í–‰ ê°’ì€ ì „ë¶€ Worldë¡œ ë°”ë€œdf21['region']=[&quot;Korea&quot; if x == 'South Korea' else &quot;World&quot; for x in df21['Q3']]df21['region'].head() ë°ì´í„° Grouping ì—°ë„ë³„ EastAsia êµ­ê°€ ì •ë¦¬EastAsia17EastAsia18EastAsia19EastAsia20EastAsia21 ì—°ë„ë³„ ì •ë¦¬df21_Ea : ë™ì•„ì‹œì•„ êµ­ê°€ë§Œ ë°ì´í„°df21_Wo : ë™ì•„ì‹œì•„ ì œì™¸í•œ ì „ì„¸ê³„ êµ­ê°€ ë°ì´í„°df21[â€˜regionâ€™] : ë™ì•„ì‹œì•„ë¥¼ ì œì™¸í•œ êµ­ê°€ëŠ” Worldë¡œ ì €ì¥ë¨ (Worldë‘ ë™ì•„ì‹œì•„êµ­ê°€ ì´ë¦„ë°–ì— ì—†ìŒ) isin()df21ì˜ Q3ì—´ì— EastAsiaì˜ ë¦¬ìŠ¤íŠ¸ê°’ê³¼ ë™ì¼í•œê²Œ ìˆì„ë•Œ True , ì—†ìœ¼ë©´ False 12345678910111213141516171819202122232425262728293031323334353637383940## East Asiaì—ëŠ” ëŒ€í•œë¯¼êµ­, ì¼ë³¸, ì¤‘êµ­, íƒ€ì´ì™„, ëª½ê³¨, ë¶ì¡°ì„  ì´ 6ê°œì˜ êµ­ê°€ê°€ ì†í•´ ìˆë‹¤. EastAsia17 = ['China',&quot;People 's Republic of China&quot;, 'Taiwan', 'South Korea', 'Japan']EastAsia18 = ['China', 'South Korea', 'Japan', 'Republic of Korea'] EastAsia19 = ['China','Taiwan', 'South Korea', 'Japan', 'Republic of Korea']EastAsia20 = ['China','Taiwan', 'South Korea', 'Japan', 'Republic of Korea']EastAsia21 = ['China','Taiwan', 'South Korea', 'Japan']EastAsia = ['Republic of Korea','China','Taiwan', 'South Korea', 'Japan', &quot;People 's Republic of China&quot; ]#21ë…„df21_Ea = df21[df21['Q3'].isin(EastAsia)]df21_Wo = df21[~df21['Q3'].isin(EastAsia )]## ë™ì•„ì‹œì•„ êµ­ê°€ë¥¼ ì œì™¸í•œ êµ­ê°€ë“¤ì„ region ì—´ì˜ ë°ì´í„° ê°’ì„ World ë¡œ ë°”ê¿”ì¤Œdf21['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df21['Q3']]#20ë…„df20_Ea = df20[df20['Q3'].isin(EastAsia)]df20_Wo = df20[~df20['Q3'].isin(EastAsia )]df20['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df20['Q3']]#19ë…„df19_Ea = df19[df19['Q3'].isin(EastAsia)]df19_Wo = df19[~df19['Q3'].isin(EastAsia )]df19['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df19['Q3']]#18ë…„df18_Ea = df18[df18['Q3'].isin(EastAsia)]df18_Wo = df18[~df18['Q3'].isin(EastAsia )]df18['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df18['Q3']]#17ë…„df17_Ea = df17[df17['Country'].isin(EastAsia)]df17_Wo = df17[~df17['Country'].isin(EastAsia )]df17['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df17['Country']] 12## ë§ˆì§€ë§‰ ì—´ì— regionì´ ì¶”ê°€ëœ ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆìŒdf21.head() 12345df21['region'].value_counts()##df20['region'].value_counts()##df19['region'].value_counts()##df18['region'].value_counts()##df17['region'].value_counts() Bar ê·¸ë˜í”„ ìƒì„±ì—°ë„ë³„ kaggle ì‚¬ìš©ì (ì „ì„¸ê³„ vs ë™ì•„ì‹œì•„) 1234567891011121314151617181920212223242526272829# ì„¤ë¬¸ ì°¸ì—¬ì ì´ ì¸ì›Ea21 = len(df21_Ea)Wo21 = len(df21) - len(df21_Ea)Ea20 = len(df20_Ea)Wo20 = len(df20) - len(df20_Ea)Ea19 = len(df19_Ea)Wo19 = len(df19) - len(df19_Ea)Ea18 = len(df18_Ea)Wo18 = len(df18) - len(df18_Ea)Ea17 = len(df17_Ea)Wo17 = len(df17) - len(df17_Ea)# í¼ì„¼íŠ¸ í•¨ìˆ˜ ë§Œë“¤ì–´ì¤Œ# percent, percentRdef percent (a, b): result =a/(a+b)*100 return resultdef percentR (b, a): result =a/(a+b)*100 return resultcountry = ['East Asia', 'Rest of the World']years = ['2017', '2018', '2019', '2020', '2021'] 123456789fig = go.Figure(data=[ go.Bar(name='Rest of the World', x=years, y=[percentR(Ea17, Wo17), percentR(Ea18, Wo18), percentR(Ea19, Wo19), percentR(Ea20, Wo20), percentR(Ea21, Wo21)]), go.Bar(name='East Asia', x=years, y=[percent(Ea17, Wo17), percent(Ea18, Wo18), percent(Ea19, Wo19), percent(Ea20, Wo20), percent(Ea21, Wo21)])])fig.update_layout(barmode='stack')fig.show() barmode =â€™stackâ€™ ì´ê±° ì œê±°í•˜ë©´ ê·¸ë˜í”„ê°€ ë‚˜ë€íˆ ë‚˜ì˜¨ë‹¤Pie ê·¸ë˜í”„ ìƒì„±ì—°ë„ë³„ kaggle ì‚¬ìš©ì (ì „ì„¸ê³„ vs ë™ì•„ì‹œì•„) 1234567891011total = ( df21['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index() )total 12345678910111213141516171819202122colors = ['#f2eda5','#bbbcbd', '#bbbcbd']fig = go.Figure(data=[go.Pie(labels=total['type'], values=total['respodents'], hole=.3)])fig.update_traces(hoverinfo='percent', textinfo='label', textfont_size=20, marker=dict(colors=colors) )fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', paper_bgcolor='#F7F7F7', title_text=&quot;&lt;b&gt;World vs EastAsia&lt;/b&gt;&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=25, color='#000000') )fig.show()# marker=dict(colors=colors,line=dict(color='#000000', width=1)) #í…Œë‘ë¦¬ ì›í˜•ê·¸ë˜í”„ ë©”ì„œë“œ ë§Œë“¤ê¸° 1234567891011121314151617181920212223242526272829303132333435def pie(df): total = ( df['region'] .value_counts() .to_frame() .reset_index() .rename(columns={'index':'type', 'region':'respodents'}) .groupby('type') .sum() .reset_index() ) colors = ['#f2eda5','#bbbcbd', '#bbbcbd'] fig = go.Figure(data=[go.Pie(labels=total['type'], values=total['respodents'], hole=.3)]) fig.update_traces(hoverinfo='percent', textinfo='label', textfont_size=20, marker=dict(colors=colors) ) fig.update_layout(showlegend=False, plot_bgcolor='#F7F7F7', paper_bgcolor='#F7F7F7', title_text=&quot;&lt;b&gt;World vs EastAsia&lt;/b&gt;&quot;, title_x=0.5, font=dict(family=&quot;Hiragino Kaku Gothic Pro, sans-serif&quot;, size=25, color='#000000') ) fig.show()# marker=dict(colors=colors,line=dict(color='#000000', width=1)) #í…Œë‘ë¦¬ ë©”ì„œë“œ í˜¸ì¶œ 1pie(df21) choropleth ì§€ë„ ê·¸ë˜í”„ ê·¸ë¦¬ê¸° 1df21_Ea['Q3'].value_counts() 1234567891011121314151617181920212223242526272829303132333435def world_map(locations,counts,title): data = [ dict( type = 'choropleth', locations = locations, z = counts, colorscale = 'Blues', locationmode = 'country names', autocolorscale = False, reversescale = True, marker = dict( line = dict(color = '#F7F7F7', width = 1.5)), colorbar = dict(autotick = True, legth = 3, len=0.75, title = 'respodents', max = 1000, min = 0) ) ] layout = dict( title = title, titlefont={'size': 28, 'family': 'san serif'}, width=750, height=475, paper_bgcolor='#F7F7F7', geo = dict( showframe = True, showcoastlines = True, fitbounds=&quot;locations&quot;, ) ) fig = dict(data=data, layout=layout) iplot(fig, validate=False, filename='world-map') z = df21_Ea['Q3'].value_counts() ## ë©”ì„œë“œ í˜¸ì¶œworld_map(locations=z.index, counts=z.values, title= '&lt;b&gt; EastAsia Countries (2021 survey) &lt;b&gt;') Bar ê·¸ë˜í”„ 21ë…„ë„ë§Œ 123456789101112131415161718192021222324252627282930## vertical bar graphs############################ def plotly_vBar(df, q, title, l=50,r=50,b=50,t=100): fig = px.histogram(df21.iloc[1:], x = df21['region'], orientation='v', width=700, height=450, histnorm='percent', color_discrete_map={ &quot;EastAsia&quot;: &quot;gold&quot;, &quot;World&quot;: &quot;salmon&quot; }, opacity=0.6 )fig.update_layout(title=&quot;21ë…„ë„ ì „ì„¸ê³„ vs ë™ì•„ì‹œì•„&quot;, font_family=&quot;San Serif&quot;, bargap=0.2, barmode='group', titlefont={'size': 28}, paper_bgcolor='#F5F5F5', plot_bgcolor='#F5F5F5', legend=dict( orientation=&quot;v&quot;, y=1, yanchor=&quot;top&quot;, x=1.250, xanchor=&quot;right&quot;,) ).update_xaxes(categoryorder='total descending')fig.show() Ref ì°¸ê³ ì‚¬ì´íŠ¸","link":"/2021/11/14/mykaggle1/"},{"title":"ë§¥ë¶ ì´ˆê¸° ì…‹íŒ…","text":"TMIì•„ë¹ ê°€ ì‚¬ì¤€ì‹  15ë…„ë„ì— êµ¬ì…í•œ ì—˜ì§€ ê·¸ë¨ì„ ê±°ì˜ 7ë…„ë™ì•ˆ ì‚¬ìš©í•˜ê³ ,ë„ˆë¬´ ëŠë ¤ì ¸ì„œ ìµœê·¼ì— ë§¥ë¶ì„ êµ¬ë§¤í–ˆë‹¤.ìœˆë„ìš°ë¥¼ ì‚¬ìš©í•˜ë˜ ë‚´ê°€ ì²˜ìŒìœ¼ë¡œ ìƒˆë¡œìš´ IOS ìš´ì˜ì²´ì œë¥¼ ì‚¬ìš©í•´ë³´ëŠ”ê±°ë¼ì„¤ë ˜ ë°˜ ê±±ì • ë°˜ ì´ì—ˆë˜ ê²ƒ ê°™ë‹¤. ì• í”Œ ê¸°ê¸°ì— ê´€ì‹¬ì´ ë¬´ì²™ ë§ì•„ì„œ ìˆ˜ì›ì—­ì— ì• í”Œ ìŠ¤í† ì–´ ë§¤ì¥ì— ìì£¼ ë°©ë¬¸ì—ì„œ êµ¬ê²½í•˜ê³ ëŠ” í–ˆëŠ”ë°ë§¥ë¶ì„ ë§Œì ¸ë´¤ë”ë‹ˆ ì •ë§ í•˜ë‚˜ë„ ëª¨ë¥´ê² ë”ë¼ ì• í”Œì´ ë§ˆê°ê³¼ ë””ìì¸ í•˜ë‚˜ëŠ” ì •ë§ ì¢‹ë‹¤! ì§±ì´ë¿œ ë‚˜ëŠ” RAM 8ê¸°ê°€, SSD 256ê¸°ê°€ë¡œ êµ¬ì…í–ˆë‹¤ì†”ì§íˆ RAM 16ê¸°ê°€ê°€ ìš•ì‹¬ì´ ë‚¬ëŠ”ë°, ê°€ê²©ë„ ë§Œë§Œì¹˜ ì•Šì•˜ê³ IOS ìš´ì˜ì²´ì œê°€ ë‚˜í•œí…Œ ì˜ ë§ì„ì§€ì— ëŒ€í•œ í™•ì‹ ì´ ì—†ì—ˆê¸° ë•Œë¬¸ì— ê¹¡í†µ ì˜µì…˜ìœ¼ë¡œ êµ¬ë§¤í•˜ì˜€ë‹¤.ë‚˜ì¤‘ì— ëˆ ë§ì´ ë²Œë©´ í”„ë¡œë¡œ ë°”ê¿€ê±°ë‹¤ ã… Apple Developer ìœ„ì˜ Apple Developerë¥¼ ì„¤ì¹˜í•˜ë©´ xcodeì™€ Developerê°€ ì„¤ì¹˜ëœë‹¤ ì„¤ì¹˜í•˜ëŠ”ë° êµ‰ì¥íˆ ì˜¤ëœ ì‹œê°„ì´ ê±¸ë ¸ë‹¤. ì•„ë§ˆ 30ë¶„ ì •ë„ ê±¸ë¦°ê²ƒ ê°™ë‹¤. xcodeë€?Appleì˜ macOS, iOS, watchOS ë° tvOSìš© ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì„ ìœ„í•œ IDE. ì—‘ìŠ¤ì½”ë“œë¼ ì½ìœ¼ë©°, macOS ì „ìš©ì´ë‹¤. NodejsğŸ”— https://nodejs.org/ko/ ìœ„ì˜ ì‚¬ì´íŠ¸ì—ì„œ nodejsë¥¼ ì„¤ì¹˜ í•  ìˆ˜ ìˆë‹¤ pycharm ì„¤ì¹˜pythonì„ ì‚¬ìš©í• ê±´ ì•„ë‹Œë°, ë¸”ë¡œê·¸ë¥¼ ì¢€ í¸í•˜ê²Œ ì‚¬ìš©í•  IDEê°€ í•„ìš”í–ˆë‹¤ git ì„¤ì¹˜ Homebrewë¥¼ ì„¤ì¹˜gitì„ ì„¤ì¹˜í•˜ê¸° ì „ì— ë¨¼ì € Homebrewë¥¼ ì„¤ì¹˜í•´ì•¼í•œë‹¤ ğŸ”— https://brew.sh/ ìœ„ì˜ ë§í¬ì— ì ‘ì†í•˜ë©´ ë°©ë²•ì´ ë‚˜ì™€ìˆë‹¤.ê²°ë¡ ì€ ì•„ë˜ ì½”ë“œë¥¼ í„°ë¯¸ë„ì—ì„œ ì…ë ¥í•˜ë©´ ë°”ë¡œ ì„¤ì¹˜ ì™„ë£Œ /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot; git ì„¤ì¹˜ì•„ë˜ ì‚¬ì´íŠ¸ì— ë“¤ì–´ê°€ë©´ ê¹ƒì„ ì„¤ì¹˜í•˜ëŠ” ë°©ë²•ì´ ë‚˜ì™€ìˆì§€ë§Œì•„ë˜ ì½”ë“œë¥¼ í„°ë¯¸ë„ì—ì„œ ì…ë ¥í•˜ë©´ ê¹ƒ ì„¤ì¹˜ê°€ ì™„ë£Œë¨ ğŸ”— http://git-scm.com/download/mac ìœˆë„ìš°ì™€ ë‹¤ë¥´ê²Œ í„°ë¯¸ë„ì—ì„œ ì•„ë˜ ì½”ë“œ í•œ ì¤„ ì…ë ¥í•˜ë©´ git ì„¤ì¹˜ê°€ ëë‚œë‹¤ brew install git git config ì„¤ì • (ê³„ì • ë¡œê·¸ì¸) git config global user.name &quot;wldnjd2&quot; git config global user.email &quot;jeewon3665@naver.com&quot; ê¹ƒì„ ì²˜ìŒ ì„¤ì¹˜í–ˆì„ë•Œ ê³„ì • ë¡œê·¸ì¸ì„ í•´ì¤˜ì•¼ í•˜ëŠ”ë° ìœ„ì™€ ê°™ì´ í•˜ë©´ ëœë‹¤.ê°ìì˜ ì•„ì´ë””ì™€ ì´ë©”ì¼ì„ ì ìœ¼ë©´ ëœë‹¤ hexo blog ì˜®ê¸°ê¸°blogëŠ” git cloneìœ¼ë¡œ ë‚´ë ¤ë°›ì•„ì„œ í•  ìˆ˜ ìˆëŠ”ê²Œ ì•„ë‹ˆì˜€ë‹¤ ã…œ ã…œë‹¤ë¥¸ ì»´í“¨í„°ì—ì„œ ë¸”ë¡œê·¸ë¥¼ í•˜ë ¤ë©´ ê²°êµ­ ì„¤ì •ì„ ë‹¤ì‹œ í•´ì¤˜ì•¼í•˜ëŠ”ë° ì•„ë˜ì™€ ê°™ì´ í•˜ë©´ ëœë‹¤ hexo init myblog (ê°ìë¸”ë¡œê·¸ ë ˆí¬ì§€í† ë¦¬ ì´ë¦„ì ê¸°) cd myblog git init git remote add origin http://~~ (ê°ìì˜ ë ˆí¬ ì£¼ì†Œ) git clean -d -f git pull --set-upstream origin main npm installl hexo clean ë§ˆì§€ë§‰ì—” ì•„ë˜ì˜ ì½”ë“œë¡œ ì˜®ê²¨ì§„ ë¸”ë¡œê·¸ë¥¼ localhost:4000 ì—ì„œ í™•ì¸ í•  ìˆ˜ ìˆë‹¤ hexo g hexo s ë¸”ë¡œê·¸ ìˆ˜ì •ì‚¬í•­ ê¹ƒí—ˆë¸Œì— ì˜¬ë¦¬ê¸° ë¸”ë¡œê·¸ë¥¼ ê¹ƒí—ˆë¸Œì— ì˜¬ë¦¬ë ¤ê³  ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í–ˆì§€ë§Œ ì—ëŸ¬ê°€ ë‚¬ë‹¤..addì™€ commitì€ ë˜ëŠ”ë° pushê°€ ì•ˆë˜ì—ˆë‹¤ git add . gti commit -m &quot;updated&quot; git push error 1ë²ˆ)Access Token error ì—ëŸ¬ê°€ ê³„ì† í•´ì„œ ë°œìƒí–ˆëŠ”ë°ì•„ë˜ì™€ ê°™ì€ ë°©ë²•ìœ¼ë¡œ í•˜ë‹ˆê¹Œ í•´ê²° ë˜ì—ˆë‹¤ê·¸ëŸ¬ë‚˜, ë‚˜ì˜ ë»˜ì§“ìœ¼ë¡œ ë¬¸ì œê°€ ìˆì—ˆëŠ”ë°í† í° ì„¤ì • í•´ì£¼ê³  pushë¥¼ í–ˆëŠ”ë°, pushëŠ” ì•ˆë˜ê³  ê³„ì† ì•„ë˜ì™€ ê°™ì€ ë¬¸êµ¬ë§Œ ë°˜ë³µí•´ì„œ ë‚˜ì™”ë‹¤ Username for 'https://github.com': wldnjs2 Password for 'https://wldnjs2@github.com': usernameì´ë‘ passwordë¥¼ í‹€ë ¸ì„ë¦¬ ì—†ë‹¤ ìƒê°í–ˆëŠ”ë°,ì €ê¸°ì„œ passwordëŠ” ê¹ƒí—ˆë¸Œì˜ passwordê°€ ì•„ë‹Œ ë°œê¸‰ë°›ì€ í† í° ì‹œë¦¬ì–¼ë„˜ë²„ë¥¼ ì ëŠ”ê±°ì˜€ë‹¤ê³ ë¡œ, ë³µì‚¬ ë¶™ì—¬ë„£ê¸° í•˜ë©´ í•´ê²° ë‚œ ê·¸ê²ƒë„ ëª¨ë¥´ê³  ê³„ì† ê¹ƒí—ˆë¸Œ ë¹„ë²ˆ ì³¤ë‹¤ ^0^ â€¦ ì •ë§ í™”ë‚œë‹¤ ğŸ‘‰ ê¹ƒí—ˆë¸Œ í† í° ì„¤ì • error 2ë²ˆ)fatal: The upstream branch of your current branch does not match the name of your current branch. To push to the upstream branch on the remote, use git push origin HEAD:main To push to the branch of the same name on the remote, use git push origin HEAD pushê°€ ì•ˆë˜ê³  ê³„ì† ìœ„ì˜ errorê°€ ë–´ë‹¤ì´ë•Œ ì €ê¸° ì í˜€ìˆëŠ” git push origin HEAD:main ìœ¼ë¡œ pushë¥¼ í•˜ë‹ˆê¹Œí•´ê²°ë˜ì—ˆì§€ë§Œ, ë¬¸ì œëŠ” ê³„ì† ì €ë ‡ê²Œ pushë¥¼ í•´ì•¼í–ˆë‹¤â€¦ git push ë¡œëŠ” ê³„ì† ì € ëª…ë ¹ì–´ê°€ ë–´ë‹¤ í•´ê²°ë°©ë²•ì€ ì•„ë˜ì˜ ì½”ë“œë¥¼ ì³ì£¼ë©´ ëœë‹¤git push â€“set-upstream origin master ë‹¤í–‰íˆ í•´ê²°ë˜ì„œ git pushë¡œ ê°„ë‹¨í•˜ê²Œ pushë¥¼ í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤ ã…œã…œ ğŸ‘‰ ì—ëŸ¬ í•´ê²° ë¸”ë¡œê·¸","link":"/2022/01/01/macbook/"},{"title":"ë‚´ê°€ ì‚¬ìš©í•œ Pandas ë©”ì„œë“œ","text":"Pandasë€ PandasëŠ” ë°ì´í„° ì¡°ì‘ ë° ë¶„ì„ì„ ìœ„í•œ Python í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ìš©ìœ¼ë¡œ ì‘ì„±ëœ ì†Œí”„íŠ¸ì›¨ì–´ ë¼ì´ë¸ŒëŸ¬ì´ë‹¤.íŠ¹íˆ ìˆ«ì í…Œì´ë¸”ê³¼ ì‹œê³„ì—´ ì„ ì¡°ì‘í•˜ê¸° ìœ„í•œ ë°ì´í„° êµ¬ì¡° ì™€ ì—°ì‚°ì„ ì œê³µí•œë‹¤. ì£¼ë¡œ ë°ì´í„° ë¶„ì„ì— ì‚¬ìš© ëœë‹¤. Kaggle ëŒ€íšŒë¥¼ ì¤€ë¹„í• ë•Œ ë°ì´í„° ì „ì²˜ë¦¬ì— ì‚¬ìš©í–ˆë˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë‹¤. import pandas as pd import pandas as pd ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¶ˆëŸ¬ì£¼ê¸° ìœ„í•œ ëª…ë ¹ì–´ë¡œ as ë’¤ì˜ ì•½ì–´ëŠ” pdë¡œ ì •í•´ ì£¼ë¡œ í˜¸ì¶œí•œë‹¤. csv íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° df = pd.read_csv(â€œíŒŒì¼ê²½ë¡œ/íŒŒì¼ëª….csvâ€) df21= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2021/kaggle_survey_2021_responses.csv&quot;) isin listì— ì¡´ì¬í•˜ëŠ” ìš”ì†Œê°€ ëŒ€ìƒ dataframeì— ì¡´ì¬í•˜ëŠ”ì§€ ë°˜í™˜í•˜ëŠ” ë©”ì„œë“œ(Trueì™€ Falseë¡œ ë°˜í™˜) df21['Q3'].isin(['China','Taiwan', 'South Korea', 'Japan']) df21ì´ë¼ëŠ” ë°ì´í„°í”„ë ˆì„ì˜ Q3ë¼ëŠ” ì»¬ëŸ¼ê°’ì—China Taiwan South Korea Japan ê°’ì´ ìˆë‹¤ë©´ ë°˜í™˜í•œë‹¤. EastAsia21 = ['China','Taiwan', 'South Korea', 'Japan'] df21_Ea = df21[df21['Q3'].isin(EastAsia21)] ìœ„ì™€ ê°™ì´ ì‘ì„±í•˜ê²Œ ë˜ë©´ df21ì—ì„œ EastAsia21ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì§„ True ê°’ì˜ í–‰ë“¤ë§Œ ê°€ì§„ df21_Eaì˜ë°ì´í„° í”„ë ˆì„ì´ ë§Œë“¤ì–´ì§ replace ë°ì´í„°ì˜ ë¬¸ìì—´ì„ ì¹˜í™˜í•´ì¤Œ, ì €ì¥ëœ ë¬¸ìì—´ì„ ë°”ê¿”ì¤€ë‹¤.ex1. Q3ì˜ ì»¬ëŸ¼ê°’ì´ ì¹˜í™˜ëœë‹¤. df18['Q3'].replace({'Republic of Korea':'South Korea','I do not wish to disclose my location' : 'Other'}) #ê²°ê³¼ê°’ 1 United States of America 2 Indonesia 3 United States of America 4 United States of America 5 India ... ex2. ìœ„ì™€ ê°™ì§€ë§Œ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ë°ì´í„°ê°€ ì¶œë ¥ëœë‹¤. df18.replace({'Q3': {'Republic of Korea':'South Korea','I do not wish to disclose my location' : 'Other'}}) ex3. ì „ì²´ ë°ì´í„°ì—ì„œ Republic of Koreaì˜ ë°ì´í„°ê°’ì´ ëª¨ë‘ South Koreaë¡œ ë°”ë€ë‹¤ df18.replace{'Republic of Korea':'South Korea'} merge ë°ì´í„° í”„ë ˆì„ì„ í•©ì¹˜ëŠ” ë©”ì„œë“œì´ë‹¤. mer = pd.merge(df21, df20, how = 'outer', on = 'JOB' ) ë°ì´í„° í”„ë ˆì„ df21ê³¼ df20ì„ ì»¬ëŸ¼ JOBì„ ê¸°ì¤€ìœ¼ë¡œ í•©ì¹¨ on: ë‘ê°œì˜ ë°ì´í„° í”„ë ˆì„ì˜ ê¸°ì¤€ì—´ how: ì¡°ì¸ ë°©ì‹ {â€˜leftâ€™, â€˜rigthtâ€™, â€˜innerâ€™, â€˜outerâ€™} ê¸°ë³¸ê°’ì€ innerì´ë‹¤. left: ì™¼ìª½ ë°ì´í„° í”„ë ˆì„ì„ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì¸ right: ì˜¤ë¥¸ìª½ ë°ì´í„° í”„ë ˆì„ì„ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì¸ inner: êµì§‘í•©ì„ ì¡°ì¸ outer: ëª¨ë“  ê°’ì´ ë‚˜íƒ€ë‚˜ë„ë¡ í•œë‹¤(ë°ì´í„° í”„ë ˆì„ì— ì—†ëŠ” ê°’ë“¤ì€ NaNìœ¼ë¡œ í‘œì‹œë¨) concat mergeì™€ ë§ˆì°¬ê°€ì§€ë¡œ ë°ì´í„° í”„ë ˆì„ì„ í•©ì¹˜ëŠ” ë©”ì„œë“œmergeëŠ” DBì˜ joinê³¼ ë¹„ìŠ·í•˜ë‹¤ë©´, Concatì€ ë‹¨ìˆœí•œ ë¶™ì´ê¸°ì´ë‹¤. con = pd.concat([df21, df20, df19, df18], axis = 0) axis = 0 (ê¸°ë³¸ê°’)í–‰ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° í”„ë ˆì„ì„ í•©ì¹œë‹¤ë™ì¼í•œ columnëª…ì„ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° í”„ë ˆì„ì´ ìœ„ì•„ë˜ë¡œ ìŒ“ì•„ì§„ë‹¤. axis = 1ì—´ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° í”„ë ˆì„ì„ í•©ì¹œë‹¤ë°ì´í„° í”„ë ˆì„ì´ ì˜†ìœ¼ë¡œ ë¶™ëŠ”ë‹¤ sort_values ë°ì´í„°ë¥¼ ì •ë ¬í•˜ëŠ” ë©”ì„œë“œì´ë‹¤ df = df21.sort_values(by=&quot;Q3&quot;, ascending=False) Q3 ì»¬ëŸ¼ì„ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•œë‹¤ ascending=Falseë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ ascending=Trueì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ groupby ê·¸ë£¹ë³„ë¡œ ë°ì´í„°ë¥¼ ì§‘ê³„, ìš”ì•½í•˜ëŠ” ì—°ì‚°ìì´ë‹¤. df21 = df21.groupby(['Q3']) ì»¬ëŸ¼ Q3ì˜ ë°ì´í„° ê°’ì´ ê°™ì€ê²ƒë¼ë¦¬ ê·¸ë£¹ë³„ë¡œ ë¬¶ëŠ”ë‹¤ì˜ˆë¥¼ë“¤ì–´ Q3 ì»¬ëŸ¼ê°’ìœ¼ë¡œ êµ­ê°€ì´ë¦„ì´ ì—¬ëŸ¬ê°œ ìˆë‹¤ë©´, êµ­ê°€ë³„ë¡œ ë¬¶ì–´ì„œ ë³¼ ìˆ˜ ìˆë‹¤. fillna fillnaëŠ” ê²°ì¸¡ê°’ì„ íŠ¹ì •ê°’ìœ¼ë¡œ ì±„ìš¸ìˆ˜ ìˆë‹¤. df21.fillna(0) ê²°ì¸¡ê°’ì„ 0ìœ¼ë¡œ ì±„ì›€, ë¬¸ìì—´ë„ ê°€ëŠ¥í•˜ë‹¤ pivot ë°ì´í„°ë¥¼ ì¬êµ¬ì¡°í™”í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤. https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;blogId=wideeyed&amp;logNo=221347221214 transpose ë°ì´í„° í”„ë ˆì„ì˜ í–‰ê³¼ ì—´ì„ ë°”ê¾¸ëŠ” ë©”ì„œë“œì´ë‹¤. to_numpy pandas ê°ì²´ë¥¼ numpy ë°°ì—´ ê°ì²´ë¡œ ë°˜í™˜í•˜ëŠ” ë©”ì„œë“œì´ë‹¤.plotlyë¡œ ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ë•Œ ë°ì´í„° ê°’ì„ ë„£ì–´ì¤˜ì•¼í•˜ëŠ”ë° ì´ë•Œ numpyë¥¼ í†µí•´ ë°°ì—´ë¡œ ë°”ê¿”ì¤˜ì„œ ë„£ì–´ì£¼ëŠ”ë° ì‚¬ìš©í–ˆë‹¤. df21['Q3'].to_numpy() ê²°ê³¼ê°’ array(['India', 'Indonesia', 'Pakistan', ..., 'Sweden', 'United States of America', 'India'], dtype=object) tolist dataframeì˜ ê°’ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ë©”ì†Œë“œ df21['Q3'].tolist() ê²°ê³¼ê°’ ['India', 'Indonesia', 'Pakistan', ..., 'Sweden', 'United States of America', 'India'] Ref ìœ„í‚¤ë°±ê³¼mergeconcat","link":"/2021/12/03/pandas-01/"},{"title":"Kaggle Competition(3)","text":"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸° &amp; ìºê¸€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° 1234567891011121314151617181920212223import numpy as npimport pandas as pdimport seaborn as snsimport matplotlib.pylab as pltimport plotly.io as pioimport plotly.express as pximport plotly.graph_objects as goimport plotly.figure_factory as fffrom plotly.subplots import make_subplotsfrom plotly.offline import init_notebook_mode, iplotinit_notebook_mode(connected=True)pio.templates.default = &quot;none&quot;# import plotly.offline as py# py.offline.init_notebook_mode()import osfor dirname, _, filenames in os.walk('/kaggle/input'): for filename in filenames: print(os.path.join(dirname, filename))import warningswarnings.filterwarnings(&quot;ignore&quot;) 12345df17= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2017/multipleChoiceResponses.csv&quot;, encoding=&quot;ISO-8859-1&quot;)df18= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2018/multipleChoiceResponses.csv&quot;, )df19= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2019/multiple_choice_responses.csv&quot;, )df20= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2020/kaggle_survey_2020_responses.csv&quot;, )df21= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2021/kaggle_survey_2021_responses.csv&quot;, ) ë°ì´í„° Grouping 12345678910111213141516171819202122232425262728293031323334353637383940## East Asiaì—ëŠ” ëŒ€í•œë¯¼êµ­, ì¼ë³¸, ì¤‘êµ­, íƒ€ì´ì™„, ëª½ê³¨, ë¶ì¡°ì„  ì´ 6ê°œì˜ êµ­ê°€ê°€ ì†í•´ ìˆë‹¤. EastAsia17 = ['China',&quot;People 's Republic of China&quot;, 'Taiwan', 'South Korea', 'Japan']EastAsia18 = ['China', 'South Korea', 'Japan', 'Republic of Korea'] EastAsia19 = ['China','Taiwan', 'South Korea', 'Japan', 'Republic of Korea']EastAsia20 = ['China','Taiwan', 'South Korea', 'Japan', 'Republic of Korea']EastAsia21 = ['China','Taiwan', 'South Korea', 'Japan']EastAsia = ['Republic of Korea','China','Taiwan', 'South Korea', 'Japan', &quot;People 's Republic of China&quot; ]#21ë…„df21_Ea = df21[df21['Q3'].isin(EastAsia)]df21_Wo = df21[~df21['Q3'].isin(EastAsia )]## ë™ì•„ì‹œì•„ êµ­ê°€ë¥¼ ì œì™¸í•œ êµ­ê°€ë“¤ì„ region ì—´ì˜ ë°ì´í„° ê°’ì„ World ë¡œ ë°”ê¿”ì¤Œdf21['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df21['Q3']]#20ë…„df20_Ea = df20[df20['Q3'].isin(EastAsia)]df20_Wo = df20[~df20['Q3'].isin(EastAsia )]df20['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df20['Q3']]#19ë…„df19_Ea = df19[df19['Q3'].isin(EastAsia)]df19_Wo = df19[~df19['Q3'].isin(EastAsia )]df19['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df19['Q3']]#18ë…„df18_Ea = df18[df18['Q3'].isin(EastAsia)]df18_Wo = df18[~df18['Q3'].isin(EastAsia )]df18['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df18['Q3']]#17ë…„df17_Ea = df17[df17['Country'].isin(EastAsia)]df17_Wo = df17[~df17['Country'].isin(EastAsia )]df17['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df17['Country']] Heatmap 12345678910111213141516171819# 21ë…„ Business Analystê°€ ì§ì—…ì¸ êµ­ê°€ë³„ ì¸ì›ìˆ˜df21_BA = df21[df21['Q5'] == 'Business Analyst']df21_BA = df21_BA['Q3'].value_counts().to_frame().reset_index().rename(columns={'index':'Country', 'Q3':'Business Analyst'})df21_BA# 21ë…„ Data Analystê°€ ì§ì—…ì¸ êµ­ê°€ë³„ ì¸ì›ìˆ˜df21_DA = df21[df21['Q5'] == 'Data Analyst']df21_DA = df21_DA['Q3'].value_counts().to_frame().reset_index().rename(columns={'index':'Country', 'Q3':'Data Analyst'})df21_DA# 21ë…„ Data Engineerê°€ ì§ì—…ì¸ êµ­ê°€ë³„ ì¸ì›ìˆ˜df21_DE = df21[df21['Q5'] == 'Data Engineer']df21_DE = df21_DE['Q3'].value_counts().to_frame().reset_index().rename(columns={'index':'Country', 'Q3':'Data Engineer'})df21_DE# 21ë…„ Data Scientistê°€ ì§ì—…ì¸ êµ­ê°€ë³„ ì¸ì›ìˆ˜df21_DS = df21[df21['Q5'] == 'Data Scientist']df21_DS = df21_DS['Q3'].value_counts().to_frame().reset_index().rename(columns={'index':'Country', 'Q3':'Data Scientist'})df21_DS 123merge = pd.merge(df21_BA, df21_DA)job=merge.loc[:,[&quot;Business Analyst&quot;,&quot;Data Analyst&quot;]]job.columns.tolist() ['B]usiness Analyst', 'Data Analyst] 1merge 1merge.to_numpy().reshape(-1) 12merge.columns.tolist()#merge.Country.tolist() ['Country', Business Analyst', 'Data Analyst] 1merge.to_numpy() 1234# 21ë…„ Data Engineerê°€ ì§ì—…ì¸ êµ­ê°€ë³„ ì¸ì›ìˆ˜df21_DE = df21[df21['Q5'] == 'Data Engineer']df21_DE = df21_DE['Q3'].value_counts().to_frame().reset_index().rename(columns={'index':'Country', 'Q3':'Data Engineer'})df21_DE.head() 1merge.iloc[:,[1,2]].to_numpy() 123456789101112131415161718192021222324252627282930313233343536373839404142# xì¶•ì§ì—…# yì¶•êµ­ê°€fig = go.Figure(data=go.Heatmap( z=merge.iloc[:,[1,2]].to_numpy(), x=job.columns.tolist(), y = merge.Country.tolist(), hoverongaps = True, coloraxis = &quot;coloraxis&quot; ))fig.update_layout(title_text='&lt;i&gt;&lt;b&gt;Heatmap&lt;/b&gt;&lt;/i&gt;', xaxis = dict(title='x'), yaxis = dict(title='x') )# add custom xaxis titlefig.add_annotation(dict(font=dict(color=&quot;black&quot;,size=14), x=0.5, y=-0.15, showarrow=False, text=&quot;&quot;, xref=&quot;paper&quot;, yref=&quot;paper&quot;))# add custom yaxis titlefig.add_annotation(dict(font=dict(color=&quot;black&quot;,size=14), x=-0.35, y=0.5, showarrow=False, text=&quot;&quot;, textangle=-90, xref=&quot;paper&quot;, yref=&quot;paper&quot;))# adjust margins to make room for yaxis titlefig.update_layout(margin=dict(t=50, l=200))# add colorbarfig['data'][0]['showscale'] = Truefig.show() 1merge.iloc[0,[1,2]].values.tolist() 1merge['Business Analyst'].values.tolist() 123#21ë…„ ì§ì—… ì¢…ë¥˜df21_job = df21['Q5'].value_counts().to_frame().reset_index().rename(columns={'index':'Job', 'Q5':'CNT'})df21_job = df21_job['Job'].to_frame() ë°ì´í„° ì „ì²˜ë¦¬ 1234567891011121314#data í™•ì¸Data_Analyst =['Data Analyst','Data Engineer','Data Miner,Information technology', 'networking, or system ...','Predictive Modeler' ]Data_Engineer =['A business discipline (accounting, economics, ...', 'Business Analyst', 'Statistician', 'Mathematics or statistics', 'Data Scientist', 'Environmental science or geology', 'Humanities', 'Machine Learning Engineer', 'Medical or life sciences (biology, chemistry, ...', 'Physics or astronomy', 'Research Scientist', 'Researcher', 'Scientist/Researcher', 'Social sciences (anthropology, psychology, soc...','Software Developer/Software Engineer']Developer=['Developer Relations/Advocacy','Engineer','Engineering (non-computer focused)', 'Programmer','Software Engineer', 'Computer Scientist','Computer science (software engineering, etc.)', 'Fine arts or performing arts','Product Manager', 'Product/Project Manager','Program/Project Manager','DBA/Database Engineer']Not_Employeed =['Currently not employed', 'Not employed', 'Student']Others = ['I never declared a major', 'Other']","link":"/2021/11/16/mykaggle3-Heatmap/"},{"title":"Plotlyë¥¼ ì´ìš©í•´ ë‹¤ì–‘í•œ bar ê·¸ë˜í”„ ê·¸ë¦¬ê¸°","text":"Bar Graph 1 ìœ„ì˜ ê·¸ë˜í”„ ê²½ìš°ëŠ” bar ê·¸ë˜í”„ë§Œ ìˆëŠ”ê²Œ ì•„ë‹ˆê³  scatter ê·¸ë˜í”„ë„ ê°™ì´ ìˆë‹¤.ë”°ë¼ì„œ ê·¸ë˜í”„ 2ê°œë¥¼ í•˜ë‚˜ì˜ í˜ì´ì§€ì— ê·¸ë¦°ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤. ë‘ê°œì˜ ê·¸ë˜í”„ë¥¼ ë™ì‹œì— ê·¸ë¦´ë•Œ add_traceë¥¼ ì´ìš©í•´ì„œ í•˜ë‚˜ì”© ê·¸ë¦°ë‹¤ê³  ë³´ë©´ ëœë‹¤.fig.add_trace(go.Bar) â€“&gt; ê·¸ë˜í”„-1fig.add_trace(go.Scatter) â€“&gt; ê·¸ë˜í”„-2 xì¶•ì€ ê³µí†µì‚¬í•­ì´ë¯€ë¡œ ê°™ì€ ê°’ì„ ë„£ì–´ì£¼ì—ˆë‹¤.yëŠ” ê°’ì´ ë‹¤ë¥´ë¯€ë¡œ ê°ê°ì˜ ê°’ì„ ë„£ì–´ì£¼ì—ˆë‹¤ ì•„ë˜ëŠ” ì™¼ìª½ ì˜¤ë¥¸ìª½ ê°ê°ì˜ ì¶•ì„ ë‚˜íƒ€ëƒˆê³ , ê°ê°ì˜ ê·¸ë˜í”„ì— ì§€ì •í•´ì£¼ì—ˆë‹¤.yaxis = â€œy1â€yaxis = â€œy2â€ ë‚˜ë¨¸ì§€ fig.update_trace, fig.update_layout, fig.add_annotationëŠ” ê·¸ë˜í”„ë¥¼ ê¾¸ë©°ì£¼ëŠ” ì—­í• ì„ í•œë‹¤. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546fig = go.Figure()fig.add_trace(go.Bar(x=years, y=[len(df17_Ea),len(df18_Ea), len(df19_Ea),len(df20_Ea),len(df21_Ea)], marker_color='#F2D64B', yaxis = &quot;y1&quot;, name='East Asia', text= percent, texttemplate='%{text} %', textposition='outside', hovertemplate='&lt;b&gt;KaggleUser&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{y}'))fig.add_trace(go.Scatter(name = &quot;World&quot;, x=years, y=[len(df17), len(df18), len(df19), len(df20), len(df21)], marker_color='#979DA6', mode = 'lines+markers', # please check option here yaxis = &quot;y2&quot;))fig.update_traces(hovertemplate='&lt;b&gt;Count&lt;/b&gt;: %{y}&lt;br&gt;&lt;extra&gt;&lt;/extra&gt;'+ '&lt;b&gt;Year&lt;/b&gt;: %{x}&lt;br&gt;')fig.update_layout(yaxis = dict(title = &quot;Kaggle User in East Asia&quot;,showgrid = False, range=[0, len(df21_Ea)*1.2]), yaxis2 = dict(title = &quot;Kaggle User in World&quot;, overlaying = &quot;y1&quot;, side = &quot;right&quot;, showgrid = False, zeroline = False, range=[0, len(df21)*1.2]))fig.update_layout(title='&lt;b&gt;Kaggle Users&lt;/b&gt;',title_font_size=20, margin = dict(t=200, l=100, r=50, b=200), height=700, width=700)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.1, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.9, y=-0.25, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Bar Graph2 í•˜ë‚˜ì˜ ê·¸ë˜í”„ì— ì—¬ëŸ¬ê°œì˜ ë°ì´í„°ë¥¼ í‘œí˜„í• ë•Œdata=[]ëŠ” ì™œ ì“¸ê¹Œ? ì•ˆì“°ë©´ ì—ëŸ¬ë‚¨ ì˜ë¬¸ ë˜‘ê°™ì´ go.barë¡œ xì¶• yì¶•ì— ê°ê°ì˜ ê°’ì„ ë„£ì–´ì¤€ë‹¤.ì´ë•Œ ë‚´ê°€ ê·¸ë¦¬ê³ ì í•˜ëŠ” ê·¸ë˜í”„ê°€ ì´ 5ê°œì´ë‹ˆê¹Œ í•˜ë‚˜ì”© ì„¤ì •í•´ì„œ ê·¸ë¦°ë‹¤ê³  ìƒê°í•˜ë©´ ëœë‹¤. ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œëŠ” add_trace ì´ìš©í•´ì„œ ê·¸ë ¤ë„ ëœë‹¤ 12345678910111213141516171819202122232425262728fig = go.Figure(data=[ go.Bar(name='2017', x=df5years['Country'], y=df5years['17'], marker_color='#F2798F',text=df5years['17'].tolist(), textposition='outside'), go.Bar(name='2018', x=df5years['Country'], y=df5years['18'], marker_color='#88BFBA',text=df5years['18'].fillna(0).astype(int).tolist(), textposition='outside',), go.Bar(name='2019', x=df5years['Country'], y=df5years['19'], marker_color='#CDD9A3',text=df5years['19'].tolist(), textposition='outside'), go.Bar(name='2020', x=df5years['Country'], y=df5years['20'], marker_color='#F28705',text=df5years['20'].tolist(), textposition='outside',), go.Bar(name='2021', x=df5years['Country'], y=df5years['21'], marker_color='#D9946C',text=df5years['21'].tolist(), textposition='outside')])fig.update_layout(title='&lt;b&gt;Kaggle User in East Asia&lt;/b&gt;',title_font_size=23, margin = dict(t=200, l=100, r=10, b=200), height=600, width=700)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_traces(hovertemplate='&lt;b&gt;Count&lt;/b&gt;: %{y}')fig.update_layout(legend=dict( orientation=&quot;v&quot;, yanchor=&quot;bottom&quot;, y=1.15, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Bar Graph3 ìœ„ì˜ ê·¸ë˜í”„ëŠ” ìˆ˜í‰ìœ¼ë¡œ ê·¸ë¦° ê·¸ë˜í”„ì´ë‹¤.orientation=â€™hâ€™ -&gt; ìˆ˜í‰ìœ¼ë¡œ ê·¸ë˜í”„ë¥¼ ê·¸ë¦°ë‹¤orientation=â€™vâ€™ -&gt; ìˆ˜ì§ìœ¼ë¡œ ê·¸ë˜í”„ë¥¼ ê·¸ë¦°ë‹¤ base = 0ëŠ” ê°’ì˜ ê¸°ì¤€ì ì´ 0 ì´ë¼ëŠ” ì˜ë¯¸ yê°’ì€ ê°™ì§€ë§Œ, xê°’ì€ 0ì„ ê¸°ì¤€ìœ¼ë¡œ -ì™€ +ë¡œ ë‚˜ëˆ„ì–´ì§€ê¸° ë•Œë¬¸ì—í•œìª½ê°’ì— -ì„ ë¶™ì—¬ì•¼ í•œë‹¤ë‚˜ëŠ” x=World, x=-East_Asia ê°ê° ì´ë ‡ê²Œ ì„¤ì •í•´ì£¼ì—ˆë‹¤ 123456789101112131415161718192021222324252627fig = go.Figure(data=[ go.Bar(y=y, x=World, orientation='h', name=&quot;World&quot;, base=0, hovertemplate='&lt;b&gt;World&lt;/b&gt;: %{x}%&lt;br&gt;', marker_color='#979DA6', text=World, textposition='outside'), go.Bar(y=y, x=-East_Asia, orientation='h', name=&quot;East Asia&quot;, base=0, hovertemplate='&lt;b&gt;East Asia&lt;/b&gt;: %{x}%&lt;br&gt;', marker_color='#F2D64B', text=East_Asia, textposition='outside')])fig.update_layout(barmode='stack')fig.update_layout(title='&lt;b&gt;World vs EastAsia&lt;/b&gt;',title_font_size=22, margin = dict(t=200, l=100, r=50, b=200), height=700, width=750, xaxis_title=None, yaxis_title=None)fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.1, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Bar Graph4 subplotì„ ì´ìš©í•´ ê·¸ë ¤ì¤€ê²ƒì´ë‹¤subplotì´ë€ í•˜ë‚˜ì˜ í˜ì´ì§€ì— ì—¬ëŸ¬ê°œì˜ ê·¸ë˜í”„ë¥¼ í•©ì³ë†“ì€ ê²ƒì´ë‹¤ fig = make_subplots(rows = 1, cols = 4, shared_yaxes=True, vertical_spacing = 0.05) ìœ„ì—ì²˜ëŸ¼ í–‰ ì—´ì„ ì§€ì •í•´ì¤˜ì•¼í•˜ëŠ”ë°ë‚´ê°€ ê·¸ë¦° ê·¸ë˜í”„ëŠ” 1í–‰ 4ì—´ ê·¸ë˜í”„ì´ë‹¤ add_traceë¥¼ ì´ìš©í•´ ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ì£¼ë©´ ëœë‹¤ subplotì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ê·¸ëƒ¥ add_traceë§Œ ì´ìš©í•´ë„ ë˜ëŠ”ë°,ê·¸ëŸ´ê²½ìš°ì—ëŠ” ì•„ë˜ ì‚¬ì§„ì²˜ëŸ¼ ê·¸ë˜í”„ xì¶•ì´ ë¶„ë¦¬ë˜ì§€ ì•Šê³  ì´ì–´ì§„ë‹¤. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758fig = make_subplots(rows = 1, cols = 4, shared_yaxes=True, vertical_spacing = 0.05)fig.add_trace(go.Bar(x = dfCh_Edu21['Dgree'], y = dfCh_Edu21['%'], text = dfCh_Edu21['%'].astype(str) + &quot;%&quot;, textposition='outside', name='China', marker_color='#88BFBA'), row = 1, col = 1)fig.add_trace(go.Bar(x = dfJp_Edu21['Dgree'], y = dfJp_Edu21['%'], text = dfJp_Edu21['%'].astype(str) + &quot;%&quot;, textposition='outside', name='Japan', marker_color='#CDD9A3'), row = 1, col = 2)fig.add_trace(go.Bar(x = dfKo_Edu21['Dgree'], y = dfKo_Edu21['%'], text = dfKo_Edu21['%'].astype(str) + &quot;%&quot;, textposition='outside', name='South Korea', marker_color='#F28705'), row = 1, col = 3)fig.add_trace(go.Bar(x = dfTw_Edu21['Dgree'], y = dfTw_Edu21['%'], text = dfTw_Edu21['%'].astype(str) + &quot;%&quot;, textposition='outside', name='Taiwan', marker_color='#D9946C'), row = 1, col = 4)fig.update_layout(showlegend=True,title='&lt;b&gt;Degree in East Asia&lt;/b&gt;',title_font_size=22, margin = dict(t=200, l=100, r=50, b=200), height=700, width=700)fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{y}%&lt;br&gt;'+ '&lt;b&gt;Degree&lt;/b&gt;: %{x}&lt;br&gt;')fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.1, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Bar Graph5 fig.update_layout(barmode='stack') ìœ„ì˜ í•œ ì¤„ì„ ì¶”ê°€í•´ì£¼ë©´ ê·¸ë˜í”„ê°€ Stackìœ¼ë¡œ ìŒ“ì—¬ì„œ ê·¸ë ¤ì§„ë‹¤. ìœ„ì˜ í•œ ì¤„ì„ ëºì„ë•ŒëŠ” ì´ë ‡ê²Œ ë”°ë¡œë”°ë¡œ ë¶„ë¦¬ë˜ì–´ì„œ ê·¸ë ¤ì§„ë‹¤. 1234567891011121314151617181920212223242526272829303132333435363738fig = go.Figure()fig.add_trace(go.Bar(x = df21_Ea_DS_salary.index, y = df21_Ea_DS_salary['Data Scientist'], name = &quot;Data Scientist&quot;, text = df21_Ea_DS_salary['Data Scientist'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#F2798F'))fig.add_trace(go.Bar(x = df21_Ea_DS_salary.index, y = df21_Ea_DS_salary['Machine Learning Engineer'], name = &quot;Machine Learning Engineer&quot;, text = df21_Ea_DS_salary['Machine Learning Engineer'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#CDD9A3'))fig.add_trace(go.Bar(x = df21_Ea_DS_salary.index, y = df21_Ea_DS_salary['Research Scientist'], name = &quot;Research Scientist&quot;, text = df21_Ea_DS_salary['Research Scientist'].astype(str) + &quot;%&quot;, textposition='auto', marker_color='#88BFBA'))fig.update_layout(barmode='stack', showlegend=True, height=600, width=700, title_text=&quot;&lt;b&gt;Data Scientist's Salary in East Asia&lt;/b&gt;&quot;, title_x=0.5, title_font_size=20, margin=dict(l=100, r=100, t=100, b=100))fig.update_traces(hovertemplate='&lt;b&gt;Percent&lt;/b&gt;: %{y}%&lt;br&gt;'+ '&lt;b&gt;Salary&lt;/b&gt;: %{x}$&lt;br&gt;')fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.update_layout(legend=dict( orientation=&quot;v&quot;, yanchor=&quot;bottom&quot;, y=0.8, xanchor=&quot;right&quot;, x=1.2))fig.show() ëŠë‚€ì  ì²˜ìŒ ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ë©´ì„œ barê·¸ë˜í”„ì—ë„ ë‹¤ì–‘í•œ ì¢…ë¥˜ê°€ ìˆëŠ”ë°ë‚´ê°€ ì›í•˜ëŠ”ëŒ€ë¡œ ê·¸ë¦¬ê¸°ê°€ ì‰½ì§€ ì•Šì•˜ë‹¤í•˜ì§€ë§Œ ì‚¬ì‹¤ ë³µì¡í•œê²Œ ì•„ë‹ˆê¸°ì— ì¡°ê¸ˆë§Œ ê³µë¶€í•˜ë©´ ì‰½ê²Œ ê·¸ë¦´ìˆ˜ ìˆë‹¤ëª¨ë¥¼ë•ŒëŠ” ì‚¬ì‹¤ plotly ì›ë¬¸ ì‚¬ì´íŠ¸ë¥¼ ë“¤ì–´ê°€ì„œ ê·¸ë ¤ë³´ëŠ”ê²Œ ë„ì›€ì´ ë¬ë‹¤ìœ„ì˜ ê·¸ë˜í”„ë¥¼ ì°¸ê³ í•´ì„œ ê·¸ë¦¬ë©´ ëœë‹¤ëˆ„êµ°ê°€ì—ê²Œ ë„ì›€ì´ ë˜ì—ˆê¸°ë¥¼â€¦","link":"/2021/11/28/plotly-bar/"},{"title":"Plotlyë¥¼ ì´ìš©í•´ Heatmap ê·¸ë˜í”„ ê·¸ë¦¬ê¸°","text":"heatmap Graph ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ í†µí•´ì„œ ì •ë¦¬ëœ ë°ì´í„° ì…‹ì´ë‹¤ xì¶• yì¶•ì˜ index ê°’ì„ ê°ê° ì„¤ì •í•´ì£¼ê³ zì—ëŠ” ë°ì´í„° ê°’ì„ ë„£ì–´ì¤€ë‹¤ 1234567891011121314151617181920212223242526x1=['South Korea','Taiwan','China','Japan']y1=merge.sort_values(by=['index'], ascending=True)['index'].tolist()z1=merge.iloc[:,[2,4,6,8]].to_numpy()fig = go.Figure(data=go.Heatmap( z=z1, x=x1, y=y1, hoverongaps = True, opacity=1.0, xgap=2.5, ygap=2.5))fig = ff.create_annotated_heatmap(z1, x = x1, y = y1, colorscale='sunset')fig.update_layout(height=500, width=600, title_text=&quot;&lt;b&gt;East Asia Age (2021)&lt;/b&gt;&quot;, title_font_size=20, title_x=0.5)fig.update_traces(hovertemplate='&lt;b&gt;Age&lt;/b&gt;: %{y}&lt;br&gt;'+ '&lt;b&gt;Country&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Percent&lt;/b&gt;: %{z}%')fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Heatmap Graph2 Heatmapì„ subplotì„ ì´ìš©í•´ì„œ ê·¸ë ¸ë‹¤ì—¬íƒœê¹Œì§€ í•´ì™”ë˜ pieê·¸ë˜í”„, barê·¸ë˜í”„ì™€ëŠ” ë‹¬ë¦¬ ë” ë³µì¡í–ˆë‹¤ x=['2017-year','2018-year','2019-year','2020-year','2021-year'] ì¼ë‹¨ xê°’ì„ â€˜2017-yearâ€™ ì´ëŸ°ì‹ìœ¼ë¡œ ì´ë¦„ì„ ì§€ì—ˆëŠ”ë°,ë²„ê·¸ë¥¼ ë°œê²¬í–ˆë‹¤!â€˜2017â€™ë¡œë§Œ ì§€ìœ¼ë©´ ìˆ«ìë¡œ ì¸ì‹í•´ì„œ ê³„ì† ì—ëŸ¬ê°€ ë‚¬ë˜ê²ƒâ€¦ 12345678910111213141516171819202122232425262728293031323334z1=((merge_Wo.iloc[:,[1,2,3,4,5]].to_numpy()/merge_Wo.iloc[:,[1,2,3,4,5]].to_numpy().sum())*100).round(1)z2=((merge.iloc[:,[1,2,3,4,5]].to_numpy()/merge.iloc[:,[1,2,3,4,5]].to_numpy().sum())*100).round(1)x=['2017-year','2018-year','2019-year','2020-year','2021-year']y1=merge_Wo['JOB'].tolist()y2=merge['JOB'].tolist()fig1 = ff.create_annotated_heatmap(z1, x = x, y = y1, colorscale='sunset')fig2 = ff.create_annotated_heatmap(z2, x = x, y = y2, colorscale='sunset')for annot in fig2['layout']['annotations']: annot['xref'] = 'x2' fig = make_subplots(rows=1, cols=2)fig.add_trace(fig1.data[0], row=1, col=1)fig.add_trace(fig2.data[0], row=1, col=2)fig.update_layout(fig1.layout, title='&lt;b&gt; World vs EastAsia&lt;/b&gt;',title_font_size=22, margin = dict(t=200, l=100, r=10, b=200), height=700, width=1150, coloraxis=dict(showscale=True, colorscale='sunset'))fig.update_traces(hovertemplate='&lt;b&gt;Job&lt;/b&gt;: %{y}&lt;br&gt;'+ '&lt;b&gt;Year&lt;/b&gt;: %{x}&lt;br&gt;'+ '&lt;b&gt;Percent&lt;/b&gt;: %{z}%')fig.layout.annotations += fig2.layout.annotationsfig.add_annotation(dict(font=dict(size=14), x=0.9, y=-0.25, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Ref https://plotly.com/python/heatmaps/","link":"/2021/11/28/plotly-heatmap/"},{"title":"Bar ê·¸ë˜í”„ vì™€ h","text":"importë¬¸ 1234567891011121314151617181920212223import numpy as npimport pandas as pdimport seaborn as snsimport matplotlib.pylab as pltimport plotly.io as pioimport plotly.express as pximport plotly.graph_objects as goimport plotly.figure_factory as fffrom plotly.subplots import make_subplotsfrom plotly.offline import init_notebook_mode, iplotinit_notebook_mode(connected=True)pio.templates.default = &quot;none&quot;# import plotly.offline as py# py.offline.init_notebook_mode()import osfor dirname, _, filenames in os.walk('/kaggle/input'): for filename in filenames: print(os.path.join(dirname, filename))import warningswarnings.filterwarnings(&quot;ignore&quot;) ìºê¸€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° 12345df17= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2017/multipleChoiceResponses.csv&quot;, encoding=&quot;ISO-8859-1&quot;)df18= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2018/multipleChoiceResponses.csv&quot;, )df19= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2019/multiple_choice_responses.csv&quot;, )df20= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2020/kaggle_survey_2020_responses.csv&quot;, )df21= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2021/kaggle_survey_2021_responses.csv&quot;, ) 1-1. ìˆ˜í‰ê·¸ë˜í”„(Bar_h)ë°ì´í„° ì „ì²˜ë¦¬ ë¦¬ìŠ¤íŠ¸ ìƒì„±africa17, africa18, africa19, africa20, africa21 isinPandasì—ì„œëŠ” ì–´ë–¤ listì— ì¡´ì¬í•˜ëŠ” ìš”ì†Œê°€ ëŒ€ìƒ DataFrameì´ë‚˜ Seriesì— ì¡´ì¬ í•˜ëŠ”ì§€ True(ì¡´ì¬), False(ì¡´ì¬ì•ˆí•¨)ë¡œ ë°˜í™˜ì¤€ë‹¤ [df21[â€˜Q3â€™].isin(africa)]ê±°ì£¼ì§€ì—­ì´ africa ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ì§€ì—­ì— í•´ë‹¹í• ê²½ìš° Trueë¡œ ë°˜í™˜ df21[df21[â€˜Q3â€™].isin(africa)](21ë…„ë„ ê¸°ì¤€)africaì— ì‚¬ëŠ” ì‚¬ëŒë“¤ì˜ df21ì˜ ë°ì´í„° ê°’ë§Œ ë¶ˆëŸ¬ì˜´ 123456789101112131415161718192021222324252627282930313233# grouping african countries# ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ì–´ì¤Œafrica17 = ['Nigeria','Kenya', 'South Africa', 'Egypt']africa18 = ['Nigeria','Kenya', 'South Africa', 'Egypt', 'Tunisia', 'Morocco'] africa19 = ['Nigeria','Kenya', 'South Africa', 'Egypt', 'Tunisia', 'Morocco', 'Algeria']africa20 = ['Nigeria','Kenya', 'South Africa', 'Egypt', 'Tunisia', 'Morocco', 'Ghana']africa21 = ['Nigeria','Kenya', 'South Africa', 'Egypt', 'Tunisia', 'Morocco', 'Algeria', 'Ghana', 'Uganda', 'Ethiopia']#df21['Q3'] -&gt; In which country do you currently reside? ê±°ì£¼ì§€ì—­ì€?africa = ['Nigeria', 'Egypt', 'South Africa', 'Algeria', 'Tunisia', 'Morocco', 'Kenya', 'Uganda', 'Ghana', 'Ethiopia']#21ë…„ë„ ê¸°ì¤€df21_africa = df21[df21['Q3'].isin(africa)]df21_world = df21[~df21['Q3'].isin(africa )]df21['region']=[&quot;Africa&quot; if x in africa else &quot;World&quot; for x in df21['Q3']]df20_africa = df20[df20['Q3'].isin(africa)]df20_world = df20[~df20['Q3'].isin(africa )]df20['region']=[&quot;Africa&quot; if x in africa else &quot;World&quot; for x in df20['Q3']]df19_africa = df19[df19['Q3'].isin(africa)]df19_world = df19[~df19['Q3'].isin(africa)]df19['region']=[&quot;Africa&quot; if x in africa else &quot;World&quot; for x in df19['Q3']]df18_africa = df18[df18['Q3'].isin(africa)]df18_world = df18[~df18['Q3'].isin(africa)]df18['region']=[&quot;Africa&quot; if x in africa else &quot;World&quot; for x in df18['Q3']]df17_africa = df17[df17['Country'].isin(africa)]df17_world = df17[~df17['Country'].isin(africa )]df17['region']=[&quot;Africa&quot; if x in africa else &quot;World&quot; for x in df17['Country']] 1print(africa) [â€˜Nigeriaâ€™, â€˜Egyptâ€™, â€˜South Africaâ€™, â€˜Algeriaâ€™, â€˜Tunisiaâ€™, â€˜Moroccoâ€™, â€˜Kenyaâ€™, â€˜Ugandaâ€™, â€˜Ghanaâ€™, â€˜Ethiopiaâ€™] 1print(df21['Q3']) 0 In which country do you currently reside? 1 India 2 Indonesia 3 Pakistan 4 Mexico â€¦ 25969 Egypt 25970 China 25971 Sweden 25972 United States of America 25973 India Name: Q3, Length: 25974, dtype: object 1print(df21['Q3'].isin(africa)) 0 False 1 False 2 False 3 False 4 False â€¦ 25969 True 25970 False 25971 False 25972 False 25973 False Name: Q3, Length: 25974, dtype: bool 1print(df21) 1print(df21[df21['Q3'].isin(africa)]) ë°ì´í„° ì „ì²˜ë¦¬ afro21 = len(df21_africa)df21_africaì˜ í–‰ ê°¯ìˆ˜ -&gt; ì•„í”„ë¦¬ì¹´ì— ê±°ì£¼í•˜ëŠ” ìºê¸€ëŸ¬ ìˆ˜ len(df21)í–‰ì˜ ê°¯ìˆ˜ -&gt; ì„¤ë¬¸ì¡°ì‚¬ì— ì‘ë‹µí•œ ì „ì„¸ê³„ ìºê¸€ëŸ¬ ìˆ˜ row21 = len(df21) - afro21ì „ì„¸ê³„ ìºê¸€ëŸ¬ ìˆ˜ - ì•„í”„ë¦¬ì¹´ ê±°ì£¼í•˜ëŠ” ìºê¸€ëŸ¬ ìˆ˜ = ë‚˜ë¨¸ì§€ 1234567891011121314afro21 = len(df21_africa)row21 = len(df21) - afro21afro20 = len(df20_africa)row20 = len(df20) - afro20afro19 = len(df19_africa)row19 = len(df19) - afro19afro18 = len(df18_africa)row18 = len(df18) - afro18afro17 = len(df17_africa)row17 = len(df17) - afro17 123print(afro21) print(len(df21)) print(row21) 2060 25974 23914 1234#ë¦¬ìŠ¤íŠ¸ ìƒì„±region = ['Africa', 'Rest of the World']value = [afro21, row21]percent =[afro21/(afro21 +row21)*100, row21/(afro21+row21)*100] 123print(region)print(value)print(percent) #ì•„í”„ë¦¬ì¹´ì— ì‚¬ëŠ” ìºê¸€ëŸ¬, ì „ì„¸ê³„ì˜ ìºê¸€ëŸ¬ percent ê°’ [â€˜Africaâ€™, â€˜Rest of the Worldâ€™] [2060, 23914] [7.931007931007931, 92.06899206899207] 1-1. africaì— ì‚¬ëŠ” kaggler ìˆ˜ VS ì „ ì„¸ê³„ kaggler ìˆ˜ ë°ì´í„° ì‹œê°í™”í•˜ê¸° go.Barë§‰ëŒ€ê·¸ë˜í”„ ìƒì„± np.round(percent,1)ë°˜ì˜¬ë¦¼í•˜ê¸° textposition=[â€˜outsideâ€™, â€˜insideâ€™]ê´„í˜¸ ì•ˆì€ ê°ê° ì„¤ì •ê°’[afica, rest of the world] textfont=dict()ë§‰ëŒ€ê·¸ë˜í”„ ë°ì´í„° ê°’ í°íŠ¸ ì„¤ì • orientation=â€™hâ€™ìˆ˜í‰ìœ¼ë¡œ ê·¸ë˜í”„ ê·¸ë¦¬ê¸° marker_color=[â€˜goldâ€™, â€˜salmonâ€™]ë§‰ëŒ€ê·¸ë˜í”„ ìƒ‰ìƒ ì„¤ì • (africa, rest of the world) opacity=0.6ê·¸ë˜í”„ íˆ¬ëª…ë„ ì„¤ì • (0.0 ~ 1) 12345678910111213fig = go.Figure(data=[go.Bar( x=value, y=region, text=(np.round(percent,1)), textposition=['outside', 'inside'], texttemplate = [&quot;&lt;b style='color: #f'&gt;%{text}%&lt;/b&gt;&quot;]*2, textfont=dict( family=&quot;sans serif&quot;, size=16, color=&quot;black&quot;), orientation='h', marker_color=['gold', 'salmon'], opacity=0.6, )])fig.show() update_traces marker_line_color=â€™blackâ€™: ë§‰ëŒ€ê·¸ë˜í”„ í…Œë‘ë¦¬ ìƒ‰ìƒ marker_line_width=2.5: ë§‰ëŒ€ê·¸ë˜í”„ í…Œë‘ë¦¬ ë‘ê»˜ update_layout yaxis_linewidth=2.5yì¶• í…Œë‘ë¦¬ ë‘ê»˜ bargap=0.2ë§‰ëŒ€ê·¸ë˜í”„ ë‘ê»˜ (0 ~ 1.0 ìˆ«ìê°€ ì‘ì„ìˆ˜ë¡ ë‘êº¼ì›€) barmode=â€™groupâ€™ 12345678910111213fig.update_traces(marker_line_color='black', marker_line_width=2.5)fig.update_layout(title='&lt;b&gt;Number of respondents: Africa vs Rest of the world (2021)&lt;b&gt;', font_family=&quot;San Serif&quot;, yaxis_linewidth=2.5, bargap=0.2, barmode='group', titlefont={'size': 24}, paper_bgcolor='#F5F5F5', plot_bgcolor='#F5F5F5', ) update_layout fig.update_layout(xaxis = dict(xì¶• ë ˆì´ì•„ì›ƒ ì„¤ì • autosize=Falseì‚¬ì´ì¦ˆ ê³ ì •trueë¡œ ì„¤ì •ì‹œ ëŒ€ì‹œë³´ë“œ ìì²´ê°€ í™”ë©´ì— ë§ëŠ” í¬ê¸°ë¡œ ì—„ì²­ ì»¤ì§ (ì¢Œìš°ë¡œ) showgrid=Falseë°°ê²½ ê²©ìë¬´ëŠ¬ ìƒì„± ì•ˆí•¨ marginë°°ê²½í™”ë©´ì—ì„œì˜ ê·¸ë˜í”„ í¬ê¸° ë¹„ìœ¨ ì¡°ì • 12345678910111213141516171819fig.update_layout( xaxis = dict( zeroline = False, showline = False, showticklabels = False, gridwidth = 1 ), autosize=False, margin=dict( l=150, r=50, b=50, t=100, ), )fig.update_xaxes(showgrid=False)fig.update_yaxes(showgrid=False)fig.show() 1-2. ìˆ˜ì§ ê·¸ë˜í”„(Bar_v)ì—°ë„ë³„ african kagglersì˜ ìˆ˜ ë¹„êµë°ì´í„° ì „ì²˜ë¦¬ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253## historical data, all genderyear = ['2017', '2018', '2019', '2020', '2021']value = [afro17, afro18, afro19, afro20, afro21]percent =[ afro17/(afro17 +row17)*100, afro18/(afro18 +row18)*100, afro19/(afro19 +row19)*100, afro20/(afro20 +row20)*100, afro21/(afro21 +row21)*100] color = 5* ['salmon'] color[4] = 'gold'fig = go.Figure(data=[go.Bar( y=value, x=year, text=np.round(percent, 1), textposition='outside', texttemplate = [&quot;&lt;b style='color: #f'&gt;%{text}%&lt;/b&gt;&quot;]*5, textfont=dict( family=&quot;sans serif&quot;, size=16, color=&quot;black&quot;), orientation='v', marker_color= color, opacity=0.6 )])fig.update_traces(marker_line_color='black', marker_line_width=2.5)fig.update_layout(title='&lt;b&gt;The rise of African kagglers&lt;b&gt;', font_family=&quot;San Serif&quot;, xaxis_linewidth=2.5, bargap=0.2, barmode='group', titlefont={'size': 28}, template='simple_white', paper_bgcolor='#F5F5F5', plot_bgcolor='#F5F5F5', )fig.update_layout(yaxis_title='Number of Respondents',xaxis_title='Year', autosize=False, margin=dict( l=100, r=50, b=50, t=70, pad=0, ), )fig.show()","link":"/2021/11/10/kaggle8-bar-h-v/"},{"title":"Plotlyë¥¼ ì´ìš©í•´ Sunburst ê·¸ë˜í”„ ê·¸ë¦¬ê¸°","text":"Ref https://plotly.com/python/sunburst-charts/ Sunburst Graph2 ì²˜ìŒ ì´ ê·¸ë˜í”„ë¥¼ ë³´ê³ ëŠ” ì‹ ê¸°í•´ì„œ ê¼­ ê·¸ë ¤ë´ì•¼ì§€ ë‹¤ì§í–ˆë‹¤ê·¼ë° ì‚¬ì‹¤ ì •ë§ ë‹¨ìˆœí•˜ë‹¤..ì •ë§ ê·¸ë¦¬ê¸° ì‰¬ì›€ (ì‚¬ì‹¤ ê·¸ë¦¬ê¸° ì–´ë ¤ìš´ ê·¸ë˜í”„ëŠ” ì—†ë‹¤ ..ã…‹ã…‹) df21_Ea_degree_yearlyì˜ ë°ì´í„° ì…‹ì¸ë°sunburstë¥¼ ê·¸ë¦¬ê¸° ìœ„í•´ì„œ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ í†µí•´ì„œ ë‹¤ë“¬ì€ ê²ƒ! plotlyëŠ” ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ìˆ˜ ìˆëŠ” ë°©ë²•ìœ¼ë¡œ px(express)ì™€ go(graph_objects) ë¡œ ë‘ê°€ì§€ê°€ ìˆëŠ”ë°pxëŠ” ë¹ ë¥´ê³  ì‰½ê²Œ ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ëŠ” ë°©ë²•goëŠ” í•˜ë‚˜í•˜ë‚˜ ì„¸ë¶€ ì„¤ì •ìœ¼ë¡œ ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ìˆ˜ ìˆë‹¤. ìœ„ì˜ ê·¸ë˜í”„ëŠ” pxë¡œ ê·¸ë ¸ë‹¤.goë¡œ ê·¸ë¦´ìˆ˜ë„ ìˆì§€ë§Œ ë°ì´í„°ë¥¼ í•˜ë‚˜í•˜ë‚˜ ì •ë¦¬í•´ì„œ ì§ì ‘ ë„£ì–´ì¤˜ì•¼í•˜ëŠ” ë²ˆê±°ë¡œì›€ ë•Œë¬¸ì—ë‚´ê°€ ê·¸ë¦°ê·¸ë˜í”„ì²˜ëŸ¼ ë°ì´í„° ê°’ì´ ë§ê³  ë³µì¡í•´ì§€ë©´ pxë¡œ ê·¸ë ¤ì•¼í•œë‹¤. pathpath=[â€˜yearâ€™,â€™degreeâ€™]ë‚´ê°€ ë‚˜ëˆ ì¤„ êµ¬ê°„ì„¤ì • í•  ìˆ˜ ìˆë‹¤ valuesë°ì´í„° ê°’ì„ ë„£ì–´ì¤¬ë‹¤ìˆœì„œëŠ” ê·¸ë‹¤ì§€ ì¤‘ìš”í•œê²ƒ ê°™ì§€ ì•Šë‹¤ê°’ì´ ë§ê²Œ ì˜ ê·¸ë ¤ì¡ŒìŒ! 12345678910111213141516171819fig = px.sunburst(df21_Ea_degree_yearly, path=['year','degree'], values=df21_Ea_degree_yearly['value'].tolist())fig.update_layout( margin = dict(t=10, l=10, r=10, b=10),colorway=(&quot;#F2798F&quot;,&quot;#88BFBA&quot;,&quot;#CDD9A3&quot;,'#F28705','#D9946C'))fig.update_layout(title='&lt;b&gt; Degree&lt;/b&gt;',title_font_size=25, margin = dict(t=100, l=100, r=50, b=100), height=700, width=700)fig.update_traces(hovertemplate='&lt;b&gt;Name&lt;/b&gt;: %{id}&lt;br&gt;'+ '&lt;b&gt;Count&lt;/b&gt;: %{value}&lt;br&gt;'+ '&lt;b&gt;Parent&lt;/b&gt;: %{parent}') fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.2, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()","link":"/2021/11/28/plotly-sunburst/"},{"title":"Plotlyë¥¼ ì´ìš©í•´ Pie ê·¸ë˜í”„ ê·¸ë¦¬ê¸°","text":"Ref https://plotly.com/python/subplots/https://plotly.com/python/pie-charts/ Pie Graph1 Pie ê·¸ë˜í”„ëŠ” ì› ê·¸ë˜í”„ë¡œ, ë°ì´í„° ê°’ì´ %ê°€ ì•„ë‹ˆì—¬ë„ ìë™ìœ¼ë¡œ percent ìˆ˜ì¹˜ë¡œ ê·¸ë ¤ì§€ê²Œ ëœë‹¤. 5ê°œì˜ ì›ì„ í•˜ë‚˜ì˜ í˜ì´ì§€ì— ê·¸ë¦¬ê¸° ìœ„í•´ì„œ subplotì„ ì´ìš©í–ˆë‹¤ fig = make_subplots(rows=1, cols=5, specs=[[{'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}]],) specsëŠ” ê·¸ë˜í”„ì˜ ì¢…ë¥˜ë¥¼ ì •ì˜í•´ì£¼ëŠ”ê²ƒì¸ë°, (Barì™€ Scatter ê·¸ë˜í”„ëŠ” ë”°ë¡œ ì •ì˜ ì•ˆí•´ì¤˜ë„ ëœë‹¤)ìœ„ì˜ ì½”ë“œëŠ” pie ê·¸ë˜í”„ê°€ 1í–‰ 5ì—´ë¡œ ë°°ì¹˜ ë˜ì–´ìˆëŠ”ê²ƒì„ ì˜ë¯¸í•œë‹¤Pieê·¸ë˜í”„ê°€ ì•„ë‹Œê²½ìš°ì—ëŠ” â€˜domainâ€™ ë¶€ë¶„ì„ ë°”ê¿”ì¤˜ì•¼í•¨â€˜pieâ€™ ë¼ê³  ì •ì˜í•´ë„ ë¨ ex) specs=[[{&quot;type&quot;: &quot;domain&quot;}, {&quot;type&quot;: &quot;domain&quot;}], [{&quot;type&quot;: &quot;domain&quot;}, {&quot;type&quot;: &quot;domain&quot;}]] ìœ„ì˜ ì½”ë“œëŠ” pieê·¸ë˜í”„ 4ê°œê°€ 2í–‰ 2ì—´ë¡œ ê·¸ë ¤ì§ˆë•Œ ì´ì „ì— bar ê·¸ë˜í”„ë¥¼ ê·¸ë ¸ë˜ê±°ì™€ ë§ˆì°¬ê°€ì§€ë¡œ, add_trace() ë¥¼ ì´ìš©í•´ì„œ ê·¸ë ¸ë‹¤ scalegroup=â€™oneâ€™ëŠ” ê·¸ë˜í”„ í¬ê¸°ë¥¼ í•˜ë‚˜ë¡œ ì§€ì •í–ˆë‹¤ê° ê·¸ë˜í”„ ë³„ë¡œ ìœ„ì˜ ì½”ë“œë¥¼ ì¶”ê°€í•´ì£¼ë©´ pieì˜ í¬ê¸°ê°€ ë‹¬ë¼ì§„ë‹¤ê°’ì´ í´ìˆ˜ë¡ ê·¸ë˜í”„ê°€ í¬ê³ , ì‘ì„ìˆ˜ë¡ ì‘ë‹¤. 12345678910111213141516171819202122232425262728293031323334353637colors = ['#D9946C','#88BFBA', '#CDD9A3']fig = make_subplots(rows=1, cols=5, specs=[[{'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}]],)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_21['type'], values=Gender_21['Gender'], name=&quot;2021&quot;, scalegroup='one', text=np.array(Gender_21['Gender'].sum()), title=&quot;2021&quot;, titleposition='bottom center'), 1, 5)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_20['type'], values=Gender_20['Gender'], name=&quot;2020&quot;, scalegroup='one', text=np.array(Gender_20['Gender'].sum()), title=&quot;2020&quot;, titleposition='bottom center'), 1, 4)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_19['type'], values=Gender_19['Gender'], name=&quot;2019&quot;, scalegroup='one', text=np.array(Gender_19['Gender'].sum()), title=&quot;2019&quot;, titleposition='bottom center'), 1, 3)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_18['type'], values=Gender_18['Gender'], name=&quot;2018&quot;, scalegroup='one', text=np.array(Gender_18['Gender'].sum()), title=&quot;2018&quot;, titleposition='bottom center'), 1, 2)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=Gender_17['type'], values=Gender_17['Gender'], name=&quot;2017&quot;, scalegroup='one', text=np.array(Gender_17['Gender'].sum()), title=&quot;2017&quot;, titleposition='bottom center'), 1, 1)fig.update_traces(hole=.0, hoverinfo=&quot;label+percent+name&quot;, textinfo='label+percent+value')fig.update_layout(title='&lt;b&gt;World Gender&lt;/b&gt;',title_font_size=23, margin = dict(t=300, l=100, r=0, b=200), height=700, width=1000)fig.update_layout(legend=dict( orientation=&quot;v&quot;, yanchor=&quot;bottom&quot;, y=1.3, xanchor=&quot;right&quot;, x=1))fig.add_annotation(dict(font=dict(size=14), x=0.85, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show() Pie Graph2 dictì˜ ì˜ë¯¸ëŠ” dictionaryì´ë‹¤. 12345678910111213141516171819202122232425262728#graphcolors = ['#F2798F','#88BFBA', '#CDD9A3', '#F28705', '#D9946C']fig = make_subplots(rows=1, cols=2, specs=[[{'type':'pie'}, {'type':'pie'}]], subplot_titles=(&quot;World&quot;, &quot;East Asia&quot;))fig.add_trace(go.Pie(marker=dict(colors=colors), labels=degree_wo.index, values=degree_wo['Q4'].to_numpy(), name=&quot;World&quot;), 1, 1)fig.add_trace(go.Pie(marker=dict(colors=colors), labels=degree_ea.index, values=degree_ea['Q4'].to_numpy(), name=&quot;East Asia&quot;), 1, 2)fig.update_traces(hole=.0, hoverinfo=&quot;label+percent+name&quot;)fig.update_layout(title='&lt;b&gt;World vs East Asia&lt;/b&gt;',title_font_size=22, margin = dict(t=200, l=30, r=0, b=200), height=700, width=700)fig.update_layout(legend=dict( orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1.1, xanchor=&quot;right&quot;, x=1.0))fig.add_annotation(dict(font=dict(size=14), x=0.8, y=-0.5, showarrow=False, text=&quot;@green_yhjw&quot;, xanchor='left', xref=&quot;paper&quot;, yref=&quot;paper&quot;))fig.show()","link":"/2021/11/28/plotly-pie/"},{"title":"Pycharm ê°€ìƒí™˜ê²½ ì„¤ì • &amp; ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜","text":"Pycharm ê°€ìƒí™˜ê²½ ì„¤ì • ë°©ë²•File -&gt; Setting -&gt; ì™¼ìª½ ë©”ë‰´ì—ì„œ í´ë” ì´ë¦„ í´ë¦­ -&gt; Python Interpreter-&gt; Virtualenv Environment -&gt; ìš°ì¸¡ìƒë‹¨ í†±ë‹ˆë°”í€´ -&gt; ADD ìœ„ì— Location ì—ì„œ ê²½ë¡œ í™•ì¸í•´ì£¼ê¸°!Apply í´ë¦­í•˜ë©´ venv í´ë”ê°€ ìƒì„±ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ê°€ìƒí™˜ê²½ ì‚¬ìš©ì´ìœ ê°€ìƒí™˜ê²½ì€ ì—¬ëŸ¬ê°œì˜ íŒŒì´ì¬ í”„ë¡œì íŠ¸ê°€ í•˜ë‚˜ì˜ ì»´í“¨í„°ì—ì„œ ì¶©ë™ì„ ì¼ìœ¼í‚¤ì§€ ì•Šê³  ì¡´ì¬í•  ìˆ˜ ìˆë„ë¡ í•´ì¤€ë‹¤.-&gt; ë…ë¦½ì ì¸ ì‘ì—… í™˜ê²½ì—ì„œ íŒ¨í‚¤ì§€ ë° ë²„ì „ê´€ë¦¬ë¥¼ í•˜ê¸°ìœ„í•´ ê°€ìƒí™˜ê²½ì„ ì‚¬ìš©í•œë‹¤. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë°©ë²•File -&gt; Settings -&gt; + í´ë¦­ -&gt; ì›í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì…ë ¥í•´ì„œ ì„¤ì¹˜ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ëª©ë¡ í™•ì¸pip freeze &gt; requirements.txt í˜„ì¬ pythonì— pipë¡œ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ëª©ë¡ì— ëŒ€í•œ ì •ë³´ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ freezeë¼ëŠ” ëª…ë ¹ì–´ ì‚¬ìš©(pipë€ íŒŒì´ì¬ìœ¼ë¡œ ì‘ì„±ëœ íŒ¨í‚¤ì§€ ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ ì„œë¦¬ ê´€ë¦¬í•˜ëŠ” íŒ¨í‚¤ì§€ ê´€ë¦¬ ì‹œìŠ¤í…œ) requirements.txt ì† íŒ¨í‚¤ì§€ ì„¤ì¹˜requirements.txtë¼ëŠ” íŒŒì¼ì´ ì£¼ì–´ì¡Œì„ë•Œ,ê·¸ ì•ˆì˜ íŒ¨í‚¤ì§€ë“¤ì„ ëª¨ë‘ ì„¤ì¹˜ í•˜ê¸° ìœ„í•œ ëª…ë ¹ì–´ pip install -r requirements.txt Ref requirement.txtíŒŒì¼","link":"/2021/12/06/python00/"},{"title":"íŒŒì´ì¬ List","text":"ë¦¬ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ëŠ” ëŒ€ê´„í˜¸[] ì•ˆì— ë¬¸ìë‚˜ ìˆ«ìë¥¼ ì €ì¥í• ìˆ˜ ìˆëŠ” ìë£Œí˜•ì´ë‹¤. ì•„ë˜ì²˜ëŸ¼ ë¦¬ìŠ¤íŠ¸ëŠ” ë‹¤ì–‘í•œ í˜•íƒœ ì´ë‹¤ 12345a = []b = [1, 2, 3]c = ['Life', 'is', 'too', 'short']d = [1, 2, 'Life', 'is']e = [1, 2, ['Life', 'is']] ë¦¬ìŠ¤íŠ¸ ì¸ë±ì‹±ë¦¬ìŠ¤íŠ¸ëŠ” ìë°”ì˜ ë°°ì—´ì²˜ëŸ¼ ì¸ë±ìŠ¤ë¥¼ ê°€ì§€ê³  ìˆë‹¤.ìœ„ì— ë§Œë“¤ì–´ë†“ì€ eë¥¼ ì•„ë˜ì—ì„œ í™œìš©í•´ ë³´ì•˜ë‹¤. 123456e[0] &gt;&gt; 1e[1]&gt;&gt; 2e[0]+e[1]&gt;&gt; 3 e[-1]ì—ì„œ -1ì€ ë§ˆì§€ë§‰ ìš”ì†Œê°’ì„ ë‚˜íƒ€ë‚¸ë‹¤. 12e[-1]&gt;&gt; ['Life', 'is'] ìœ„ì— ë§Œë“¤ì–´ë†“ì€ eë¦¬ìŠ¤íŠ¸ ì•ˆì—ëŠ” ë¦¬ìŠ¤íŠ¸ [â€˜Lifeâ€™, â€˜isâ€™]ë¦¬ìŠ¤íŠ¸ê°€ ìˆë‹¤ì´ë•Œ Life ê°’ê³¼ is ê°’ì„ ì•„ë˜ì™€ ê°™ì´ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë‹¤ 1234e[2][0]&gt;&gt; 'Life'e[-1][1]&gt;&gt; 'is' ë¦¬ìŠ¤íŠ¸ì˜ ìŠ¬ë¼ì´ì‹±12345678e[0:2]&gt;&gt; [1, 2, ['Life', 'is']]e[:2]&gt;&gt; [1, 2, ['Life', 'is']]e[1:]&gt;&gt; [2, ['Life', 'is']]e[2][:1]&gt;&gt; ['Life', 'is'] ë¦¬ìŠ¤íŠ¸ì˜ ì—°ì‚°ë¬¸ìì—´ê³¼ ìˆ«ìë¥¼ ë”í•˜ëŠ”ê²ƒì€ ë¶ˆê°€ëŠ¥í•˜ë‹¤. 1234b + c&gt;&gt; [1, 2, 3, 'Life', 'is', 'too', 'short']b * 3&gt;&gt; [1, 2, 3, 1, 2, 3, 1, 2, 3] ë¦¬ìŠ¤íŠ¸ì˜ ê¸¸ì´12len(b)&gt;&gt; 3 ë¦¬ìŠ¤íŠ¸ ê°’ ìˆ˜ì •1234567b[1] = 5b&gt;&gt; [1, 5, 3]del b[1:]b&gt;&gt; [1] ë¦¬ìŠ¤íŠ¸ ê´€ë ¨ ë©”ì„œë“œ append ìš”ì†Œ ì¶”ê°€ 12b.append(5)&gt;&gt; [1,2,3,5] sort ì •ë ¬ 12b.sort()&gt;&gt; [1,2,3] reverse ë’¤ì§‘ê¸° 123b.reverse()b&gt;&gt; [3, 2, 1] indexb ë¦¬ìŠ¤íŠ¸ ì•ˆì— 2ê°€ ìˆìœ¼ë©´ 2ì˜ ì¸ë±ìŠ¤ ê°’ì„ ë°˜í™˜ 123b.index(2)b&gt;&gt; 1 insert(ì¸ë±ìŠ¤, ì‚½ì…í•  ê°’) 123b.insert(0,6)b&gt;&gt; [6, 1, 2, 3] remove ì‚­ì œ 123b.remove(1)b&gt;&gt; [1, 3] pop ë§¨ ë§ˆì§€ë§‰ ê°’ ë°˜í™˜í•˜ê³  ì‚­ì œ 1234b.pop &gt;&gt; 3b &gt;&gt; [1, 2] count ë¦¬ìŠ¤íŠ¸ì˜ ìš”ì†Œ ê°œìˆ˜ë¦¬ìŠ¤íŠ¸ bì•ˆì— 1ì˜ ê°¯ìˆ˜12b.count(1)&gt;&gt; 1 extend 12345678a = [1,2,3]a.extend([4,5])a&gt;&gt; [1, 2, 3, 4, 5]b = [6, 7]a.extend(b)a&gt;&gt; [1, 2, 3, 4, 5, 6, 7] Refhttps://wikidocs.net/14","link":"/2021/12/06/python01-list/"},{"title":"íŒŒì´ì¬ Tuple","text":"Tuple ë¦¬ìŠ¤íŠ¸ì™€ ë‹¤ë¥¸ì ë¦¬ìŠ¤íŠ¸ëŠ” []ë¡œ ë‘˜ëŸ¬ì‹¸ì§€ë§Œ íŠœí”Œì€ ()ë¡œ ë‘˜ëŸ¬ì‹¼ë‹¤.ë¦¬ìŠ¤íŠ¸ëŠ” ê°’ì˜ ìƒì„±, ì‚­ì œ, ìˆ˜ì •ì´ ê°€ëŠ¥í•˜ì§€ë§Œ íŠœí”Œì€ ê°’ì„ ë°”ê¿€ ìˆ˜ ì—†ë‹¤.ë¦¬ìŠ¤íŠ¸ë³´ë‹¤ ì†ë„ê°€ ë¹ ë¥´ë‹¤.ì¸ë±ì‹±, ìŠ¬ë¼ì´ì‹±, ë”í•˜ê¸°, ê³±í•˜ê¸° â€¦ ë“±ë“± ë¦¬ìŠ¤íŠ¸ì™€ ë‹¤ ë™ì¼í•˜ë‹¤. 12345t1 = ()t2 = (1,)t3 = (1, 2, 3)t4 = 1, 2, 3t5 = ('a', 'b', ('ab', 'cd')) 1234menu = (&quot;ê¹€ì¹˜ë³¶ìŒë°¥, ì—½ê¸°ë–¡ë³¶ì´&quot;)name = &quot;ê¹€ì§€ì›&quot;age = 20hobby = &quot;ì½”ë”©&quot; Refhttps://wikidocs.net/15","link":"/2021/12/06/python02-tuple/"},{"title":"Kaggle Competition(4)","text":"ê·¸ë˜í”„ ëª©ë¡ í•™ë ¥ ì§ì—… ê²½ë ¥ ì—°ë´‰ ì–¸ì–´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸° &amp; ìºê¸€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° 1234567891011121314151617181920212223import numpy as npimport pandas as pdimport seaborn as snsimport matplotlib.pylab as pltimport plotly.io as pioimport plotly.express as pximport plotly.graph_objects as goimport plotly.figure_factory as fffrom plotly.subplots import make_subplotsfrom plotly.offline import init_notebook_mode, iplotinit_notebook_mode(connected=True)pio.templates.default = &quot;none&quot;# import plotly.offline as py# py.offline.init_notebook_mode()import osfor dirname, _, filenames in os.walk('/kaggle/input'): for filename in filenames: print(os.path.join(dirname, filename))import warningswarnings.filterwarnings(&quot;ignore&quot;) 12345df17= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2017/multipleChoiceResponses.csv&quot;, encoding=&quot;ISO-8859-1&quot;)df18= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2018/multipleChoiceResponses.csv&quot;, )df19= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2019/multiple_choice_responses.csv&quot;, )df20= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2020/kaggle_survey_2020_responses.csv&quot;, )df21= pd.read_csv(&quot;/kaggle/input/kaggle-survey-2021/kaggle_survey_2021_responses.csv&quot;, ) EastAsia ë°ì´í„° Grouping 1234567891011121314151617181920212223242526272829303132333435363738394041## East Asiaì—ëŠ” ëŒ€í•œë¯¼êµ­, ì¼ë³¸, ì¤‘êµ­, íƒ€ì´ì™„, ëª½ê³¨, ë¶ì¡°ì„  ì´ 6ê°œì˜ êµ­ê°€ê°€ ì†í•´ ìˆë‹¤. EastAsia17 = ['China',&quot;People 's Republic of China&quot;, 'Taiwan', 'South Korea', 'Japan']EastAsia18 = ['China', 'South Korea', 'Japan', 'Republic of Korea'] EastAsia19 = ['China','Taiwan', 'South Korea', 'Japan', 'Republic of Korea']EastAsia20 = ['China','Taiwan', 'South Korea', 'Japan', 'Republic of Korea']EastAsia21 = ['China','Taiwan', 'South Korea', 'Japan']EastAsia = ['Republic of Korea','China','Taiwan', 'South Korea', 'Japan', &quot;People 's Republic of China&quot; ]#21ë…„df21_Ea = df21[df21['Q3'].isin(EastAsia)]df21_Wo = df21[~df21['Q3'].isin(EastAsia )]## ë™ì•„ì‹œì•„ êµ­ê°€ë¥¼ ì œì™¸í•œ êµ­ê°€ë“¤ì„ region ì—´ì˜ ë°ì´í„° ê°’ì„ World ë¡œ ë°”ê¿”ì¤Œ# region ì—´ ìƒì„±df21['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df21['Q3']]#20ë…„df20_Ea = df20[df20['Q3'].isin(EastAsia)]df20_Wo = df20[~df20['Q3'].isin(EastAsia )]df20['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df20['Q3']]#19ë…„df19_Ea = df19[df19['Q3'].isin(EastAsia)]df19_Wo = df19[~df19['Q3'].isin(EastAsia )]df19['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df19['Q3']]#18ë…„df18_Ea = df18[df18['Q3'].isin(EastAsia)]df18_Wo = df18[~df18['Q3'].isin(EastAsia )]df18['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df18['Q3']]#17ë…„df17_Ea = df17[df17['Country'].isin(EastAsia)]df17_Wo = df17[~df17['Country'].isin(EastAsia )]df17['region']=[&quot;EastAsia&quot; if x in EastAsia else &quot;World&quot; for x in df17['Country']] í•™ë ¥ Q4 12df21_degree= df21['Q4'].value_counts().to_frame().reset_index()df21_degree 12#ë§ˆì§€ë§‰ í–‰ ì‚­ì œdf21_degree.drop(df21_degree.index[7]) 1df21_degree['Q4'].to_numpy() 1df21_degree['index'].tolist() 12345678degree = df21_degree['index'].tolist()fig = go.Figure(data=[ go.Bar(name='21ë…„ World kagglerë“¤ì˜ í•™ë ¥', x=degree, y=df21_degree['Q4'].to_numpy() ,orientation='v')])fig.update_layout(title_text=&quot;&lt;b&gt;21ë…„ World kagglerë“¤ì˜ í•™ë ¥&lt;/b&gt;&quot;,title_font_size=35)fig.show() 123456789101112131415#ì „ì²´ ì½”ë“œdf21_degree= df21['Q4'].value_counts().to_frame().reset_index()df21_degree#ë§ˆì§€ë§‰ í–‰ ì‚­ì œdf21_degree.drop(df21_degree.index[7])degree = df21_degree['index'].tolist()fig = go.Figure(data=[ go.Bar(name='21ë…„ World kagglerë“¤ì˜ í•™ë ¥', x=degree, y=df21_degree['Q4'].to_numpy() ,orientation='v')])fig.update_layout(title_text=&quot;&lt;b&gt;21ë…„ World kagglerë“¤ì˜ í•™ë ¥&lt;/b&gt;&quot;,title_font_size=35)fig.show() 1df21_Ea['Q4'].value_counts().index 12df21_ea_degree = df21_Ea['Q4'].value_counts().to_frame().reset_index()df21_ea_degree['Q4'].to_numpy() 123456789101112131415degree = df21_Ea['Q4'].value_counts().indexfig = go.Figure(data=[ go.Bar(name='China', x = degree, y=df21_Ea['Q4'][df21_Ea['Q3'] =='China'].value_counts()), go.Bar(name='Japan', x = degree, y=df21_Ea['Q4'][df21_Ea['Q3'] =='Japan'].value_counts()), go.Bar(name='South Korea', x= degree, y=df21_Ea['Q4'][df21_Ea['Q3'] =='South Korea'].value_counts()), go.Bar(name='Taiwan', x= degree, y=df21_Ea['Q4'][df21_Ea['Q3'] =='Taiwan'].value_counts()) ])fig.update_layout(title_text=&quot;&lt;b&gt;21ë…„ EastAisa kagglerë“¤ì˜ í•™ë ¥&lt;/b&gt;&quot;,title_font_size=35)fig.show() 12345678910111213141516171819#ì „ì²´ ì½”ë“œdf21_ea_degree = df21_Ea['Q4'].value_counts().to_frame().reset_index()degree = df21_Ea['Q4'].value_counts().indexfig = go.Figure(data=[ go.Bar(name='China', x = degree, y=df21_Ea['Q4'][df21_Ea['Q3'] =='China'].value_counts()), go.Bar(name='Japan', x = degree, y=df21_Ea['Q4'][df21_Ea['Q3'] =='Japan'].value_counts()), go.Bar(name='South Korea', x= degree, y=df21_Ea['Q4'][df21_Ea['Q3'] =='South Korea'].value_counts()), go.Bar(name='Taiwan', x= degree, y=df21_Ea['Q4'][df21_Ea['Q3'] =='Taiwan'].value_counts()) ])fig.update_layout(title_text=&quot;&lt;b&gt;21ë…„ EastAisa kagglerë“¤ì˜ í•™ë ¥&lt;/b&gt;&quot;,title_font_size=35)fig.show() ì§ì—… Q5 12345678910111213Data_Analyst =['Data Analyst','Data Miner,Information technology','Data Miner', 'Predictive Modeler','Information technology, networking, or system administration' ]Data_Engineer =['A business discipline (accounting, economics, finance, etc.)', 'Business Analyst', 'Statistician', 'Mathematics or statistics', 'Data Scientist', 'Environmental science or geology', 'Humanities', 'Machine Learning Engineer', 'Medical or life sciences (biology, chemistry, medicine, etc.)', 'Physics or astronomy', 'Research Scientist', 'Researcher', 'Scientist/Researcher', 'Data Engineer', 'Social sciences (anthropology, psychology, sociology, etc.)','Software Developer/Software Engineer','Humanities (history, literature, philosophy, etc.)']Developer=['Developer Relations/Advocacy','Engineer','Engineering (non-computer focused)', 'Programmer','Software Engineer', 'Computer Scientist','Computer science (software engineering, etc.)', 'Fine arts or performing arts','Product Manager', 'Product/Project Manager','Program/Project Manager','DBA/Database Engineer']Not_Employeed =['Currently not employed', 'Not employed', 'Student']Others = ['I never declared a major', 'Other'] 1df21['Q5'].value_counts() 12345df21_Ea_DA=df21_Ea['Q3'][df21_Ea['Q5'].isin(Data_Analyst)].value_counts().to_frame().rename(columns = {'Q3':'Data_Analyst'})df21_Ea_DE=df21_Ea['Q3'][df21_Ea['Q5'].isin(Data_Engineer)].value_counts().to_frame().rename(columns = {'Q3':'Data_Engineer'})df21_Ea_D=df21_Ea['Q3'][df21_Ea['Q5'].isin(Developer)].value_counts().to_frame().rename(columns = {'Q3':'Developer'})df21_Ea_NE=df21_Ea['Q3'][df21_Ea['Q5'].isin(Not_Employeed)].value_counts().to_frame().rename(columns = {'Q3':'Not_Employeed'})df21_Ea_O=df21_Ea['Q3'][df21_Ea['Q5'].isin(Others)].value_counts().to_frame().rename(columns = {'Q3':'Others'}) 12job=(df21_Ea_DA.join(df21_Ea_DE).join(df21_Ea_D).join(df21_Ea_NE).join(df21_Ea_O))job 1job.iloc[1,0:5].to_numpy() array([ 46, 292, 254, 211, 118]) 1234567891011121314job_ =job.columnsfig = go.Figure(data=[ go.Bar(name='China', x = job_, y=job.iloc[0,0:5].to_numpy()), go.Bar(name='Japan', x = job_, y=job.iloc[1,0:5].to_numpy()), go.Bar(name='South Korea', x= job_, y=job.iloc[2,0:5].to_numpy()), go.Bar(name='Taiwan', x= job_, y=job.iloc[3,0:5].to_numpy()) ])fig.update_layout(title_text=&quot;&lt;b&gt;21ë…„ EastAisa kagglerë“¤ì˜ ì§ì—…&lt;/b&gt;&quot;,title_font_size=35)fig.show() 1234567891011121314151617181920212223242526272829303132333435363738#ì „ì²´ ì½”ë“œData_Analyst =['Data Analyst','Data Miner,Information technology','Data Miner', 'Predictive Modeler','Information technology, networking, or system administration' ]Data_Engineer =['A business discipline (accounting, economics, finance, etc.)', 'Business Analyst', 'Statistician', 'Mathematics or statistics', 'Data Scientist', 'Environmental science or geology', 'Humanities', 'Machine Learning Engineer', 'Medical or life sciences (biology, chemistry, medicine, etc.)', 'Physics or astronomy', 'Research Scientist', 'Researcher', 'Scientist/Researcher', 'Data Engineer', 'Social sciences (anthropology, psychology, sociology, etc.)','Software Developer/Software Engineer','Humanities (history, literature, philosophy, etc.)']Developer=['Developer Relations/Advocacy','Engineer','Engineering (non-computer focused)', 'Programmer','Software Engineer', 'Computer Scientist','Computer science (software engineering, etc.)', 'Fine arts or performing arts','Product Manager', 'Product/Project Manager','Program/Project Manager','DBA/Database Engineer']Not_Employeed =['Currently not employed', 'Not employed', 'Student']Others = ['I never declared a major', 'Other']df21_Ea_DA=df21_Ea['Q3'][df21_Ea['Q5'].isin(Data_Analyst)].value_counts().to_frame().rename(columns = {'Q3':'Data_Analyst'})df21_Ea_DE=df21_Ea['Q3'][df21_Ea['Q5'].isin(Data_Engineer)].value_counts().to_frame().rename(columns = {'Q3':'Data_Engineer'})df21_Ea_D=df21_Ea['Q3'][df21_Ea['Q5'].isin(Developer)].value_counts().to_frame().rename(columns = {'Q3':'Developer'})df21_Ea_NE=df21_Ea['Q3'][df21_Ea['Q5'].isin(Not_Employeed)].value_counts().to_frame().rename(columns = {'Q3':'Not_Employeed'})df21_Ea_O=df21_Ea['Q3'][df21_Ea['Q5'].isin(Others)].value_counts().to_frame().rename(columns = {'Q3':'Others'})job=(df21_Ea_DA.join(df21_Ea_DE).join(df21_Ea_D).join(df21_Ea_NE).join(df21_Ea_O))job_ =job.columnsfig = go.Figure(data=[ go.Bar(name='China', x = job_, y=job.iloc[0,0:5].to_numpy()), go.Bar(name='Japan', x = job_, y=job.iloc[1,0:5].to_numpy()), go.Bar(name='South Korea', x= job_, y=job.iloc[2,0:5].to_numpy()), go.Bar(name='Taiwan', x= job_, y=job.iloc[3,0:5].to_numpy()) ])fig.update_layout(title_text=&quot;&lt;b&gt;21ë…„ EastAisa kagglerë“¤ì˜ ì§ì—…&lt;/b&gt;&quot;,title_font_size=35)fig.show() ê²½ë ¥ Q6 1df21['Q6'].value_counts() 1234567891011_3year = ['I have never written code', '&lt; 1 years', '1-3 years']_5year = ['3-5 years ','5-10 years']_10year = ['10-20 years','20+ years']df21_3year = df21['Q6'][df21['Q6'].isin(_3year)]df21_5year = df21['Q6'][df21['Q6'].isin(_5year)]df21_10year = df21['Q6'][df21['Q6'].isin(_10year)]df21_3year.count()df21_5year.count()df21_10year.count() 1df21_3year 1234567891011years =['_3year','_5year', '_10year']values =[df21_3year.count(), df21_5year.count(), df21_10year.count()]fig = go.Figure(data=[ go.Bar(name='21ë…„ World kagglerë“¤ì˜ ê²½ë ¥', x=years, y=values ,orientation='v'),])fig.update_layout(title_text=&quot;&lt;b&gt;21ë…„ World kagglerë“¤ì˜ ê²½ë ¥&lt;/b&gt;&quot;,title_font_size=35)fig.show() 123456789101112131415161718192021222324#ì „ì²´ ì½”ë“œ_3year = ['I have never written code', '&lt; 1 years', '1-3 years']_5year = ['3-5 years ','5-10 years']_10year = ['10-20 years','20+ years']df21_3year = df21['Q6'][df21['Q6'].isin(_3year)]df21_5year = df21['Q6'][df21['Q6'].isin(_5year)]df21_10year = df21['Q6'][df21['Q6'].isin(_10year)]df21_3year.count()df21_5year.count()df21_10year.count()years =['_3year','_5year', '_10year']values =[df21_3year.count(), df21_5year.count(), df21_10year.count()]fig = go.Figure(data=[ go.Bar(name='21ë…„ World kagglerë“¤ì˜ ê²½ë ¥', x=years, y=values ,orientation='v'),])fig.update_layout(title_text=&quot;&lt;b&gt;21ë…„ World kagglerë“¤ì˜ ê²½ë ¥&lt;/b&gt;&quot;,title_font_size=35)fig.show() 1df21_Ea['Q3'] 123456789_3year = ['I have never written code', '&lt; 1 years', '1-3 years']_5year = ['3-5 years ','5-10 years']_10year = ['10-20 years','20+ years']df21_Ea_3year = df21_Ea['Q3'][df21_Ea['Q6'].isin(_3year)].value_counts().to_frame().rename(columns = {'Q3':'3year'})df21_Ea_5year = df21_Ea['Q3'][df21_Ea['Q6'].isin(_5year)].value_counts().to_frame().rename(columns = {'Q3':'5year'})df21_Ea_10year = df21_Ea['Q3'][df21_Ea['Q6'].isin(_10year)].value_counts().to_frame().rename(columns = {'Q3':'10year'}) 1df21_Ea_3year 1df21_Ea_5year 1df21_Ea_10year 12career=(df21_Ea_3year.join(df21_Ea_5year).join(df21_Ea_10year))career 1234career.iloc[0,0:3] #Chinacareer.iloc[1,0:3] #Japancareer.iloc[2,0:3] #South Koreacareer.iloc[3,0:3] #Taiwan 12345678910111213fig = go.Figure(data=[ go.Bar(name='China', x = years, y=career.iloc[0,0:3]), go.Bar(name='Japan', x = years, y=career.iloc[1,0:3]), go.Bar(name='South Korea', x= years, y=career.iloc[2,0:3]), go.Bar(name='Taiwan', x= years, y=career.iloc[3,0:3]) ])fig.update_layout(title_text=&quot;&lt;b&gt;21ë…„ EastAisa kagglerë“¤ì˜ ê²½ë ¥&lt;/b&gt;&quot;,title_font_size=35)fig.show() 123456789101112131415161718192021222324252627282930#ìµœì¢… í•©ì¹œ ì½”ë“œ_3year = ['I have never written code', '&lt; 1 years', '1-3 years']_5year = ['3-5 years ','5-10 years']_10year = ['10-20 years','20+ years']df21_Ea_3year = df21_Ea['Q3'][df21_Ea['Q6'].isin(_3year)].value_counts().to_frame().rename(columns = {'Q3':'3year'})df21_Ea_5year = df21_Ea['Q3'][df21_Ea['Q6'].isin(_5year)].value_counts().to_frame().rename(columns = {'Q3':'5year'})df21_Ea_10year = df21_Ea['Q3'][df21_Ea['Q6'].isin(_10year)].value_counts().to_frame().rename(columns = {'Q3':'10year'})career=(df21_Ea_3year.join(df21_Ea_5year).join(df21_Ea_10year))careercareer.iloc[0,0:3] #Chinacareer.iloc[1,0:3] #Japancareer.iloc[2,0:3] #South Koreacareer.iloc[3,0:3] #Taiwanfig = go.Figure(data=[ go.Bar(name='China', x = years, y=career.iloc[0,0:3]), go.Bar(name='Japan', x = years, y=career.iloc[1,0:3]), go.Bar(name='South Korea', x= years, y=career.iloc[2,0:3]), go.Bar(name='Taiwan', x= years, y=career.iloc[3,0:3]) ])fig.update_layout(title_text=&quot;&lt;b&gt;21ë…„ EastAisa kagglerë“¤ì˜ ê²½ë ¥&lt;/b&gt;&quot;,title_font_size=35)fig.show() ì—°ë´‰ Q25 1234#ë§ˆì§€ë§‰ í–‰ ì‚­ì œí•´ì¤Œdf21_=(df21['Q25'].value_counts().to_frame())df21_=df21_.drop(df21_.index[26])df21_ 1df21_['Q25'].index 1df21_['Q25'].to_numpy() 1234567compensation = df21_['Q25'].indexfig = go.Figure(data=[ go.Bar(name='21ë…„ World kagglerë“¤ì˜ ì—°ë´‰', x=compensation, y=df21_['Q25'].to_numpy() ,orientation='v')])fig.update_layout(title_text=&quot;&lt;b&gt;21ë…„ World kagglerë“¤ì˜ ì—°ë´‰&lt;/b&gt;&quot;,title_font_size=35)fig.show() 1234567891011121314#ì „ì²´ ì½”ë“œ#ë§ˆì§€ë§‰ í–‰ ì‚­ì œí•´ì¤Œdf21_=(df21['Q25'].value_counts().to_frame())df21_=df21_.drop(df21_.index[26])df21_compensation = df21_['Q25'].indexfig = go.Figure(data=[ go.Bar(name='21ë…„ World kagglerë“¤ì˜ ì—°ë´‰', x=compensation, y=df21_['Q25'].to_numpy() ,orientation='v')])fig.update_layout(title_text=&quot;&lt;b&gt;21ë…„ World kagglerë“¤ì˜ ì—°ë´‰&lt;/b&gt;&quot;,title_font_size=35)fig.show() 12#ì¼ë³¸ ì—°ë´‰df21_Ea['Q25'][df21_Ea['Q3'] =='Japan'].value_counts() 1df21_Ea['Q3'].value_counts() 1df21_Ea['Q25'][df21_Ea['Q3'] =='Taiwan'].value_counts() 123456789101112131415161718compensation = df21_['Q25'].indexfig = go.Figure(data=[ go.Bar(name='China', x = compensation, y = df21_Ea['Q25'][df21_Ea['Q3'] =='Japan'].value_counts()), go.Bar(name='Japan', x = compensation, y=df21_Ea['Q25'][df21_Ea['Q3'] =='Taiwan'].value_counts()), go.Bar(name='South Korea', x = compensation, y=df21_Ea['Q25'][df21_Ea['Q3'] =='South Korea'].value_counts()), go.Bar(name='Taiwan', x = compensation, y=df21_Ea['Q25'][df21_Ea['Q3'] =='China'].value_counts()) ])fig.update_layout(title_text=&quot;&lt;b&gt;21ë…„ EastAisa kagglerë“¤ì˜ ì—°ë´‰&lt;/b&gt;&quot;,title_font_size=35)fig.show() 1234567891011121314151617181920#ì „ì²´ ì½”ë“œcompensation = df21_['Q25'].indexfig = go.Figure(data=[ go.Bar(name='China', x = compensation, y = df21_Ea['Q25'][df21_Ea['Q3'] =='Japan'].value_counts()), go.Bar(name='Japan', x = compensation, y=df21_Ea['Q25'][df21_Ea['Q3'] =='Taiwan'].value_counts()), go.Bar(name='South Korea', x = compensation, y=df21_Ea['Q25'][df21_Ea['Q3'] =='South Korea'].value_counts()), go.Bar(name='Taiwan', x = compensation, y=df21_Ea['Q25'][df21_Ea['Q3'] =='China'].value_counts()) ])fig.update_layout(title_text=&quot;&lt;b&gt;21ë…„ EastAisa kagglerë“¤ì˜ ì—°ë´‰&lt;/b&gt;&quot;,title_font_size=35)fig.show() ì–¸ì–´ Q7 123456789101112df21_p = df21['Q7_Part_1'].value_counts().to_frame() #pythondf21_r = df21['Q7_Part_2'].value_counts().to_frame() #rdf21_s = df21['Q7_Part_3'].value_counts().to_frame() #sqldf21_c = df21['Q7_Part_4'].value_counts().to_frame() #cdf21_cc = df21['Q7_Part_5'].value_counts().to_frame() #c++df21_j = df21['Q7_Part_6'].value_counts().to_frame() #javadf21_js = df21['Q7_Part_7'].value_counts().to_frame() #javascriptdf21_ju = df21['Q7_Part_8'].value_counts().to_frame() #juliadf21_sw = df21['Q7_Part_9'].value_counts().to_frame() #swiftdf21_b = df21['Q7_Part_10'].value_counts().to_frame() #bashdf21_ma = df21['Q7_Part_11'].value_counts().to_frame() #matlabdf21_n = df21['Q7_Part_12'].value_counts().to_frame() #none 1df21_p.iloc[0,0] 12345678910111213141516171819202122languages = ['Python','R','SQL','C','C++','Java','Javascript','Julia','Swift','Bash','MATLAB','None']fig = go.Figure(data=[ go.Bar(name='21ë…„ World kagglerë“¤ì´ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´', x = languages, y = [df21_p.iloc[0,0], df21_r.iloc[0,0], df21_s.iloc[0,0], df21_c.iloc[0,0], df21_cc.iloc[0,0], df21_j.iloc[0,0], df21_js.iloc[0,0], df21_ju.iloc[0,0], df21_sw.iloc[0,0], df21_b.iloc[0,0], df21_ma.iloc[0,0], df21_n.iloc[0,0]],orientation='v') ])fig.update_layout(title_text=&quot;&lt;b&gt;21ë…„ World kagglerë“¤ì´ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´&lt;/b&gt;&quot;,title_font_size=35)fig.show() 12345678910111213141516171819202122232425262728293031323334353637#ì½”ë“œ ì „ì²´df21_p = df21['Q7_Part_1'].value_counts().to_frame() #pythondf21_r = df21['Q7_Part_2'].value_counts().to_frame() #rdf21_s = df21['Q7_Part_3'].value_counts().to_frame() #sqldf21_c = df21['Q7_Part_4'].value_counts().to_frame() #cdf21_cc = df21['Q7_Part_5'].value_counts().to_frame() #c++df21_j = df21['Q7_Part_6'].value_counts().to_frame() #javadf21_js = df21['Q7_Part_7'].value_counts().to_frame() #javascriptdf21_ju = df21['Q7_Part_8'].value_counts().to_frame() #juliadf21_sw = df21['Q7_Part_9'].value_counts().to_frame() #swiftdf21_b = df21['Q7_Part_10'].value_counts().to_frame() #bashdf21_ma = df21['Q7_Part_11'].value_counts().to_frame() #matlabdf21_n = df21['Q7_Part_12'].value_counts().to_frame() #nonelanguages = ['Python','R','SQL','C','C++','Java','Javascript','Julia','Swift','Bash','MATLAB','None']fig = go.Figure(data=[ go.Bar(name='21ë…„ World kagglerë“¤ì´ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´', x = languages, y = [df21_p.iloc[0,0], df21_r.iloc[0,0], df21_s.iloc[0,0], df21_c.iloc[0,0], df21_cc.iloc[0,0], df21_j.iloc[0,0], df21_js.iloc[0,0], df21_ju.iloc[0,0], df21_sw.iloc[0,0], df21_b.iloc[0,0], df21_ma.iloc[0,0], df21_n.iloc[0,0]],orientation='v') ])fig.update_layout(title_text=&quot;&lt;b&gt;21ë…„ World kagglerë“¤ì´ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´&lt;/b&gt;&quot;,title_font_size=35)fig.show() 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758df21_lan_ch_p=df21_Ea['Q7_Part_1'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_1':'cnt'})df21_lan_ch_r=df21_Ea['Q7_Part_2'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_2':'cnt'})df21_lan_ch_s=df21_Ea['Q7_Part_3'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_3':'cnt'})df21_lan_ch_c=df21_Ea['Q7_Part_4'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_4':'cnt'})df21_lan_ch_cc=df21_Ea['Q7_Part_5'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_5':'cnt'})df21_lan_ch_j=df21_Ea['Q7_Part_6'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_6':'cnt'})df21_lan_ch_js=df21_Ea['Q7_Part_7'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_7':'cnt'})df21_lan_ch_ju=df21_Ea['Q7_Part_8'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_8':'cnt'})df21_lan_ch_sw=df21_Ea['Q7_Part_9'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_9':'cnt'})df21_lan_ch_b=df21_Ea['Q7_Part_10'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_10':'cnt'})df21_lan_ch_ma=df21_Ea['Q7_Part_11'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_11':'cnt'})df21_lan_ch_n=df21_Ea['Q7_Part_12'][df21_Ea['Q3']=='China'].value_counts().to_frame().rename(columns = {'Q7_Part_12':'cnt'})ch_lan = pd.concat([df21_lan_ch_p,df21_lan_ch_r,df21_lan_ch_s,df21_lan_ch_c,df21_lan_ch_cc,df21_lan_ch_j,df21_lan_ch_js,df21_lan_ch_ju,df21_lan_ch_sw,df21_lan_ch_b,df21_lan_ch_ma,df21_lan_ch_n])df21_lan_jp_p=df21_Ea['Q7_Part_1'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_1':'cnt'})df21_lan_jp_r=df21_Ea['Q7_Part_2'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_2':'cnt'})df21_lan_jp_s=df21_Ea['Q7_Part_3'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_3':'cnt'})df21_lan_jp_c=df21_Ea['Q7_Part_4'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_4':'cnt'})df21_lan_jp_cc=df21_Ea['Q7_Part_5'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_5':'cnt'})df21_lan_jp_j=df21_Ea['Q7_Part_6'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_6':'cnt'})df21_lan_jp_js=df21_Ea['Q7_Part_7'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_7':'cnt'})df21_lan_jp_ju=df21_Ea['Q7_Part_8'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_8':'cnt'})df21_lan_jp_sw=df21_Ea['Q7_Part_9'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_9':'cnt'})df21_lan_jp_b=df21_Ea['Q7_Part_10'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_10':'cnt'})df21_lan_jp_ma=df21_Ea['Q7_Part_11'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_11':'cnt'})df21_lan_jp_n=df21_Ea['Q7_Part_12'][df21_Ea['Q3']=='Japan'].value_counts().to_frame().rename(columns = {'Q7_Part_12':'cnt'})jp_lan = pd.concat([df21_lan_jp_p,df21_lan_jp_r,df21_lan_jp_s,df21_lan_jp_c,df21_lan_jp_cc,df21_lan_jp_j,df21_lan_jp_js,df21_lan_jp_ju,df21_lan_jp_sw,df21_lan_jp_b,df21_lan_jp_ma,df21_lan_jp_n])df21_lan_tw_p=df21_Ea['Q7_Part_1'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_1':'cnt'})df21_lan_tw_r=df21_Ea['Q7_Part_2'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_2':'cnt'})df21_lan_tw_s=df21_Ea['Q7_Part_3'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_3':'cnt'})df21_lan_tw_c=df21_Ea['Q7_Part_4'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_4':'cnt'})df21_lan_tw_cc=df21_Ea['Q7_Part_5'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_5':'cnt'})df21_lan_tw_j=df21_Ea['Q7_Part_6'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_6':'cnt'})df21_lan_tw_js=df21_Ea['Q7_Part_7'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_7':'cnt'})df21_lan_tw_ju=df21_Ea['Q7_Part_8'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_8':'cnt'})df21_lan_tw_sw=df21_Ea['Q7_Part_9'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_9':'cnt'})df21_lan_tw_b=df21_Ea['Q7_Part_10'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_10':'cnt'})df21_lan_tw_ma=df21_Ea['Q7_Part_11'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_11':'cnt'})df21_lan_tw_n=df21_Ea['Q7_Part_12'][df21_Ea['Q3']=='Taiwan'].value_counts().to_frame().rename(columns = {'Q7_Part_12':'cnt'})tw_lan = pd.concat([df21_lan_tw_p,df21_lan_tw_r,df21_lan_tw_s,df21_lan_tw_c,df21_lan_tw_cc,df21_lan_tw_j,df21_lan_tw_js,df21_lan_tw_ju,df21_lan_tw_sw,df21_lan_tw_b,df21_lan_tw_ma,df21_lan_tw_n])df21_lan_ko_p=df21_Ea['Q7_Part_1'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_1':'cnt'})df21_lan_ko_r=df21_Ea['Q7_Part_2'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_2':'cnt'})df21_lan_ko_s=df21_Ea['Q7_Part_3'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_3':'cnt'})df21_lan_ko_c=df21_Ea['Q7_Part_4'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_4':'cnt'})df21_lan_ko_cc=df21_Ea['Q7_Part_5'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_5':'cnt'})df21_lan_ko_j=df21_Ea['Q7_Part_6'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_6':'cnt'})df21_lan_ko_js=df21_Ea['Q7_Part_7'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_7':'cnt'})df21_lan_ko_ju=df21_Ea['Q7_Part_8'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_8':'cnt'})df21_lan_ko_sw=df21_Ea['Q7_Part_9'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_9':'cnt'})df21_lan_ko_b=df21_Ea['Q7_Part_10'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_10':'cnt'})df21_lan_ko_ma=df21_Ea['Q7_Part_11'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_11':'cnt'})df21_lan_ko_n=df21_Ea['Q7_Part_12'][df21_Ea['Q3']=='South Korea'].value_counts().to_frame().rename(columns = {'Q7_Part_12':'cnt'})ko_lan = pd.concat([df21_lan_ko_p,df21_lan_ko_r,df21_lan_ko_s,df21_lan_ko_c,df21_lan_ko_cc,df21_lan_ko_j,df21_lan_ko_js,df21_lan_ko_ju,df21_lan_ko_sw,df21_lan_ko_b,df21_lan_ko_ma,df21_lan_ko_n]) 1ch_lan['cnt'].to_list() 123456789101112131415161718languages = ['Python','R','SQL','C','C++','Java','Javascript','Julia','Swift','Bash','MATLAB','None']fig = go.Figure(data=[ go.Bar(name='China', x = languages, y = ch_lan['cnt'].tolist()), go.Bar(name='Japan', x = languages, y=jp_lan['cnt'].tolist()), go.Bar(name='South Korea', x = languages, y=ko_lan['cnt'].tolist()), go.Bar(name='Taiwan', x = languages, y=tw_lan['cnt'].tolist()) ])fig.update_layout(title_text=&quot;&lt;b&gt;21ë…„ EastAisa kagglerë“¤ì´ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´&lt;/b&gt;&quot;,title_font_size=35)fig.show()","link":"/2021/11/17/mykaggle4/"},{"title":"íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬","text":"Dictionaryë€ ì‚¬ì „ì´ë‹¤ìš°ë¦¬ê°€ í‰ìƒì‹œì— ì‚¬ìš©í•˜ëŠ” ì‚¬ì „ì—ì„œ ë‹¨ì–´ë¥¼ ì°¾ìœ¼ë©´, ë‹¨ì–´ê°€ ë‚˜ì˜¤ê³  ê·¸ì—ëŒ€í•œ ì •ì˜ê°€ ë‚˜ì˜¨ë‹¤.ì´ì²˜ëŸ¼ íŒŒì´ì¬ì˜ ë”•ì…”ë„ˆë¦¬ë„ keyì™€ value í˜•íƒœì´ë‹¤. ex) 100ë²ˆ ì‚¬ë¬¼í•¨ -&gt; 100ë²ˆ keyê°€ ì‚¬ìš© 200ë²ˆ key ì‚¬ìš© ë¶ˆê°€ëŠ¥ =&gt; í‚¤ì—ëŒ€í•œ ì¤‘ë³µì´ í—ˆìš©ë˜ì§€ ì•ŠëŠ”ë‹¤ ë”•ì…”ë„ˆë¦¬ì˜ í˜•íƒœkeyì™€ valueê°€ {}ë¡œ êµ¬ì„±ë˜ì–´ìˆë‹¤. 1{{Key1:Value1, Key2:Value2, Key3:Value3, ...}} valueì— ë¦¬ìŠ¤íŠ¸ë„ ë„£ì„ìˆ˜ ìˆë‹¤. keyê°’ìœ¼ë¡œ ì •ìˆ˜ê°’ì´ë‚˜, ë¬¸ìì—´ë„ ê°€ëŠ¥í•˜ë‹¤. ì•„ë˜ëŠ” ì˜ˆì‹œì´ë‹¤ 12cabinet = {9:&quot;ê¹€ë•¡ë•¡&quot;, 7:&quot;ë°•ëª¨ëª¨&quot;}a = {'a': [1, 2, 3]} ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©í•´ë³´ê¸°ëŒ€ê´„í˜¸[]ë‚˜, getì„ í†µí•´ valueë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤. 1234print(cabinet[9])&gt;&gt; ê¹€ë•¡ë•¡print(cabinet.get(7))&gt;&gt; ë°•ëª¨ëª¨ í‚¤ì˜ value ê°’ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆë‹¤.ì´ë•Œ ë°˜í™˜ê°’ì€ Trueì™€ Falseë¡œ êµ¬ë¶„ë˜ì–´ì§„ë‹¤. 1234print(9 in cabinet)&gt;&gt; Trueprint(7 in cabinet)&gt;&gt; False ë”•ì…”ë„ˆë¦¬ ì¶”ê°€, ë³€ê²½, ì‚­ì œì•„ë˜ëŠ” ë”•ì…”ë„ˆë¦¬ ì¶”ê°€ ì˜ˆì‹œì´ë‹¤. 12345print(cabinet)&gt;&gt; {9:&quot;ê¹€ë•¡ë•¡&quot;, 7:&quot;ë°•ëª¨ëª¨&quot;}cabinet[15] = &quot;ì´ë•¡ë•¡&quot; #ìƒˆë¡œìš´ ê°’ ì¶”ê°€print(cabinet)&gt;&gt; {9:&quot;ê¹€ë•¡ë•¡&quot;, 7:&quot;ë°•ëª¨ëª¨&quot;, 15:&quot;ì´ë•¡ë•¡&quot;} ì•„ë˜ëŠ” ë”•ì…”ë„ˆë¦¬ ë³€ê²½ ì˜ˆì‹œì´ë‹¤. ì¶”ê°€ì™€ ê°™ì€ í˜•íƒœì´ë‹¤.ìœ„ì˜ ì˜ˆì œì—ì„œ key 15ì˜ valueë¡œ ì´ë•¡ë•¡ìœ¼ë¡œ ìƒˆë¡œ ì¶”ê°€í•´ì£¼ì—ˆì§€ë§Œ,ë‚˜ë•¡ë•¡ìœ¼ë¡œ value ê°’ì„ ë°”ê¾¼ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. 123cabinet[15]=&quot;ë‚˜ë•¡ë•¡&quot;print(cabinet)&gt;&gt; {9:&quot;ê¹€ë•¡ë•¡&quot;, 7:&quot;ë°•ëª¨ëª¨&quot;, 15:&quot;ë‚˜ë•¡ë•¡&quot;} ì•„ë˜ëŠ” ë”•ì…”ë„ˆë¦¬ ì‚­ì œ ì˜ˆì‹œì´ë‹¤.ë”•ì…”ë„ˆë¦¬ ì•ì— delì„ ë¶™ì—¬ ì‚­ì œí•  ìˆ˜ ìˆë‹¤. 12del cabinet[15] &gt;&gt; {9:&quot;ê¹€ë•¡ë•¡&quot;, 7:&quot;ë°•ëª¨ëª¨&quot;} clear() í•¨ìˆ˜ë¥¼ ì´ìš©í•´ì„œ ë”•ì…”ë„ˆë¦¬ ì „ì²´ ì‚­ì œë¥¼ í•  ìˆ˜ ìˆë‹¤. 12cabinet.clear()&gt;&gt; key ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°key()ë¥¼ ì‚¬ìš©í•´ keyë§Œ ëª¨ì•„ì„œ dict_keys ê°ì²´ë¥¼ ëŒë ¤ì¤€ë‹¤ 123a = {'name': 'jw', 'phone': '010-1234-5678', 'birth': '1014'}a.keys()&gt;&gt; dict_keys(['name', 'phone', 'birth']) keyê°’ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í• ìˆ˜ë„ ìˆë‹¤ 12list(a.keys())&gt;&gt; ['name', 'phone', 'birth'] value ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°values()ë¥¼ ì´ìš©í•´ì„œ value ê°’ë§Œ ëª¨ì•„ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•  ìˆ˜ ìˆë‹¤ 12a.values()&gt;&gt; dict_values(['jw', '010-1234-567', '1014']) Refë‚˜ë„ì½”ë”©ì í”„íˆ¬íŒŒì´ì¬","link":"/2021/12/06/python03-dic/"},{"title":"íŒŒì´ì¬ ì¡°ê±´ë¬¸ê³¼ ë°˜ë³µë¬¸ (if, while, for)","text":"ë“¤ì—¬ì“°ê¸°íŒŒì´ì¬ì€ ìë°”ë‚˜ ë‹¤ë¥¸ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì™€ëŠ” ë‹¤ë¥¸ê²Œ ë“¤ì—¬ì“°ê¸°ë¥¼ ê¼­ í•´ì£¼ì–´ì•¼ í•œë‹¤ë“¤ì—¬ì“°ê¸°ë¥¼ ë¬´ì‹œí•  ê²½ìš° ì—ëŸ¬ê°€ ë‚¨ ì½œë¡ (:)íŒŒì´ì¬ì€ ì„¸ë¯¸ì½œë¡ (;)ì„ ì‚¬ìš©í•˜ëŠ” ìë°”ì™€ëŠ” ë‹¤ë¥´ê²Œë¬¸ì¥ ëì— í•­ìƒ ì½œë¡ (:)ì„ ì‚¬ìš©í•œë‹¤ ifë¬¸ if - else ë¬¸ì—¬íƒœê¹Œì§€ ë°°ì› ë˜ ifë¬¸ê³¼ í¬ê²Œ ë‹¤ë¥¼ê²Œ ì—†ë‹¤ else ifì•„ë‹Œ elifë¥¼ ì‚¬ìš©í•œë‹¤ 1234567weather = input(&quot;ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ì–´ë•Œìš”?&quot;) if weather == &quot;ë¹„&quot;or&quot;ëˆˆ&quot;: print(&quot;ìš°ì‚°ì„ ì±™ê¸°ì„¸ìš”&quot;) elif weather == &quot;ë¯¸ì„¸ë¨¼ì§€&quot;: print(&quot;ë§ˆìŠ¤í¬ë¥¼ ì±™ê¸°ì„¸ìš”&quot;) else: print(&quot;ì¤€ë¹„ë¬¼ í•„ìš” ì—†ì–´ìš”&quot;) inputìë°”ì—ì„œ Scannerë¼ê³  ìƒê°í•˜ë©´ ëœë‹¤ê°’ì„ ì…ë ¥í•  ìˆ˜ ìˆë‹¤. inì„ ì‚¬ìš©í•œ ì¡°ê±´ë¬¸ì˜ì–´ë¡œ inì´ ~ì•ˆì—ë¼ëŠ” ëœ»ì„ ê°€ì§€ê³  ìˆëŠ”ë°, íŒŒì´ì¬ì—ì„œë„ ê°™ì€ ì˜ë¯¸ë¡œ ì‚¬ìš©ë˜ì–´ì§„ë‹¤ì•„ë˜ ì½”ë“œì—ì„œ 1ì´ [1, 2, 3, 4]ì•ˆì— ìˆìœ¼ë©´ True ì—†ìœ¼ë©´, Falseë¡œ ë°˜í™˜í•œë‹¤not in ì€ inì˜ ë°˜ëŒ€ì´ë‹¤ 121 in [1, 2, 3, 4]&gt;&gt; True passì¡°ê±´ë¬¸ì—ì„œ ì•„ë¬´ ì¼ë„ í•˜ì§€ ì•Šê²Œ ì„¤ì • í•  ìˆ˜ ìˆë‹¤ 123456789weather = input(&quot;ì˜¤ëŠ˜ì˜ ë‚ ì”¨ëŠ”?&quot;)if 'ë¹„' in weather: print(&quot;ìš°ì‚°ì„ ì¤€ë¹„í•˜ì„¸ìš”&quot;)elif 'ëˆˆ' in weather: print(&quot;ìš°ì‚°ì„ ì¤€ë¹„í•˜ì„¸ìš”&quot;)elif 'í•´' in weather: print(&quot;ì¤€ë¹„ë¬¼ì´ ì—†ìŠµë‹ˆë‹¤&quot;)else: pass whilejavaì—ì„œ whileë¬¸ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ê³¼ í¬ê²Œ ë‹¤ë¥´ì§€ ì•Šë‹¤ 123456a = 0while a &lt; 10: a = a + 1``` print(a) if a == 10:&lt;br&gt; pass ì•„ë˜ëŠ” ì»¤í”¼ ì£¼ë¬¸ ìíŒê¸°ë¥¼ êµ¬í˜„í•œê²ƒì´ë‹¤ 12345678910111213coffee = 100while True: order = input(&quot;ì£¼ë¬¸í•  ì»¤í”¼ ê°œìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”. &quot;) coffee = coffee - int(order) if coffee &gt; 0: print(&quot;ë‚¨ì€ ì»¤í”¼ëŠ” %dì”ì…ë‹ˆë‹¤. &quot; %coffee) elif coffee == 0: print(&quot;ë‚¨ì€ ì»¤í”¼ëŠ” %dì”ì…ë‹ˆë‹¤. &quot; %coffee) break else: coffee = coffee + int(order) print(&quot;ì¬ê³ ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•˜ì„¸ìš”.&quot;) 1234567customer = &quot;ì†ë‹˜&quot;i = 5while i &gt;= 1: print(&quot;{0}, ì»¤í”¼ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. {1}ë²ˆ ë‚¨ì•˜ì–´ìš”.&quot;.format(customer, i)) i -= 1 if i == 0: print(&quot;ì»¤í”¼ëŠ” íê¸°ì²˜ë¶„ ë˜ì—ˆìŠµë‹ˆë‹¤&quot;) ì†ë‹˜, ì»¤í”¼ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. 5ë²ˆ ë‚¨ì•˜ì–´ìš”. ì†ë‹˜, ì»¤í”¼ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. 4ë²ˆ ë‚¨ì•˜ì–´ìš”. ì†ë‹˜, ì»¤í”¼ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. 3ë²ˆ ë‚¨ì•˜ì–´ìš”. ì†ë‹˜, ì»¤í”¼ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. 2ë²ˆ ë‚¨ì•˜ì–´ìš”. ì†ë‹˜, ì»¤í”¼ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. 1ë²ˆ ë‚¨ì•˜ì–´ìš”. ì»¤í”¼ëŠ” íê¸°ì²˜ë¶„ ë˜ì—ˆìŠµë‹ˆë‹¤ forë¬¸ì˜ ê¸°ë³¸êµ¬ì¡° for ë³€ìˆ˜ in ë¦¬ìŠ¤íŠ¸(ë˜ëŠ” íŠœí”Œ, ë¬¸ìì—´): ìˆ˜í–‰í•  ë¬¸ì¥1 ìˆ˜í–‰í•  ë¬¸ì¥2 123test = ['a', 'b', 'c']for i in test: print(i) a b c 12345678score = [100, 90, 60, 50, 40, 30]number = 0for i in score: number += 1 if i &lt; 60: print(&quot;{0}ë²ˆ í•™ìƒì€ ë¶ˆí•©ê²©ì…ë‹ˆë‹¤.&quot;.format(number)) else: print(&quot;{0}ë²ˆ í•™ìƒì€ í•©ê²©ì…ë‹ˆë‹¤.&quot;.format(number)) 1ë²ˆ í•™ìƒì€ í•©ê²©ì…ë‹ˆë‹¤. 2ë²ˆ í•™ìƒì€ í•©ê²©ì…ë‹ˆë‹¤. 3ë²ˆ í•™ìƒì€ í•©ê²©ì…ë‹ˆë‹¤. 4ë²ˆ í•™ìƒì€ ë¶ˆí•©ê²©ì…ë‹ˆë‹¤. 5ë²ˆ í•™ìƒì€ ë¶ˆí•©ê²©ì…ë‹ˆë‹¤. 6ë²ˆ í•™ìƒì€ ë¶ˆí•©ê²©ì…ë‹ˆë‹¤. 123a = [(1,2), (3,4), (5,6)]for (first, last) in a: print(first + last) 3 7 11 forë¬¸ì—ì„œ range í•¨ìˆ˜ rangeìˆ«ì ë¦¬ìŠ¤íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ëŠ” í•¨ìˆ˜ ì•„ë˜ëŠ” 0ë¶€í„° 10ë¯¸ë§Œì˜ ìˆ«ìë¥¼ í¬í•¨í•˜ëŠ” range ê°ì²´ë¥¼ ë§Œë“¤ì–´ì¤€ë‹¤ 123a = range(10)a&gt;&gt; range(0, 10) ì´ë¥¼ forë¬¸ì—ì„œ ì‚¬ìš©í•´ë³´ì 123for i in range(1, 6): #1,2,3,4,5print(i) 1 2 3 4 5 len(marks)ëŠ” 5, number ë³€ìˆ˜ì—ëŠ” 0ì—ì„œ 4ê¹Œì§€ ìˆ«ìê°€ ëŒ€ì…ë  ê²ƒì´ë‹¤. marks[number]ëŠ” ì°¨ë¡€ë¡œ 90, 25, 67, 45, 80 ê°’ì„ ê°€ì§€ê²Œ ëœë‹¤ 12345marks = [90, 25, 67, 45, 80]for number in range(len(marks)): if marks[number] &lt; 60: continue print(&quot;%dë²ˆ í•™ìƒ ì¶•í•˜í•©ë‹ˆë‹¤. í•©ê²©ì…ë‹ˆë‹¤.&quot; % (number+1)) **** Refë‚˜ë„ì½”ë”©ì í”„íˆ¬íŒŒì´ì¬","link":"/2021/12/07/python05-%EB%B0%98%EB%B3%B5%EB%AC%B8%EC%A1%B0%EA%B1%B4%EB%AC%B8/"},{"title":"íŒŒì´ì¬ List comprehension","text":"List comprehension ë¦¬ìŠ¤íŠ¸ë¥¼ ì‰½ê²Œ ìƒì„±í•˜ê¸° ìœ„í•œ ë°©ë²•ìœ¼ë¡œ ì•„ë˜ì™€ ê°™ì€ í˜•ì‹ì„ ê°–ëŠ”ë‹¤ [ì¶œë ¥í‘œí˜„ì‹ for ìš”ì†Œ in ì…ë ¥Sequence [if ì¡°ê±´ì‹]] 1234oldlist = [1,2,'A',False,3]newlist = [i*i for i in oldlist if type(i)==int]print(newlist)&gt;&gt; [1, 4, 9] ìœ„ì˜ ì˜ˆì‹œë¥¼ í•´ì„í•´ë³´ì.oldlistì˜ ë¦¬ìŠ¤íŠ¸ ê°’ì´ ì¡°ê±´ë¬¸ì„ ë§Œì¡±í•œë‹¤ë©´, ë§Œì¡±í•œ ë¦¬ìŠ¤íŠ¸ ê°’ë§Œ iì— ìˆœì°¨ ì ìœ¼ë¡œ ëŒ€ì…í•œë‹¤.ëŒ€ì…ëœ i ê°’ìœ¼ë¡œ, ì—°ì‚°ì‹ì¸ â€œi*iâ€ë¥¼ ì‹¤í–‰í•˜ì—¬ ê³„ì‚°í•˜ê³ , ê·¸ì— ëŒ€í•œ ê²°ê³¼ë¥¼ newlistì¸ ë¦¬ìŠ¤íŠ¸ë¡œ ì–»ê²Œ ëœë‹¤ 12345a = [1,2,3,4]result = [num * 3 for num in a]print(result)&gt;&gt; [3, 6, 9, 12] Ref ë¸”ë¡œê·¸ì í”„íˆ¬íŒŒì´ì¬","link":"/2021/12/08/python06-listcomprehension/"},{"title":"íŒŒì´ì¬ Class","text":"í´ë˜ìŠ¤ì™€ ê°ì²´ í´ë˜ìŠ¤ëŠ” ë¶•ì–´ë¹µ í‹€ì— ë¹„ìœ ë¥¼ í•  ìˆ˜ ìˆë‹¤.ë¶•ì–´ë¹µ í‹€ë¡œ ìˆ˜ë°±ê°œì˜ ë¶•ì–´ë¹µì„ ë§Œë“¤ì–´ ë‚¼ ìˆ˜ ìˆë“¯ì´ í´ë˜ìŠ¤ë¡œ ë§ì€ ê°ì²´ë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤.ìŠ¤íƒ€í¬ë˜í”„íŠ¸ ê²Œì„ì˜ ì˜ˆë¡œ ë“¤ë©´ í´ë˜ìŠ¤ë¥¼ ì´ìš©í•´ì„œ ìˆ˜ë°±ê°œì˜ ìœ ë‹›ì„ ë§Œë“¤ ìˆ˜ ìˆëŠ”ê²ƒì´ë‹¤. ë˜ í•œê°€ì§€ ì˜ˆë¥¼ ë“¤ë©´ í´ë˜ìŠ¤ëŠ” ì„¤ê³„ ë„ë©´ì´ê³ , ê°ì²´ëŠ” í´ë˜ìŠ¤(ì„¤ê³„ ë„ë©´)ì„ ì´ìš©í•´ ë§Œë“  ì–´ë– í•œ í”¼ì¡°ë¬¼ì´ë‹¤. ë”°ë¼ì„œ í´ë˜ìŠ¤ë¥¼ ì‹¤ì²´í™” í•œê²ƒì´ë‹¤ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ  ê¸€ë¡œë²Œ ë³€ìˆ˜ë¥¼ ì—†ì• ê³ , ëª¨ë“  ë³€ìˆ˜ë¥¼ ì–´ë– í•œ ìŠ¤ì½”í”„ì— ì†Œì†ì‹œí‚¨ë‹¤ ëª‡ë²ˆì´ê³  ì¬ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤ ì½”ë“œì˜ ìˆ˜ì •ì„ ìµœì†Œí™”í•œë‹¤ í•¨ìˆ˜ ì‹¤í–‰ì¤‘ì—, í•¨ìˆ˜ ìì‹ ì„ ë‹¤ì‹œ í˜¸ì¶œí•˜ëŠ” ì²˜ë¦¬ ë“±ì´ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤ ìŠ¤íƒ€í¬ë˜í”„íŠ¸ ì˜ˆì‹œ 1234567891011class Unit: def __init__(self, name, hp, damage): self.name = name self.hp = hp self.damage = damage print(&quot;{0}ìœ ë‹›ì´ ìƒì„± ë˜ì—ˆìŠµë‹ˆë‹¤.&quot;.format(self.name)) print(&quot;ì²´ë ¥ {0}, ê³µê²©ë ¥ {1}&quot;.format(self.hp, self.damage))marine1 = Unit(&quot;ë§ˆë¦°&quot;, 40, 5)marine2 = Unit(&quot;ë§ˆë¦°&quot;, 40, 5)tank = Unit(&quot;íƒ±í¬&quot;, 150, 3) ìœ„ì˜ ì˜ˆì‹œì—ì„œëŠ” marine1, marine2, tankë¼ëŠ” ê°ì²´ë¥¼ ìƒì„±í•œ ê²ƒì´ë‹¤.ê°ê°ì˜ ê°ì²´ëŠ” ê°ìì˜ íŠ¹ì§•ì„ ê°€ì¡Œë‹¤.-&gt; ë§¤ê°œ ë³€ìˆ˜ ê°’ì´ ë‹¤ë¦„marine1, marine2, tank ëŠ” Unit í´ë˜ìŠ¤ì˜ ì¸ìŠ¤í„´ìŠ¤ì´ë‹¤.ì¸ìŠ¤í„´ìŠ¤ì™€ ê°ì²´ì˜ ì°¨ì´ëŠ” ì¸ìŠ¤í„´ìŠ¤ëŠ” í´ë˜ìŠ¤ì™€ ê°ì²´ì˜ ê´€ê³„ë¥¼ ìœ„ì£¼ë¡œ ì„¤ëª…í• ë•Œ ì‚¬ìš©ëœë‹¤.â€˜Unit í´ë˜ìŠ¤ì˜ ê°ì²´â€™ ë¼ëŠ” í‘œí˜„ë³´ë‹¤ëŠ” â€˜Unit í´ë˜ìŠ¤ì˜ ì¸ìŠ¤í„´ìŠ¤â€™ ë¼ëŠ” í‘œí˜„ì„ ì“´ë‹¤. init __init__ë€ ìë°”ì—ì„œ ìƒì„±ì ì—­í• ì„ í•˜ëŠ” ë©”ì„œë“œì´ë‹¤. ê°ì²´ê°€ ë§Œë“¤ì–´ì§ˆë•Œ ìë™ìœ¼ë¡œ í˜¸ì¶œë˜ì–´ì§„ë‹¤. (ìƒì„±ìë€ ê°ì²´ê°€ ìƒì„±ë ë•Œ ìë™ìœ¼ë¡œ í˜¸ì¶œë˜ëŠ” ë©”ì„œë“œë¥¼ ì˜ë¯¸í•œë‹¤) ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì´ˆê¸°í™” í•´ì¤€ë‹¤ê³  ìƒê° self selfëŠ” ìê¸° ìì‹ ì„ ì˜ë¯¸í•˜ê³ , ì¦‰ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê°€ë¦¬í‚¨ë‹¤ selfëŠ” ìë°”ì—ì„œ thisì™€ ê°™ë‹¤. ë©”ì†Œë“œ ì•„ë˜ëŠ” attak, damaged ë¼ëŠ” ë©”ì†Œë“œë¥¼ ë§Œë“¤ì—ˆê³ ê°ì²´ì—ì„œ ë©”ì†Œë“œë¥¼ ë¶ˆëŸ¬ì™€ ì‚¬ìš©í•´ë³´ì•˜ë‹¤ 12345678910111213141516171819202122class AttackUnit: def __init__(self, name, hp, damage): self.name = name self.hp = hp self.damage = damage def attack(self, location): print(&quot;{0} : {1} ë°©í–¥ìœ¼ë¡œ ì êµ°ì„ ê³µê²¨ê°‘ë‹ˆë‹¤. [ê³µê²©ë ¥ {2}]&quot;\\ .format(self.name, location, self.damage)) def damaged(self, damage): print(&quot;{0} : {1} ë°ë¯¸ì§€ë¥¼ ì…ì—ˆìŠµë‹ˆë‹¤.&quot;.format(self.name, damage)) self.hp -= damage print(&quot;{0} : í˜„ì¬ ì²´ë ¥ì€ {1} ì…ë‹ˆë‹¤. &quot;.format(self.name, self.hp)) if self.hp &lt;= 0: print(&quot;{0} : íŒŒê´´ë˜ì—ˆìŠµë‹ˆë‹¤. &quot;.format(self.name))firebat1 = AttackUnit(&quot;íŒŒì´ì–´ë±ƒ&quot;, 50, 16)firebat1.attack(&quot;5ì‹œ&quot;)firebat1.damaged(25)firebat1.damaged(25) íŒŒì´ì–´ë±ƒ : 5ì‹œ ë°©í–¥ìœ¼ë¡œ ì êµ°ì„ ê³µê²¨ê°‘ë‹ˆë‹¤. [ê³µê²©ë ¥ 16] íŒŒì´ì–´ë±ƒ : 25 ë°ë¯¸ì§€ë¥¼ ì…ì—ˆìŠµë‹ˆë‹¤. íŒŒì´ì–´ë±ƒ : í˜„ì¬ ì²´ë ¥ì€ 25 ì…ë‹ˆë‹¤. íŒŒì´ì–´ë±ƒ : 25 ë°ë¯¸ì§€ë¥¼ ì…ì—ˆìŠµë‹ˆë‹¤. íŒŒì´ì–´ë±ƒ : í˜„ì¬ ì²´ë ¥ì€ 0 ì…ë‹ˆë‹¤. íŒŒì´ì–´ë±ƒ : íŒŒê´´ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒì† í´ë˜ìŠ¤ AttackUnitì€ Unitì„ ìƒì† ë°›ì•˜ë‹¤. 123456789101112class Unit: def __init__(self, name, hp): self.name = name self.hp = hp class AttackUnit(Unit): #ìƒì† def __init__(self, name, hp, damage): #self.name = name #self.hp = hp Unit.__init__(self, name, hp) self.damage = damage ë‹¤ì¤‘ìƒì† ë¶€ëª¨ê°€ ë‘˜ì´ì—¬ì„œ ìì‹ì´ ì—¬ëŸ¬ê³³ì—ì„œ ìƒì†ì„ ë°›ëŠ”ë‹¤ê³  ìƒê°í•˜ë©´ ëœë‹¤.ì•„ë˜ ì˜ˆì‹œì—ì„œ FlyableAttackUnitì€ AttackUnitê³¼ Flyableì„ ìƒì†ë°›ëŠ”ë‹¤. 123456789101112131415161718192021222324252627282930313233343536373839class Unit: def __init__(self, name, hp): self.name = name self.hp = hp class AttackUnit(Unit): #ìƒì† def __init__(self, name, hp, damage): #self.name = name #self.hp = hp Unit.__init__(self, name, hp) self.damage = damage def attack(self, location): print(&quot;{0} : {1} ë°©í–¥ìœ¼ë¡œ ì êµ°ì„ ê³µê²©í•©ë‹ˆë‹¤. [ê³µê²©ë ¥ {2}]&quot;\\ .format(self.name, location, self.damage)) def damaged(self, damage): print(&quot;{0} : {1} ë°ë¯¸ì§€ë¥¼ ì…ì—ˆìŠµë‹ˆë‹¤.&quot;.format(self.name, damage)) self.hp -= damage print(&quot;{0} : í˜„ì¬ ì²´ë ¥ì€ {1} ì…ë‹ˆë‹¤. &quot;.format(self.name, self.hp)) if self.hp &lt;= 0: print(&quot;{0} : íŒŒê´´ë˜ì—ˆìŠµë‹ˆë‹¤. &quot;.format(self.name))class Flyable: def __init__(self, flying_speed): self.flying_speed = flying_speed def fly(self, name, location): print(&quot;{0} : {1} ë°©í–¥ìœ¼ë¡œ ë‚ ì•„ê°‘ë‹ˆë‹¤. [ì†ë„ {2}]&quot; \\ .format(name, location, self.flying_speed))class FlyableAttackUnit(AttackUnit, Flyable): def __init__(self, name, hp, damage, flying_speed): AttackUnit.__init__(self, name, hp, damage) Flyable.__init__(self, flying_speed) valkyrie = FlyableAttackUnit(&quot;ë°œí‚¤ë¦¬&quot;,200, 6, 5)valkyrie.fly(valkyrie.name, &quot;3ì‹œ&quot;) Super ì›ë˜ëŠ” ìƒì† ë°›ì„ë•Œ ì•„ë˜ì™€ ê°™ì´ ì ì—ˆì§€ë§Œ, Unit.__init__(self, name, hp) superë¥¼ ì´ìš©í•´ì„œ ë” ê°„ë‹¨í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ì´ë•Œ selfë¥¼ ì œê±°í•˜ê³  ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ super().__init__(name, hp, 0) 12345678910class Unit: def __init__(self, name, hp): self.name = name self.hp = hp class AttackUnit(Unit): #ìƒì† def __init__(self, name, hp, damage): #Unit.__init__(self, name, hp) super().__init__(name, hp, 0) self.damage = damage í•˜ì§€ë§Œ ë‹¤ì¤‘ ìƒì†ì—ì„œëŠ” ë¬¸ì œê°€ ë°œìƒí•œë‹¤. ì•„ë˜ ì˜ˆì œì—ì„œëŠ” FlyableUnitì´ Unitê³¼ Flyableì„ ë‹¤ì¤‘ ìƒì†ë°›ëŠ”ë‹¤ì´ë•Œ ì•„ë˜ì™€ ê°™ì´ super()ë¥¼ í†µí•´ ìƒì†ì„ í•´ì£¼ê²Œ ë˜ë©´â€œclass FlyableUnit(Flyable, Unit):â€ Flyableì„ ë¨¼ì € ì„ ì–¸í•´ì¤¬ê¸° ë•Œë¬¸ì—Flyable ìƒì„±ìë¼ê³  ì‹¤í–‰ ê²°ê³¼ê°€ ë‚˜ì˜¤ê²Œ ëœë‹¤ (Unit ìƒì„±ìê°€ í˜¸ì¶œì´ ì•ˆë¨) ë”°ë¼ì„œ Unit.init(self), Flyable.init(self) ë¡œ ìƒì†ì„ í•´ì¤„ ìˆ˜ ìˆë‹¤. 123456789101112131415class Unit: def __init__(self): print(&quot;Unit ìƒì„±ì&quot;) class Flyable: def __init__(self): print(&quot;Flyable ìƒì„±ì&quot;) class FlyableUnit(Flyable, Unit): def __init__(self): #super().__init__() Unit.__init__(self) Flyable.__init__(self) dropship = FlyableUnit() Refë‚˜ë„ì½”ë”©ì í”„íˆ¬íŒŒì´ì¬(https://engineer-mole.tistory.com/190)","link":"/2021/12/09/python08-class/"},{"title":"íŒŒì´ì¬ ì§‘í•©","text":"ì§‘í•©(Set)ì´ë€ ì§‘í•©ì€ íŒŒì´ì¬ 2.3ë¶€í„° ì§€ì›í•˜ê¸° ì‹œì‘í•œ ìë£Œí˜•ìœ¼ë¡œ, ì§‘í•©ì— ê´€ë ¨ëœ ê²ƒì„ ì‰½ê²Œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ë§Œë“  ìë£Œí˜•ì´ë‹¤. íŠ¹ì§• ì§‘í•©ì€ ì¤‘ë³µì„ í—ˆìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ ìˆœì„œê°€ ì—†ë‹¤ (ì¸ë±ì‹±ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ”ë‹¤) ì§‘í•© í˜•íƒœ setì´ë¼ëŠ” í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•´ ë§Œë“¤ ìˆ˜ ìˆë‹¤ 123456789my_set1 = set{[1,2,3]}my_set1&gt;&gt; {1,2,3}my_set2 = {1,2,3,4,5}my_set2&gt;&gt; {1,2,3,4,5}my_set3 = {1,2,3,4,4,4} my_set3&gt;&gt; {1,2,3,4} #ì¤‘ë³µì„ í—ˆìš©í•˜ì§€ ì•Šì•„ì„œ ì§¤ë¦¼ ë¬¸ìì—´ì„ ì…ë ¥í•˜ì—¬ ì§‘í•©ì„ ë§Œë“¤ ìˆ˜ë„ ìˆë‹¤ 123s1 = set(&quot;jeewon&quot;)s1&gt;&gt; {'e', 'j', 'n', 'o', 'w'} #ìˆœì„œê°€ ì—†ë‹¤ ì§‘í•©ì„ ì¸ë±ì‹± í•˜ë ¤ë©´?ì§‘í•©ì€ ìˆœì„œê°€ ì—†ê¸° ë•Œë¬¸ì— ì¸ë±ì‹±ìœ¼ë¡œ ê°’ì„ ì–»ëŠ”ê²Œ ë¶ˆê°€ëŠ¥í•˜ë‹¤í•˜ì§€ë§Œ ì´ë•Œ íŠœí”Œì´ë‚˜ ë¦¬ìŠ¤íŠ¸ë¡œ ê°’ì„ ë³€í™˜í•˜ë©´ ì¸ë±ì‹±ì´ ê°€ëŠ¥í•˜ë‹¤ì•„ë˜ëŠ” ì§‘í•©ì„ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œë¡œ ë³€í™˜í•œê²ƒì´ë‹¤ 123456s_li = list(my_set)s_li&gt;&gt; [1, 2, 3]s_tu = tuple(my_set)s_tu&gt;&gt; (1, 2, 3) êµì§‘í•©, í•©ì§‘í•©, ì°¨ì§‘í•©ì•„ë˜ëŠ” ìë°”ì™€ íŒŒì´ì¬ì„ ì‚¬ìš©í• ì¤„ ì•„ëŠ” ê°œë°œìë¥¼ ì§‘í•©ìœ¼ë¡œ ì •ì˜í•œê²ƒì´ë‹¤ 12java = {&quot;ê¹€ë•¡ë•¡&quot;, &quot;ë°•ë•¡ë•¡&quot;, &quot;ì´ë•¡ë–™&quot;}python = {&quot;ê¹€ë•¡ë•¡&quot;, &quot;ê°•ë•¡ë•¡&quot;} êµì§‘í•©javaì™€ pythonì„ ëª¨ë‘ í•  ì¤„ ì•„ëŠ” ê°œë°œì1234print(java &amp; python)print(java.intersection(python))&gt;&gt; {'ê¹€ë•¡ë•¡'}&gt;&gt; {'ê¹€ë•¡ë•¡'} í•©ì§‘í•©javaë¥¼ í• ìˆ˜ìˆê±°ë‚˜ pythonì„ í•  ìˆ˜ ìˆëŠ” ê°œë°œì1234print(java | python)&gt;&gt; {'ë°•ë•¡ë•¡', 'ê¹€ë•¡ë•¡', 'ê°•ë•¡ë•¡', 'ì´ë•¡ë–™'}print(java.union(python))&gt;&gt; {'ë°•ë•¡ë•¡', 'ê¹€ë•¡ë•¡', 'ê°•ë•¡ë•¡', 'ì´ë•¡ë–™'} ì°¨ì§‘í•©javaëŠ” í•  ì¤„ ì•Œì§€ë§Œ pythonì€ í•  ì¤„ ëª¨ë¥´ëŠ” ê°œë°œì1234print(java - python)&gt;&gt; {'ì´ë•¡ë–™', 'ë°•ë•¡ë•¡'}print(java.difference(python))&gt;&gt; {'ì´ë•¡ë–™', 'ë°•ë•¡ë•¡'} ì§‘í•© ì¶”ê°€ì™€ ì‚­ì œaddë¥¼ ì´ìš©í•´ì„œ ì¶”ê°€í•  ìˆ˜ ìˆë‹¤pythonì„ í•  ì¤„ ì•„ëŠ” ì‚¬ëŒì´ ëŠ˜ì–´ë‚¨ 123python.add(&quot;ìœ¤ë•¡ë•¡&quot;)print(python)&gt;&gt; {'ìœ¤ë•¡ë•¡', 'ê¹€ë•¡ë•¡', 'ê°•ë•¡ë•¡'} updateë¥¼ ì´ìš©í•´ì„œ ì—¬ëŸ¬ê°œë¥¼ í•œë²ˆì— ì¶”ê°€í•  ìˆ˜ë„ ìˆë‹¤ì´ë•Œ ëŒ€ê´„í˜¸[]ë¡œ ë¬¶ì–´ì£¼ì§€ ì•Šìœ¼ë©´ {â€˜ë°•â€™, â€˜ë•¡â€™}ì´ ì¶”ê°€ëœë‹¤ 1234c = {&quot;ê¹€ë•¡ë•¡&quot;}c.update([&quot;ë°•ë•¡ë•¡&quot;])c&gt;&gt; {'ê¹€ë•¡ë•¡', 'ë°•ë•¡ë•¡'} removeë¥¼ ì´ìš©í•´ì„œ ì‚­ì œí•  ìˆ˜ ìˆë‹¤ìë°”ë¥¼ ê¹Œë¨¹ì€ ê¹€ë•¡ë•¡â€¦. ì€ ë°”ë¡œ ë‚˜ 123java.remove(&quot;ê¹€ë•¡ë•¡&quot;)java&gt;&gt; {'ë°•ë•¡ë•¡', 'ì´ë•¡ë–™'} Refë‚˜ë„ì½”ë”©ì í”„íˆ¬íŒŒì´ì¬","link":"/2021/12/06/python04-set/"},{"title":"íŒŒì´ì¬ Method","text":"íŒŒì´ì¬ í•¨ìˆ˜ íŒŒì´ì¬ì—ì„œëŠ” defë¡œ í•¨ìˆ˜ë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤.ê·¸ ë‹¤ìŒ í•¨ìˆ˜ì´ë¦„ì„ ì ê³  ì½œë¡ (:)ìœ¼ë¡œ ë§ˆë¬´ë¦¬ í•´ì¤€ë‹¤.í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ â€˜í•¨ìˆ˜ì´ë¦„()â€™ ë°©ë²•ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆë‹¤. def í•¨ìˆ˜ëª…(ë§¤ê°œë³€ìˆ˜): &lt;ìˆ˜í–‰í•  ë¬¸ì¥1&gt; &lt;ìˆ˜í–‰í•  ë¬¸ì¥2&gt; ... 12345678def multiply(a, b): return a*ba = 3b = 4c = multiply(a,b)print(c)&gt;&gt; 12 12345678910111213141516171819202122def deposit(balance, money): print(&quot;ì…ê¸ˆì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì”ì•¡ì€ {0}ì› ì…ë‹ˆë‹¤.&quot;.format(balance + money)) return balance + moneydef withdraw(balance, money): if balance &gt;= money: print(&quot;ì¶œê¸ˆì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì”ì•¡ì€ {0}ì› ì…ë‹ˆë‹¤. &quot;.format(balance - money)) return balance - money else: print(&quot;ì¶œê¸ˆì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì”ì•¡ì€ {0}ì› ì…ë‹ˆë‹¤.&quot;.format(balance)) return balancedef withdraw_night(balance, money): commission = 100 return commission, balance - money - commission #ì—¬ëŸ¬ê°œì˜ ê°’ë„ í•œë²ˆì— ë°˜í™˜ ê°€ëŠ¥ balance = 0balance = deposit(balance, 1000)balance = withdraw(balance, 2000)commission, balance = withdraw_night(balance, 500)print(&quot;ìˆ˜ìˆ˜ë£Œ {0}ì›ì´ë©°, ì”ì•¡ì€ {1}ì› ì…ë‹ˆë‹¤.&quot;.format(commission, balance)) ì…ê¸ˆì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì”ì•¡ì€ 1000ì› ì…ë‹ˆë‹¤. ì¶œê¸ˆì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì”ì•¡ì€ 1000ì› ì…ë‹ˆë‹¤. ìˆ˜ìˆ˜ë£Œ 100ì›ì´ë©°, ì”ì•¡ì€ 400ì› ì…ë‹ˆë‹¤. ê°€ë³€ì¸ì 12345678def profile(name, age, *language): print(&quot;ì´ë¦„: {0}\\të‚˜ì´: {1}\\t&quot;.format(name, age),end=&quot; &quot;) for lang in language: print(lang, end=&quot; &quot;) print() profile(&quot;ìœ ì¬ì„&quot;, 20, &quot;Python&quot;, &quot;Java&quot;, &quot;C&quot;, &quot;C++&quot;)profile(&quot;ê¹€íƒœí˜¸&quot;, 25, &quot;Kotlin&quot;, &quot;Swift&quot;) ì´ë¦„: ìœ ì¬ì„ ë‚˜ì´: 20 Python Java C C++ ì´ë¦„: ê¹€íƒœí˜¸ ë‚˜ì´: 25 Kotlin Swift Refë‚˜ë„ì½”ë”©ì í”„íˆ¬íŒŒì´ì¬","link":"/2021/12/08/python07-method/"},{"title":"ì„¤ì¹˜ í”„ë¡œê·¸ë¨ ë²„ì „ | ë¶€ìŠ¤íŠ¸ì½”ìŠ¤ ë°±ì—”ë“œ","text":"ì•„ë˜ëŠ” ë‚´ê°€ ë¶€ìŠ¤íŠ¸ì½”ìŠ¤ ê°•ì˜ë¥¼ ë“¤ìœ¼ë©´ì„œ ì„¤ì¹˜ í•œ í”„ë¡œê·¸ë¨ ë²„ì „ì´ë‹¤.êµ¬ì²´ì ìœ¼ë¡œ ì„¤ì¹˜ ì„¸íŒ… ì´ˆê¸°í™”ëŠ” ì˜ˆì „ì— ì •ë¦¬í•´ë‘” ë„¤ì´ë²„ ë¸”ë¡œê·¸ë¥¼ ë³´ë©´ì„œ í•˜ì. tomcatğŸ”— https://tomcat.apache.org/ Download -&gt; Tomcat8 -&gt; zip í†°ìº£8 ì„¤ì¹˜ EclipseğŸ”— https://www.eclipse.org/downloads/packages/release/2020-06/rì´í´ë¦½ìŠ¤ ë²„ì „ 2020-06 ìœ„ì˜ ì„¤ì¹˜ íŒŒì¼ì„ ì•„ë˜ ê²½ë¡œì— ë‹¤ìš´ë°›ì•˜ë‹¤ (ê´€ë¦¬ìš©ğŸ”—)C:\\JavaUtils ì´í´ë¦½ìŠ¤ ì´ˆê¸° ì„¤ì •window -&gt; perspective-&gt; open perspective-&gt; java EE í†°ìº£ ì´ˆê¸° ì„¤ì • í•´ì¤˜ì•¼í•¨í•˜ë‹¨ì— server í´ë¦­ -&gt; í†°ìº£ 8.5 ë§ì¶°ì„œ ì„¤ì •í•´ì£¼ê¸° í†°ìº£ 404 ì—ëŸ¬ í•´ê²°ë²•ì„œë²„íƒ­ì„ ë”ë¸”í´ë¦­í•˜ë©´ Overview ì°½ì´ ë‚˜ì˜¨ë‹¤server Locations -&gt; Use Tomcat installation (takes control of Tomcat installation) ORACLE ë‹¤ìš´ë¡œë“œ 11GğŸ”— https://www.oracle.com/database/technologies/xe-prior-release-downloads.htmlğŸ‘‰ ì˜¤ë¼í´ ë‹¤ìš´ë¡œë“œ ë°©ë²•","link":"/2022/01/03/boostcourse-version/"},{"title":"ë°ì´í„°ë² ì´ìŠ¤ | ë¶€ìŠ¤íŠ¸ì½”ìŠ¤ ë°±ì—”ë“œ 01","text":"ë¶€ìŠ¤íŠ¸ì½”ìŠ¤ì›¹ ë°±ì—”ë“œ ê³µë¶€ í•´ë³´ê¸°https://www.boostcourse.org/web326/joinLectures/28762ì¸í”„ëŸ° ê°•ì˜ë¥¼ ë“£ë‹¤ê°€ ë„ˆë¬´ ì–´ë ¤ì›Œì„œ ë¶€ìŠ¤íŠ¸ì½”ìŠ¤ì—ì„œ ë¬´ë£Œê°•ì˜ì¸ ë°±ì—”ë“œ ì½”ìŠ¤ë¥¼ ë¨¼ì € ë“¤ì–´ë³´ê¸°ë¡œ í•˜ì˜€ë‹¤. ë°ì´í„° ë² ì´ìŠ¤ë°ì´í„°ë“¤ì˜ ì§‘í•©ì²´ ë°ì´í„°ë² ì´ìŠ¤ì˜ íŠ¹ì„±ì‹¤ì‹œê°„ ì ‘ê·¼ì„±ê³„ì†ì ì¸ ë³€í™˜ë™ì‹œê³µìœ ì„±ë‚´ìš©ì°¸ì¡° DBMS (Database Management System)ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê´€ë¦¬í•˜ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê´€ë¦¬, ìš´ì˜í•˜ëŠ” ì‹œìŠ¤í…œì„ ì˜ë¯¸ë˜í•œ ì—¬ëŸ¬ ì‚¬ìš©ìë‚˜ í”Œê·¸ë¨ì´ ë°ì´í„°ë¥¼ ê³µìœ í•˜ê³  ë™ì‹œì— ì ‘ê·¼ì´ ê°€ëŠ¥í•´ì•¼í•¨ í•„ìˆ˜ 3ê¸°ëŠ¥ ì •ì˜ê¸°ëŠ¥: ë°ì´í„° ë² ì´ìŠ¤ì˜ ë…¼ë¦¬ì , ë¬¼ë¦¬ì  êµ¬ì¡°ë¥¼ ì •ì˜ì¡°ì‘ê¸°ëŠ¥: ë°ì´í„°ë¥¼ ê²€ìƒ‰, ì‚­ì œ, ê°±ì‹ , ì‚½ì…, ì‚­ì œí•˜ëŠ” ê¸°ëŠ¥ì œì–´ê¸°ëŠ¥: ë°ì´í„° ë² ì´ìŠ¤ì˜ ë‚´ìš© ì •í™•ì„±ê³¼ ì•ˆì „ì„±ì„ ìœ ì§€í•˜ë„ë¡ ì œì–´í•˜ëŠ” ê¸°ëŠ¥Oracle, SQL Server, MySQL, DB2 ë“±ì˜ ìƒìš© ë˜ëŠ” ê³µê°œ DBMSê°€ ìˆë‹¤ DBMS ì‹œìŠ¤í…œ ì¥/ë‹¨ì  ì¥ì ë°ì´í„° ì¤‘ë³µì´ ìµœì†Œí™”ë°ì´í„°ì˜ ì¼ê´€ì„± ë° ë¬´ê²°ì„± ìœ ì§€ë°ì´í„° ë³´ì•ˆ ë³´ì¥ ë‹¨ì ìš´ì˜ë¹„ê°€ ë¹„ì‹¸ë‹¤ë°±ì—… ë° ë³µêµ¬ì— ëŒ€í•œ ê´€ë¦¬ê°€ ë³µì¡ë¶€ë¶„ì  ë°ì´í„°ë² ì´ìŠ¤ ì†ì‹¤ì´ ì „ì²´ ì‹œìŠ¤í…œì„ ì •ì§€ DBMSì˜ íŠ¹ì§•ë°ì´í„°ì˜ ë¬´ê²°ì„± : ë°ì´í„°ë² ì´ìŠ¤ ë‚´ë¶€ì˜ ë°ì´í„°ëŠ” ì˜¤ë¥˜ê°€ ìˆì–´ì„  ì•ˆëœë‹¤.ë°ì´í„°ì˜ ë…ë¦½ì„± : ë°ì´í„°ì™€ ê·¸ê²ƒì„ ì‚¬ìš©í•˜ëŠ” ì‘ìš©í”„ë¡œê·¸ë¨ì€ ë…ë¦½ì ìœ¼ë¡œ ì‘ë™ë˜ì–´ì•¼í•œë‹¤.ë°ì´í„°ì˜ ì¤‘ë³µì˜ ìµœì†Œì„± : ë™ì¼í•œ ë°ì´í„°ê°€ ì¤‘ë³µë˜ì–´ ì €ì¥ë˜ëŠ”ê²ƒì„ ë°©ì§€í•œë‹¤.ë°ì´í„°ì˜ ë³´ì•ˆì„± : ë°ì´í„°ë² ì´ìŠ¤ ë‚´ë¶€ì˜ ë°ì´í„°ëŠ” ì•„ë¬´ë‚˜ ì ‘ê·¼í•  ìˆ˜ ì—†ê³  ë°ì´í„°ë¥¼ ì†Œìœ í•œ ì‚¬ëŒì´ë‚˜ ì ‘ê·¼ì´ í—ˆê°€ëœ ì‚¬ëŒë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ì•¼í•œë‹¤.ë°ì´í„°ì˜ ì•ˆì „ì„± : ë°±ì—…ê³¼ ë³µì› ê¸°ëŠ¥ì„ ì§€ì›í•¨ìœ¼ë¡œ ë°ì´í„°ê°€ ê¹¨ì§€ëŠ” ë¬¸ì œê°€ ë°œìƒì‹œ ì› ìƒíƒœë¡œ ë³µêµ¬ê°€ ê°€ëŠ¥í•´ì•¼í•œë‹¤. DBMSì˜ ìœ í˜•ê³„ì¸µí˜• DBMSë§í˜•(ë„¤íŠ¸ì›Œí¬í˜•) DBMSê´€ê³„í˜• DBMSê°ì²´ê´€ê³„í˜• DBMS ìš°ë¦¬ê°€ ì£¼ë¡œ ì‚¬ìš©í•˜ê²Œ ë  DBMSëŠ” ê´€ê³„í˜• ë°ì´í„° ë² ì´ìŠ¤ë¡œí…Œì´ë¸”ì´ë¼ëŠ” ìµœì†Œë‹¨ìœ„ë¡œ êµ¬ì„±ë¨í…Œì´ë¸”ì€ ë¦´ë ˆì´ì…˜ ì—”í‹°í‹° ë“±ìœ¼ë¡œë„ ë¶ˆë¦¼í…Œì´ë¸”ì€ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì €ì¥í•˜ê¸° ìœ„í•œ êµ¬ì¡°ì´ë‹¤ SQL (Structured Query Language)SQLì€ ë°ì´í„°ë¥¼ ë³´ë‹¤ ì‰½ê²Œ ê²€ìƒ‰í•˜ê³  ì¶”ê°€, ì‚­ì œ, ìˆ˜ì •ê°™ì€ ì¡°ì‘ì„ í•  ìˆ˜ ìˆë„ë¡ ê³ ì•ˆëœ ì»´í“¨í„° ì–¸ì–´ì´ë‹¤. ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´ë°ì´í„°ë¥¼ ì¡°ì‘í•˜ê¸° ìœ„í•œ ì–¸ì–´ë¡œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì™€ëŠ” ë‹¤ë¥´ë‹¤.êµ­ì œ í‘œì¤€í™” ê¸°êµ¬ì—ì„œ í‘œì¤€ì„ ì œì •í•œë‹¤.(ë‹¤ë§Œ DBMSë¥¼ ì œì‘í•˜ëŠ” íšŒì‚¬ë§ˆë‹¤ íŠ¹ì§•ì´ ìˆê¸° ë•Œë¬¸ì— ì™„ë²½í•˜ê²Œ ë™ì¼í•˜ì§€ ì•Šë‹¤)ëŒ€í™”ì‹ ì–¸ì–´ì´ë‹¤. ì§ˆì˜ë¥¼ í•˜ê³  ê²°ê³¼ë¥¼ ì–»ëŠ” êµ¬ì¡°ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ê´€ê³„í˜• ë°ì´í„° ë² ì´ìŠ¤ëŒ€í‘œì ìœ¼ë¡œ oracle, mySQL, SQL server, MariaDB ë°ì´í„°ë² ì´ìŠ¤ ìš©ì–´ë°ì´í„° ë² ì´ìŠ¤ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ í˜„ì‹¤ì„¸ê³„ì˜ ë°ì´í„°ë¥¼ ì»´í“¨í„° ë°ì´í„°ë¡œ ì˜®ê²¨ ë†“ì€ ê³µê°„ì„ ì˜ë¯¸ ex)ëŒ€ìƒë¬¼ì€ ì—¬ëŸ¬ê°€ì§€ ì •ë³´ë¥¼ ê°€ì§„ë‹¤íšŒì›ì´ë¼ë©´ ì´ë¦„ ì£¼ë¯¼ë²ˆí˜¸ ì£¼ì†Œ ì „í™”ë²ˆí˜¸ì œí’ˆì´ë¼ë©´ ì œí’ˆëª… ê°€ê²© ì œì¡°ì¼ìì´ëŸ° ì •ë³´ë¥¼ ë‹¨ìˆœí•˜ê²Œ ì €ì¥í•˜ëŠ”ê²Œ ì•„ë‹ˆë¼ â€œí…Œì´ë¸”â€ ì´ë¼ëŠ” í˜•ì‹ì— ë§ì¶°ì„œ ì €ì¥ í…Œì´ë¸”ë°ì´í„°ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ êµ¬ì¡°ë¥¼ í‘œë¡œ í‘œí˜„ ìŠ¤í‚¤ë§ˆí…Œì´ë¸”, ë·° ë“±ì´ ì €ì¥ë˜ëŠ” ì €ì¥ì†Œë°ì´í„° ë² ì´ìŠ¤ì— ì €ì¥ë˜ëŠ” ë°ì´í„° êµ¬ì¡°ì™€ ì œì•½ì¡°ê±´ì„ ì •ì˜ë³´í†µ ì˜¤ë¼í´ì—ì„œëŠ” DB ì‚¬ìš©ì ì´ë¦„ê³¼ ë™ì¼ì‹œ í•´ì„œ ì‚¬ìš© ë°ì´í„°ë² ì´ìŠ¤ì—¬ëŸ¬ ìŠ¤í‚¤ë§ˆê°€ ì €ì¥ë˜ëŠ” ê³µê°„XEë²„ì „ì€ í•œë²ˆ í•œê°œì˜ ë°ì´í„° ë² ì´ìŠ¤ë§Œ ìš´ì˜ ê°€ëŠ¥standardì´ìƒ ë²„ì „ì€ ì—¬ëŸ¬ê°œì˜ ë°ì´í„° ë² ì´ìŠ¤ ìš´ì˜ ê°€ëŠ¥ í–‰(ë¡œìš°, ë ˆì½”ë“œ, íŠœí”Œ) - ì‹¤ì§ˆì ì¸ ë°ì´í„°ë¥¼ ì˜ë¯¸ì—´(ì»¬ëŸ¼, í•„ë“œ, ì†ì„±) - ë°ì´í„°ë¥¼ êµ¬ë¶„í•˜ê¸° ìœ„í•œ íŠ¹ì§•ë“¤ì„ ì»¬ëŸ¼ì´ë¼ê³  ë¶€ë¦„ ì°¨ìˆ˜(degree): ì†ì„±ì˜ ê°œìˆ˜ê¸°ìˆ˜(cardinality): íŠœí”Œì˜ ê°œìˆ˜ë„ë©”ì¸(domain): ì†ì„±ì´ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ê°’ì˜ ë²”ìœ„íŠ¸ëœì ì…˜: ë°ì´í„°ë² ì´ìŠ¤ì˜ ìƒíƒœë¥¼ ë³€í™”ì‹œí‚¤ëŠ” ë…¼ë¦¬ì  ê¸°ëŠ¥ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ì‘ì—…ì˜ ë‹¨ìœ„ ë°ì´í„° ì–¸ì–´ (SQL) ë°ì´í„° ì •ì˜ì–´ (DDL Data Manipulation Language) : ìŠ¤í‚¤ë§ˆë¥¼ ì •ì˜í•˜ê±°ë‚˜, ìˆ˜ì • ë˜ëŠ” ì‚­ì œí•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš© (ex INSERT, UPDATE, DELETE, SELECT) ë°ì´í„° ì¡°ì‘ì–´(DML Data Definition Language) : ë°ì´í„°ì˜ ì‚½ì… ì‚­ì œ ìˆ˜ì • ê²€ìƒ‰ ë“±ì˜ ì²˜ë¦¬ë¥¼ ìš”êµ¬í•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš© (ex CEATE, DROP, ALTER) ë°ì´í„° ì œì–´ì–´ (DCL Data Control Language) : ë‚´ë¶€ì ìœ¼ë¡œ í•„ìš”í•œ ê·œì¹™ì´ë‚˜ ê¸°ë²•ì„ ì •ì˜í•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš© (ex GRANT, REVOKE) MySQL ì„¤ì¹˜url ë§í¬ : https://www.mysql.com/downloads/ë¹„ë°€ë²ˆí˜¸ëŠ” ë¬´ì¡°ê±´ 1234 (ì§§ê²Œ í•˜ëŠ”ê²Œ ìµœê³ ë‹¤)ê°„ë‹¨í•œê²Œ ìµœê³ ë‹¤,,MySQLì€ ì„¤ì¹˜ë¶€ë¶„ì— ìˆì–´ì„œ ì–´ë ¤ìš´ ì ì€ ì—†ì—ˆë‹¤ íë¦„ëŒ€ë¡œ ì„¤ì¹˜í•˜ë©´ ëœë‹¤. í™˜ê²½ë³€ìˆ˜ì—ì„œ ì•„ë˜ì˜ MySQL ê²½ë¡œë¥¼ ì¶”ê°€í•´ì£¼ì—ˆë‹¤ (ê°ìì˜ ê²½ë¡œê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)C:\\Program Files\\MySQL\\MySQL Server 8.0\\bin ì„œë²„ ì‹¤í–‰ í™•ì¸ì„œë¹„ìŠ¤ë¼ê³  ê²€ìƒ‰ -&gt; MySQL ì°¾ê¸° -&gt; ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ì¤‘ì„ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤MySQLì´ ë™ì‘í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ í•´ë‹¹ ì„œë¹„ìŠ¤ì—ì„œ ì‹¤í–‰ì¤‘ ì´ë¼ê³  í‘œì‹œë˜ëŠ”ì§€ í™•ì¸í•´ë³´ì MySQL ì„œë²„ ì¢…ë£Œí•˜ê¸°ì„œë¹„ìŠ¤ì—ì„œ MySQL ìš°í´ë¦­ -&gt; ì¤‘ì§€MySQL ì„œë²„ ì •ì§€ ë¨ìœˆë„ìš°ê°€ ì‹¤í–‰ë ë•Œ ìë™ìœ¼ë¡œ ì‹¤í–‰ë˜ê¸¸ ì›í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´, ì‹œì‘ ìœ í˜• â€œìë™â€ì„ ìˆ˜ë™ìœ¼ë¡œ ë³€ê²½í•œ í›„ â€œí™•ì¸â€ë²„íŠ¼ì„ í´ë¦­ì´ ê²½ìš° ë§¤ë²ˆ ì‹œì‘ì„ ëˆŒëŸ¬ì•¼ ì„œë²„ê°€ ì‹¤í–‰ëœë‹¤. DBMSì— ë§ì€ ì‚¬ëŒë“¤ì´ ë™ì‹œì— ì ‘ì†í•´ì„œ ì‚¬ìš©í•˜ëŠ”ë°ì´ë•Œ ì„œë²„ê°€ ì¢…ë£Œëœë‹¤ë©´ë°ì´í„°ê°€ ë‚ ì•„ê°€ëŠ” ë¶ˆìƒì‚¬ê°€ ìƒê¸°ê±°ë‚˜, í•„ìš”í•œ ë°ì´í„°ë¥¼ ì „ë‹¬ ë°›ì§€ ëª»í•˜ì—¬ ì—¬ëŸ¬ ì‚¬ëŒì´ ë™ì¼í•œ ë°ì´í„°ì—ì ‘ê·¼í•  ìˆ˜ ì—†ëŠ” ìƒí™©ì´ ë°œìƒí•œë‹¤. Database ìƒì„±í•˜ê¸°cmd ì°½ì—ì„œ ì‹¤í–‰í•´ë³´ì MySQL ê´€ë¦¬ì ê³„ì •ì¸ rootë¡œ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ ì‹œìŠ¤í…œì— ì ‘ì†í•˜ê² ë‹¤ëŠ” ê²ƒ mysql -uroot -p connecdb ë°ì´í„° ë² ì´ìŠ¤ ìƒì„± create database connectdb; ê¶Œí•œì£¼ê¸°Databaseë¥¼ ìƒì„±í–ˆë‹¤ë©´, í•´ë‹¹ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ëŠ” ê³„ì •ì„ ìƒì„±í•´ì•¼í•œë‹¤.ë˜í•œ í•´ë‹¹ ê³„ì •ì´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì´ìš©í•  ìˆ˜ ìˆëŠ” ê¶Œí•œì„ ì¤˜ì•¼í•œë‹¤.ì•„ë˜ì™€ ê°™ì€ ëª…ë ¹ì„ ì´ìš©í•´ì„œ ì‚¬ìš©ì ìƒì„±ê³¼ ê¶Œí•œì„ ì¤„ ìˆ˜ ìˆë‹¤.dbì´ë¦„ ë’¤ì˜ *ëŠ” ëª¨ë“  ê¶Œí•œì„ ì˜ë¯¸@â€™%â€™ëŠ” ì–´ë–¤ í´ë¼ì´ì–¸íŠ¸ì—ì„œë“  ì ‘ê·¼ ê°€ëŠ¥í•˜ë‹¤ëŠ” ì˜ë¯¸@â€™localhostâ€™ëŠ” í•´ë‹¹ ì»´í“¨í„°ì—ì„œë§Œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë‹¤ëŠ” ì˜ë¯¸fush privilegesëŠ” DBMSì—ê²Œ ì ìš©ì„ í•˜ë¼ëŠ” ì˜ë¯¸ì´ë¯€ë¡œ ë°˜ë“œì‹œ ì‹¤í–‰í•´ì•¼í•¨ ì‚¬ìš©ì ê³„ì •ì´ë¦„ì€ connectuser, ì•”í˜¸ëŠ” connect123!@#ìœ¼ë¡œ ì„¤ì • grant all privileges on connectdb.* to connectuser@â€™localhostâ€™ identified by â€˜connect123!@#â€™; ê·¸ëŸ°ë° ì—¬ê¸°ì„œ ì—ëŸ¬ê°€ ë‚¬ë‹¤ ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'identified by 'connect123!@#'' at line 1 ì˜¤íƒ€ê°€ ìˆëŠ”ì§€ ìˆ˜ì‹­ë²ˆì„ í™•ì¸í•œ í›„ì°¾ì•„ë³´ë‹ˆ MySQL8ë¶€í„°ëŠ” grantë¡œ user ìƒì„±ì´ ë¶ˆê°€ëŠ¥ ì•„ë˜ ë°©ë°¥ìœ¼ë¡œ í•´ê²° CREATE USER connectuser@localhost IDENTIFIED BY 'connect123!@#'; GRANT ALL PRIVILEGES ON connectdb.* TO 'connectuser'@'localhost'; FLUSH PRIVILEGES: Databaseì— ì ‘ì†í•˜ê¸°mysql -hí˜¸ìŠ¤íŠ¸ëª… -uDBê³„ì •ëª… -p ë°ì´í„°ë² ì´ìŠ¤ì´ë¦„ mysql -h127.0.0.1 -uconnectuser -p connectdb mysql -uconnectuser -p connectdb SQL ì…ë ¥ í‚¤ì›Œë“œëŠ” ëŒ€ì†Œë¬¸ìë¥¼ êµ¬ë¶„í•˜ì§€ ì•ŠëŠ”ë‹¤ ì—¬ëŸ¬ë¬¸ì¥ì„ í•œì¤„ì— ì—°ì†ìœ¼ë¡œ ì…ë ¥ ê°€ëŠ¥ ë¼ì¸ìœ¼ë¡œ êµ¬ë¶„í•˜ì§€ ì•Šê³ , semicolon(;)ìœ¼ë¡œ êµ¬ë¬¸ \\c -&gt; ê¸´ ì¿¼ë¦¬ë¥¼ ì‘ì„±í•˜ë‹¤ ì¤‘ê°„ì— ì·¨ì†Œí•´ì•¼í•˜ëŠ” ê²½ìš° ë¶™ì—¬ì¤€ë‹¤ Database ì¢…ë£Œquit exit í˜„ì¬ ë‚ ì§œì™€ ë²„ì „ í™•ì¸select version(), current_date; DBMSì— ì¡´ì¬í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸show database í˜„ì¬ ì„œë²„ì— ì¡´ì¬í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì°¾ì•„ë³´ê¸° ìœ„í•´ì„œ SHOW statementë¥¼ ì‚¬ìš© ì‚¬ìš©ì¤‘ì¸ ë°ì´í„°ë² ì´ìŠ¤ ì „í™˜í•˜ê¸°Databaseë¥¼ ì„ íƒí•˜ê¸° ìœ„í•´ â€˜useâ€™ command ì‚¬ìš©: use mydb;ë°ì´í„° ë² ì´ìŠ¤ë¥¼ ì „í™˜í•˜ë ¤ë©´, ì´ë¯¸ ë°ì´í„° ë² ì´ìŠ¤ê°€ ì¡´ì¬í•´ì•¼í•˜ë©° í˜„ì¬ ì ‘ì†ì¤‘ì¸ ê³„ì •ì´í•´ë‹¹ ë°ì´í„° ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê¶Œí•œì´ ìˆì–´ì•¼í•œë‹¤. í…Œì´ë¸” (Table)ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ê³µê°„ ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ì˜ ì—‘ì…€(Excel)ì„ ì‹¤í–‰í•˜ë©´ í‘œê°€ ë‚˜ì˜µë‹ˆë‹¤. ì´ëŸ¬í•œ í‘œì— ê°ì¢… ê°’ì„ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ë„ ì—‘ì…€ì˜ í‘œì™€ ìœ ì‚¬í•œ í…Œì´ë¸”ì„ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—‘ì…€ê³¼ ë‹¤ë¥¸ ì ì€ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•´ë„ í…Œì´ë¸”ì€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ë ¤ë©´ í…Œì´ë¸”ì„ ìƒì„±í•˜ëŠ” SQLì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³ , í…Œì´ë¸”ì— ê°’ì„ ì €ì¥í•˜ë ¤ë©´ ì €ì¥í•˜ê¸° ìœ„í•œ SQLì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ###SQLì—°ìŠµì„ ìœ„í•œ í…Œì´ë¸” ìƒì„±ê³¼ ê°’ì˜ ì €ì¥ë°”íƒ•í™”ë©´ì— data í´ë”ë¥¼ ë§Œë“¤ê³  examples.sql íŒŒì¼ì„ ë‹¤ìš´ë°›ì•˜ë‹¤mysqlì„ ì¢…ë£Œí•˜ê³  (quit)data ë””ë ‰í„°ë¦¬ë¡œ ì´ë™ í•œ í›„ ì•„ë˜ ëª…ë ¹ë¬¸ì„ ì…ë ¥ mysql -uconnectuser -p connectdb &lt; examples.sql ë‹¤ì‹œ mysql ë¡œê·¸ì¸ mysql -uconnectuser -p connectdb í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ì— ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” ëª©ë¡ í™•ì¸í•˜ê¸° show tables í…Œì´ë¸” êµ¬ì¡°ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•œ DESCRIBE ëª…ë ¹ desc EMPLOYEE; ë°ì´í„° ì¡°ì‘ì–´ì˜ ì¢…ë¥˜SELECT ê²€ìƒ‰INSERT ì‚½ì…UPDATE ìˆ˜ì •DELETE ì‚­ì œ SELECT êµ¬ë¬¸ì˜ ê¸°ë³¸ ë¬¸í˜• SELECT ì¹¼ëŸ¼ëª… FROM í…Œì´ë¸”ëª…; ì»¬ëŸ¼ì— Alias ë¶€ì—¬í•˜ê¸°ì»¬ëŸ¼ì— ëŒ€í•œ ALIAS(ë³„ì¹­)ì„ ë¶€ì—¬í•´ì„œ ë‚˜íƒ€ë‚´ëŠ” ì¹¼ëŸ¼ì˜ HEADINGì„ ë³€ê²½í•  ìˆ˜ ìˆë‹¤. ì˜ˆì œ : employee í…Œì´ë¸”ì—ì„œ ì§ì›ì˜ ì‚¬ë²ˆ(empno), ì´ë¦„(name), ì§ì—…(job)ì„ ì¶œë ¥í•˜ì‹œì˜¤. select empno as ì‚¬ë²ˆ, name as ì´ë¦„, job as ì§ì—… from employee; ë¬¸ìì—´ ê²°í•©í•¨ìˆ˜ concat SELECT concat( empno, â€˜-â€˜, deptno) AS â€˜ì‚¬ë²ˆ-ë¶€ì„œë²ˆí˜¸â€™ FROM employee; ì¤‘ë³µí–‰ ì œê±° distinct select distinct deptno from employee; ì •ë ¬í•˜ê¸° order by select empno, name, job from employee order by name; íŠ¹ì • í–‰ ê²€ìƒ‰ whereì ˆemployee í…Œì´ë¸”ì—ì„œ ê³ ìš©ì¼(hiredate)ì´ 1981ë…„ ì´ì „ì˜ ì‚¬ì›ì´ë¦„ê³¼ ê³ ìš©ì¼ì„ ì¶œë ¥í•˜ì‹œì˜¤. select name, hiredate from employee where hiredate &lt; â€˜1981-01-01â€™; employee í…Œì´ë¸”ì—ì„œ ë¶€ì„œë²ˆí˜¸ê°€ 30ì¸ ì‚¬ì›ì´ë¦„ê³¼ ë¶€ì„œë²ˆí˜¸ë¥¼ ì¶œë ¥í•˜ì‹œì˜¤. select name, deptno from employee where deptno = 30; INemployee í…Œì´ë¸”ì—ì„œ ë¶€ì„œë²ˆí˜¸ê°€ 10ë˜ëŠ” 30ì¸ ì‚¬ì›ì´ë¦„ê³¼ ë¶€ì„œë²ˆí˜¸ë¥¼ ì¶œë ¥í•˜ì‹œì˜¤. select name, deptno from employee where deptno in (10, 30); LIKE í‚¤ì›Œë“œì™€ì¼ë“œ ì¹´ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ë¬¸ìë¥¼ í¬í•¨í•œ ê°’ì— ëŒ€í•œ ì¡°ê±´ì„ ì²˜ë¦¬%ëŠ” 0ì—ì„œë¶€í„° ì—¬ëŸ¬ê°œì˜ ë¬¸ìì—´ì„ ë‚˜íƒ€ëƒ„_ëŠ” ë‹¨ í•˜ë‚˜ì˜ ë¬¸ìë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì™€ì¼ë“œ ì¹´ë“œ employee í…Œì´ë¸”ì—ì„œ ì´ë¦„ì— â€˜Aâ€™ê°€ í¬í•¨ëœ ì‚¬ì›ì˜ ì´ë¦„(name)ê³¼ ì§ì—…(job)ì„ ì¶œë ¥í•˜ì‹œì˜¤. select name, job from employee where name like â€˜%A%â€™; INSERTINSERT INTO í…Œì´ë¸”ëª…(í•„ë“œ1, í•„ë“œ2, í•„ë“œ3, í•„ë“œ4, â€¦ ) VALUES ( í•„ë“œ1ì˜ ê°’, í•„ë“œ2ì˜ ê°’, í•„ë“œ3ì˜ ê°’, í•„ë“œ4ì˜ ê°’, â€¦ ) ex) ROLEí…Œì´ë¸”ì— role_idëŠ” 200, descriptionì—ëŠ” â€˜CEOâ€™ë¡œ í•œê±´ì˜ ë°ì´í„°ë¥¼ ì €ì¥í•˜ì‹œì˜¤. insert into ROLE (role_id, description) values ( 200, â€˜CEOâ€™); UPDATEUPDATE í…Œì´ë¸”ëª…SET í•„ë“œ1=í•„ë“œ1ì˜ê°’, í•„ë“œ2=í•„ë“œ2ì˜ê°’, í•„ë“œ3=í•„ë“œ3ì˜ê°’, â€¦WHERE ì¡°ê±´ì‹ ex) ROLEí…Œì´ë¸”ì— role_idê°€ 200ì¼ ê²½ìš° descriptionì„ â€˜CTOâ€™ë¡œ ìˆ˜ì •í•˜ì‹œì˜¤. update ROLE set description = â€˜CTOâ€™ where role_id = 200; DELETEDELETEFROM í…Œì´ë¸”ëª…WHERE ì¡°ê±´ì‹ ex) ROLEí…Œì´ë¸”ì—ì„œ role_idëŠ” 200ì¸ ì •ë³´ë¥¼ ì‚­ì œí•˜ì‹œì˜¤. delete from ROLE where role_id = 200; DDL(create, alter, drop) í…Œì´ë¸” ìƒì„± create table í…Œì´ë¸”ëª…( í•„ë“œëª…1 íƒ€ì… [NULL | NOT NULL][DEFAULT ][AUTO_INCREMENT], í•„ë“œëª…2 íƒ€ì… [NULL | NOT NULL][DEFAULT ][AUTO_INCREMENT], í•„ë“œëª…3 íƒ€ì… [NULL | NOT NULL][DEFAULT ][AUTO_INCREMENT], .......... PRIMARY KEY(í•„ë“œëª…) ); í…Œì´ë¸” ìˆ˜ì • (ì»¬ëŸ¼ ì¶”ê°€/ ì‚­ì œ) alter table í…Œì´ë¸”ëª… add í•„ë“œëª… íƒ€ì… [NULL | NOT NULL][DEFAULT ][AUTO_INCREMENT]; alter table í…Œì´ë¸”ëª… drop í•„ë“œëª…; í…Œì´ë¸” ì´ë¦„ ë³€ê²½ alter table í…Œì´ë¸”ëª… rename ë³€ê²½ì´ë¦„ í…Œì´ë¸” ì‚­ì œ drop table í…Œì´ë¸”ì´ë¦„;","link":"/2022/01/03/boostcourse-01-db/"},{"title":"Maven | ë¶€ìŠ¤íŠ¸ì½”ìŠ¤ ë°±ì—”ë“œ 02","text":"Maven Mavenì€ ì§€ê¸ˆê¹Œì§€ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•˜ê¸° ìœ„í•´ ë°˜ë³µì ìœ¼ë¡œ ì§„í–‰í•´ì™”ë˜ ì‘ì—…ë“¤ì„ ì§€ì›í•˜ê¸° ìœ„í•˜ì—¬ ë“±ì¥í•œ ë„êµ¬ì´ë‹¤. Mavenì„ ì‚¬ìš©í•˜ë©´ ë¹Œë“œ(Build), íŒ¨í‚¤ì§•, ë¬¸ì„œí™”, í…ŒìŠ¤íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ë¦¬í¬íŒ…, git, ì˜ì¡´ì„±ê´€ë¦¬, svnë“±ê³¼ ê°™ì€ í˜•ìƒê´€ë¦¬ì„œë²„ì™€ ì—°ë™(SCMs), ë°°í¬ ë“±ì˜ ì‘ì—…ì„ ì†ì‰½ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. COC(Convention over Configuration) CoCë€ ì¼ì¢…ì˜ ê´€ìŠµì„ ë§í•˜ëŠ”ë°,ì˜ˆë¥¼ ë“¤ìë©´ í”„ë¡œê·¸ë¨ì˜ ì†ŒìŠ¤íŒŒì¼ì€ ì–´ë–¤ ìœ„ì¹˜ì— ìˆì–´ì•¼ í•˜ê³ , ì†ŒìŠ¤ê°€ ì»´íŒŒì¼ëœ íŒŒì¼ë“¤ì€ ì–´ë–¤ ìœ„ì¹˜ì— ìˆì–´ì•¼ í•˜ê³  ë“±ì„ ë¯¸ë¦¬ ì •í•´ë†¨ë‹¤ëŠ” ê²ƒì´ë‹¤. ì´ ë§ì€ ê´€ìŠµì— ì´ë¯¸ ìµìˆ™í•œ ì‚¬ìš©ìëŠ” ì‰½ê²Œ Mavenì„ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ”ë°,ê´€ìŠµì— ìµìˆ™í•˜ì§€ ì•Šì€ ì‚¬ìš©ìëŠ” ì´ëŸ¬í•œ ì œì•½ì‚¬í•­ì— ëŒ€í•´ì„œ ì‹¬í•œ ê±°ë¶€ê°ì„ ëŠë‚„ ìˆ˜ ìˆë‹¤. Mavenì„ ì‚¬ìš©í•œë‹¤ëŠ” ê²ƒì€ ì–´ì©Œë©´ ì´ëŸ¬í•œ ê´€ìŠµ ì¦‰ CoCì— ëŒ€í•´ì„œ ì•Œì•„ë‚˜ê°€ëŠ” ê²ƒì´ë¼ê³ ë„ ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Mavenì˜ ì¥ì  Mavenì„ ì‚¬ìš©í•  ê²½ìš°, êµ‰ì¥íˆ í¸ë¦¬í•œ ì ë“¤ì´ ë§ìŠµë‹ˆë‹¤. ë§ì€ ì‚¬ëŒì´ ì†ê¼½ëŠ” ì¥ì  ì¤‘ì—ëŠ” í¸ë¦¬í•œ ì˜ì¡´ì„± ë¼ì´ë¸ŒëŸ¬ë¦¬ ê´€ë¦¬ê°€ ìˆìŠµë‹ˆë‹¤. ì•ì—ì„œ JSTLì„ í•™ìŠµí•  ë•Œ, ëª‡ ê°€ì§€ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ í•˜ì—¬ /WEB-INF/libí´ë”ì— ë³µì‚¬í•˜ì—¬ ì‚¬ìš©í–ˆì—ˆìŠµë‹ˆë‹¤. ê´€ë ¨ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë§ì•„ì§ˆìˆ˜ë¡ ì´ëŸ¬í•œ ë°©ì‹ì€ ìƒë‹¹íˆ ë¶ˆí¸í•´ì§‘ë‹ˆë‹¤. Mavenì„ ì‚¬ìš©í•˜ë©´ ì„¤ì • íŒŒì¼ì— ëª‡ ì¤„ ì ì–´ì¤Œìœ¼ë¡œì¨ ì§ì ‘ ë‹¤ìš´ë¡œë“œ ë°›ê±°ë‚˜ í•˜ëŠ” ê²ƒì„ í•˜ì§€ ì•Šì•„ë„ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ì— ì°¸ì—¬í•˜ëŠ” ê°œë°œìê°€ ë§ì•„ì§€ê²Œ ë˜ë©´, í”„ë¡œì íŠ¸ë¥¼ ë¹Œë“œí•˜ëŠ” ë°©ë²•ì— ëŒ€í•˜ì—¬ ê°€ì´ë“œí•˜ëŠ” ê²ƒë„ ì‰¬ìš´ ì¼ì´ ì•„ë‹™ë‹ˆë‹¤. Mavenì„ ì‚¬ìš©í•˜ê²Œ ë˜ë©´ Mavenì— ì„¤ì •í•œ ëŒ€ë¡œ ëª¨ë“  ê°œë°œìê°€ ì¼ê´€ëœ ë°©ì‹ìœ¼ë¡œ ë¹Œë“œë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. Mavenì€ ë˜í•œ ë‹¤ì–‘í•œ í”ŒëŸ¬ê·¸ì¸ì„ ì œê³µí•´ì¤˜ì„œ, êµ‰ì¥íˆ ë§ì€ ì¼ë“¤ì„ ìë™í™”ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Maven ê¸°ë³¸ Archetypeì„ ì´ìš©í•˜ì—¬ Maven ê¸°ë°˜ í”„ë¡œì íŠ¸ë¥¼ ìƒì„±í•  ê²½ìš° ìƒì„±ëœ í”„ë¡œì íŠ¸ í•˜ìœ„ì— pom.xml íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤.pom.xml íŒŒì¼ì„ ì‚´í´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. 1234567891011121314151617181920&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;kr.or.connect&lt;/groupId&gt; &lt;artifactId&gt;examples&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;mysample&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; ê°ê°ì˜ íƒœê·¸ì˜ ì˜ë¯¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. project : pom.xml íŒŒì¼ì˜ ìµœìƒìœ„ ë£¨íŠ¸ ì—˜ë¦¬ë¨¼íŠ¸(Root Element)ì…ë‹ˆë‹¤.modelVersion : POM modelì˜ ë²„ì „ì…ë‹ˆë‹¤.groupId : í”„ë¡œì íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¡°ì§ì˜ ê³ ìœ  ì•„ì´ë””ë¥¼ ê²°ì •í•©ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ë„ë©”ì¸ ì´ë¦„ì„ ê±°ê¾¸ë¡œ ì ìŠµë‹ˆë‹¤.artifactId : í•´ë‹¹ í”„ë¡œì íŠ¸ì— ì˜í•˜ì—¬ ìƒì„±ë˜ëŠ” artifactì˜ ê³ ìœ  ì•„ì´ë””ë¥¼ ê²°ì •í•©ë‹ˆë‹¤. Mavenì„ ì´ìš©í•˜ì—¬ pom.xmlì„ ë¹Œë“œí•  ê²½ìš° ë‹¤ìŒê³¼ ê°™ì€ ê·œì¹™ìœ¼ë¡œ artifactê°€ ìƒì„±ë©ë‹ˆë‹¤. artifactid-version.packaging. ìœ„ ì˜ˆì˜ ê²½ìš° ë¹Œë“œí•  ê²½ìš° examples-1.0-SNAPSHOT.jar íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤.packaging : í•´ë‹¹ í”„ë¡œì íŠ¸ë¥¼ ì–´ë–¤ í˜•íƒœë¡œ packaging í•  ê²ƒì¸ì§€ ê²°ì •í•©ë‹ˆë‹¤. jar, war, ear ë“±ì´ í•´ë‹¹ë©ë‹ˆë‹¤.version : í”„ë¡œì íŠ¸ì˜ í˜„ì¬ ë²„ì „. ì¶”í›„ ì‚´í´ë³´ê² ì§€ë§Œ í”„ë¡œì íŠ¸ê°€ ê°œë°œ ì¤‘ì¼ ë•ŒëŠ” SNAPSHOTì„ ì ‘ë¯¸ì‚¬ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. Mavenì˜ ë²„ì „ ê´€ë¦¬ ê¸°ëŠ¥ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê´€ë¦¬ë¥¼ í¸í•˜ê²Œ í•©ë‹ˆë‹¤.name : í”„ë¡œì íŠ¸ì˜ ì´ë¦„ì…ë‹ˆë‹¤.url : í”„ë¡œì íŠ¸ ì‚¬ì´íŠ¸ê°€ ìˆë‹¤ë©´ ì‚¬ì´íŠ¸ URLì„ ë“±ë¡í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.Maven ì„ ì´ìš©í•  ê²½ìš° ì–»ê²Œ ë˜ëŠ” í° ì´ì  ì¤‘ì˜ í•˜ë‚˜ëŠ” Dependency Management ê¸°ëŠ¥ì…ë‹ˆë‹¤. ìœ„ pom.xml íŒŒì¼ì—ì„œ ì—˜ë¦¬ë¨¼íŠ¸ê°€ Dependency Management ê¸°ëŠ¥ì˜ í•µì‹¬ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•´ë‹¹ ì—˜ë¦¬ë¨¼íŠ¸ ì•ˆì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì§€ì •í•˜ê²Œ ë©ë‹ˆë‹¤. https://maven.apache.org/pom.html#POM_Relationships Refë¶€ìŠ¤íŠ¸ì½”ìŠ¤ ë°±ì—”ë“œ","link":"/2022/01/03/boostcourse-02-maven/"},{"title":"WEB | ë¶€ìŠ¤íŠ¸ì½”ìŠ¤ ë°±ì—”ë“œ 04","text":"ì›¹ì˜ ë™ì‘ ì›ë¦¬ì¸í„°ë„· != WWW(World Wide Web)ì¸í„°ë„· ê¸°ë°˜ì˜ ëŒ€í‘œ ì„œë¹„ìŠ¤ ì¤‘ í•˜ë‚˜TCP/ IP ê¸°ë°˜ì˜ ë„¤í¬ì›Œí¬ê°€ ì „ì„¸ê³„ì ìœ¼ë¡œ í™•ëŒ€ë˜ì–´ í•˜ë‚˜ë¡œ ì—°ê²°ëœ ë„¤íŠ¸ì›Œí¬ë“¤ì˜ ë„¤íŠ¸ì›Œí¬(ë„¤íŠ¸ì›Œí¬ì˜ ê²°í•©ì²´) HTTP (Hypertext Transfer Protocol)ë€HTTPëŠ” ì„œë²„ì™€ í´ë¼ì´ì–¸íŠ¸ê°€ ì¸í„°ë„·ìƒì—ì„œ ë°ì´í„°ë¥¼ ì£¼ê³ ë°›ê¸° ìœ„í•œ í”„ë¡œí† ì½œ(protocol)ì…ë‹ˆë‹¤.HTTPëŠ” ê³„ì† ë°œì „í•˜ì—¬ HTTP/2ê¹Œì§€ ë²„ì „ì´ ë“±ì¥í•œ ìƒíƒœì…ë‹ˆë‹¤. HTTP ì‘ë™ ë°©ì‹HTTPëŠ” ì„œë²„/í´ë¼ì´ì–¸íŠ¸ ëª¨ë¸ì„ ë”°ë¦…ë‹ˆë‹¤.í´ë¼ì´ì–¸íŠ¸ê°€ ìš”ì²­ì„ ì„œë²„ë¡œ ë³´ë‚´ë©´ ì„œë²„ê°€ ìš”ì²­ì„ ë°›ì•„ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì‘ë‹µì„ ë³´ë‚¸ë‹¤ ì¥ì  ë¶ˆíŠ¹ì • ë‹¤ìˆ˜ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ëŠ” ì„œë¹„ìŠ¤ì—ëŠ” ì í•©í•˜ë‹¤. í´ë¼ì´ì–¸íŠ¸ì™€ ì„œë²„ê°€ ê³„ì† ì—°ê²°ëœ í˜•íƒœê°€ ì•„ë‹ˆê¸° ë•Œë¬¸ì— í´ë¼ì´ì–¸íŠ¸ì™€ ì„œë²„ ê°„ì˜ ìµœëŒ€ ì—°ê²° ìˆ˜ë³´ë‹¤ í›¨ì”¬ ë§ì€ ìš”ì²­ê³¼ ì‘ë‹µì„ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.ë‹¨ì  ì—°ê²°ì„ ëŠì–´ë²„ë¦¬ê¸° ë•Œë¬¸ì—, í´ë¼ì´ì–¸íŠ¸ì˜ ì´ì „ ìƒí™©ì„ ì•Œ ìˆ˜ê°€ ì—†ë‹¤. ì´ëŸ¬í•œ íŠ¹ì§•ì„ ë¬´ìƒíƒœ(Stateless)ë¼ê³  ë§í•œë‹¤. ì´ëŸ¬í•œ íŠ¹ì§• ë•Œë¬¸ì— ì •ë³´ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ì„œ Cookieì™€ ê°™ì€ ê¸°ìˆ ì´ ë“±ì¥í•˜ê²Œ ë˜ì—ˆë‹¤. ###URL(Uniform Resource Locator) ì¸í„°ë„·ìƒì˜ ìì›ì˜ ìœ„ì¹˜ íŠ¹ì • ì›¹ ì„œë²„ì˜ íŠ¹ì • íŒŒì¼ì— ì ‘ê·¼í•˜ê¸° ìœ„í•œ ê²½ë¡œ í˜¹ì€ ì£¼ì†Œ ì ‘ê·¼í”„ë¡œí† ì½œ://IPì£¼ì†Œë˜ëŠ”ë„ë©”ì¸ì´ë¦„/ë¬¸ì„œì˜ê²½ë¡œ/ë¬¸ì„œì´ë¦„http://www.oracle.co.kr/docs/index.html IP -&gt; ìš°ë¦¬ì§‘ ì£¼ì†Œ, í•˜ë‚˜ì˜ ì§‘ì— í•˜ë‚˜ì˜ ip ì¡´ì¬í¬íŠ¸ -&gt; ì§‘ì•ˆì˜ ë°©ì´ ì—¬ëŸ¬ê°œì„ ë°©ì„ ì˜ë¯¸ì„œë²„ -&gt; í•˜ë‚˜ì˜ ë°©ì— ì—¬ëŸ¬ê°œ ì„œë²„ ì¡´ì¬í•  ìˆ˜ ì—†ë‹¤ í•˜ë‚˜ì˜ ë¬¼ë¦¬ì  ì»´í“¨í„°ì—ëŠ” ì—¬ëŸ¬ê°œì˜ ì†Œí”„íŠ¸ì›¨ì–´ ì„œë²„ ë™ì‘ì„œë²„ëŠ” í¬íŠ¸ê°’ì´ ë‹¤ë¥´ê²Œ ë™ì‘í¬íŠ¸ê°’ì€ 0ë³´ë‹¤ í° ìˆ«ìê°’ì´ë‹¤. ìš”ì²­ ë©”ì„œë“œ : GET, PUT, POST, PUSH, OPTIONS ë“±ì˜ ìš”ì²­ ë°©ì‹ì´ ì˜¨ë‹¤.ìš”ì²­ URI : ìš”ì²­í•˜ëŠ” ìì›ì˜ ìœ„ì¹˜ë¥¼ ëª…ì‹œí•œë‹¤.HTTP í”„ë¡œí† ì½œ ë²„ì „ : ì›¹ ë¸Œë¼ìš°ì €ê°€ ì‚¬ìš©í•˜ëŠ” í”„ë¡œí† ì½œ ë²„ì „ì´ë‹¤.ì²«ë²ˆì§¸ ì¤„ì˜ ìš”ì²­ë©”ì†Œë“œëŠ” ì„œë²„ì—ê²Œ ìš”ì²­ì˜ ì¢…ë¥˜ë¥¼ ì•Œë ¤ì£¼ê¸° ìœ„í•´ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤. ê°ê°ì˜ ë©”ì†Œë“œ ì´ë¦„ì€ ë‹¤ìŒê³¼ ê°™ì€ ì˜ë¯¸ë¥¼ ê°€ì§‘ë‹ˆë‹¤. ì°¸ê³ ë¡œ ìµœì´ˆì˜ ì›¹ ì„œë²„ëŠ” GETë°©ì‹ë§Œ ì§€ì›í•´ì¤¬ìŠµë‹ˆë‹¤. GET : ì •ë³´ë¥¼ ìš”ì²­í•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš©í•œë‹¤. (SELECT)POST : ì •ë³´ë¥¼ ë°€ì–´ë„£ê¸° ìœ„í•´ì„œ ì‚¬ìš©í•œë‹¤. (INSERT)PUT : ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš©í•œë‹¤. (UPDATE)DELETE : ì •ë³´ë¥¼ ì‚­ì œí•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš©í•œë‹¤. (DELETE)HEAD : (HTTP)í—¤ë” ì •ë³´ë§Œ ìš”ì²­í•œë‹¤. í•´ë‹¹ ìì›ì´ ì¡´ì¬í•˜ëŠ”ì§€ í˜¹ì€ ì„œë²„ì— ë¬¸ì œê°€ ì—†ëŠ”ì§€ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš©í•œë‹¤.OPTIONS : ì›¹ì„œë²„ê°€ ì§€ì›í•˜ëŠ” ë©”ì„œë“œì˜ ì¢…ë¥˜ë¥¼ ìš”ì²­í•œë‹¤.TRACE : í´ë¼ì´ì–¸íŠ¸ì˜ ìš”ì²­ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜í•œë‹¤. ì˜ˆì»¨ë° echo ì„œë¹„ìŠ¤ë¡œ ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•˜ê¸° ìœ„í•œ ëª©ì ìœ¼ë¡œ ì£¼ë¡œ ì‚¬ìš©í•œë‹¤. ë¸Œë¼ìš°ì €ex) ì‚¬íŒŒë¦¬, êµ¬ê¸€í¬ë¡¬, íŒŒì´ì–´í­ìŠ¤ â€¦etcì„œë²„ì—ì„œ ì „ì†¡í•œ ë°ì´í„°(HTMLê³¼ ê°™ì€)ê°€ í´ë¼ì´ì–¸íŠ¸ì— ë„ì°©í•˜ëŠ”ê³³Browserì—ëŠ” ë°ì´í„°ë¥¼ í•´ì„í•´ì£¼ëŠ” íŒŒì„œì™€ ë°ì´í„°ë¥¼ í™”ë©´ì— í‘œí˜„í•´ì£¼ëŠ” ë Œë”ë§ì—”ì§„ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì €ì˜ íë¦„Pasing HTML to construct the DOM tree #pasing ë¶„ì„ í•´ì„ Render tree contruction Layout of the render tree #í™”ë©´ ë°°ì¹˜ Painting the render tee ì„œë²„ì—ì„œ ì „ì†¡í•œ ë°ì´í„°(HTMLê³¼ ê°™ì€)ê°€ í´ë¼ì´ì–¸íŠ¸ì— ë„ì°©í•´ì•¼ í•  ê³³ì€ â€˜Browserâ€™ì…ë‹ˆë‹¤. Browserì—ëŠ” ë°ì´í„°ë¥¼ í•´ì„í•´ì£¼ëŠ” íŒŒì„œì™€ ë°ì´í„°ë¥¼ í™”ë©´ì— í‘œí˜„í•´ì£¼ëŠ” ë Œë”ë§ì—”ì§„ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ###ì›¹ì„œë²„ì›¹ ì„œë²„ëŠ” ì†Œí”„íŠ¸ì›¨ì–´(Software)ë¥¼ ë³´í†µ ë§í•˜ì§€ë§Œ, ì›¹ ì„œë²„ ì†Œí”„íŠ¸ì›¨ì–´ê°€ ë™ì‘í•˜ëŠ” ì»´í“¨í„°ë¥¼ ë§í•©ë‹ˆë‹¤.ì›¹ ì„œë²„ì˜ ê°€ì¥ ì¤‘ìš”í•œ ê¸°ëŠ¥ì€ í´ë¼ì´ì–¸íŠ¸(Client)ê°€ ìš”ì²­í•˜ëŠ” HTML ë¬¸ì„œë‚˜ ê°ì¢… ë¦¬ì†ŒìŠ¤(Resource)ë¥¼ ì „ë‹¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.ì›¹ ë¸Œë¼ìš°ì €ë‚˜ ì›¹ í¬ë¡¤ëŸ¬ê°€ ìš”ì²­í•˜ëŠ” ë¦¬ì†ŒìŠ¤ëŠ” ì»´í“¨í„°ì— ì €ì¥ëœ ì •ì (static)ì¸ ë°ì´í„°ì´ê±°ë‚˜ ë™ì ì¸ ê²°ê³¼ê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤ ###ì›¹ ì„œë²„ ì†Œí”„íŠ¸ì›¨ì–´ì˜ ì¢…ë¥˜ ê°€ì¥ ë§ì´ ì‚¬ìš©í•˜ëŠ” ì›¹ ì„œë²„ëŠ” Apache, Nginx, Microsoft IIS Apacheì›¹ ì„œë²„ëŠ” Apache Software Foundationì—ì„œ ê°œë°œí•œ ì›¹ì„œë²„ë¡œ ì˜¤í”ˆì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´(Open-source Software)ì´ë©°, ê±°ì˜ ëŒ€ë¶€ë¶„ ìš´ì˜ì²´ì œì—ì„œ ì„¤ì¹˜ ë° ì‚¬ìš©ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. NginxëŠ” ì°¨ì„¸ëŒ€ ì›¹ì„œë²„ë¡œ ë¶ˆë¦¬ë©° ë” ì ì€ ìì›ìœ¼ë¡œ ë” ë¹ ë¥´ê²Œ ë°ì´í„°ë¥¼ ì„œë¹„ìŠ¤í•˜ëŠ” ê²ƒì„ ëª©ì ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ ì„œë²„ì´ë©° Apacheì›¹ ì„œë²„ì™€ ë§ˆì°¬ê°€ì§€ë¡œ ì˜¤í”ˆì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ì…ë‹ˆë‹¤. ###í´ë¼ì´ì–¸íŠ¸ì™€ ì„œë²„ êµ¬ì¡°í´ë¼ì´ì–¸íŠ¸ëŠ” ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ì„œë²„ì—ê²Œ ì •ë³´ë¥¼ ìš”ì²­í•˜ì—¬ ì‘ë‹µë°›ì€ ê²°ê³¼ë¥¼ ì‚¬ìš©í•œë‹¤.ì›¹ì„œë²„ì™€ ì›¹ ë¸Œë¼ìš°ì €ê°€ ì„œë²„ì™€ í´ë¼ì´ì–¸íŠ¸ì˜ ê´€ê³„ì´ë‹¤. ###ë¯¸ë“¤ì›¨ì–´ (Middle Ware) DBMSì˜ ë¬¸ì œì ì„ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ ìƒê²¨ë‚¬ë‹¤ (ë³´ì•ˆì·¨ì•½, ë„ˆë¬´ ë§ì€ í´ë¼ì´ì–¸íŠ¸ ê³¼ë¶€í™”)í´ë¼ì´ì–¸íŠ¸ ìª½ì— ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì´ ë§ì€ ê²½ìš°, í´ë¼ì´ì–¸íŠ¸ ê´€ë¦¬(ë°°í¬ ë“±)ë¡œ ì¸í•´ ë¹„ìš©ì´ ë§ì´ ë°œìƒí•˜ëŠ” ë¬¸ì œ ë°œìƒë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ í´ë¼ì´ì–¸íŠ¸ì™€ DBMS ì‚¬ì´ì˜ ë¯¸ë“¤ì›¨ì–´ ì„œë²„ì—ì„œ ë™ì‘í•˜ë„ë¡ í•¨ìœ¼ë¡œì¨ í´ë¼ì´ì–¸íŠ¸ëŠ” ì…ë ¥ê³¼ ì¶œë ¥ë§Œ ë‹´ë‹¹í•˜ë„ë¡ í•¨. WAS (Web Application Server)ë¸Œë¼ìš°ì €ì™€ í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ì—ì„œ ë™ì‘WASëŠ” ì¼ì¢…ì˜ ë¯¸ë“¤ì›¨ì–´ë¡œ ì›¹ í´ë¼ì´ì–¸íŠ¸ (ë³´í†µ ì›¹ ë¸Œë¼ìš°ì €)ì˜ ìš”ì²­ ì¤‘ ë³´í†µ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ë™ì‘í•˜ë„ë¡ ì§€ì›í•˜ëŠ” ëª©ì ì„ ê°€ì§„ë‹¤. ê¸°ëŠ¥ í”„ë¡œê·¸ë¨ ì‹¤í–‰í™˜ê²½ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ì ‘ì† ê¸°ëŠ¥ ì œê³µ ì—¬ëŸ¬ê°œì˜ íŠ¸ëœì ì…˜ì„ ê´€ë¦¬í•œë‹¤ ì—…ë¬´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ìˆ˜í–‰í•œë‹¤ex) Tomcat ìµœì´ˆì˜ ì›¹ì´ ë“±ì¥í–ˆì„ë•Œ ì›¹ë¸Œë¼ìš°ì €ëŠ” ì •ì ì¸ë°ì´í„°ë§Œ ë³´ì—¬ì¤¬ë‹¤ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­ ì»¤ì§ -&gt; ë™ì ì¸ ì›¹ì„ ìš”êµ¬ -&gt; ###ì›¹ ì„œë²„ vs WASWASë„ ë³´í†µ ìì²´ì ìœ¼ë¡œ ì›¹ ì„œë²„ ê¸°ëŠ¥ì„ ë‚´ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤.í˜„ì¬ëŠ” WASê°€ ê°€ì§€ê³  ìˆëŠ” ì›¹ ì„œë²„ë„ ì •ì ì¸ ì½˜í…ì¸ ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ìˆì–´ì„œ ì„±ëŠ¥ìƒ í° ì°¨ì´ê°€ ì—†ìŠµë‹ˆë‹¤.ê·œëª¨ê°€ ì»¤ì§ˆìˆ˜ë¡ ì›¹ ì„œë²„ì™€ WASë¥¼ ë¶„ë¦¬í•©ë‹ˆë‹¤.ìì› ì´ìš©ì˜ íš¨ìœ¨ì„± ë° ì¥ì•  ê·¹ë³µ, ë°°í¬ ë° ìœ ì§€ë³´ìˆ˜ì˜ í¸ì˜ì„±ì„ ìœ„í•´ ì›¹ì„œë²„ì™€ WASë¥¼ ëŒ€ì²´ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤ https://jsbin.com/?html,output Refë¶€ìŠ¤íŠ¸ì½”ìŠ¤","link":"/2022/01/03/boostcourse-04-web/"},{"title":"JDBC | ë¶€ìŠ¤íŠ¸ì½”ìŠ¤ ë°±ì—”ë“œ03","text":"JDBCë€ JDBC(Java Database Connectivity)ì˜ ì •ì˜ ìë°”ë¥¼ ì´ìš©í•œ ë°ì´í„°ë² ì´ìŠ¤ ì ‘ì†ê³¼ SQL ë¬¸ì¥ì˜ ì‹¤í–‰, ê·¸ë¦¬ê³  ì‹¤í–‰ ê²°ê³¼ë¡œ ì–»ì–´ì§„ ë°ì´í„°ì˜ í•¸ë“¤ë§ì„ ì œê³µí•˜ëŠ” ë°©ë²•ê³¼ ì ˆì°¨ì— ê´€í•œ ê·œì•½ ìë°” í”„ë¡œê·¸ë¨ ë‚´ì—ì„œ SQLë¬¸ì„ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ìë°” API SQLê³¼ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì˜ í†µí•© ì ‘ê·¼ ì¤‘ í•œ í˜•íƒœJAVAëŠ” í‘œì¤€ ì¸í„°í˜ì´ìŠ¤ì¸ JDBC APIë¥¼ ì œê³µë°ì´í„°ë² ì´ìŠ¤ ë²¤ë”, ë˜ëŠ” ê¸°íƒ€ ì¨ë“œíŒŒí‹°ì—ì„œëŠ” JDBC ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•œ ë“œë¼ì´ë²„(driver)ë¥¼ ì œê³µí•œë‹¤. +ì›¹ì„ ë™ì‘í• ë•Œ í”„ë¡œê·¸ë¨ì´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í• ìˆ˜ ìˆê²Œ ì´ë¯¸ ë§Œë“¤ì–´ì§„ íˆ´ì´ë¼ê³  ìƒê°í•˜ì JDBC í™˜ê²½ êµ¬ì„± JDK ì„¤ì¹˜JDBC ë“œë¼ì´ë²„ ì„¤ì¹˜ Mavenì— ë‹¤ìŒê³¼ ê°™ì€ ì˜ì¡´ì„±ì„ ì¶”ê°€í•œë‹¤. MySQLì‚¬ì´íŠ¸ì—ì„œ ë‹¤ìš´ë¡œë“œ í•œë‹¤. mysql mysql-connector-java 5.1.45 ###JDBCë¥¼ ì´ìš©í•œ í”„ë¡œê·¸ë˜ë° ë°©ë²• import java.sql.*; ë“œë¼ì´ë²„ë¥¼ ë¡œë“œ í•œë‹¤. Connection ê°ì²´ë¥¼ ìƒì„±í•œë‹¤. //dbì— ì ‘ì† Statement ê°ì²´ë¥¼ ìƒì„± ë° ì§ˆì˜ ìˆ˜í–‰ //ì¿¼ë¦¬ ìƒì„±ê³¼ ì‹¤í–‰ì„ statementê°€ ë„ì™€ì¤Œ SQLë¬¸ì— ê²°ê³¼ë¬¼ì´ ìˆë‹¤ë©´ ResultSet ê°ì²´ë¥¼ ìƒì„±í•œë‹¤. ëª¨ë“  ê°ì²´ë¥¼ ë‹«ëŠ”ë‹¤. JDBC í´ë˜ìŠ¤ì˜ ìƒì„± ê´€ê³„ ###JDBC ì‚¬ìš© 12345678910111213141516171819202122232425262728293031323334353637383940414243//importimport java.sql.*;//ë“œë¼ì´ë²„ ë¡œë“œClass.forName( &quot;com.mysql.jdbc.Driver&quot; );//connection ì–»ê¸°String dburl = &quot;jdbc:mysql://localhost/dbName&quot;;Connection con = DriverManager.getConnection ( dburl, ID, PWD );//ì†ŒìŠ¤ì½”ë“œ ì˜ˆì œpublic static Connection getConnection() throws Exception{ String url = &quot;jdbc:oracle:thin:@117.16.46.111:1521:xe&quot;; //oracle String user = &quot;smu&quot;; String password = &quot;smu&quot;; Connection conn = null; Class.forName(&quot;oracle.jdbc.driver.OracleDriver&quot;); conn = DriverManager.getConnection(url, user, password); return conn;}//statementìƒì„±Statement stmt = con.createStatement();//ì§ˆì˜ ìˆ˜í–‰ResultSet rs = stmt.executeQuery(&quot;select no from user&quot; );stmt.execute(â€œqueryâ€); //any SQLstmt.executeQuery(â€œqueryâ€); //SELECTstmt.executeUpdate(â€œqueryâ€); //INSERT, UPDATE, DELETE//resultsetìœ¼ë¡œ ê²°ê³¼ ë°›ê¸°ResultSet rs = stmt.executeQuery( &quot;select no from user&quot; );while ( rs.next() ) System.out.println( rs.getInt( &quot;no&quot;) );//closers.close();stmt.close();con.close(); ###ì˜ˆì œ01 123456789101112131415161718192021222324252627public List&lt;GuestBookVO&gt; getGuestBookList(){ List&lt;GuestBookVO&gt; list = new ArrayList&lt;&gt;(); GuestBookVO vo = null; Connection conn = null; PreparedStatement ps = null; ResultSet rs = null; try{ conn = DBUtil.getConnection(); String sql = &quot;select * from guestbook&quot;; ps = conn.prepareStatement(sql); rs = ps.executeQuery(); while(rs.next()){ vo = new GuestBookVO(); vo.setNo(rs.getInt(1)); vo.setId(rs.getString(2)); vo.setTitle(rs.getString(3)); vo.setConetnt(rs.getString(4)); vo.setRegDate(rs.getString(5)); list.add(vo); } }catch(Exception e){ e.printStackTrace(); }finally { DBUtil.close(conn, ps, rs); } return list; } ###ì˜ˆì œ02 123456789101112131415161718192021public int addGuestBook(GuestBookVO vo){ int result = 0; Connection conn = null; PreparedStatement ps = null; try{ conn = DBUtil.getConnection(); String sql = &quot;insert into guestbook values(&quot; + &quot;guestbook_seq.nextval,?,?,?,sysdate)&quot;; ps = conn.prepareStatement(sql); ps.setString(1, vo.getId()); ps.setString(2, vo.getTitle()); ps.setString(3, vo.getConetnt()); result = ps.executeUpdate(); }catch(Exception e){ e.printStackTrace(); }finally { DBUtil.close(conn, ps); } return result; } ì •ë¦¬ìœ„ì˜ ë‘ ì˜ˆì¬ë¥¼ ë³´ë©´ ë°˜ë³µë˜ëŠ” ë¶€ë¶„ì´ ë§ì€ë°ì´ê²ƒì„ í”„ë ˆì„ì›Œí¬í™” í•˜ë©´ ê°„í¸í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ì´ ê³¼ì •ì—ì„œ ì•ìœ¼ë¡œ ë‚´ê°€ ì‚¬ìš©í• ê±´ Spring í”„ë ˆì„ ì›Œí¬ì´ë‹¤.","link":"/2022/01/03/boostcourse-03-jdbc/"},{"title":"í†°ìº£ ì„¤ì¹˜ì™€ ì´ˆê¸° ì„¤ì • | ë¶€ìŠ¤íŠ¸ì½”ìŠ¤ ë°±ì—”ë“œ 06","text":"ë„¤ì´ë²„ ë¸”ë¡œê·¸ì— ì •ë¦¬í•œê±° ë‹¤ì‹œ ì •ë¦¬í•˜ê¸°!! ###Apache Tomcatì´ë€?ì„¸ê³„ì—ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” WAS(Web Application Server)ì´ë‹¤.ì»´í“¨í„°ì— ìš´ì˜ì²´ì œë¥¼ ì„¤ì¹˜í•´ì•¼ë§Œ ì»´í“¨í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê²ƒì²˜ëŸ¼, ìë°”ë¥¼ ì´ìš©í•˜ì—¬ ì‘ì„±ëœ ì›¹ ì–´í”Œë¦¬ì¼€ì´ì…˜ì€ WASê°€ ìˆì–´ì•¼ë§Œ ì‹¤í–‰ ê°€ëŠ¥í•˜ë‹¤. ê°„ë‹¨í•œ ì›¹ ì–´í”Œë¦¬ì¼€ì´ì…˜ ë§Œë“¤ì–´ë³´ê¸°new -&gt; servlet -&gt; ì´ë¦„ Helloservletìœ¼ë¡œ ì„¤ì •í•´ì¤Œhttp://localhost:8080/{í”„ë¡œì íŠ¸ì´ë¦„}/{URL Mappingê°’}http://localhost:8080/firstweb/Helloservlet 1234567protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType(&quot;text/html;charset=UTF-8&quot;); PrintWriter out = response.getWriter(); out.print(&quot;&lt;h1&gt;Hello Servlet&lt;/h1&gt;&quot;); } ìœ„ì˜ ì½”ë“œì²˜ëŸ¼ ê°„ë‹¨í•œ ì˜ˆì œë¥¼ ìˆ˜í–‰í•´ë³´ì•˜ë‹¤doGet()ë©”ì„œë“œë§Œ ìˆ˜ì •í•´ì£¼ì—ˆë‹¤ ì‹¤í–‰ê²°ê³¼ doGet() ë©”ì„œë“œì›¹ì„œë²„ê°€ getë©”ì„œë“œ ë°©ì‹ìœ¼ë¡œ ìš”ì²­ì„ ë³´ë‚¼ë•Œ ì„œë¸”ë¦¿ì— doGet()ë©”ì„œë“œê°€ í˜¸ì¶œì´ ëœë‹¤get ë©”ì„œë“œëŠ” ì›¹ë¸Œë¼ìš°ì €ê°€ ì„œë²„ì—ê²Œ ë¬¸ì„œë¥¼ ìš”ì²­í• ë•Œ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ í¬ë¡¬ ë¸Œë¼ìš°ì €ì—ì„œ ë³´ëŠ”ë²•Window -&gt; Web Browser -&gt; Chromeìœ¼ë¡œ ì„¤ì •í•˜ë©´ í¬ë¡¬ì—ì„œ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤","link":"/2022/01/03/boostcourse-06-tomcat/"},{"title":"Servlet | ë¶€ìŠ¤íŠ¸ì½”ìŠ¤ ë°±ì—”ë“œ 07","text":"ìë°” ì›¹ ì–´í”Œë¦¬ì¼€ì´ì…˜WASì— ì„¤ì¹˜ë˜ì–´ ë™ì‘í•˜ëŠ” ì–´í”Œë¦¬ì¼€ì´ì…˜ìë°” ì›¹ ì–´í”Œë¦¬ì¼€ì´ì…˜ì—ëŠ” HTML, CSS, ì´ë¯¸ì§€, ìë°”ë¡œ ì‘ì„±ëœ í´ë˜ìŠ¤(Servletë„ í¬í•¨ë¨, package, ì¸í„°í˜ì´ìŠ¤ ë“±), ê°ì¢… ì„¤ì • íŒŒì¼ ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤. ë‚´ê°€ ì¸í„°ë„·ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì‡¼í•‘ëª° ë¸”ë¡œê·¸ê°€ ì›¹ ì–´í”Œë¦¬ì¼€ì´ì…˜ì´ë¼ê³  ë§ í•  ìˆ˜ ìˆë‹¤.ì•ì—ì„œ ë§Œë“ ê±´ ì„œë¸”ë¦¿ìœ¼ë¡œë§Œ ì´ë£¨ì–´ì§„ ì•„ì£¼ì•„ì£¼ì•„ì£¼ ê°„ë‹¨í•œ ì›¹ ì–´í”Œë¦¬ì¼€ì´ì…˜ì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤. ìë°” ì›¹ ì–´í”Œë¦¬ì¼€ì´ì…˜ í´ë” êµ¬ì¡° WEB-INFì´ í´ë” ì•ˆì—ëŠ” web.xmlì´ ìˆë‹¤.web.xmlì€ ë°°í¬ ê¸°ìˆ ìë¼ê³ ë„ í•˜ê³ , ì›¹ ì–´í”Œë¦¬ì¼€ì´ì…˜ì— ëŒ€í•œ ì •ë³´ë¥¼ ë‹¤ ê°€ì§€ê³  ìˆëŠ” íŒŒì¼ì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤.WEB-INFí´ë” í•˜ìœ„ í´ë”ë¡œ libë¼ëŠ” í´ë”,classes ë¼ëŠ” í´ë”ê°€ ì¡´ì¬í•¨ web.xmlhttps://lordofkangs.tistory.com/35WEB-INF í´ë” ë°–ì€ ì ‘ê·¼ ê°€ëŠ¥í•˜ì§€ë§Œ, WEB-INF í´ë” ì•ˆì˜ ì„œë¸”ë¦¿ì—ëŠ” ì ‘ê·¼ì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤ì´ë•Œ WEB-INF í´ë” ì•ˆì˜ ì„œë¸”ë¦¿ì— ì ‘ê·¼ í•˜ê¸° ìœ„í•´ì„œ ì§„ì§œ ê²½ë¡œë¥¼ ìˆ¨ê¸°ê³  ê°€ì§œ ê²½ë¡œë¥¼ ë§Œë“¤ì–´ ì™¸ë¶€ ì ‘ê·¼ìœ¼ë¡œë¶€í„°ì„œë²„ë¡œì§ì„ ë³´í˜¸í•  ìˆ˜ ìˆë‹¤. libí´ë”ê°ì¢… jars íŒŒì¼ classes í´ë”java íŒ¨í‚¤ì§€, ì»´íŒŒì¼ ëœ class ë“¤..ë‚´ê°€ ì‘ì„±í•œ ì„œë¸”ë¦¿ íŒŒì¼ì´ ë“¤ì–´ê° ë¦¬ì†ŒìŠ¤ë“¤ê°ì¢… í´ë”, ì´ë¯¸ì§€, ë‹¤ì–‘í•œ ë¦¬ì†ŒìŠ¤ë“¤ Servletìë°” ì›¹ ì–´í”Œë¦¬ì¼€ì´ì…˜ì˜ êµ¬ì„± ìš”ì†Œ ì¤‘ ë™ì ì¸ ì²˜ë¦¬ë¥¼ í•˜ëŠ” í”„ë¡œê·¸ë¨ì˜ ì—­í• ë™ì ìœ¼ë¡œ ë§Œë“¤ì–´ ë‚¸ë‹¤ëŠ” ê²ƒì€!ì´ë¯¸ ì‘ë‹µí•  í˜ì´ì§€ë¥¼ ë§Œë“¤ì–´ì„œ ê°€ì§€ê³  ìˆëŠ”ê²Œ ì•„ë‹ˆë¼ , ìš”ì²­ì´ ë“¤ì–´ì™”ì„ë•Œ í”„ë¡œê·¸ë¨ì´ ì‹¤í–‰ë˜ë©´ì„œì‘ë‹µí•  ì½”ë“œë¥¼ ë§Œë“¤ì–´ ë‚´ê³  ê·¸ ì½”ë“œë¡œ ì‘ë‹µì„ í•˜ëŠ” ê²ƒì„ ë§í•œë‹¤. ì„œë¸”ë¦¿ì„ ì •ì˜í•´ë³´ë©´ ì„œë¸”ë¦¿(servlet)ì€ WASì— ë™ì‘í•˜ëŠ” JAVA í´ë˜ìŠ¤ì…ë‹ˆë‹¤. ì„œë¸”ë¦¿ì€ HttpServlet í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ì•¼ í•©ë‹ˆë‹¤. ì„œë¸”ë¦¿ê³¼ JSPë¡œë¶€í„° ìµœìƒì˜ ê²°ê³¼ë¥¼ ì–»ìœ¼ë ¤ë©´, ì›¹ í˜ì´ì§€ë¥¼ ê°œë°œí•  ë•Œ ì´ ë‘ ê°€ì§€(JSP, ì„œë¸”ë¦¿)ë¥¼ ì¡°í™”ë¡­ê²Œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì›¹ í˜ì´ì§€ë¥¼ êµ¬ì„±í•˜ëŠ” í™”ë©´(HTML)ì€ JSPë¡œ í‘œí˜„í•˜ê³ , ë³µì¡í•œ í”„ë¡œê·¸ë˜ë°ì€ ì„œë¸”ë¦¿ìœ¼ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤. ###Servlet ì‘ì„±ë°©ë²•ë‘ê°€ì§€ê°€ ìˆëŠ”ë° Servlet 3.0 ì´ìƒì¼ë•Œ ì–´ë…¸í…Œì´ì…˜ì„ ì‚¬ìš©í•œë‹¤ Servlet 3.0 ë¯¸ë§Œì—ì„œëŠ” web.xml íŒŒì¼ì— ì§ì ‘ ì ì–´ì„œ í•œë‹¤ í˜„ì¬ ì‹¤ë¬´ì—ì„œëŠ” ì›¹ì„ ê°œë°œí• ë•Œ ì„œë¸”ë¦¿ì„ ì¨ì„œ ê°œë°œí•˜ì§€ ì•ŠìŒì¡°ê¸ˆ ë” í¸í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ëŠ” ë‹¤ì–‘í•œ í”„ë ˆì„ ì›Œí¬ë¥¼ ì‚¬ìš©í•œë‹¤. í•˜ì§€ë§Œ í”„ë ˆì„ ì›Œí¬ë“¤ë„ ì„œë¸”ë¦¿ ì—†ì´ëŠ” ë™ì‘ í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— ì„œë¸”ë¦¿ì˜ ê¸°ë³¸ì ì¸ ì‘ì„±ë²•ì´ë‚˜, ì„œë¸”ë¦¿ì˜ ë¼ì´í”„ì‚¬ì´í´ì„ ì´í•´í•  ì¤„ ì•Œë©´ ì¢‹ë‹¤. Servlet 3.0 ì´ìƒ ë°©ë²•ì—ì„œ ì‘ì„±í•´ë³´ê¸°ìƒˆë¡œìš´ ë‹¤ì´ë‚˜ë¯¹ ì›¹ í”„ë¡œì íŠ¸ë¥¼ ë§Œë“¤ë•Œ Dynamic web module versiondì„ 3.1ë¡œ ì„¤ì • í•˜ì˜€ë‹¤. HttpServletRequest request, HttpServletResponse responseí´ë¼ì´ì–¸íŠ¸ê°€ ìš”ì²­ -&gt; ì„œë²„ê°€ ì‘ë‹µí´ë¼ì´ì–¸íŠ¸ê°€ ìš”ì²­í• ë•Œ ì„œë²„ê°€ ìš”ì²­ì„ ë°›ì•„ë‚´ëŠ” ê°ì²´ì™€ ì‘ë‹µì„ í•˜ê¸° ìœ„í•œ ê°ì²´ë¥¼ ë‘ê°œë¥¼ ìë™ì„ ë§Œë“ ë‹¤.ìš”ì²­ì— ëŒ€í•œ ê°ì²´ëŠ” HttpServletRequest, ì‘ë‹µì— ê´€í•œ ê°ì²´ëŠ” HttpServletResponseì— ë‹´ì•„ë‘”ë‹¤ê³  ìƒê°í•˜ë©´ ëœë‹¤. 123456789101112131415161718192021222324@WebServlet(&quot;/Ten&quot;)public class TenServlet extends HttpServlet { private static final long serialVersionUID = 1L; /** * @see HttpServlet#HttpServlet() */ public TenServlet() { super(); // TODO Auto-generated constructor stub } /** * @see HttpServlet#doGet(HttpServletRequest request, HttpServletResponse response) */ protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType(&quot;text/html;charset=utf-8&quot;); PrintWriter out = response.getWriter(); out.println(&quot;&lt;h1&gt;1-10ê¹Œì§€ ì¶œë ¥ &lt;h1&gt;&quot;); for(int i = 1; i&lt;=10; i++) { out.println(i + &quot;&lt;br&gt;&quot;); } response.setContentType(â€œtext/html;charset=utf-8â€);íŒŒì¼ì˜ í˜•ì‹ì´ ë­”ì§€ ì•Œë ¤ì¤€ë‹¤ìœ„ëŠ” htmlì„ì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤. PrintWriter out = response.getWriter();response ê°ì²´ì— getWriter() ë©”ì„œë“œê°€ ì¡´ì¬í•˜ëŠ”ë°,getWriter()ë¼ëŠ” ë©”ì„œë“œë¥¼ ìˆ˜í–‰í•˜ë©´ PrintWriter ê°ì²´ê°€ ë°˜í™˜ ëœë‹¤ @WebServlet(â€œ/Tenâ€)url ì£¼ì†Œê°’ì´ë‹¤ìœ„ì˜ ì½”ë“œì˜ ì£¼ì†Œê°€ http://localhost:8080/exam31/Tenë¡œ ì„¤ì • ë¨ì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤ Servlet 3.0 ë¯¸ë§Œì˜ ë°©ë²•ì—ì„œ ì‘ì„±í•´ë³´ê¸°ìƒˆë¡œìš´ ë‹¤ì´ë‚˜ë¯¹ ì›¹ í”„ë¡œì íŠ¸ë¥¼ ë§Œë“¤ë•Œ Dynamic web module versiondì„ 2.5ë¡œ ì„¤ì • í•˜ì˜€ë‹¤.3.1ê³¼ëŠ” ë‹¤ë¥´ê²Œ web.xmlì´ ìë™ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ë‹¤ (3.1ì€ í”„ë¡œì íŠ¸ ë§Œë“¤ë©´ì„œ ë”°ë¡œ ì²´í¬í•´ì¤˜ì•¼í•¨) 1234567891011121314151617181920212223242526272829public class TenServlet extends HttpServlet { private static final long serialVersionUID = 1L; /** * @see HttpServlet#HttpServlet() */ public TenServlet() { super(); // TODO Auto-generated constructor stub } /** * @see HttpServlet#doGet(HttpServletRequest request, HttpServletResponse response) */ protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { // TODO Auto-generated method stub response.getWriter().append(&quot;Served at: &quot;).append(request.getContextPath()); } /** * @see HttpServlet#doPost(HttpServletRequest request, HttpServletResponse response) */ protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { // TODO Auto-generated method stub doGet(request, response); }} 3.0ë¯¸ë§Œì˜ ë²„ì „ì€ ì–´ë…¸í…Œì´ì…˜ì´ ì—†ë‹¤ ì•„ë˜ëŠ” web.xmlì˜ ì¼ë¶€ì´ë‹¤ 123456789101112 &lt;servlet&gt; &lt;description&gt;&lt;/description&gt; &lt;display-name&gt;TenServlet&lt;/display-name&gt; &lt;servlet-name&gt;TenServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;exam.TenServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;TenServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/Ten&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; urlì´ /tenì´ë¼ëŠ” ìš”ì²­ì´ ë“¤ì–´ì˜¤ë©´-&gt; URL mappingì—ì„œ ì°¾ì•„ë‚¸ë‹¤ urlì´ ì¡´ì¬í•œë‹¤ë©´ (ì¡´ì¬ì•ˆí•˜ë©´ 404)-&gt; ì„ í™•ì¸í•˜ê³  ì´ë¦„ì´ TenServletê³¼ ê°™ì€ ì´ë¦„ì„ ì—ì„œ í™•ì¸í•œë‹¤-&gt; ì„œë¸”ë¦¿ì„ ì°¾ì•„ì„œ ì‹¤í–‰ì‹œí‚¬ ì„œë¸”ë¦¿ì´ ëˆ„êµ°ì§€ ì—ì„œ ì°¾ì„ ìˆ˜ ìˆë‹¤ 3.0ì´ìƒì˜ ë²„ì „ì—ì„œëŠ” ì–´ë…¸í…Œì´ì…˜ì´ ìœ„ì˜ ê°™ì€ ì—­í• ì„ í•œë‹¤ Servlet ë¼ì´í”„ ì‹¸ì´í´ |ì„œë¸”ë¦¿ì´ ì–¸ì œ ìƒì„±ë˜ê³  ì´ëŸ° ë©”ì„œë“œë“¤ì´ ì–¸ì œ í˜¸ì¶œì´ ë˜ëŠ”ì§€ ì•Œì•„ë³¼ ìˆ˜ ìˆë‹¤. 1234567891011121314151617181920212223242526272829303132333435package examples;import java.io.IOException;import javax.servlet.ServletConfig;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;@WebServlet(&quot;/LifecycleServlet&quot;)public class LifecycleServlet extends HttpServlet { private static final long serialVersionUID = 1L; public LifecycleServlet() { System.out.println(&quot;LifecycleServlet ìƒì„±&quot;); //ì½˜ì†”ì— ì¶œë ¥ } public void init(ServletConfig config) throws ServletException { System.out.println(&quot;init í˜¸ì¶œ&quot;); } public void destroy() { System.out.println(&quot;destroy í˜¸ì¶œ&quot;); } protected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { System.out.println(&quot;service í˜¸ì¶œ&quot;); }} LifecycleServlet ìƒì„± init í˜¸ì¶œ service í˜¸ì¶œ ìœ„ì˜ ê²°ê³¼ê°€ ì½˜ì†”ì— ì¶œë ¥ë¨ìµœì´ˆë¡œ LifecycleServletë¥¼ í˜¸ì¶œì‹œ ê°ì²´ê°€ ë§Œë“¤ì–´ì§€ë©´ì„œìƒì„±ìê°€ ë§Œë“¤ì–´ì§„ë‹¤ ë”°ë¼ì„œ ìƒì„±ìì— ë„£ì–´ì¤€ ë©”ì„¸ì§€ê°€ ì¶œë ¥ëœë‹¤ -&gt; LifecycleServlet ìƒì„± service í˜¸ì¶œë¸Œë¼ìš°ì € ìƒˆë¡œê³ ì¹¨ì‹œ ì € í•œì¤„ë§Œ ë‚˜ì˜¨ë‹¤ì„œë¸”ë¦¿ì€ ì„œë²„ì— ê°ì²´ë¥¼ ì—¬ëŸ¬ë²ˆ ë§Œë“¤ì§€ ì•ŠìŒìš”ì²­ëœ ê°ì²´ê°€ ë©”ëª¨ë¦¬ì— ìˆëŠ”ì§€ ì—†ëŠ”ì§€ í™•ì¸í•˜ê³ , ìˆìœ¼ë©´ serviceë¼ëŠ” ë©”ì„œë“œë§Œ í˜¸ì¶œí•œë‹¤ destroy í˜¸ì¶œì„œë¸”ë¦¿ì´ ìˆ˜ì •ë˜ë©´ í˜„ì¬ ë©”ëª¨ë¦¬ì— ì˜¬ë¼ê°€ ìˆëŠ” ì„œë¸”ë¦¿ ê°ì²´ê°€ ë” ì´ìƒ ì‚¬ìš©ë  ìˆ˜ ì—†ë‹¤ì´ë•Œ destroy ë˜ë©´ì„œ ë©”ëª¨ë¦¬ì— ê°ì²´ë¥¼ ì‚­ì œí•¨ ì •ë¦¬Servlet ìƒëª…ì£¼ê¸° WASëŠ” ì„œë¸”ë¦¿ ìš”ì²­ì„ ë°›ìœ¼ë©´ í•´ë‹¹ ì„œë¸”ë¦¿ì´ ë©”ëª¨ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. if (ë©”ëª¨ë¦¬ì— ì—†ìŒ) { í•´ë‹¹ ì„œë¸”ë¦¿ í´ë˜ìŠ¤ë¥¼ ë©”ëª¨ë¦¬ì— ì˜¬ë¦¼ init() ë©”ì†Œë“œë¥¼ ì‹¤í–‰} service()ë©”ì†Œë“œë¥¼ ì‹¤í–‰wasê°€ ì¢…ë£Œë˜ê±°ë‚˜, ì›¹ ì–´í”Œë¦¬ì¼€ì´ì…˜ì´ ìƒˆë¡­ê²Œ ê°±ì‹ ë  ê²½ìš° destroy() ë©”ì†Œë“œê°€ ì‹¤í–‰ë©ë‹ˆë‹¤. service (request, response) ë©”ì„œë“œservice()ë©”ì„œë“œëŠ” httpservletì— êµ¬í˜„ì´ ë˜ì–´ ìˆë‹¤service(request, response) ë©”ì†Œë“œ HttpServletì˜ serviceë©”ì†Œë“œëŠ” í…œí”Œë¦¿ ë©”ì†Œë“œ íŒ¨í„´ìœ¼ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤. í´ë¼ì´ì–¸íŠ¸ì˜ ìš”ì²­ì´ GETì¼ ê²½ìš°ì—ëŠ” ìì‹ ì´ ê°€ì§€ê³  ìˆëŠ” doGet(request, response)ë©”ì†Œë“œë¥¼ í˜¸ì¶œ í´ë¼ì´ì–¸íŠ¸ì˜ ìš”ì²­ì´ Postì¼ ê²½ìš°ì—ëŠ” ìì‹ ì´ ê°€ì§€ê³  ìˆëŠ” doPost(request, response)ë¥¼ í˜¸ì¶œ ì˜ˆì œ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package examples;import java.io.IOException;import java.io.PrintWriter;import javax.servlet.ServletConfig;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;@WebServlet(&quot;/LifecycleServlet&quot;)public class LifecycleServlet extends HttpServlet { private static final long serialVersionUID = 1L; public LifecycleServlet() { System.out.println(&quot;LifecycleServlet ìƒì„±!!&quot;); } public void init(ServletConfig config) throws ServletException { System.out.println(&quot;init test í˜¸ì¶œ!!&quot;); } public void destroy() { System.out.println(&quot;destroy í˜¸ì¶œ!!&quot;); } @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType(&quot;text/html&quot;); PrintWriter out = response.getWriter(); out.println(&quot;&lt;html&gt;&quot;); out.println(&quot;&lt;head&gt;&lt;title&gt;form&lt;/title&gt;&lt;/head&gt;&quot;); out.println(&quot;&lt;body&gt;&quot;); out.println(&quot;&lt;form method='post' action='/firstweb/LifecycleServlet'&gt;&quot;); out.println(&quot;name : &lt;input type='text' name='name'&gt;&lt;br&gt;&quot;); out.println(&quot;&lt;input type='submit' value='ok'&gt;&lt;br&gt;&quot;); out.println(&quot;&lt;/form&gt;&quot;); out.println(&quot;&lt;/body&gt;&quot;); out.println(&quot;&lt;/html&gt;&quot;); out.close(); } protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType(&quot;text/html&quot;); PrintWriter out = response.getWriter(); String name = request.getParameter(&quot;name&quot;); out.println(&quot;&lt;h1&gt; hello &quot; + name + &quot;&lt;/h1&gt;&quot;); out.close(); }// protected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {// System.out.println(&quot;service í˜¸ì¶œ!!&quot;);// }// } í•´ë‹¹ ì„œë¸”ë¦¿ì˜ urlì£¼ì†Œë¥¼ ì…ë ¥í•˜ê±°ë‚˜, ë§í¬ë¥¼ í´ë¦­í•˜ëŠ” ê²ƒì€ GETë°©ì‹ìœ¼ë¡œ ì„œë²„ì— ìš”ì²­ì„ ë³´ë‚´ëŠ” ê²ƒì´ë‹¤ì´ ê²½ìš°ì— service ë©”ì„œë“œê°€ í˜¸ì¶œì´ ë˜ë©´ì„œ doGet()ë©”ì„œë“œë¥¼ í˜¸ì¶œ","link":"/2022/01/03/boostcourse-07-servlet/"},{"title":"JSP | ë¶€ìŠ¤íŠ¸ì½”ìŠ¤ ë°±ì—”ë“œ 08","text":"ì„ ìƒë‹˜ì´ JSPëŠ” Servletìœ¼ë¡œ ì–´ë–»ê²Œ ë°”ë€”ì§€ ìƒê°í•˜ëŠ”ê²Œ ì¤‘ìš”í•˜ë‹¤ê³  í•˜ì…¨ë‹¤!ê·¼ë° ì‚¬ì‹¤ ì•„ì§ ì™œ ê·¸ê²Œ ì¤‘ìš”í•œì§€ ëª¨ë¥´ê² ë‹¤JSPëŠ” ì–´ë µì§€ ì•Šì€ë° ì´ê±¸ ì–´ë–¤ì‹ìœ¼ë¡œ ì ìš©í•´ì„œ ì‹¤ë¬´ì—ì„œ ì‚¬ìš©í•˜ëŠ”ì§€ëŠ” ì˜ ëª¨ë¥´ê²Ÿë‹¤í”„ë¡œì íŠ¸ë¥¼ í•˜ë‹¤ë³´ë©´ ì•Œê² ì§€.. JSP (Java Server Servlet)ì›¹ì„ ì‰½ê²Œ ê°œë°œ í•  ìˆ˜ ìˆëŠ” ìŠ¤í¬ë¦½íŠ¸ ì—”ì§„ì„ ë§Œë“ ê²ƒ.JSPëŠ” ì„œë¸”ë¦¿ ê¸°ìˆ ì„ ì‚¬ìš©í•œë‹¤htmlê³¼ êµ‰ì¥íˆ ë¹„ìŠ·í•˜ë‹¤JSPëŠ” JSP ìì²´ê°€ ë™ì‘í•˜ì§€ ì•Šê³ , ëª¨ë“  JSPëŠ” ì„œë¸”ë¦¿ìœ¼ë¡œ ë°”ë€Œì–´ì„œ ë™ì‘í•œë‹¤í†°ìº£ì´ JSPë¥¼ ì„œë¸”ë¦¿ìœ¼ë¡œ ë°”ê¾¸ëŠ”ê²ƒì´ë‹¤. JSP -&gt; ServletC:\\Users\\jiwon\\eclipse-workspace.metadata.plugins\\org.eclipse.wst.server.core\\tmp0\\work\\Catalina\\localhostìœ„ì˜ ê²½ë¡œë¡œ ì´ë™í•˜ë©´ JSPíŒŒì¼ì´ servletìœ¼ë¡œ ë³€í™˜ëœê²ƒì„ ì°¾ì„ ìˆ˜ ìˆë‹¤ ###JSPì˜ ì‹¤í–‰ìˆœì„œ ë¸Œë¼ìš°ì €ê°€ ì›¹ì„œë²„ì— JSPì— ëŒ€í•œ ìš”ì²­ ì •ë³´ë¥¼ ì „ë‹¬í•œë‹¤. ë¸Œë¼ìš°ì €ê°€ ìš”ì²­í•œ JSPê°€ ìµœì´ˆë¡œ ìš”ì²­í–ˆì„ ê²½ìš°ë§Œ JSPë¡œ ì‘ì„±ëœ ì½”ë“œê°€ ì„œë¸”ë¦¿ìœ¼ë¡œ ì½”ë“œë¡œ ë³€í™˜í•œë‹¤. (java íŒŒì¼ ìƒì„±) ì„œë¸”ë¦¿ ì½”ë“œë¥¼ ì»´íŒŒì¼í•´ì„œ ì‹¤í–‰ê°€ëŠ¥í•œ bytecodeë¡œ ë³€í™˜í•œë‹¤. (class íŒŒì¼ ìƒì„±) ì„œë¸”ë¦¿ í´ë˜ìŠ¤ë¥¼ ë¡œë”©í•˜ê³  ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•œë‹¤. ì„œë¸”ë¦¿ì´ ì‹¤í–‰ë˜ì–´ ìš”ì²­ì„ ì²˜ë¦¬í•˜ê³  ì‘ë‹µ ì •ë³´ë¥¼ ìƒì„±í•œë‹¤. ê°„ë‹¨í•œ ì˜ˆì œFile -&gt; new -&gt; JSPJSP íŒŒì¼ ìœ„ì¹˜ëŠ” Web Contentì˜ ë°‘ì— ìˆë‹¤ì´ ìœ„ì¹˜ì— html, css, javascript ë‹¤ ë„£ìœ¼ë©´ ëœë‹¤. 123456789101112131415161718192021&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;&lt;title&gt;sum10&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;% int total = 0; for(int i = 1; i &lt;= 10; i++){ total = total + i; }%&gt;1ë¶€í„° 10ê¹Œì§€ì˜ í•© : &lt;%=total %&gt;&lt;/body&gt;&lt;/html&gt; ì§€ì‹œì&lt;%@ ì•„ë˜ ì½”ë“œëŠ” JSP íŒŒì¼ì—ì„œ java ì–¸ì–´ë¡œ ì‘ì„±ëœ ì½”ë“œê°€ ë‚˜ì˜¨ë‹¤ê³  ì˜ë¯¸í•¨ì¸ì½”ë”©ì„ ë§ì¶°ì¤¬ë‹¤ ì•ˆí•˜ë©´ í•œê¸€ì´ ê¹¨ì§„ë‹¤ &lt;%@ page language=â€javaâ€ contentType=â€text/html; charset=UTF-8â€ pageEncoding=â€UTF-8â€%&gt; Scriptlet&lt;% %&gt;&lt;% %&gt; ì´ëŸ° ê¸°í˜¸ë“¤ì€ ì„œë¸”ë¦¿ìœ¼ë¡œ ë°”ê¿€ë•Œ ì–´ë–»ê²Œ ë°”ê¾¸ëŠ”ì§€ ì•Œë ¤ì£¼ê¸° ìœ„í•œ ë¶€ë¶„ì„ ì˜ë¯¸í•œë‹¤JSPì—ì„œëŠ” ë‹¤ë¥¸ ì–¸ì–´ë„ ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ì§€ë§Œ ë³´í†µ javaë§Œ ì‚¬ìš©í•œë‹¤ í‘œí˜„ì‹&lt;%= %&gt;out.print();ì™€ ë˜‘ê°™ì€ ì—­í• ì„ í•œë‹¤. JSP ë¬¸ë²•ìŠ¤í¬ë¦½íŠ¸ ìš”ì†Œì˜ ì´í•´ JSP í˜ì´ì§€ì—ì„œëŠ” ì„ ì–¸ë¬¸(Declaration), ìŠ¤í¬ë¦½íŠ¸ë¦¿(Scriptlet), í‘œí˜„ì‹(Expression) ì´ë¼ëŠ” 3ê°€ì§€ì˜ ìŠ¤í¬ë¦½íŠ¸ ìš”ì†Œë¥¼ ì œê³µì„ ì–¸ë¬¸ &lt;%! %&gt;: ì „ì—­ë³€ìˆ˜ ì„ ì–¸ ë° ë©”ì†Œë“œ ì„ ì–¸ì— ì‚¬ìš©ìŠ¤í¬ë¦½íŠ¸ë¦¿ &lt;% %&gt;: í”„ë¡œê·¸ë˜ë° ì½”ë“œ ê¸°ìˆ ì— ì‚¬ìš©í‘œí˜„ì‹ &lt;%=%&gt;: í™”ë©´ì— ì¶œë ¥í•  ë‚´ìš© ê¸°ìˆ ì— ì‚¬ìš© ì„ ì–¸ë¬¸JSPê°€ Servletìœ¼ë¡œ ë°”ë€Œì—ˆì„ë•Œ, Service() ë©”ì„œë“œ ì•ˆì—ì„œ ìë°” ì½”ë“œë¡œ ë°”ë€Œì–´ìˆë‹¤ê·¸ëŸ¬ë‚˜, ì„ ì–¸ë¬¸ì„ ì‚¬ìš©í–ˆì„ë•ŒëŠ” Service() ë©”ì„œë“œê°€ ì•„ë‹ˆë¼ í´ë˜ìŠ¤ ë°”ë””ìª½ì— ì½”ë“œê°€ ë°”ë€Œì—ˆìŒì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤ì•„ë˜ëŠ” ê·¸ì— í•´ë‹¹í•˜ëŠ” ì˜ˆì œì´ë‹¤ 123456789101112131415161718192021&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;id : &lt;%=getId() %&gt; //ì„ ì–¸ë¬¸ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ service() ì•ˆì— ìë°”ì½”ë“œë¡œ ë°”ë€Œì—ˆìŒ&lt;/body&gt;&lt;/html&gt;&lt;%! String id = &quot;u001&quot;; //ë©¤ë²„ë³€ìˆ˜ ì„ ì–¸ public String getId( ) { //ë©”ì†Œë“œ ì„ ì–¸ return id; }%&gt; //ì„ ì–¸ë¬¸ì„ ì‚¬ìš©í–ˆê¸° ë•Œë¬¸ì— í´ë˜ìŠ¤ ë°”ë””ì— ì„ ì–¸ë¨ ìŠ¤í¬ë¦½íŠ¸ë¦¿&lt;% %&gt;ê°€ì¥ ì¼ë°˜ì ìœ¼ë¡œ ë§ì´ ì“°ì´ëŠ” ìŠ¤í¬ë¦½íŠ¸ ìš”ì†Œì£¼ë¡œ í”„ë¡œê·¸ë˜ë°ì˜ ë¡œì§ì„ ê¸°ìˆ í•  ë•Œ ì‚¬ìš©ìŠ¤í¬ë¦½íŠ¸ë¦¿ì—ì„œ ì„ ì–¸ëœ ë³€ìˆ˜ëŠ” ì§€ì—­ë³€ìˆ˜ -&gt; service() ë©”ì„œë“œ ì•ˆì— ì„ ì–¸ë˜ëŠ” ë³€ìˆ˜ì´ë‹¤ 1234567891011121314151617181920&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;%for(int i = 1; i &lt;= 5; i++){%&gt;&lt;H&lt;%=i %&gt;&gt; ì•„ë¦„ë‹¤ìš´ í•œê¸€ &lt;/H&lt;%=i %&gt;&gt;&lt;%}%&gt;&lt;/body&gt;&lt;/html&gt; í‘œí˜„ì‹&lt;% %&gt;JSPí˜ì´ì§€ì—ì„œ ì›¹ ë¸Œë¼ìš°ì €ì— ì¶œë ¥í•  ë¶€ë¶„ì„ í‘œí˜„ì¦‰, í™”ë©´ì— ì¶œë ¥í•˜ê¸° ìœ„í•œê²ƒìŠ¤í¬ë¦½íŠ¸ë¦¿ ë‚´ì—ì„œ ì¶œë ¥í•  ë¶€ë¶„ì€ ë‚´ì¥ê°ì²´ì¸ outê°ì²´ì˜ print() ë˜ëŠ” println() ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•´ì„œ ì¶œë ¥ ###JSP ë‚´ì¥ ê°ì²´ JSPë¥¼ ì‹¤í–‰í•˜ë©´ ì„œë¸”ë¦¿ ì†ŒìŠ¤ê°€ ìƒì„±ë˜ê³  ì‹¤í–‰ëœë‹¤.JSPì— ì…ë ¥í•œ ëŒ€ë¶€ë¶„ì˜ ì½”ë“œëŠ” ìƒì„±ë˜ëŠ” ì„œë¸”ë¦¿ ì†ŒìŠ¤ì˜ _jspService() ë©”ì†Œë“œ ì•ˆì— ì‚½ì…ë˜ëŠ” ì½”ë“œë¡œ ìƒì„±ëœë‹¤._jspService()ì— ì‚½ì…ëœ ì½”ë“œì˜ ìœ—ë¶€ë¶„ì— ë¯¸ë¦¬ ì„ ì–¸ëœ ê°ì²´ë“¤ì´ ìˆëŠ”ë°, í•´ë‹¹ ê°ì²´ë“¤ì€ jspì—ì„œë„ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤.response, request, application, session, outê³¼ ê°™ì€ ë³€ìˆ˜ë¥¼ ë‚´ì¥ê°ì²´ë¼ê³  í•œë‹¤. 123456789101112131415161718&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;% StringBuffer url = request.getRequestURL(); out.println(&quot;url : &quot; + url.toString()); out.println(&quot;&lt;br&gt;&quot;);%&gt;&lt;/body&gt;&lt;/html&gt; ìœ„ì˜ ì˜ˆì œì—ì„œëŠ” ê°ì²´ ì„ ì–¸ì´ ë¹ ì ¸ìˆë‹¤ì›ë˜ javaëŠ” ë³€ìˆ˜ ì„ ì–¸ì´ ë¬´ì¡°ê±´ ë˜ì•¼í•˜ëŠ”ë° JSPì—ì„œëŠ” ë‚´ì¥ ê°ì²´ê°€ ì„ ì–¸ë˜ì–´ ìˆì–´ì„œìœ„ì˜ ì˜ˆì œì—ì„œëŠ” ê°ì²´ ì„ ì–¸ ì—†ì´ ì‚¬ìš©í•  ìˆ˜ ìˆì—ˆë‹¤. protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { PrintWriter out = response.getWriter(); ìœ„ì˜ ì½”ë“œê°€ ë¹ ì ¸ìˆëŠ”ì…ˆì´ë‹¤","link":"/2022/01/03/boostcourse-08-jsp/"},{"title":"HTTP | ë¶€ìŠ¤íŠ¸ì½”ìŠ¤ ë°±ì—”ë“œ 05","text":"HTTP (Hypertext Transfer Protocol)ì›¹ ë¸Œë¼ìš°ì €ì™€ ì›¹ ì„œë²„ ê°„ì—ë„ ì„œë¡œ í†µì‹ í•˜ê¸° ìœ„í•œ ê·œì•½ì„œë²„ì™€ í´ë¼ì´ì–¸íŠ¸ê°€ ì¸í„°ë„·ìƒì—ì„œ ë°ì´í„°ë¥¼ ì£¼ê³ ë°›ê¸° ìœ„í•œ í”„ë¡œí† ì½œì´ë‹¤. HTTP ì‘ë™ë°©ì‹HTTPëŠ” ì„œë²„/í´ë¼ì´ì–¸íŠ¸ ëª¨ë¸ì„ ë”°ë¦…ë‹ˆë‹¤.ì¥ì  ë¶ˆíŠ¹ì • ë‹¤ìˆ˜ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ëŠ” ì„œë¹„ìŠ¤ì—ëŠ” ì í•©í•˜ë‹¤. í´ë¼ì´ì–¸íŠ¸ì™€ ì„œë²„ê°€ ê³„ì† ì—°ê²°ëœ í˜•íƒœê°€ ì•„ë‹ˆê¸° ë•Œë¬¸ì— í´ë¼ì´ì–¸íŠ¸ì™€ ì„œë²„ ê°„ì˜ ìµœëŒ€ ì—°ê²° ìˆ˜ë³´ë‹¤ í›¨ì”¬ ë§ì€ ìš”ì²­ê³¼ ì‘ë‹µì„ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.ë‹¨ì  ì—°ê²°ì„ ëŠì–´ë²„ë¦¬ê¸° ë•Œë¬¸ì—, í´ë¼ì´ì–¸íŠ¸ì˜ ì´ì „ ìƒí™©ì„ ì•Œ ìˆ˜ê°€ ì—†ë‹¤. ì´ëŸ¬í•œ íŠ¹ì§•ì„ ë¬´ìƒíƒœ(Stateless)ë¼ê³  ë§í•œë‹¤. ì´ëŸ¬í•œ íŠ¹ì§• ë•Œë¬¸ì— ì •ë³´ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ì„œ Cookieì™€ ê°™ì€ ê¸°ìˆ ì´ ë“±ì¥í•˜ê²Œ ë˜ì—ˆë‹¤. URL (Uniform Resource Locator)ì¸í„°ë„· ìƒì˜ ìì›ì˜ ìœ„ì¹˜íŠ¹ì • ì›¹ ì„œë²„ì˜ íŠ¹ì • íŒŒì¼ì— ì ‘ê·¼í•˜ê¸° ìœ„í•œ ê²½ë¡œ í˜¹ì€ ì£¼ì†Œ ###ìš”ì²­ ë©”ì„œë“œ : GET, PUT, POST, PUSH, OPTIONS ë“±ì˜ ìš”ì²­ ë°©ì‹ì´ ì˜¨ë‹¤.ìš”ì²­ URI : ìš”ì²­í•˜ëŠ” ìì›ì˜ ìœ„ì¹˜ë¥¼ ëª…ì‹œí•œë‹¤.HTTP í”„ë¡œí† ì½œ ë²„ì „ : ì›¹ ë¸Œë¼ìš°ì €ê°€ ì‚¬ìš©í•˜ëŠ” í”„ë¡œí† ì½œ ë²„ì „ì´ë‹¤.ì²«ë²ˆì§¸ ì¤„ì˜ ìš”ì²­ë©”ì†Œë“œëŠ” ì„œë²„ì—ê²Œ ìš”ì²­ì˜ ì¢…ë¥˜ë¥¼ ì•Œë ¤ì£¼ê¸° ìœ„í•´ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤. ê°ê°ì˜ ë©”ì†Œë“œ ì´ë¦„ì€ ë‹¤ìŒê³¼ ê°™ì€ ì˜ë¯¸ë¥¼ ê°€ì§‘ë‹ˆë‹¤. ì°¸ê³ ë¡œ ìµœì´ˆì˜ ì›¹ ì„œë²„ëŠ” GETë°©ì‹ë§Œ ì§€ì›í•´ì¤¬ìŠµë‹ˆë‹¤. GET : ì •ë³´ë¥¼ ìš”ì²­í•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš©í•œë‹¤. (SELECT)POST : ì •ë³´ë¥¼ ë°€ì–´ë„£ê¸° ìœ„í•´ì„œ ì‚¬ìš©í•œë‹¤. (INSERT)PUT : ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš©í•œë‹¤. (UPDATE)DELETE : ì •ë³´ë¥¼ ì‚­ì œí•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš©í•œë‹¤. (DELETE)HEAD : (HTTP)í—¤ë” ì •ë³´ë§Œ ìš”ì²­í•œë‹¤. í•´ë‹¹ ìì›ì´ ì¡´ì¬í•˜ëŠ”ì§€ í˜¹ì€ ì„œë²„ì— ë¬¸ì œê°€ ì—†ëŠ”ì§€ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš©í•œë‹¤.OPTIONS : ì›¹ì„œë²„ê°€ ì§€ì›í•˜ëŠ” ë©”ì„œë“œì˜ ì¢…ë¥˜ë¥¼ ìš”ì²­í•œë‹¤.TRACE : í´ë¼ì´ì–¸íŠ¸ì˜ ìš”ì²­ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜í•œë‹¤. ì˜ˆì»¨ë° echo ì„œë¹„ìŠ¤ë¡œ ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•˜ê¸° ìœ„í•œ ëª©ì ìœ¼ë¡œ ì£¼ë¡œ ì‚¬ìš©í•œë‹¤. ë¸Œë¼ìš°ì €ex) ì‚¬íŒŒë¦¬, êµ¬ê¸€í¬ë¡¬, íŒŒì´ì–´í­ìŠ¤ â€¦etcì„œë²„ì—ì„œ ì „ì†¡í•œ ë°ì´í„°(HTMLê³¼ ê°™ì€)ê°€ í´ë¼ì´ì–¸íŠ¸ì— ë„ì°©í•˜ëŠ”ê³³Browserì—ëŠ” ë°ì´í„°ë¥¼ í•´ì„í•´ì£¼ëŠ” íŒŒì„œì™€ ë°ì´í„°ë¥¼ í™”ë©´ì— í‘œí˜„í•´ì£¼ëŠ” ë Œë”ë§ì—”ì§„ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì €ì˜ íë¦„Pasing HTML to construct the DOM tree #pasing ë¶„ì„ í•´ì„ Render tree contruction Layout of the render tree #í™”ë©´ ë°°ì¹˜ Painting the render tee","link":"/2022/01/03/boostcourse-05-http/"},{"title":"Scope | ë¶€ìŠ¤íŠ¸ì½”ìŠ¤ ë°±ì—”ë“œ 09","text":"Scopeê°ì²´ì˜ ë²”ìœ„ë¥¼ ì •ì˜ìœ íš¨ë²”ìœ„-&gt; ìŠ¤ì½”í”„ ì˜ˆì œë¥¼ í•œë²ˆ ì°¾ì•„ë´ì•¼í• ê²ƒ ê°™ë‹¤ Application Session Request Page Applicationì›¹ ì–´í”Œë¦¬ì¼€ì´ì…˜ì´ ì‹œì‘ë˜ê³  ì¢…ë£Œë  ë•Œê¹Œì§€ ë³€ìˆ˜ê°€ ìœ ì§€ë˜ëŠ” ê²½ìš° ì‚¬ìš© Sessionì›¹ ë¸Œë¼ìš°ì € ë³„ë¡œ ë³€ìˆ˜ê°€ ê´€ë¦¬ë˜ëŠ” ê²½ìš° ì‚¬ìš©ì„¸ì…˜ ê°ì²´ê°€ ìƒì„±ë˜ì„œ ì„¸ì…˜ ê°ì²´ê°€ ì†Œë©¸ ë ë•Œê¹Œì§€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê²ƒì´ë‹¤.ìƒíƒœìœ ì§€ Requesthttpìš”ì²­ì„ WASê°€ ë°›ì•„ì„œ ì›¹ ë¸Œë¼ìš°ì €ì—ê²Œ ì‘ë‹µí•  ë•Œê¹Œì§€ ë³€ìˆ˜ê°€ ìœ ì§€ë˜ëŠ” ê²½ìš° ì‚¬ìš©í´ë¼ì´ì–¸íŠ¸ë¡œ ìš”ì²­ì´ ë“¤ì–´ì™€ì„œ ì„œë²„ê°€ ì–´ë–¤ ì¼ë“¤ì„ ìˆ˜í–‰í•œ ë‹¤ìŒì— ì‘ë‹µì„ í• ë•Œê¹Œì§€ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤ Pageí˜ì´ì§€ ë‚´ì—ì„œ ì§€ì—­ë³€ìˆ˜ì²˜ëŸ¼ ì‚¬ìš©Page ScopeëŠ” ì„ ì–¸ëœ í•œ í˜ì´ì§€ ê·¸ ë‚´ì—ì„œë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê²ƒì´ë‹¤ Page Scope PageContext ì¶”ìƒ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•œë‹¤. JSP í˜ì´ì§€ì—ì„œ pageContextë¼ëŠ” ë‚´ì¥ ê°ì²´ë¡œ ì‚¬ìš© ê°€ëŠ¥ í•˜ë‹¤. forwardê°€ ë  ê²½ìš° í•´ë‹¹ Page scopeì— ì§€ì •ëœ ë³€ìˆ˜ëŠ” ì‚¬ìš©í•  ìˆ˜ ì—†ë‹¤. ì‚¬ìš©ë°©ë²•ì€ Application scopeë‚˜ Session scope, request scopeì™€ ê°™ë‹¤. ë§ˆì¹˜ ì§€ì—­ë³€ìˆ˜ì²˜ëŸ¼ ì‚¬ìš©ëœë‹¤ëŠ” ê²ƒì´ ë‹¤ë¥¸ Scopeë“¤ê³¼ ë‹¤ë¥´ë‹¤. jspì—ì„œ pageScopeì— ê°’ì„ ì €ì¥í•œ í›„ í•´ë‹¹ ê°’ì„ ELí‘œê¸°ë²• ë“±ì—ì„œ ì‚¬ìš©í•  ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤. ì§€ì—­ ë³€ìˆ˜ì²˜ëŸ¼ í•´ë‹¹ jspë‚˜ ì„œë¸”ë¦¿ì´ ì‹¤í–‰ë˜ëŠ” ë™ì•ˆì—ë§Œ ì •ë³´ë¥¼ ìœ ì§€í•˜ê³ ì í•  ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤. Request Scope http ìš”ì²­ì„ WASê°€ ë°›ì•„ì„œ ì›¹ ë¸Œë¼ìš°ì €ì—ê²Œ ì‘ë‹µí•  ë•Œê¹Œì§€ ë³€ìˆ˜ê°’ì„ ìœ ì§€í•˜ê³ ì í•  ê²½ìš° ì‚¬ìš©í•œë‹¤. HttpServletRequest ê°ì²´ë¥¼ ì‚¬ìš©í•œë‹¤. JSPì—ì„œëŠ” request ë‚´ì¥ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•œë‹¤. ì„œë¸”ë¦¿ì—ì„œëŠ” HttpServletRequest ê°ì²´ë¥¼ ì‚¬ìš©í•œë‹¤. ê°’ì„ ì €ì¥í•  ë•ŒëŠ” request ê°ì²´ì˜ setAttribute()ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•œë‹¤. ê°’ì„ ì½ì–´ ë“¤ì¼ ë•ŒëŠ” request ê°ì²´ì˜ getAttribute()ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•œë‹¤. forward ì‹œ ê°’ì„ ìœ ì§€í•˜ê³ ì ì‚¬ìš©í•œë‹¤. ì•ì—ì„œ forwardì— ëŒ€í•˜ì—¬ ë°°ìš¸ ë•Œ forward í•˜ê¸° ì „ì— request ê°ì²´ì˜ setAttribute() ë©”ì†Œë“œë¡œ ê°’ì„ ì„¤ì •í•œ í›„, ì„œë¸”ë¦¿ì´ë‚˜ jspì—ê²Œ ê²°ê³¼ë¥¼ ì „ë‹¬í•˜ì—¬ ê°’ì„ ì¶œë ¥í•˜ë„ë¡ í•˜ì˜€ëŠ”ë° ì´ë ‡ê²Œ í¬ì›Œë“œ ë˜ëŠ” ë™ì•ˆ ê°’ì´ ìœ ì§€ë˜ëŠ” ê²ƒì´ Request scopeë¥¼ ì´ìš©í–ˆë‹¤ê³  í•©ë‹ˆë‹¤. Session Scope ì›¹ ë¸Œë¼ìš°ì €ë³„ë¡œ ë³€ìˆ˜ë¥¼ ê´€ë¦¬í•˜ê³ ì í•  ê²½ìš° ì‚¬ìš©í•œë‹¤. ì›¹ ë¸Œë¼ìš°ì €ê°„ì˜ íƒ­ ê°„ì—ëŠ” ì„¸ì…˜ì •ë³´ê°€ ê³µìœ ë˜ê¸° ë•Œë¬¸ì—, ê°ê°ì˜ íƒ­ì—ì„œëŠ” ê°™ì€ ì„¸ì…˜ì •ë³´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. HttpSession ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•œ ê°ì²´ë¥¼ ì‚¬ìš©í•œë‹¤. JSPì—ì„œëŠ” session ë‚´ì¥ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•œë‹¤. ì„œë¸”ë¦¿ì—ì„œëŠ” HttpServletRequestì˜ getSession()ë©”ì†Œë“œë¥¼ ì´ìš©í•˜ì—¬ session ê°ì²´ë¥¼ ì–»ëŠ”ë‹¤. ê°’ì„ ì €ì¥í•  ë•ŒëŠ” session ê°ì²´ì˜ setAttribute()ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•œë‹¤. ê°’ì„ ì½ì–´ ë“¤ì¼ ë•ŒëŠ” session ê°ì²´ì˜ getAttribute()ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•œë‹¤. ì¥ë°”êµ¬ë‹ˆì²˜ëŸ¼ ì‚¬ìš©ìë³„ë¡œ ìœ ì§€ê°€ ë˜ì–´ì•¼ í•  ì •ë³´ê°€ ìˆì„ ë•Œ ì‚¬ìš©í•œë‹¤. ###Application Scope ì›¹ ì–´í”Œë¦¬ì¼€ì´ì…˜ì´ ì‹œì‘ë˜ê³  ì¢…ë£Œë  ë•Œê¹Œì§€ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ServletContext ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•œ ê°ì²´ë¥¼ ì‚¬ìš©í•œë‹¤. jspì—ì„œëŠ” application ë‚´ì¥ ê°ì²´ë¥¼ ì´ìš©í•œë‹¤. ì„œë¸”ë¦¿ì˜ ê²½ìš°ëŠ” getServletContext()ë©”ì†Œë“œë¥¼ ì´ìš©í•˜ì—¬ applicationê°ì²´ë¥¼ ì´ìš©í•œë‹¤. ì›¹ ì–´í”Œë¦¬ì¼€ì´ì…˜ í•˜ë‚˜ë‹¹ í•˜ë‚˜ì˜ applicationê°ì²´ê°€ ì‚¬ìš©ëœë‹¤. ê°’ì„ ì €ì¥í•  ë•ŒëŠ” applicationê°ì²´ì˜ setAttribute()ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•œë‹¤. ê°’ì„ ì½ì–´ ë“¤ì¼ ë•ŒëŠ” applicationê°ì²´ì˜ getAttribute()ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•œë‹¤. ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ê°€ ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•´ì•¼ í•  ê°’ë“¤ì´ ìˆì„ ë•Œ ì‚¬ìš©í•œë‹¤. Application Scope ì˜ˆì œ ApplicationScope01, ApplicationScope02 ì„œë¸”ë¦¿ 2ê°œ ìƒì„± applicationscope01.jspë¥¼ ìƒì„± ApplicationScope02ëŠ” ApplicationScopeë¡œ valueì— 1ì„ ì €ì¥í•œë‹¤. ApplicationScope02ëŠ” Applicationscopeë¡œ ì €ì¥ëœ valueì˜ ê°’ì— 1ì„ ë”í•œ í›„ ê·¸ ê²°ê³¼ë¥¼ ì¶œë ¥ applicationscope01.jspëŠ” Application scopeë¡œ ì €ì¥ëœ valueì˜ ê°’ì— 2ë¥¼ ë”í•œ í›„ ê·¸ ê²°ê³¼ë¥¼ ì¶œë ¥ Application scopeëŠ” ì›¹ ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ì‚¬ìš©í•˜ëŠ” ëª¨ë“  ë¸Œë¼ìš°ì €ì—ì„œ ê°™ì€ ê°’ì„ ì‚¬ìš©í•˜ê²Œ í•œë‹¤.í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ì„œ í¬ë¡¬ê³¼ ì¸í„°ë„· ìµìŠ¤í”Œë¡œëŸ¬ë¥¼ ì‚¬ìš©í•´ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•œë‹¤. ApplicationScope01 12345678910111213141516171819202122232425@WebServlet(&quot;/ApplicationScope01&quot;)public class ApplicationScope01 extends HttpServlet { private static final long serialVersionUID = 1L; public ApplicationScope01() { super(); // TODO Auto-generated constructor stub } protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType(&quot;text/html; charset=UTF-8&quot;); PrintWriter out = response.getWriter(); ServletContext application = getServletContext(); int value = 1; application.setAttribute(&quot;value&quot;, value); out.println(&quot;&lt;h1&gt;value: &quot;+ value + &quot;&lt;/h1&gt;&quot;); }} setAttributeì™€ getAttributeëŠ” ë‹¤ë¥¸ scopeì—ì„œë„ ë™ì¼í•˜ê²Œ ì‚¬ìš©í•œë‹¤ ApplicationScope02 123456789101112131415161718192021222324252627@WebServlet(&quot;/ApplicationScope02&quot;)public class ApplicationScope02 extends HttpServlet { private static final long serialVersionUID = 1L; public ApplicationScope02() { super(); // TODO Auto-generated constructor stub } protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setContentType(&quot;text/html; charset=UTF-8&quot;); PrintWriter out = response.getWriter(); ServletContext application = getServletContext(); try { int value = (int)application.getAttribute(&quot;value&quot;); value++; application.setAttribute(&quot;value&quot;, value); out.println(&quot;&lt;h1&gt;value: &quot;+ value + &quot;&lt;/h1&gt;&quot;); }catch(NullPointerException e) { out.print(&quot;valueì˜ ê°’ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.&quot;); } }} applicationScope01.jsp 1234567891011121314151617181920212223242526&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=EUC-KR&quot; pageEncoding=&quot;EUC-KR&quot;%&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;EUC-KR&quot;&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;% try{ int value = (int)application.getAttribute(&quot;value&quot;); value = value + 2; application.setAttribute(&quot;value&quot;, value);%&gt; &lt;h1&gt;&lt;%=value %&gt;&lt;/h1&gt;&lt;% }catch(NullPointerException ex){%&gt; &lt;h1&gt;ì„¤ì •ëœ ê°’ì´ ì—†ìŠµë‹ˆë‹¤.&lt;/h1&gt;&lt;% }%&gt;&lt;/body&gt;&lt;/html&gt; í•´ë‹¹ ì–´í”Œë¦¬ì¼€ì´ì…˜ ì„œë²„ë¥¼ ì¢…ë£Œí–ˆë‹¤ê°€ ë‹¤ì‹œ ì¬ì‹œì‘ í•´ì•¼ì§€ valueê°’ì´ ì´ˆê¸°í™” ë¨Application01ì„ ë¨¼ì € ì‹œì‘í•´ì•¼ì§€ valueê°’ì´ ì´ˆê¸°í™” ë¨ Application scopeëŠ” servletcontextë¼ëŠ” ê°ì²´ë¥¼ ì´ìš©í•´ì„œ ì–»ì–´ë‚¼ ìˆ˜ ìˆë‹¤servletcontextëŠ” getServletContextë¼ëŠ” ë©”ì„œë“œë¡œ ì•Œì•„ë‚¼ ìˆ˜ ìˆë‹¤servletcontextë¼ëŠ” ê°ì²´ê°€ ì‹¤ì œ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ì˜ì—­ìœ¼ë¡œ ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•œê²ƒì´ë‹¤ ê·¸ëŸ¬ë¯€ë¡œ ì‹¤ì œ Servletì´ë‹¤setAttributeì™€ getAttributeëŠ” ë‹¤ë¥¸ scopeì—ì„œë„ ë™ì¼í•˜ê²Œ ì‚¬ìš©í•œë‹¤ try-catch ì‚¬ìš©í•˜ëŠ” ì´ìœ ApplicationScope02ê°€ 01ë³´ë‹¤ ë¨¼ì € ì‹¤í–‰ë˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ê°’ì´ ì—†ê¸° ë•Œë¬¸ì— nullì„ ì¶œë ¥í•œë‹¤ë”°ë¼ì„œ NullpointerException ì²˜ë¦¬ë¥¼ í•´ì¤€ê²ƒì´ë‹¤","link":"/2022/01/03/boostcourse-09-scope/"},{"title":"EL &amp; JSTL | ë¶€ìŠ¤íŠ¸ì½”ìŠ¤ ë°±ì—”ë“œ 10","text":"EL (Expression Language)í‘œí˜„ì–¸ì–´ì´ë‹¤.ê°’ì„ í‘œí˜„í•˜ëŠ”ë° ì‚¬ìš©ë˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ ì–¸ì–´ë¡œì„œ JSPì˜ ê¸°ë³¸ ë¬¸ë²•ì„ ë³´ì™„í•˜ëŠ” ì—­í• ì„ í•œë‹¤JSPì—ì„œ ë‚´ì¥ê°ì²´ë¥¼ ê°€ì§€ê³  ìë°” ì½”ë“œë¥¼ ì´ìš©í•´ì„œë„ ì‚¬ìš©í•  ìˆ˜ ê°€ ìˆê¸´í•¨ ê¸°ëŠ¥JSPì˜ ìŠ¤ì½”í”„(scope)ì— ë§ëŠ” ì†ì„± ì‚¬ìš©ì§‘í•© ê°ì²´ì— ëŒ€í•œ ì ‘ê·¼ ë°©ë²• ì œê³µìˆ˜ì¹˜ ì—°ì‚°, ê´€ê³„ ì—°ì‚°, ë…¼ë¦¬ ì—°ì‚°ì ì œê³µìë°” í´ë˜ìŠ¤ ë©”ì†Œë“œ í˜¸ì¶œ ê¸°ëŠ¥ ì œê³µí‘œí˜„ì–¸ì–´ë§Œì˜ ê¸°ë³¸ ê°ì²´ ì œê³µ ì‚¬ìš©ë²•${expr} ì˜ˆì‹œ Scopeì— ì ìš©í•œ EL í‘œê¸°ë²• ì˜ˆì‹œê°ê°ì˜ ìŠ¤ì½”í”„ì—ë‹¤ê°€ ê°’ì„ ì„¤ì •í•˜ê³ , ì„¤ì •í•œ ê°’ì„ EL ì½”ë“œë¥¼ í†µí•´ì„œ ì¶œë ¥í•´ë³¸ë‹¤ 12345678910111213141516171819202122232425262728293031&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;% pageContext.setAttribute(&quot;p1&quot;, &quot;page scope value&quot;); request.setAttribute(&quot;r1&quot;, &quot;request scope value&quot;); session.setAttribute(&quot;s1&quot;, &quot;session scope value&quot;); application.setAttribute(&quot;a1&quot;, &quot;application scope value&quot;);%&gt; &lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;pageContext.getAttribute(&quot;p1&quot;) : ${pageScope.p1 }&lt;br&gt;request.getAttribute(&quot;r1&quot;) : ${requestScope.r1 }&lt;br&gt;session.getAttribute(&quot;s1&quot;) : ${sessionScope.s1 }&lt;br&gt;application.getAttribute(&quot;a1&quot;) : ${applicationScope.a1 }&lt;br&gt;&lt;br&gt;&lt;br&gt;pageContext.getAttribute(&quot;p1&quot;) : ${p1 }&lt;br&gt; //ë” ì •í™•í•˜ê²Œ ë¶ˆëŸ¬ì˜¨ê²ƒrequest.getAttribute(&quot;r1&quot;) : ${r1 }&lt;br&gt;session.getAttribute(&quot;s1&quot;) : ${s1 }&lt;br&gt;application.getAttribute(&quot;a1&quot;) : ${a1 }&lt;br&gt;&lt;/body&gt;&lt;/html&gt; pageContext.setAttribute(&quot;p1&quot;, &quot;page scope value&quot;); request.setAttribute(&quot;r1&quot;, &quot;request scope value&quot;); session.setAttribute(&quot;s1&quot;, &quot;session scope value&quot;); application.setAttribute(&quot;a1&quot;, &quot;application scope value&quot;); page scope, request scope, session scope, application scopeì— ê°ê°ì˜ ê°’ì„ ì„¤ì •í•˜ì˜€ë‹¤ pageContext.getAttribute(â€œp1â€) : ${pageScope.p1 } request.getAttribute(â€œr1â€) : ${requestScope.r1 } session.getAttribute(â€œs1â€) : ${sessionScope.s1 } application.getAttribute(â€œa1â€) : ${applicationScope.a1 } pageContext.getAttribute(â€œp1â€) : ${p1 } //ë” ì •í™•í•˜ê²Œ ë¶ˆëŸ¬ì˜¨ê²ƒ request.getAttribute(â€œr1â€) : ${r1 } session.getAttribute(â€œs1â€) : ${s1 } application.getAttribute(â€œa1â€) : ${a1 } ì›ë˜ JSPë¡œëŠ” ì•„ë˜ì™€ ê°™ì´ ì¶œë ¥í•  ìˆ˜ ìˆë‹¤pageContext.getAttribute(â€œp1â€) : &lt;%=pageContext.getAttribute(â€œp1â€) %&gt; ê²°ê³¼ê°’ EL í‘œê¸°ë²• ì˜ˆì œ123456789101112131415161718192021222324252627282930313233&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=EUC-KR&quot; pageEncoding=&quot;EUC-KR&quot;%&gt; &lt;%request.setAttribute(&quot;k&quot;, 10); request.setAttribute(&quot;m&quot;, true);%&gt; &lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;EUC-KR&quot;&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;k : ${k } &lt;br&gt;k + 5 : ${k + 5} &lt;br&gt;k - 5 : ${k - 5} &lt;br&gt;k * 5 : ${k * 5} &lt;br&gt;k / 5 : ${ k div 5 } &lt;br&gt;k : ${k} &lt;br&gt;m : m{m} &lt;br&gt;k &gt; 5 : ${ k &gt; 5 } &lt;br&gt;k &lt; 5 : ${ k &lt; 5 } &lt;br&gt;k &lt;= 10 : ${ k &lt;= 10} &lt;br&gt;k &gt;= 10 : ${ k &gt;= 10 } &lt;br&gt;m : ${ m } &lt;br&gt;!m : ${ !m } &lt;br&gt;&lt;/body&gt;&lt;/html&gt; ìœ„ì˜ ì½”ë“œì—ì„œ ë§¨ ìœ„ì— &lt;%@ page isELIgnored = â€œtrueâ€ %&gt; ë¥¼ ì¶”ê°€í•˜ê²Œ ë˜ë©´ELì½”ë“œê°€ ë¬´ì‹œë˜ì–´ì„œ htmlë¡œ ì¶œë ¥ëœë‹¤ JSTL (JSP Standard Tag Library)JSTLì€ JSP í˜ì´ì§€ì—ì„œ ì¡°ê±´ë¬¸ ì²˜ë¦¬, ë°˜ë³µë¬¸ ì²˜ë¦¬ ë“±ì„ html tagí˜•íƒœë¡œ ì‘ì„±í•  ìˆ˜ ìˆê²Œ ë„ì™€ì¤ë‹ˆë‹¤.ë‚´ê°€ ì§ì ‘ íƒœê·¸ë¥¼ ë§Œë“œëŠ” ê²ƒë„ ê°€ëŠ¥í•˜ë‹¤JSPëŠ” javaì½”ë“œì™€ html ì´ ì„ì—¬ìˆì–´ì„œ í”„ë¡ íŠ¸ ê°œë°œìê°€ ì‘ì—…ì„ í•˜ê¸°ê°€ í˜ë“¤ì—ˆë‹¤ -&gt; ìœ ì§€ë³´ìˆ˜ê°€ ì–´ë ¤ì›€-&gt; ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ JSTLì´ ë‚˜ì™”ë‹¤ JSTL ì‚¬ìš©ë²•http://tomcat.apache.org/download-taglibs.cgi ìœ„ì˜ ì‚¬ì´íŠ¸ì—ì„œ ì•„ë˜ì˜ ì„¸ê°€ì§€ ì½”ë“œë¥¼ ë‹¤ìš´ë°›ì•„C:\\Users\\jiwon\\eclipse-workspace\\firstweb\\WebContent\\WEB-INF\\lib ê²½ë¡œì— ë„£ì–´ì£¼ì—ˆë‹¤ JSTL ì˜ˆì œ 12345678910111213141516171819202122&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;%@ taglib prefix=&quot;c&quot; uri=&quot;http://java.sun.com/jsp/jstl/core&quot; %&gt; &lt;c:set var=&quot;value1&quot; scope=&quot;request&quot; value=&quot;kang&quot;/&gt;&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;ì„± : ${value1} &lt;br&gt;&lt;c:remove var=&quot;value1&quot; scope=&quot;request&quot;/&gt;ì„± : ${value1 }&lt;/body&gt;&lt;/html&gt; &lt;%@ taglib prefix=â€câ€ uri=â€http://java.sun.com/jsp/jstl/core&quot; %&gt;-&gt; JSTL ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©ì„ ì•Œë ¤ì¤Œ ë³€ìˆ˜ì§€ì› íƒœê·¸ íë¦„ì œì–´ íƒœê·¸ -if 1234567891011121314151617181920212223&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot;pageEncoding=&quot;UTF-8&quot;%&gt;&lt;%@ taglib prefix=&quot;c&quot; uri=&quot;http://java.sun.com/jsp/jstl/core&quot; %&gt; &lt;%request.setAttribute(&quot;n&quot;, 10);%&gt;&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;c:if test=&quot;${n == 0}&quot;&gt;nì€ ê³¼ 0ê³¼ ê°™ìŠµë‹ˆë‹¤.&lt;/c:if&gt;&lt;c:if test=&quot;${n == 10}&quot;&gt;nì€ ê³¼ 10ê³¼ ê°™ìŠµë‹ˆë‹¤.&lt;/c:if&gt;&lt;/body&gt;&lt;/html&gt; ###íë¦„ì œì–´ íƒœê·¸ -choose 12345678910111213141516171819202122232425262728293031323334&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;%@ taglib prefix=&quot;c&quot; uri=&quot;http://java.sun.com/jsp/jstl/core&quot; %&gt; &lt;%@ page import=&quot;java.util.*&quot; %&gt;&lt;% request.setAttribute(&quot;score&quot;, 83);%&gt;&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;c:choose&gt; &lt;c:when test=&quot;${score &gt;=90 }&quot;&gt; Aí•™ì ì…ë‹ˆë‹¤. &lt;/c:when&gt; &lt;c:when test=&quot;${score &gt;=80 }&quot;&gt; Bí•™ì ì…ë‹ˆë‹¤. &lt;/c:when&gt; &lt;c:when test=&quot;${score &gt;=70 }&quot;&gt; Cí•™ì ì…ë‹ˆë‹¤. &lt;/c:when&gt; &lt;c:when test=&quot;${score &gt;=60 }&quot;&gt; Dí•™ì ì…ë‹ˆë‹¤. &lt;/c:when&gt; &lt;c:otherwise&gt; Fí•™ì ì…ë‹ˆë‹¤. &lt;/c:otherwise&gt; &lt;/c:choose&gt;&lt;/body&gt;&lt;/html&gt; ###íë¦„ì œì–´ íƒœê·¸- forEach 123456789101112131415161718192021222324&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;%@ taglib prefix=&quot;c&quot; uri=&quot;http://java.sun.com/jsp/jstl/core&quot; %&gt; &lt;%@ page import=&quot;java.util.*&quot; %&gt;&lt;% List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(&quot;hello&quot;); list.add(&quot;world&quot;); list.add(&quot;!!!&quot;); request.setAttribute(&quot;list&quot;, list);%&gt;&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;c:forEach items=&quot;${list}&quot; var=&quot;item&quot;&gt;${item } &lt;br&gt;&lt;/c:forEach&gt;&lt;/body&gt;&lt;/html&gt; ###íë¦„ì œì–´íƒœê·¸ - import ì•„ë˜ì˜ˆì œjstlValue.jsp 123&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;Kang kyungmi jstl05.jsp 1234567891011121314151617&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;%@ taglib prefix=&quot;c&quot; uri=&quot;http://java.sun.com/jsp/jstl/core&quot; %&gt; &lt;%@ page import=&quot;java.util.*&quot; %&gt;&lt;c:import url=&quot;http://localhost:8080/webapp/jstlValue.jsp&quot; var=&quot;urlValue&quot; scope=&quot;request&quot;&gt;&lt;/c:import&gt;&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;ì½ì–´ë“¤ì¸ ê°’ : ${urlValue}&lt;/body&gt;&lt;/html&gt; íë¦„ì œì–´ íƒœê·¸ - redirect jtl06.jsp 1234&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;%@ taglib prefix=&quot;c&quot; uri=&quot;http://java.sun.com/jsp/jstl/core&quot; %&gt; &lt;c:redirect url=&quot;jstlRedirectPage.jsp&quot;&gt;&lt;/c:redirect&gt; jstlRedirectPage.jsp 123456789101112&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt; redirectëœ í™”ë©´ì…ë‹ˆë‹¤.&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; ê¸°íƒ€íƒœê·¸-out 1234567891011121314151617&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;%@ taglib prefix=&quot;c&quot; uri=&quot;http://java.sun.com/jsp/jstl/core&quot; %&gt;&lt;%@ taglib prefix=&quot;fn&quot; uri=&quot;http://java.sun.com/jsp/jstl/functions&quot;%&gt; &lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;c:set var=&quot;t&quot; value=&quot;&lt;script type='text/javascript'&gt;alert(1);&lt;/script&gt;&quot; /&gt;${t}&lt;c:out value=&quot;${t}&quot; escapeXml=&quot;true&quot; /&gt;&lt;c:out value=&quot;${t}&quot; escapeXml=&quot;false&quot; /&gt;&lt;/body&gt;&lt;/html&gt;","link":"/2022/01/03/boostcourse-10-jstl-el/"}],"tags":[{"name":"Node.js","slug":"Node-js","link":"/tags/Node-js/"},{"name":"kaggle, plotly","slug":"kaggle-plotly","link":"/tags/kaggle-plotly/"},{"name":"github, hexo","slug":"github-hexo","link":"/tags/github-hexo/"},{"name":"python, coding, study","slug":"python-coding-study","link":"/tags/python-coding-study/"},{"name":"markdown, python, pycharm, numpy","slug":"markdown-python-pycharm-numpy","link":"/tags/markdown-python-pycharm-numpy/"},{"name":"markdown, python, pycharm","slug":"markdown-python-pycharm","link":"/tags/markdown-python-pycharm/"},{"name":"markdown, python, pycharm, pandas","slug":"markdown-python-pycharm-pandas","link":"/tags/markdown-python-pycharm-pandas/"},{"name":"markdown, python, pycharm, visualization","slug":"markdown-python-pycharm-visualization","link":"/tags/markdown-python-pycharm-visualization/"},{"name":"machine learning, decision tree","slug":"machine-learning-decision-tree","link":"/tags/machine-learning-decision-tree/"},{"name":"python, Heroku, Dashboard","slug":"python-Heroku-Dashboard","link":"/tags/python-Heroku-Dashboard/"},{"name":"kaggle, plotly, pie, bar","slug":"kaggle-plotly-pie-bar","link":"/tags/kaggle-plotly-pie-bar/"},{"name":"python, pandas","slug":"python-pandas","link":"/tags/python-pandas/"},{"name":"plotly, bar graph, bar","slug":"plotly-bar-graph-bar","link":"/tags/plotly-bar-graph-bar/"},{"name":"plotly, heatmap graph, heatmap, subplot","slug":"plotly-heatmap-graph-heatmap-subplot","link":"/tags/plotly-heatmap-graph-heatmap-subplot/"},{"name":"plotly, pie graph, pie, sunburst","slug":"plotly-pie-graph-pie-sunburst","link":"/tags/plotly-pie-graph-pie-sunburst/"},{"name":"plotly, pie graph, pie, subplot","slug":"plotly-pie-graph-pie-subplot","link":"/tags/plotly-pie-graph-pie-subplot/"},{"name":"python, requirements.txt","slug":"python-requirements-txt","link":"/tags/python-requirements-txt/"},{"name":"python, list","slug":"python-list","link":"/tags/python-list/"},{"name":"python, tuple","slug":"python-tuple","link":"/tags/python-tuple/"},{"name":"python, dictionary","slug":"python-dictionary","link":"/tags/python-dictionary/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"python, set","slug":"python-set","link":"/tags/python-set/"},{"name":"tomcat, eclipse, oracle","slug":"tomcat-eclipse-oracle","link":"/tags/tomcat-eclipse-oracle/"},{"name":"database","slug":"database","link":"/tags/database/"},{"name":"tomcat","slug":"tomcat","link":"/tags/tomcat/"},{"name":"servlet, jsp","slug":"servlet-jsp","link":"/tags/servlet-jsp/"},{"name":"scope","slug":"scope","link":"/tags/scope/"},{"name":"servlet, web.xml","slug":"servlet-web-xml","link":"/tags/servlet-web-xml/"},{"name":"JSTL, EL","slug":"JSTL-EL","link":"/tags/JSTL-EL/"},{"name":"mac, macbook","slug":"mac-macbook","link":"/tags/mac-macbook/"}],"categories":[{"name":"Blog setting","slug":"Blog-setting","link":"/categories/Blog-setting/"},{"name":"First Post","slug":"First-Post","link":"/categories/First-Post/"},{"name":"Hexo","slug":"Blog-setting/Hexo","link":"/categories/Blog-setting/Hexo/"},{"name":"íŒŒì´ì¬","slug":"íŒŒì´ì¬","link":"/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/"},{"name":"ë¨¸ì‹ ëŸ¬ë‹","slug":"ë¨¸ì‹ ëŸ¬ë‹","link":"/categories/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/"},{"name":"kaggle í•„ì‚¬","slug":"kaggle-í•„ì‚¬","link":"/categories/kaggle-%ED%95%84%EC%82%AC/"},{"name":"Python ê¸°ì´ˆ","slug":"íŒŒì´ì¬/Python-ê¸°ì´ˆ","link":"/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/Python-%EA%B8%B0%EC%B4%88/"},{"name":"Project","slug":"Project","link":"/categories/Project/"},{"name":"Python Setting","slug":"íŒŒì´ì¬/Python-Setting","link":"/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/Python-Setting/"},{"name":"Python Pandas","slug":"íŒŒì´ì¬/Python-Pandas","link":"/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/Python-Pandas/"},{"name":"Python Visualization","slug":"íŒŒì´ì¬/Python-Visualization","link":"/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/Python-Visualization/"},{"name":"Python Plotly","slug":"íŒŒì´ì¬/Python-Plotly","link":"/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/Python-Plotly/"},{"name":"Python heroku","slug":"íŒŒì´ì¬/Python-heroku","link":"/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/Python-heroku/"},{"name":"Kaggle Competition","slug":"Project/Kaggle-Competition","link":"/categories/Project/Kaggle-Competition/"},{"name":"boostcourse ë°±ì—”ë“œ","slug":"boostcourse-ë°±ì—”ë“œ","link":"/categories/boostcourse-%EB%B0%B1%EC%97%94%EB%93%9C/"},{"name":"ë¶€ìŠ¤íŠ¸ì½”ìŠ¤ ë°±ì—”ë“œ","slug":"ë¶€ìŠ¤íŠ¸ì½”ìŠ¤-ë°±ì—”ë“œ","link":"/categories/%EB%B6%80%EC%8A%A4%ED%8A%B8%EC%BD%94%EC%8A%A4-%EB%B0%B1%EC%97%94%EB%93%9C/"},{"name":"ë§¥ë¶","slug":"ë§¥ë¶","link":"/categories/%EB%A7%A5%EB%B6%81/"}]}